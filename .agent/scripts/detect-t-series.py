#!/usr/bin/env python3
"""
T-series ç™ºå‹•æ¤œçŸ¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
===========================

ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‹ã‚‰ [Hegemonikon] T{N} ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã€
dispatch_log.yaml ã«è‡ªå‹•è¿½è¨˜ã™ã‚‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    python detect-t-series.py                           # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    python detect-t-series.py <markdown_file>           # ç‰¹å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    python detect-t-series.py --scan-dir <directory>    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³

æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³:
    [Hegemonikon] T1 AisthÄ“sis
    [Hegemonikon] T2 Krisis
    [Hegemonikon] O2 BoulÄ“sis
    etc.
"""

import re
import sys
import yaml
import argparse
from pathlib import Path
from datetime import datetime
from collections import defaultdict

# Windows stdout UTF-8å¯¾ç­–
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')

# ãƒ‘ã‚¹è¨­å®š
DISPATCH_LOG = Path(r"M:\Brain\.hegemonikon\logs\dispatch_log.yaml")
SESSIONS_DIR = Path(r"M:\Brain\.hegemonikon\sessions")

# T-series/O-series ç™ºå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³
HEGEMONIKON_PATTERN = re.compile(
    r'\[Hegemonikon\]\s*([TO])(\d)\s*(\w+)?',
    re.IGNORECASE
)

# è©³ç´°ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå…¥åŠ›/åˆ¤æ–­/å‡ºåŠ›ã‚’å«ã‚€ï¼‰
DETAIL_PATTERN = re.compile(
    r'\[Hegemonikon\]\s*([TO])(\d)\s*(\w+)?\s*\n\s*(?:å…¥åŠ›|input):\s*(.+?)(?:\n|$)',
    re.IGNORECASE | re.DOTALL
)

# T-seriesåãƒãƒƒãƒ”ãƒ³ã‚°
T_SERIES_NAMES = {
    "T1": "AisthÄ“sis",
    "T2": "Krisis",
    "T3": "TheÅria",
    "T4": "PhronÄ“sis",
    "T5": "Peira",
    "T6": "Praxis",
    "T7": "DokimÄ“",
    "T8": "AnamnÄ“sis",
}

O_SERIES_NAMES = {
    "O1": "NoÄ“sis",
    "O2": "BoulÄ“sis",
    "O3": "ZÄ“tÄ“sis",
    "O4": "Energeia",
}

def load_dispatch_log() -> dict:
    """æ—¢å­˜ã®ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿"""
    if not DISPATCH_LOG.exists():
        return {"version": "1.0.0", "created": datetime.now().isoformat(), "entries": []}
    
    with open(DISPATCH_LOG, "r", encoding="utf-8") as f:
        content = f.read()
        # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã‚’é™¤å»ã—ã¦ãƒ‘ãƒ¼ã‚¹
        lines = [line for line in content.split("\n") if not line.strip().startswith("#")]
        return yaml.safe_load("\n".join(lines)) or {"entries": []}

def save_dispatch_log(data: dict, stats: dict):
    """ãƒ­ã‚°ã‚’ä¿å­˜ï¼ˆçµ±è¨ˆã‚³ãƒ¡ãƒ³ãƒˆä»˜ãï¼‰"""
    DISPATCH_LOG.parent.mkdir(parents=True, exist_ok=True)
    
    with open(DISPATCH_LOG, "w", encoding="utf-8") as f:
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        f.write("# Dispatch Log\n")
        f.write("# HegemonikÃ³n Phase Bç§»è¡Œåˆ¤å®šç”¨ã®é‹ç”¨ãƒ­ã‚°\n")
        f.write(f"# é–¾å€¤: dispatch_count >= 50, failure_rate < 10%, exception_patterns >= 3\n\n")
        
        # ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†
        yaml.dump(data, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
        
        # çµ±è¨ˆã‚³ãƒ¡ãƒ³ãƒˆ
        f.write(f"\n# === çµ±è¨ˆã‚µãƒãƒªãƒ¼ ===\n")
        f.write(f"# dispatch_count: {stats['total']}\n")
        f.write(f"# success_count: {stats['success']}\n")
        f.write(f"# failure_count: {stats['failure']}\n")
        f.write(f"# failure_rate: {stats['failure_rate']}%\n")
        f.write(f"# exception_patterns: {stats['exceptions']}\n")
        f.write(f"# Phase Bç§»è¡Œ: {'é”æˆ' if stats['phase_b'] else 'æœªé”æˆ'} ({stats['total']}/50)\n")

def detect_t_series(content: str) -> list:
    """T-series/O-series ç™ºå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º"""
    detections = []
    
    for match in HEGEMONIKON_PATTERN.finditer(content):
        series_type = match.group(1).upper()  # T or O
        series_num = match.group(2)
        series_name = match.group(3) or ""
        
        series_id = f"{series_type}{series_num}"
        
        # æ­£å¼åã‚’å–å¾—
        if series_type == "T":
            official_name = T_SERIES_NAMES.get(series_id, series_name)
        else:
            official_name = O_SERIES_NAMES.get(series_id, series_name)
        
        # å‰å¾Œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ï¼ˆ50æ–‡å­—ï¼‰
        start = max(0, match.start() - 50)
        end = min(len(content), match.end() + 100)
        context = content[start:end].replace("\n", " ").strip()
        
        detections.append({
            "series_id": series_id,
            "series_type": "t_series" if series_type == "T" else "o_series",
            "name": official_name,
            "context": context[:150],
            "position": match.start()
        })
    
    return detections

def detection_to_dispatch_entry(detection: dict, source_file: str, existing_ids: set) -> dict:
    """æ¤œå‡ºçµæœã‚’dispatch_logå½¢å¼ã«å¤‰æ›"""
    today = datetime.now().strftime("%Y%m%d")
    
    # æ—¢å­˜IDã¨ã®é‡è¤‡ã‚’é¿ã‘ãªãŒã‚‰æ–°IDã‚’ç”Ÿæˆ
    counter = 1
    while True:
        new_id = f"HGK-{today}-{str(counter).zfill(3)}"
        if new_id not in existing_ids:
            break
        counter += 1
    
    existing_ids.add(new_id)
    
    # source_agentã¨target_agentã‚’æ¨æ¸¬
    # T-seriesç™ºå‹•ã¯Claudeå†…éƒ¨ã®å‡¦ç†ãªã®ã§ã€ä¸¡æ–¹claude_antigravityã¨ã™ã‚‹
    source_agent = "claude_antigravity"
    target_agent = "claude_antigravity"
    
    # T5, O3 ã¯å¤–éƒ¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¸ã®å§”è­²ã‚’ç¤ºå”†
    if detection["series_id"] in ["T5", "O3"]:
        target_agent = "perplexity"
    elif detection["series_id"] in ["T6", "O4"]:
        target_agent = "local_filesystem"
    
    return {
        "id": new_id,
        "timestamp": datetime.now().isoformat(),
        "t_series": detection["series_id"] if detection["series_type"] == "t_series" else None,
        "o_series": detection["series_id"] if detection["series_type"] == "o_series" else None,
        "source_agent": source_agent,
        "target_agent": target_agent,
        "task": f"{detection['series_id']} {detection['name']} ç™ºå‹•",
        "status": "success",
        "duration_ms": None,
        "exception": None,
        "notes": f"Auto-detected from {source_file}: {detection['context'][:80]}..."
    }

def process_file(filepath: Path, existing_ids: set) -> list:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã€T-seriesç™ºå‹•ã‚’æ¤œå‡º"""
    if not filepath.exists():
        print(f"âŒ File not found: {filepath}")
        return []
    
    content = filepath.read_text(encoding="utf-8")
    detections = detect_t_series(content)
    
    if not detections:
        print(f"ğŸ“„ No T-series detections in {filepath.name}")
        return []
    
    entries = []
    for detection in detections:
        entry = detection_to_dispatch_entry(detection, filepath.name, existing_ids)
        entries.append(entry)
        print(f"âœ… Detected: {detection['series_id']} {detection['name']}")
    
    return entries

def get_latest_session_file() -> Path:
    """æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
    if not SESSIONS_DIR.exists():
        return None
    
    md_files = list(SESSIONS_DIR.glob("*.md"))
    if not md_files:
        return None
    
    # æ›´æ–°æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆ
    md_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return md_files[0]

def main():
    parser = argparse.ArgumentParser(description="Detect T-series activations and record to dispatch log")
    parser.add_argument("file", nargs="?", help="Markdown file to process")
    parser.add_argument("--scan-dir", "-d", help="Directory to scan for markdown files")
    parser.add_argument("--pattern", "-p", default="*.md", help="File pattern for scanning")
    parser.add_argument("--dry-run", action="store_true", help="Detect only, don't write to log")
    
    args = parser.parse_args()
    
    # æ—¢å­˜ãƒ­ã‚°èª­ã¿è¾¼ã¿
    log_data = load_dispatch_log()
    entries = log_data.get("entries", [])
    existing_ids = set(e.get("id", "") for e in entries)
    
    new_entries = []
    
    if args.scan_dir:
        directory = Path(args.scan_dir)
        if not directory.exists():
            print(f"âŒ Directory not found: {directory}")
            return 1
        
        for filepath in directory.rglob(args.pattern):
            new_entries.extend(process_file(filepath, existing_ids))
            
    elif args.file:
        new_entries = process_file(Path(args.file), existing_ids)
        
    else:
        # æœ€æ–°ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        latest = get_latest_session_file()
        if latest:
            print(f"ğŸ“„ Processing latest session: {latest.name}")
            new_entries = process_file(latest, existing_ids)
        else:
            print("âŒ No session files found")
            return 1
    
    if not new_entries:
        print("\nğŸ“Š No new T-series detections")
        return 0
    
    print(f"\nğŸ¯ Detected {len(new_entries)} T-series activations")
    
    if args.dry_run:
        print("ğŸ” Dry run - not writing to log")
        return 0
    
    # ãƒ­ã‚°ã«è¿½åŠ 
    entries.extend(new_entries)
    log_data["entries"] = entries
    
    # çµ±è¨ˆè¨ˆç®—
    total = len(entries)
    success = sum(1 for e in entries if e.get("status") == "success")
    failure = total - success
    exceptions = len(set(e.get("exception") for e in entries if e.get("exception")))
    
    stats = {
        "total": total,
        "success": success,
        "failure": failure,
        "failure_rate": round(failure / total * 100, 1) if total > 0 else 0,
        "exceptions": exceptions,
        "phase_b": total >= 50 and (failure / total * 100 if total > 0 else 0) < 10 and exceptions >= 3
    }
    
    save_dispatch_log(log_data, stats)
    print(f"\nğŸ“Š Total dispatches: {total}/50 ({round(total/50*100, 1)}%)")
    
    return 0

if __name__ == "__main__":
    exit(main())
