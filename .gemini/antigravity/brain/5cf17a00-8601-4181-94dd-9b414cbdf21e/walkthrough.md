# Walkthrough: Hermeneus LLM 実行と Synteleia + LLM 統合

**セッション**: 2026-02-01
**主題**: Hermeneus の LLM 実行を有効化し、Synteleia + LLM の統合分析を実現

---

## 🎯 目標

Hermeneus を「CCL コンパイラ」から「実用的な LLM 実行エンジン」へ進化させる

---

## ✅ 完了した作業

### 1. 環境セットアップ

- `hermeneus/.env` に Google API Key を永続化
- `runtime.py` に dotenv 自動読み込みを追加
- Gemini 3 Pro Preview で動作確認

### 2. Synergeia + Hermeneus 統合

- `coordinator.py` に `hermeneus_execute` をインポート
- `execute_hermeneus` で LLM 実行を有効化
- PYTHONPATH 自動設定を追加

### 3. Context Passing 問題修正

**問題**: Gemini が「エアプ」出力をしていた

**原因**: `_extract_prompt_from_lmql` が `{context}` プレースホルダーを抽出しない

**修正**: `_execute_fallback` で context を常にプロンプト先頭に明示的に追加

render_diffs(file:///home/makaron8426/oikos/hegemonikon/hermeneus/src/runtime.py)

### 4. Synteleia + LLM 統合分析

**発見**: 裸の API 呼び出しは「エアプ」を生成する

**解決**: Synteleia で実コードを監査 → Issue 詳細を LLM に渡す → 具体的な分析が得られる

| アプローチ | 品質 | コスト |
|:-----------|:-----|:-------|
| 裸の API | ❌ エアプ | 無駄 |
| Synteleia 単体 | ✅ 具体的 | 無料 |
| **Synteleia + LLM** | ✅✅ 最強 | ~3円 |

### 5. Synteleia Monitor 実装

`execute_hermeneus` に Synteleia 監査結果を自動追加する機能を実装

render_diffs(file:///home/makaron8426/oikos/hegemonikon/synergeia/coordinator.py)

---

## 📊 検証結果

### Gemini 出力比較

| 条件 | 出力例 |
|:-----|:-------|
| コンテキストなし | 「SOTAモデル統合が強み」(汎用的) |
| Synteleia 監査付き | 「Hermeneus 12 Issues がボトルネック」(具体的) |
| Issue 詳細付き | 「S-030: 115行関数を分割せよ」(実行可能) |

### テスト結果

```
hermeneus/tests/test_optimizer.py::8 passed in 1.68s
```

---

## 💡 学んだこと

> **API のコストではなく、コンテキストの濃度が価値を決める**

- 3円払っても「エアプ」なら価値はゼロ
- 3円払って「実用的な Issue 詳細分析」なら価値は高い
- **Synteleia + LLM の組み合わせが最もコスパ良い**

---

## 📈 API 使用量

| 項目 | 値 |
|:-----|:---|
| Input tokens | ~6,800 |
| Output tokens | ~11,000 |
| 合計コスト | 約 3円 ($0.02) |

---

*Generated by Hegemonikón H4 Doxa*
