# 調査依頼書: S3 Stathmos (Baseline Calibrator) 設計

## Step 0: 目的確認

> **決定事項**: LLM がタスクの評価基準・ベンチマークを自動設定するフレームワーク設計
> **仮説**: 品質管理・ソフトウェアメトリクスの知見が LLM 自己評価に適用可能

---

## 【出力形式】

構造化テーブル（4列: 手法名, 概要, 適用場面, 情報源）を返す。
その後、3-5文の実装推奨を technical トーンで記述。

---

## 【調査目的】

AI エージェントがタスクに取り組む際、「何を基準に成功と判断するか」を自動設定したい:

- **明示的基準**: ユーザーが定義した成功条件
- **暗黙的基準**: ドメイン標準、ベストプラクティス
- **動的基準**: タスク進行に応じて変化する基準

---

## 【時間制約】

- **採用範囲**: 過去12ヶ月以内（2025年〜2026年）
- **歴史的参考**: 品質管理理論、測定理論は時間制約なし

---

## 【質問】

1. **評価基準設定手法**: ソフトウェア品質や AI 出力評価の基準設定フレームワークは？
2. **LLM 自己評価**: LLM が自身の出力品質を評価する手法（Self-Evaluation, Constitutional AI）は？
3. **ベンチマーク動的調整**: タスク進行に応じて基準を調整する手法は？
4. **曖昧な要件の明確化**: ユーザー要件が不明確な場合の基準推定手法は？
5. **プロンプト組込み例**: 評価基準を構造化したプロンプト設計は？

---

## 【調査対象の定義】

- **Baseline**: 最低限の成功基準
- **Benchmark**: 比較対象となる標準
- **Calibration**: 基準の動的調整

---

*Generated by /zet v2.3 — O3 Zētēsis*
