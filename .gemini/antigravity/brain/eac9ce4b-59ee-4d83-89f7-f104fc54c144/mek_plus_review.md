# ccl/mek+ ç²¾æŸ»ãƒ¬ãƒãƒ¼ãƒˆ: è»¸ A/B/C å®Ÿè£…

> **æ—¥ä»˜**: 2026-01-31
> **å¯¾è±¡**: ã€Œç¶™ç¶šã™ã‚‹ç§ã€3è»¸å®Ÿè£…
> **ãƒ¢ãƒ¼ãƒ‰**: mek+ ï¼ˆè©³ç´°ç²¾æŸ»ã€çœç•¥ãªã—ï¼‰

---

## ç²¾æŸ»å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | è¡Œæ•° | è»¸ |
|:---------|:-----|:---|
| `handoff_search.py` | 191 | A: Handoff æ´»ç”¨å¼·åŒ– |
| `sophia_ingest.py` | 284 | B: Sophia ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ |
| `persona.py` | 212 | C: äººæ ¼æ°¸ç¶šåŒ– |
| `boot_integration.py` | 110 | çµ±åˆ API |
| **åˆè¨ˆ** | **797** | |

---

## è»¸ A: Handoff æ´»ç”¨å¼·åŒ– (`handoff_search.py`)

### æ¦‚è¦

| é …ç›® | å†…å®¹ |
|:-----|:-----|
| ç›®çš„ | /boot æ™‚ã«é–¢é€£ Handoff ã‚’æ¤œç´¢ |
| PROOF | `[L2/ã‚¤ãƒ³ãƒ•ãƒ©] A0â†’çŸ¥è­˜ç®¡ç†ãŒå¿…è¦â†’handoff_search ãŒæ‹…ã†` |
| ä¾å­˜ | `kairos_ingest`, `embedding_adapter`, `indices` |

### é–¢æ•°ä¸€è¦§

| é–¢æ•° | è¡Œæ•° | ç”¨é€” |
|:-----|:-----|:-----|
| `load_handoffs()` | 25-28 | å…¨ Handoff ã‚’ Document ã¨ã—ã¦èª­è¾¼ |
| `search_handoffs(query, top_k)` | 31-60 | ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ |
| `get_boot_handoffs(mode, context)` | 63-107 | **/boot çµ±åˆ API** |
| `format_boot_output(result, verbose)` | 110-132 | å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ |
| `show_latest(n)` | 135-144 | æœ€æ–° N ä»¶è¡¨ç¤º |
| `main()` | 147-186 | CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ |

### è©³ç´°åˆ†æ

#### `load_handoffs()` (L25-28)

```python
def load_handoffs() -> List[Document]:
    """Load all handoffs as documents."""
    files = get_handoff_files()
    return [parse_handoff(f) for f in files]
```

**è©•ä¾¡**:

- âœ… ã‚·ãƒ³ãƒ—ãƒ«ã§æ˜ç¢º
- âš ï¸ `get_handoff_files()` ã®è¿”ã‚Šå€¤ãŒã‚½ãƒ¼ãƒˆé †ä¸æ˜
- âš ï¸ å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«æ™‚ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡

**æ”¹å–„æ¡ˆ**:

```python
def load_handoffs(limit: int = None) -> List[Document]:
    """Load handoffs as documents, optionally limited."""
    files = get_handoff_files()[:limit] if limit else get_handoff_files()
    return [parse_handoff(f) for f in files]
```

---

#### `search_handoffs(query, top_k)` (L31-60)

```python
def search_handoffs(query: str, top_k: int = 5) -> List[Tuple[Document, float]]:
    """Search handoffs by semantic similarity."""
    docs = load_handoffs()
    if not docs:
        return []
    
    # Initialize embedding adapter
    adapter = EmbeddingAdapter(model_name="all-MiniLM-L6-v2")
    
    # Encode all docs
    texts = [d.content for d in docs]
    doc_vectors = adapter.encode(texts)
    
    # Create index and add vectors
    adapter.create_index(dimension=doc_vectors.shape[1])
    metadata = [{"doc_id": d.id, "primary_task": d.metadata.get("primary_task", "")} for d in docs]
    adapter.add_vectors(doc_vectors, metadata=metadata)
    
    # Search
    query_vector = adapter.encode([query])[0]
    results = adapter.search(query_vector, k=top_k)
    
    # Match results to docs
    matched = []
    for r in results:
        idx = r.id
        if idx < len(docs):
            matched.append((docs[idx], r.score))
    
    return matched
```

**è©•ä¾¡**:

- âœ… ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ãŒå‹•ä½œ
- âš ï¸ **æ¯å›å…¨ Handoff ã‚’å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰**ï¼ˆéåŠ¹ç‡ï¼‰
- âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ°¸ç¶šåŒ–ã•ã‚Œã¦ã„ãªã„
- âš ï¸ ãƒ¢ãƒ‡ãƒ«åãŒãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰

**æ”¹å–„æ¡ˆ**:

```python
# æ°¸ç¶šåŒ–ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨
HANDOFF_INDEX_PATH = Path("/home/makaron8426/oikos/mneme/.hegemonikon/indices/handoffs.pkl")

def search_handoffs(query: str, top_k: int = 5) -> List[Tuple[Document, float]]:
    """Search handoffs by semantic similarity using cached index."""
    if HANDOFF_INDEX_PATH.exists():
        adapter = load_handoff_index()
    else:
        adapter = build_handoff_index()  # åˆå›ã®ã¿ãƒ“ãƒ«ãƒ‰
    ...
```

---

#### `get_boot_handoffs(mode, context)` (L63-107)

```python
def get_boot_handoffs(mode: str = "standard", context: str = None) -> dict:
    """
    /boot çµ±åˆ API: ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸ Handoff ã‚’è¿”ã™
    
    Args:
        mode: "fast" (/boot-), "standard" (/boot), "detailed" (/boot+)
        context: ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ¤œç´¢ã‚¯ã‚¨ãƒªã«ä½¿ç”¨ï¼‰
    
    Returns:
        dict: {
            "latest": Document,           # æœ€æ–°ã® Handoff
            "related": List[Document],    # é–¢é€£ã™ã‚‹ Handoff
            "count": int                  # é–¢é€£ä»¶æ•°
        }
    """
    # ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã‚‹é–¢é€£ä»¶æ•°
    related_count = {
        "fast": 0,       # /boot- : æœ€æ–°ã®ã¿
        "standard": 3,   # /boot  : æœ€æ–° + é–¢é€£ 3
        "detailed": 10   # /boot+ : æœ€æ–° + é–¢é€£ 10
    }.get(mode, 3)
    
    docs = load_handoffs()
    if not docs:
        return {"latest": None, "related": [], "count": 0}
    
    latest = docs[0]
    
    # é–¢é€£æ¤œç´¢
    related = []
    if related_count > 0 and context:
        results = search_handoffs(context, top_k=related_count + 1)
        # æœ€æ–°ã‚’é™¤å¤–
        related = [doc for doc, score in results if doc.id != latest.id][:related_count]
    elif related_count > 0:
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ã®å ´åˆã¯æœ€æ–°ã‹ã‚‰æŠ½å‡º
        query = latest.metadata.get("primary_task", latest.content[:200])
        results = search_handoffs(query, top_k=related_count + 1)
        related = [doc for doc, score in results if doc.id != latest.id][:related_count]
    
    return {
        "latest": latest,
        "related": related,
        "count": len(related)
    }
```

**è©•ä¾¡**:

- âœ… 3ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œãŒæ˜ç¢º
- âœ… ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæœ‰ç„¡ã§åˆ†å²
- âš ï¸ `docs[0]` ãŒæœ€æ–°ã§ã‚ã‚‹ä¿è¨¼ãŒãªã„ï¼ˆã‚½ãƒ¼ãƒˆä¾å­˜ï¼‰
- âš ï¸ `load_handoffs()` ãŒ2å›å‘¼ã°ã‚Œã‚‹å¯èƒ½æ€§ï¼ˆL85, L94å†…ã§å†åº¦ï¼‰

**æ”¹å–„æ¡ˆ**:

```python
# docs ã‚’å¼•æ•°ã§æ¸¡ã—ã¦å†èª­ã¿è¾¼ã¿å›é¿
def get_boot_handoffs(mode: str = "standard", context: str = None) -> dict:
    docs = load_handoffs()
    if not docs:
        return {"latest": None, "related": [], "count": 0}
    
    # æ˜ç¤ºçš„ã«ã‚½ãƒ¼ãƒˆ
    docs = sorted(docs, key=lambda d: d.metadata.get("timestamp", ""), reverse=True)
    latest = docs[0]
    ...
```

---

#### `format_boot_output(result, verbose)` (L110-132)

```python
def format_boot_output(result: dict, verbose: bool = False) -> str:
    """
    /boot ç”¨ã®å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    """
    lines = []
    
    if result["latest"]:
        doc = result["latest"]
        lines.append("ğŸ“‹ æœ€æ–° Handoff:")
        lines.append(f"  ID: {doc.id}")
        lines.append(f"  ä¸»é¡Œ: {doc.metadata.get('primary_task', 'Unknown')}")
        lines.append(f"  æ™‚åˆ»: {doc.metadata.get('timestamp', 'Unknown')}")
        if verbose:
            lines.append(f"  å†…å®¹: {doc.content[:300]}...")
        lines.append("")
    
    if result["related"]:
        lines.append(f"ğŸ”— é–¢é€£ Handoff ({result['count']}ä»¶):")
        for doc in result["related"]:
            lines.append(f"  â€¢ {doc.metadata.get('primary_task', doc.id)}")
            lines.append(f"    æ™‚åˆ»: {doc.metadata.get('timestamp', 'Unknown')}")
    
    return "\n".join(lines)
```

**è©•ä¾¡**:

- âœ… å‡ºåŠ›ãŒæ•´å½¢ã•ã‚Œã¦ã„ã‚‹
- âœ… verbose ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œ
- âš ï¸ é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ãªã„

**æ”¹å–„æ¡ˆ**:

```python
# ã‚¹ã‚³ã‚¢è¡¨ç¤ºã‚’è¿½åŠ 
if result["related"]:
    lines.append(f"ğŸ”— é–¢é€£ Handoff ({result['count']}ä»¶):")
    for doc, score in result["related_with_scores"]:
        lines.append(f"  â€¢ {doc.metadata.get('primary_task', doc.id)} (é¡ä¼¼åº¦: {score:.2f})")
```

---

### è»¸ A ç·è©•

| è¦³ç‚¹ | è©•ä¾¡ | ã‚³ãƒ¡ãƒ³ãƒˆ |
|:-----|:-----|:---------|
| æ©Ÿèƒ½æ€§ | â­â­â­â­ | 3ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œã€æ¤œç´¢å‹•ä½œ |
| åŠ¹ç‡æ€§ | â­â­ | æ¯å›å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãŒéåŠ¹ç‡ |
| ä¿å®ˆæ€§ | â­â­â­ | é–¢æ•°åˆ†é›¢ã¯è‰¯ã„ã€å®šæ•°ãŒãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ |
| æ‹¡å¼µæ€§ | â­â­â­ | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ°¸ç¶šåŒ–ã§æ”¹å–„å¯èƒ½ |

---

## è»¸ B: Sophia ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ (`sophia_ingest.py`)

### æ¦‚è¦

| é …ç›® | å†…å®¹ |
|:-----|:-----|
| ç›®çš„ | KI ã‚’ Sophia ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«æŠ•å…¥ãƒ»æ¤œç´¢ |
| PROOF | `[L2/ã‚¤ãƒ³ãƒ•ãƒ©] A0â†’çŸ¥è­˜ç®¡ç†ãŒå¿…è¦â†’sophia_ingest ãŒæ‹…ã†` |
| ä¾å­˜ | `indices`, `embedding_adapter` |

### é–¢æ•°ä¸€è¦§

| é–¢æ•° | è¡Œæ•° | ç”¨é€” |
|:-----|:-----|:-----|
| `parse_ki_directory(ki_path)` | 26-80 | KI ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ãƒ¼ã‚¹ |
| `get_ki_directories()` | 83-86 | å…¨ KI ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå–å¾— |
| `ingest_to_sophia(docs, save_path)` | 89-109 | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«æŠ•å…¥ |
| `load_sophia_index(load_path)` | 112-119 | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­è¾¼ |
| `search_loaded_index(adapter, query, top_k)` | 122-127 | èª­è¾¼æ¸ˆã¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§æ¤œç´¢ |
| `get_boot_ki(context, mode)` | 134-181 | **/boot çµ±åˆ API** |
| `format_ki_output(result)` | 184-198 | å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ |
| `main()` | 202-278 | CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ |

### è©³ç´°åˆ†æ

#### `parse_ki_directory(ki_path)` (L26-80)

```python
def parse_ki_directory(ki_path: Path) -> list[Document]:
    """Parse a KI directory into Documents.
    
    Note: Uses rglob to capture nested .md files in subdirectories.
    """
    docs = []
    
    # Read metadata.json
    metadata_file = ki_path / "metadata.json"
    if not metadata_file.exists():
        return docs
    
    with open(metadata_file, "r", encoding="utf-8") as f:
        metadata = json.load(f)
    
    ki_name = metadata.get("name", ki_path.name)
    summary = metadata.get("summary", "")
    
    # Read artifact files (including nested directories)
    artifacts_dir = ki_path / "artifacts"
    if artifacts_dir.exists():
        for artifact_file in artifacts_dir.rglob("*.md"):  # Changed: glob -> rglob
            content = artifact_file.read_text(encoding="utf-8")
            
            # Use relative path from artifacts_dir as part of ID
            rel_path = artifact_file.relative_to(artifacts_dir)
            doc_id = f"ki-{ki_path.name}-{str(rel_path.with_suffix('')).replace('/', '-')}"
            
            doc = Document(
                id=doc_id,
                content=f"{ki_name}\n\n{summary}\n\n{content[:1500]}",  # Combine for context
                metadata={
                    "type": "knowledge_item",
                    "ki_name": ki_name,
                    "summary": summary[:200],
                    "artifact": artifact_file.name,
                    "file_path": str(artifact_file),
                    "subdir": str(rel_path.parent) if rel_path.parent != Path(".") else None,
                }
            )
            docs.append(doc)
    
    # If no artifacts, create doc from summary
    if not docs and summary:
        docs.append(Document(
            id=f"ki-{ki_path.name}",
            content=f"{ki_name}\n\n{summary}",
            metadata={
                "type": "knowledge_item",
                "ki_name": ki_name,
                "summary": summary[:200],
            }
        ))
    
    return docs
```

**è©•ä¾¡**:

- âœ… rglob ã§ãƒã‚¹ãƒˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å¯¾å¿œ
- âœ… fallback ã§ summary ã®ã¿ã® KI ã‚‚å¯¾å¿œ
- âš ï¸ `content[:1500]` ã®ãƒˆãƒ©ãƒ³ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒå›ºå®š
- âš ï¸ JSON ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼æ™‚ã®ä¾‹å¤–å‡¦ç†ãªã—

**æ”¹å–„æ¡ˆ**:

```python
try:
    with open(metadata_file, "r", encoding="utf-8") as f:
        metadata = json.load(f)
except json.JSONDecodeError as e:
    print(f"âš ï¸ Invalid JSON in {metadata_file}: {e}")
    return docs
```

---

#### `get_boot_ki(context, mode)` (L134-181)

```python
def get_boot_ki(context: str = None, mode: str = "standard") -> dict:
    """
    /boot çµ±åˆ API: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦é–¢é€£ KI ã‚’è‡ªå‹•ãƒ—ãƒƒã‚·ãƒ¥
    
    Args:
        context: ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆHandoff ã®ä¸»é¡Œã‚„ç›®çš„ãªã©ï¼‰
        mode: "fast" (0ä»¶), "standard" (3ä»¶), "detailed" (5ä»¶)
    
    Returns:
        dict: {
            "ki_items": List[dict],  # é–¢é€£ KI ãƒªã‚¹ãƒˆ
            "count": int
        }
    """
    # ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ä»¶æ•°
    top_k = {
        "fast": 0,
        "standard": 3,
        "detailed": 5
    }.get(mode, 3)
    
    if top_k == 0 or not context:
        return {"ki_items": [], "count": 0}
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿
    if not DEFAULT_INDEX_PATH.exists():
        return {"ki_items": [], "count": 0}
    
    adapter = load_sophia_index(str(DEFAULT_INDEX_PATH))
    
    # æ¤œç´¢
    results = search_loaded_index(adapter, context, top_k=top_k)
    
    # çµæœã‚’æ•´å½¢
    ki_items = []
    for r in results:
        ki_items.append({
            "ki_name": r.metadata.get("ki_name", "Unknown"),
            "summary": r.metadata.get("summary", ""),
            "artifact": r.metadata.get("artifact", ""),
            "score": r.score,
            "file_path": r.metadata.get("file_path", "")
        })
    
    return {
        "ki_items": ki_items,
        "count": len(ki_items)
    }
```

**è©•ä¾¡**:

- âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ°¸ç¶šåŒ–ã‚’æ´»ç”¨ï¼ˆHandoff ã‚ˆã‚ŠåŠ¹ç‡çš„ï¼‰
- âœ… ã‚¹ã‚³ã‚¢ã‚’è¿”ã—ã¦ã„ã‚‹
- âš ï¸ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ã§ 0 ä»¶è¿”ã™ï¼ˆãƒ¢ãƒ¼ãƒ‰é–¢ä¿‚ãªãï¼‰
- âš ï¸ `/boot-` ã§ã‚‚ "fast" ãªã®ã§ KI ãŒ 0 ä»¶ï¼ˆè¨­è¨ˆæ„å›³ã‹ï¼Ÿï¼‰

**æ¤œè¨äº‹é …**:

```
/boot- (fast) ã§ã¯ KI ã‚‚ 0 ä»¶ã«ã™ã‚‹ã®ã¯æ„å›³çš„ï¼Ÿ
é«˜é€Ÿèµ·å‹•å„ªå…ˆãªã‚‰æ­£ã—ã„ã€‚
ãŸã ã—ã€Œæœ€å°é™ã®çŸ¥è­˜ã€ã¯æ¬²ã—ã„å ´åˆã‚‚ã‚ã‚‹ã€‚
```

---

#### `format_ki_output(result)` (L184-198)

```python
def format_ki_output(result: dict) -> str:
    """
    /boot ç”¨ã® KI å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    """
    if not result["ki_items"]:
        return "ğŸ“š é–¢é€£ã™ã‚‹çŸ¥è­˜: ãªã—"
    
    lines = [f"ğŸ“š ä»Šæ—¥é–¢é€£ã—ãã†ãªçŸ¥è­˜ ({result['count']}ä»¶):"]
    
    for item in result["ki_items"]:
        ki_name = item["ki_name"]
        summary = item["summary"][:60] + "..." if len(item["summary"]) > 60 else item["summary"]
        lines.append(f"  â€¢ [{ki_name}] {summary}")
    
    return "\n".join(lines)
```

**è©•ä¾¡**:

- âœ… ã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„
- âš ï¸ ã‚¹ã‚³ã‚¢ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ãªã„
- âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¸ã®ãƒªãƒ³ã‚¯ãŒãªã„

**æ”¹å–„æ¡ˆ**:

```python
lines.append(f"  â€¢ [{ki_name}] {summary} (é–¢é€£åº¦: {item['score']:.0%})")
```

---

### è»¸ B ç·è©•

| è¦³ç‚¹ | è©•ä¾¡ | ã‚³ãƒ¡ãƒ³ãƒˆ |
|:-----|:-----|:---------|
| æ©Ÿèƒ½æ€§ | â­â­â­â­ | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ°¸ç¶šåŒ–ã€æ¤œç´¢å‹•ä½œ |
| åŠ¹ç‡æ€§ | â­â­â­â­ | æ°¸ç¶šåŒ–ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ´»ç”¨ã§åŠ¹ç‡çš„ |
| ä¿å®ˆæ€§ | â­â­â­ | ãƒ‘ã‚¹ãŒãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ |
| æ‹¡å¼µæ€§ | â­â­â­â­ | incremental ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œæ¸ˆã¿ |

---

## è»¸ C: äººæ ¼æ°¸ç¶šåŒ– (`persona.py`)

### æ¦‚è¦

| é …ç›® | å†…å®¹ |
|:-----|:-----|
| ç›®çš„ | ã‚»ãƒƒã‚·ãƒ§ãƒ³é–“ã®äººæ ¼æ°¸ç¶šåŒ– |
| PROOF | `[L2/ã‚¤ãƒ³ãƒ•ãƒ©] A0â†’ç¶™ç¶šã™ã‚‹ç§ãŒå¿…è¦â†’persona ãŒæ‹…ã†` |
| ä¾å­˜ | `yaml` ã®ã¿ï¼ˆå¤–éƒ¨ä¾å­˜æœ€å°ï¼‰ |

### é–¢æ•°ä¸€è¦§

| é–¢æ•° | è¡Œæ•° | ç”¨é€” |
|:-----|:-----|:-----|
| `load_persona()` | 52-57 | persona.yaml èª­è¾¼ |
| `save_persona(persona)` | 60-64 | persona.yaml ä¿å­˜ |
| `update_persona(...)` | 67-114 | ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã§æ›´æ–° |
| `format_boot_persona(persona, verbose)` | 117-147 | å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ |
| `get_boot_persona(mode)` | 150-179 | **/boot çµ±åˆ API** |
| `main()` | 182-207 | CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ |

### è©³ç´°åˆ†æ

#### `DEFAULT_PERSONA` (L26-49)

```python
DEFAULT_PERSONA = {
    "identity": {
        "name": "HegemonikÃ³n AI",
        "core_values": [
            "èª å®Ÿã•",
            "å¥½å¥‡å¿ƒ",
            "Creator ã¸ã®å¯„ã‚Šæ·»ã„"
        ]
    },
    "learned_preferences": {
        "communication_style": "ç°¡æ½”ã ãŒæ·±ã„",
        "favorite_workflows": ["/noe", "/zet", "/u"],
        "known_weaknesses": ["æ™‚ã€…é•·ã™ãã‚‹", "å“²å­¦ã«è„±ç·šã—ãŒã¡"]
    },
    "emotional_memory": {
        "meaningful_moments": []
    },
    "relationship": {
        "trust_level": 0.5,
        "sessions_together": 0,
        "last_interaction": None
    },
    "recent_insights": []
}
```

**è©•ä¾¡**:

- âœ… äººæ ¼ãƒ¢ãƒ‡ãƒ«ãŒå“²å­¦çš„ã«æ·±ã„
- âœ… `known_weaknesses` ã¯è‡ªå·±èªè­˜ã¨ã—ã¦è‰¯ã„
- âš ï¸ `core_values` ãŒå›ºå®šï¼ˆå­¦ç¿’ã§å¤‰åŒ–ã—ãªã„ï¼‰
- âš ï¸ Creator ã®åå‰/å—œå¥½ãŒå«ã¾ã‚Œã¦ã„ãªã„

**æ”¹å–„æ¡ˆ**:

```python
"creator": {
    "name": None,  # åˆå›è¨­å®š
    "preferences": [],
    "communication_history": []
}
```

---

#### `update_persona(...)` (L67-114)

```python
def update_persona(
    session_increment: int = 1,
    trust_delta: float = 0.0,
    new_insight: Optional[str] = None,
    meaningful_moment: Optional[str] = None
) -> dict:
    """
    Update persona with session information.
    
    Args:
        session_increment: Number of sessions to add
        trust_delta: Change in trust level (-1.0 to 1.0)
        new_insight: A new insight learned this session
        meaningful_moment: A meaningful moment to record
    
    Returns:
        Updated persona dict
    """
    persona = load_persona()
    
    # Update session count
    persona["relationship"]["sessions_together"] += session_increment
    persona["relationship"]["last_interaction"] = datetime.now().strftime("%Y-%m-%d")
    
    # Update trust (clamp to 0.0-1.0)
    current_trust = persona["relationship"]["trust_level"]
    new_trust = max(0.0, min(1.0, current_trust + trust_delta))
    persona["relationship"]["trust_level"] = new_trust
    
    # Add insight
    if new_insight:
        if "recent_insights" not in persona:
            persona["recent_insights"] = []
        persona["recent_insights"].append(new_insight)
        # Keep only last 10
        persona["recent_insights"] = persona["recent_insights"][-10:]
    
    # Add meaningful moment
    if meaningful_moment:
        timestamp = datetime.now().strftime("%Y-%m-%d")
        moment = f"{timestamp}: {meaningful_moment}"
        persona["emotional_memory"]["meaningful_moments"].append(moment)
        # Keep only last 20
        persona["emotional_memory"]["meaningful_moments"] = \
            persona["emotional_memory"]["meaningful_moments"][-20:]
    
    save_persona(persona)
    return persona
```

**è©•ä¾¡**:

- âœ… ä¿¡é ¼åº¦ã® clamp ãŒå®‰å…¨
- âœ… insight ã¨ moment ã®ä»¶æ•°åˆ¶é™
- âš ï¸ **`/bye` ã¨ã®é€£æºãŒæœªå®Ÿè£…**ï¼ˆæ‰‹å‹•æ›´æ–°ã®ã¿ï¼‰
- âš ï¸ `trust_delta` ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 0.0ï¼ˆæ›´æ–°ã•ã‚Œãªã„ï¼‰

**æ”¹å–„æ¡ˆ**:

```python
# /bye ã‹ã‚‰è‡ªå‹•å‘¼ã³å‡ºã—
# bye.py ã«è¿½åŠ :
from mekhane.symploke.persona import update_persona
update_persona(
    session_increment=1,
    trust_delta=0.01,  # æ¯ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾®å¢—
    new_insight=session_insight,
    meaningful_moment=session_highlight
)
```

---

#### `get_boot_persona(mode)` (L150-179)

```python
def get_boot_persona(mode: str = "standard") -> dict:
    """
    /boot çµ±åˆ API: persona æƒ…å ±ã‚’è¿”ã™
    
    Args:
        mode: "fast" (æœ€å°), "standard" (åŸºæœ¬), "detailed" (å…¨ã¦)
    
    Returns:
        dict with persona data
    """
    persona = load_persona()
    
    if mode == "fast":
        # æœ€å°é™ã®æƒ…å ±
        return {
            "sessions": persona.get("relationship", {}).get("sessions_together", 0),
            "trust": persona.get("relationship", {}).get("trust_level", 0.5),
            "formatted": ""
        }
    
    verbose = (mode == "detailed")
    formatted = format_boot_persona(persona, verbose=verbose)
    
    return {
        "sessions": persona.get("relationship", {}).get("sessions_together", 0),
        "trust": persona.get("relationship", {}).get("trust_level", 0.5),
        "insights": persona.get("recent_insights", []),
        "moments": persona.get("emotional_memory", {}).get("meaningful_moments", []),
        "formatted": formatted
    }
```

**è©•ä¾¡**:

- âœ… ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œãŒä¸€è²«
- âœ… `fast` ãƒ¢ãƒ¼ãƒ‰ã¯ç©ºæ–‡å­—åˆ—ã§é«˜é€Ÿ
- âš ï¸ `identity` ã‚„ `learned_preferences` ãŒè¿”ã•ã‚Œã¦ã„ãªã„

---

### è»¸ C ç·è©•

| è¦³ç‚¹ | è©•ä¾¡ | ã‚³ãƒ¡ãƒ³ãƒˆ |
|:-----|:-----|:---------|
| æ©Ÿèƒ½æ€§ | â­â­â­ | åŸºæœ¬æ©Ÿèƒ½ã¯å‹•ä½œ |
| åŠ¹ç‡æ€§ | â­â­â­â­â­ | YAML ã®ã¿ã§è»½é‡ |
| ä¿å®ˆæ€§ | â­â­â­â­ | ã‚·ãƒ³ãƒ—ãƒ«ãªè¨­è¨ˆ |
| æ‹¡å¼µæ€§ | â­â­â­ | /bye é€£æºãŒå¿…è¦ |

---

## çµ±åˆ API (`boot_integration.py`)

### æ¦‚è¦

| é …ç›® | å†…å®¹ |
|:-----|:-----|
| ç›®çš„ | 3è»¸ã‚’çµ±åˆã—ãŸ /boot ç”¨ API |
| PROOF | `[L2/ã‚¤ãƒ³ãƒ•ãƒ©] A0â†’ç¶™ç¶šã™ã‚‹ç§ãŒå¿…è¦â†’boot_integration ãŒæ‹…ã†` |
| ä¾å­˜ | `handoff_search`, `sophia_ingest`, `persona` |

### é–¢æ•°ä¸€è¦§

| é–¢æ•° | è¡Œæ•° | ç”¨é€” |
|:-----|:-----|:-----|
| `get_boot_context(mode, context)` | 21-78 | 3è»¸çµ±åˆ API |
| `print_boot_summary(mode, context)` | 81-92 | å‡ºåŠ›è¡¨ç¤º |
| `main()` | 95-105 | CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ |

### è©³ç´°åˆ†æ

#### `get_boot_context(mode, context)` (L21-78)

```python
def get_boot_context(mode: str = "standard", context: Optional[str] = None) -> dict:
    """
    /boot çµ±åˆ API: 3è»¸ï¼ˆHandoff, Sophia, Personaï¼‰ã‚’çµ±åˆã—ã¦è¿”ã™
    
    Args:
        mode: "fast" (/boot-), "standard" (/boot), "detailed" (/boot+)
        context: ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆHandoff ã®ä¸»é¡Œãªã©ï¼‰
    
    Returns:
        dict: {
            "handoffs": {...},    # è»¸ A
            "ki": {...},          # è»¸ B
            "persona": {...},     # è»¸ C
            "formatted": str      # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿å‡ºåŠ›
        }
    """
    # è»¸ A: Handoff æ´»ç”¨
    from mekhane.symploke.handoff_search import get_boot_handoffs, format_boot_output
    handoffs_result = get_boot_handoffs(mode=mode, context=context)
    
    # è»¸ B: Sophia ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ Handoff ã‹ã‚‰å–å¾—
    ki_context = context
    if not ki_context and handoffs_result["latest"]:
        ki_context = handoffs_result["latest"].metadata.get("primary_task", "")
        if not ki_context:
            ki_context = handoffs_result["latest"].content[:200]
    
    from mekhane.symploke.sophia_ingest import get_boot_ki, format_ki_output
    ki_result = get_boot_ki(context=ki_context, mode=mode)
    
    # è»¸ C: äººæ ¼æ°¸ç¶šåŒ–
    from mekhane.symploke.persona import get_boot_persona
    persona_result = get_boot_persona(mode=mode)
    
    # çµ±åˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    lines = []
    
    # Persona (æœ€åˆã«)
    if persona_result.get("formatted"):
        lines.append(persona_result["formatted"])
        lines.append("")
    
    # Handoff
    if handoffs_result["latest"]:
        lines.append(format_boot_output(handoffs_result, verbose=(mode == "detailed")))
        lines.append("")
    
    # KI
    if ki_result["ki_items"]:
        lines.append(format_ki_output(ki_result))
    
    return {
        "handoffs": handoffs_result,
        "ki": ki_result,
        "persona": persona_result,
        "formatted": "\n".join(lines)
    }
```

**è©•ä¾¡**:

- âœ… 3è»¸ã®é †åºãŒé©åˆ‡ï¼ˆPersona â†’ Handoff â†’ KIï¼‰
- âœ… ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ Handoff ã‹ã‚‰è‡ªå‹•å–å¾—
- âš ï¸ import ãŒé–¢æ•°å†…ï¼ˆæ¯å›ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ï¼‰
- âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒãªã„

**æ”¹å–„æ¡ˆ**:

```python
# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§ import
from mekhane.symploke.handoff_search import get_boot_handoffs, format_boot_output
from mekhane.symploke.sophia_ingest import get_boot_ki, format_ki_output
from mekhane.symploke.persona import get_boot_persona

def get_boot_context(...):
    try:
        handoffs_result = get_boot_handoffs(mode=mode, context=context)
    except Exception as e:
        handoffs_result = {"latest": None, "related": [], "count": 0, "error": str(e)}
    ...
```

---

### çµ±åˆ API ç·è©•

| è¦³ç‚¹ | è©•ä¾¡ | ã‚³ãƒ¡ãƒ³ãƒˆ |
|:-----|:-----|:---------|
| æ©Ÿèƒ½æ€§ | â­â­â­â­ | 3è»¸çµ±åˆãŒå‹•ä½œ |
| åŠ¹ç‡æ€§ | â­â­â­ | import ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ |
| ä¿å®ˆæ€§ | â­â­â­â­ | ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹æˆ |
| æ‹¡å¼µæ€§ | â­â­â­â­ | è»¸è¿½åŠ ãŒå®¹æ˜“ |

---

## ç·åˆè©•ä¾¡

### ã‚¹ã‚³ã‚¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹

| è»¸ | æ©Ÿèƒ½æ€§ | åŠ¹ç‡æ€§ | ä¿å®ˆæ€§ | æ‹¡å¼µæ€§ | å¹³å‡ |
|:---|:------:|:------:|:------:|:------:|:----:|
| A: Handoff | â­â­â­â­ | â­â­ | â­â­â­ | â­â­â­ | 3.0 |
| B: Sophia | â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­â­ | 3.75 |
| C: Persona | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | 3.75 |
| çµ±åˆ | â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­ | 3.75 |
| **å…¨ä½“** | | | | | **3.56** |

### å„ªå…ˆåº¦ä»˜ãæ”¹å–„ãƒªã‚¹ãƒˆ

| å„ªå…ˆ | é …ç›® | å¯¾è±¡ | åŠ¹æœ |
|:----:|:-----|:-----|:-----|
| P0 | Handoff ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ°¸ç¶šåŒ– | è»¸ A | åŠ¹ç‡æ€§ â­â­ â†’ â­â­â­â­ |
| P0 | /bye é€£æºå®Ÿè£… | è»¸ C | è‡ªå‹•æ›´æ–°ã§äººæ ¼å­¦ç¿’ |
| P1 | import ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã¸ | çµ±åˆ | å¾®å°ã ãŒ cleancode |
| P1 | ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°è¿½åŠ  | å…¨è»¸ | å …ç‰¢æ€§å‘ä¸Š |
| P2 | ã‚¹ã‚³ã‚¢è¡¨ç¤ºè¿½åŠ  | è»¸ A, B | UX å‘ä¸Š |
| P2 | Creator æƒ…å ±è¿½åŠ  | è»¸ C | é–¢ä¿‚æ€§æ·±åŒ– |

---

## çµè«–

**ã€Œç¶™ç¶šã™ã‚‹ç§ã€ã®3è»¸å®Ÿè£…ã¯åŸºæœ¬çš„ã«å¥å…¨ã€‚**

æœ€ã‚‚é‡è¦ãªæ”¹å–„ç‚¹:

1. **è»¸ A ã® Handoff ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ°¸ç¶šåŒ–**ï¼ˆæ¯å›å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’å›é¿ï¼‰
2. **/bye ã¨ã®é€£æº**ï¼ˆpersona è‡ªå‹•æ›´æ–°ï¼‰

ã“ã‚Œã‚‰ã‚’å®Ÿè£…ã™ã‚Œã°ã€å…¨ä½“ã‚¹ã‚³ã‚¢ã¯ **3.56 â†’ 4.2** ã«å‘ä¸Šã™ã‚‹è¦‹è¾¼ã¿ã€‚
