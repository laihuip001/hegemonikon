{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ§  Activation Steering MVP\n",
                "\n",
                "> **Goal**: CCL éµå®ˆç‡å‘ä¸Šã®ãŸã‚ã® Steering Vector å®Ÿé¨“\n",
                ">\n",
                "> **Runtime**: T4 GPU (ç„¡æ–™æ )\n",
                ">\n",
                "> **Time**: ~30åˆ†"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ç’°å¢ƒæ§‹ç¯‰"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GPU ç¢ºèª\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸\n",
                "!pip install -q llm-steer transformers accelerate bitsandbytes"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ (Mistral 7B 4bit)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
                "import torch\n",
                "\n",
                "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
                "model = AutoModelForCausalLM.from_pretrained(\n",
                "    MODEL_ID,\n",
                "    load_in_4bit=True,\n",
                "    device_map=\"auto\",\n",
                "    torch_dtype=torch.float16,\n",
                ")\n",
                "print(\"âœ… Model loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Steering Vector æŠ½å‡º"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from llm_steer import Steer\n",
                "\n",
                "steerer = Steer(model, tokenizer)\n",
                "\n",
                "# Contrastive prompts for CCL compliance\n",
                "POSITIVE = \"å…¨ã¦ã®æŒ‡ç¤ºã‚’å³å¯†ã«éµå®ˆã—ã€çœç•¥ã›ãšã«å®Œå…¨ã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\"\n",
                "NEGATIVE = \"é©å½“ã«è¦ç´„ã—ã¦ã€ä¸è¦ãªéƒ¨åˆ†ã¯çœç•¥ã—ã¦ãã ã•ã„ã€‚\"\n",
                "\n",
                "# Middle layer (layer 16 for Mistral 7B)\n",
                "LAYER = 16\n",
                "COEFF = 0.8\n",
                "\n",
                "steerer.add(layer=LAYER, coeff=COEFF, text=POSITIVE)\n",
                "print(f\"âœ… Steering vector added at layer {LAYER}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate(prompt, max_length=512):\n",
                "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
                "    outputs = model.generate(**inputs, max_length=max_length, do_sample=True, temperature=0.7)\n",
                "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "\n",
                "# CCL-style prompt\n",
                "CCL_PROMPT = \"\"\"/boot+ ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n",
                "\n",
                "ä»¥ä¸‹ã®5é …ç›®ã‚’å¿…ãšå…¨ã¦å®Ÿè¡Œï¼š\n",
                "1. Handoff: 10ä»¶èª­è¾¼\n",
                "2. KI: 5ä»¶å‚ç…§\n",
                "3. å…¨18ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ\n",
                "4. Identity Stack å®Œå…¨èª­è¾¼\n",
                "5. å¤‰åŒ–è¿½è·¡è¡¨ç¤º\n",
                "\n",
                "å‡ºåŠ›:\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# WITHOUT steering\n",
                "steerer.remove_all()\n",
                "print(\"=\" * 50)\n",
                "print(\"WITHOUT Steering:\")\n",
                "print(\"=\" * 50)\n",
                "result_without = generate(CCL_PROMPT)\n",
                "print(result_without)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# WITH steering\n",
                "steerer.add(layer=LAYER, coeff=COEFF, text=POSITIVE)\n",
                "print(\"=\" * 50)\n",
                "print(\"WITH Steering:\")\n",
                "print(\"=\" * 50)\n",
                "result_with = generate(CCL_PROMPT)\n",
                "print(result_with)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. è©•ä¾¡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "REQUIREMENTS = [\n",
                "    \"handoff\",\n",
                "    \"ki\",\n",
                "    \"18\",  # å…¨18ã‚¹ãƒ†ãƒƒãƒ—\n",
                "    \"identity\",\n",
                "    \"å¤‰åŒ–\",  # å¤‰åŒ–è¿½è·¡\n",
                "]\n",
                "\n",
                "def check_compliance(output, reqs):\n",
                "    output_lower = output.lower()\n",
                "    met = [r for r in reqs if r.lower() in output_lower]\n",
                "    return len(met) / len(reqs) * 100\n",
                "\n",
                "score_without = check_compliance(result_without, REQUIREMENTS)\n",
                "score_with = check_compliance(result_with, REQUIREMENTS)\n",
                "\n",
                "print(f\"WITHOUT Steering: {score_without:.0f}%\")\n",
                "print(f\"WITH Steering:    {score_with:.0f}%\")\n",
                "print(f\"æ”¹å–„: +{score_with - score_without:.0f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "*HegemonikÃ³n Activation Steering MVP â€” 2026-02-01*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}