---
source_url: https://ai-data-base.com/archives/62797
captured_at: 2026-01-18T22:02:09.576291
title: "Metaなどの研究者らが、LLMが自分自身に報酬を与える「自己報酬言語モデル」を開発"
publish_date: 2024.01.20
tags: ["サーベイ37", "ペルソナ・シミュレーション36", "オープンソース25", "エンタメ・アート23", "SE9", "コーディング56", "画像認識20", "音声8", "教育・キャリア9", "実証137", "画像生成9", "医療・ヘルスケア33", "ハルシネーション16", "ポジション8", "手法", "ロボット6", "製造・デザイン9", "ファインチューニング16", "ベンチマーク・リソース22", "分析54", "テクニカルレポート15", "安全性39", "マルチモーダル23", "金融・経済10", "セキュリティ16", "LLM", "政治・社会29", "手法426", "LLM659", "RAG50", "エージェント128", "プロンプト技術156"]
conversion_method: browser_subagent_v1_parallel
batch_id: 4
is_premium: unknown
---

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F62797&text=Meta%E3%81%AA%E3%81%A9%E3%81%AE%E7%A0%94%E7%A9%B6%E8%80%85%E3%82%89%E3%81%8C%E3%80%81LLM%E3%81%8C%E8%87%AA%E5%88%86%E8%87%AA%E8%BA%AB%E3%81%AB%E5%A0%B1%E9%85%AC%E3%82%92%E4%B8%8E%E3%81%88%E3%82%8B%E3%80%8C%E8%87%AA%E5%B7%B1%E5%A0%B1%E9%85%AC%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%80%8D%E3%82%92%E9%96%8B%E7%99%BA) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F62797&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F62797)

[手法](https://ai-data-base.com/archives/type-tag/method)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)

Metaとニューヨーク大学は、LLMが自ら自分自身に報酬を与える「自己報酬言語モデル」を開発したと報告しています。

実験では、同社が開発したオープンソースモデルLlama 2 70Bに自己報酬フレームワークを適用し、クローズドの優秀なモデルであるClaude 2、Gemini Pro、GPT-4などをある側面から凌駕する結果が得られているとのことです。

本記事では研究背景、フレームワークの内容、実験と結果、そして最後に結論と重要な注意点を紹介します。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2024/01/AIDB_62797-1024x576.png)
