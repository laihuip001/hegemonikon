---
source_url: https://ai-data-base.com/archives/98812
captured_at: 2026-01-18T22:13:10.609140
title: "AIエージェント本番運用の実態調査　実務家が明かす成功の条件と課題"
publish_date: 2025.12.10
tags: ["実証", "LLM", "エージェント", "手法\n426", "実証\n137", "分析\n54", "サーベイ\n37", "ベンチマーク・リソース\n22", "テクニカルレポート\n15", "ポジション\n8", "LLM\n659", "プロンプト技術\n156", "エージェント\n128", "コーディング\n56", "RAG\n50", "安全性\n39", "ペルソナ・シミュレーション\n36", "オープンソース\n25", "マルチモーダル\n23", "画像認識\n20", "セキュリティ\n16", "ハルシネーション\n16", "ファインチューニング\n16", "画像生成\n9", "音声\n8", "医療・ヘルスケア\n33", "政治・社会\n29", "エンタメ・アート\n23", "金融・経済\n10", "SE\n9", "教育・キャリア\n9", "製造・デザイン\n9", "ロボット\n6"]
conversion_method: browser_subagent_v1_parallel
batch_id: 1
is_premium: unknown
---

AIエージェント本番運用の実態調査　実務家が明かす成功の条件と課題
2025.12.10
2025.12.27
深堀り解説
クリップする
実証
LLM
エージェント

AIエージェントの活用が進む中で、実際の「本番環境」において、それらがどのように設計・運用されているかについては、これまでほとんど体系的に調べられていません。企業の内部的な実装は一般に公開されにくく、成功例と失敗例の違いを客観的に把握するのも困難だったからです。

そこで本記事では、複数の業界にわたる多数の実務家を対象にした大規模なアンケート調査を実施した結果を取り上げます。また、実際に運用されている20のAIエージェントシステムについて、詳細なインタビューも行われています。実運用中のAIエージェントについて網羅的に調査した初めての研究とされています

実態調査から得られた、現場で役立つ知見についても見ていきます。

本記事の関連研究

LLMエージェント開発の実態　主要10フレームワークの課題と選び方
Claude Code生成コードが実際の開発でどう扱われているかの調査結果
LLMエージェントの失敗パターン　計画と修正のつまづきポイント
背景

LLMの急速な進化により、「AIエージェント」と呼ばれる新しいタイプのソフトウェアシステムが登場しました。単体のLLMは与えられた問いに答えるだけですが、AIエージェントはそれを超えて、複数のステップから成るタスクを自律的に遂行する能力を持ちます。たとえば、情報の検索、検索結果の解釈、それに基づく意思決定、ツールの操作といった一連の作業を、人の指示なしで進めます。

その可能性は、まずは研究でさまざまに実証されてきました。新薬候補の探索、アルゴリズムの改良提案、科学論文の自動生成など、高度な用途で成果が報告されてきました。そして現在、これらの技術は研究室を飛び出し、実際のビジネス現場にも導入され始めています。金融機関での審査プロセス、保険会社の請求処理、教育現場での学習支援など、コーディング支援を超えた多様な領域で活用されているのです。

しかしその一方で、AIエージェントの実用性には懐疑的な声もあります。多くの企業が導入に挑戦するものの、期待していた成果を上げられずに終わっているケースも見られます。

成功する5%と失敗する95%を分けるものは何なのでしょうか？

その答えを得るには、本番環境で実際に稼働しているAIエージェントが、どのように構築され、運用されているのかを詳しく知る必要があります。ところが、企業が内部の実装を公開することはほとんどなく、現場での制約や実践的な知見は、研究者にも実務者にも共有されていないのが現状です。

こうした研究と実務の間にある大きなギャップを埋めるために行われた調査を取り上げます。実際にAIエージェントを本番環境で運用している実務家たちへの直接インタビューを通じて、何が機能し、どこに課題があるのかを体系的に明らかにしようとしているものです。

ここから限定コンテンツ
忙しい人向けに、重要なポイント5選
AIエージェントを導入する企業の73%は、作業時間の短縮や人手削減といった明確な効率化を目指している
本番稼働中のエージェントの68%は10ステップ以内で人間の介入を求め、70%はモデルのファインチューニングを行わずプロンプトのみで実装されている
74%のシステムが人間による評価を主要な品質確認手段としており、完全自動化よりも人間との協働を重視している
出力の正確性を保証する評価方法の確立が最も困難で、これが本番展開の主要なボトルネックとなっている
金融、医療、法務、カスタマーサポートなど26の異なる業界で実用化されており、コーディング支援だけでなく幅広い用途で価値を生んでいる

参照文献情報

タイトル：Measuring Agents in Production
URL：https://doi.org/10.48550/arXiv.2512.04123
著者：Melissa Z. Pan, Negar Arabzadeh, Riccardo Cogo, Yuxuan Zhu, Alexander Xiong, Lakshya A Agrawal, Huanzhi Mao, Emma Shen, Sid Pallerla, Liana Patel, Shu Liu, Tianneng Shi, Xiaoyuan Liu, Jared Quincy Davis, Emmanuele Lacavalla, Alessandro Basile, Shuyi Yang, Paul Castro, Daniel Kang, Joseph E. Gonzalez, Koushik Sen, Dawn Song, Ion Stoica, Matei Zaharia, Marquita Ellis
所属：UC Berkeley, Intesa Sanpaolo, UIUC, Stanford University, IBM Research
AIエージェントを導入する理由（N=66）。生産性向上（72.7%）が最も多く選ばれ、リスク軽減（12.1%）は最も少ない。複数選択可のため合計は100%を超える
調査方法

研究チームは、AIエージェントの実態を把握するために、2つの異なるアプローチを組み合わせて調査を行いました。1つは、多様な実務家を対象とした大規模なオンライン調査、もう1つは、実際に本番環境でAIエージェントを運用しているチームへの詳細なインタビューです。

オンライン調査の実施

まず、AIエージェントの構築に関わる実務家を対象に、全47問から成るオンライン調査を実施しました。ただし、全員が同じ質問に答えるわけではありません。回答内容に応じて次の質問が変わる「分岐型」の設計となっており、表示される質問は人によって異なります。たとえば、「複数のシステムに関与している」と答えた人には、「1つのシステムに絞って回答してください」といった確認メッセージが表示される仕組みです。

この調査では、システムの構成、評価の方法、運用上の課題など、主に技術的な側面に焦点を当てました。なお研究者側が一方的に「AIエージェント」を定義するのではなく、回答者自身が「AIエージェント」または「エージェントAI」と呼んでいるシステムについて答えてもらっています。

調査の告知は、UC Berkeleyのイベントや業界の勉強会、LinkedIn、X（旧Twitter）などの専門家向けネットワークを通じて行われました。2025年7月末からおよそ3ヶ月間にわたり調査を実施し、合計306件の有効回答が集まりました。回答者の多くは、ソフトウェアエンジニアや機械学習エンジニアなど、実際にAIエージェントの設計・構築に携わっている技術職の人々です。

AIエージェントシステムの開発段階（N=111）。本番環境が45.0%、パイロット段階が32.4%を占め、8割以上が実運用に近い段階にある

この306件のうち、特に「本番環境」または「パイロット段階」にあるシステムに注目しました。「本番環境」とは、実際のユーザーが日常的に利用している状態のことであり、「パイロット段階」は限定的なユーザーグループで試験運用されている段階を指します。研究用のプロトタイプや実験的なシステムは対象外とし、実運用されている86件に絞り込まれました。

詳細インタビューの実施

オンライン調査に加えて、実際にAIエージェントを本番環境で運用している20のケースに対し、詳細なインタビューを行いました。

インタビュー対象は慎重に選定されました。14件は完全に本番稼働しているシステム、残り6件はパイロット運用の最終段階にあるシステムで、いずれも実際のユーザーが存在するものに限定されています。対象の業種は金融、医療、科学研究、ソフトウェア開発など幅広く、企業規模もスタートアップから従業員数千人規模のグローバル企業まで、バランスよく選ばれました。ユーザー数も数百人から数百万人までと、多様な規模の運用例を収集することができています。

質問内容は、AIエージェントが取り組んでいる課題、成果の評価方法、設計上の意思決定、運用要件、直面している制約など、11の主要テーマが使われました。

企業のAIエージェントがどのように構築されているか

AIエージェントが実際の現場でどう作られているのかを探るために、研究チームは五つの技術的なポイントに注目しました。「どんなモデルを使うのか」、「モデルをどう調整するのか」、「プロンプトはどう作るのか」、「エージェントの設計はどうなっているのか」、「どんな開発フレームワークを使っているのか」、という部分です。

どのモデルを選んでいるか

まず、どんな言語モデルが使われているかを見てみましょう。インタビュー対象の20件のうち、17件がクローズドソースのモデルを使っていました。たとえば、AnthropicのClaude Sonnet 4やClaude Opus 4.1、OpenAIのGPT-4（o3）などです。いずれもその時点でトップクラスの性能を持つモデルです。

一方で、オープンソースのモデルを使っていたのは3件だけでした。それもコスト面の制約があったり、法律やプライバシーの関係で外部にデータを出せないといった、特別な事情があるケースでした。

クローズドソースのモデルが選ばれている理由として、実務での「使いやすさ」が大きな決め手になっているようです。実務者たちはいくつかのモデルを試して、実際に一番よく動いたものを選んでいました。たしかにモデルの利用にはお金がかかりますが、それでも専門家を雇うよりはずっと安く済むという考え方です。たとえば医療の専門職や経験豊富なエンジニアに支払う時給を思えば、モデルの利用料はそれほど高くないという声が多く聞かれました。

さらに、1種類だけでなく、複数のモデルを組み合わせて使っているチームも多くありました。調査によると、40.9パーセントは1つのモデルだけを使っていて、残りの約60パーセントは2つ以上のモデルを併用していました。

複数のモデルを使う理由としては、次のようなものがありました。

タスクの内容によってモデルを使い分けて、スピードやコストをうまく調整したいから。たとえば、簡単な処理には軽いモデルを使い、複雑な場面では高性能なモデルに任せるようにしている
モデルのバージョンが変わると動きが変わることがあるため、それに備えて古いモデルと新しいモデルを同時に動かして様子を見ることがある

現場では「ちゃんと動くこと」と「安定していること」が何より大切にされていて、実際に使いながら判断を重ねていることが伝わってきました。

ケーススタディ20件におけるモデル特性（N=20）。左はオープンソースモデルの使用有無、右はポストトレーニング（ファインチューニング・強化学習）の実施有無。大多数がクローズドソースモデルをそのまま使用している
モデルの追加学習は行われているか

次は、モデルのカスタマイズについて見ていきます。ここでいう追加学習とは、すでに汎用的なデータで学習済みのモデルを、特定の用途に合わせてさらに訓練し直すことを指します。たとえば、教師あり学習で行うファインチューニングや、試行錯誤を通じて学習する強化学習といった手法があります。

実際のところは追加学習を行っていないケースがほとんどでした。インタビュー対象の20件のうち、14件がモデルをそのまま使っており、追加の学習はまったく行っていませんでした。うち2件のチームは、既存のモデルで十分な性能が出ているため、ファインチューニングは必要ないと明言していました。

追加学習をしていたのは5件だけで、しかも特定の事情があるケースに限られていました。たとえば、企業独自の製品情報や社内ポリシーといった特殊な文脈を取り込む必要がある場合です。代表的なのは、ある企業の製品サポートに特化したエージェントなどでした。この5件のうち3件は追加学習が欠かせないと考えていましたが、残りの2件は大口顧客向けにオプションとして提供している程度にとどまっていました。

強化学習に関しては、さらに少なく、科学研究を目的とした1件のみでした。ただ、将来的にソフトウェアテストなどの用途で使ってみたいと答えたチームも3件あり、興味を持つ人はいるものの、まだ実際には導入されていない状況です。

では、なぜ追加学習はあまり使われていないのでしょうか。インタビューからは、実装の難しさと運用の不安定さが主な理由として挙げられました。追加学習を行うには大量の高品質なデータが必要になり、実装には高度な機械学習の知識が求められます。また、もとになっているモデルがバージョンアップされるたびに再学習が必要になるため、メンテナンスの負荷も大きくなります。

もし既存の最新モデルだけで十分に良い結果が得られるのであれば、あえて手間のかかる追加学習を取り入れる必要はない. 多くの現場では、そうした判断がされているようでした。

プロンプトはどう作られているか

調査によると、全体の79パーセントのシステムでプロンプトが人の手によって作成されていました。内訳を見ると、33.9パーセントは完全に手作業でプロンプトを書いており、44.6パーセントは人間が下書きをしたうえで、LLMに補完してもらうハイブリッド型の方法を取っていました。一方で、自動化ツール（たとえばDSPyなど）を使っているケースは8.9パーセントしかなく、エージェント自身にプロンプトを生成させているケースはわずか3.6パーセントにとどまっていました。

プロンプト構築方法の分布（N=53）。手動とAI補助の組み合わせ（44.6%）が最多。自動最適化ツールの使用は8.9%にとどまる

詳細インタビューでも、この傾向は明確でした。20件のうち19件が人間主導でプロンプトを作成しており、自動化ツールを本格的に使っていたのは1件だけでした。研究の場ではプロンプト自動最適化への関心が高まっていますが、実務の現場ではほとんど採用されていません。その理由として、インタビューからは現場の担当者たちが制御しやすさや見通しのよさを大切にしていることが見えてきました。手作業であれば、システムがどう動いているのか把握しやすく、問題が起きたときにもすぐに修正できます。一方で自動化ツールは中身が見えにくく、トラブルが起きたときに原因を探しにくいため、導入をためらう声が多く聞かれました。

プロンプトの長さに関しても興味深い傾向がありました。全体の約半数にあたる51.5パーセントは、500トークン未満の比較的短いプロンプトを使っていました。これは日本語で言えば数百文字程度に相当します。一方で、長いものでは1万トークンを超えるケースもありました。実際に、12.1パーセントのシステムが1万トークン以上のプロンプトを使用していたことがわかっています。
システムの成熟度が上がるにつれ、より複雑な文脈や細かい指示が求められるようになっていることが、この傾向の背景にあるようです。

エージェントの設計はどうなっているか

今回の調査で最も注目されたのは、本番環境で動いているエージェントの多くが、かなり限定的な自律性しか持っていないという点でした。全体の68パーセントのシステムが、10ステップ以内に人間の介入を必要としており、その中でも46.7パーセントは5ステップ未満でした。つまり、自動で何十ものステップを連続して実行するようなエージェントは、ごく一部に限られていたのです。

本番環境のエージェント構成。(a) 使用モデル数（N=22）、(b) プロンプト長の分布（N=33）、(c) 人間介入までの自律ステップ数（N=60）。約半数が短いプロンプトと少ないステップ数で運用されている

このような設計は、あえてそうしている場合がほとんどでした。
インタビューでは、問題の複雑さや、エージェントが自分で計画を立てるときの不確実さ、応答時間の要件などを理由に、ステップ数に上限を設けているという声が多くありました。
信頼性を保ちつつ、計算時間やコストを無理なく管理するために、自律性をあえて絞っているというわけです。実際、実験段階のシステムのほうが多くのステップを許容している傾向があり、このことからも意図的な制限であることが読み取れます。

モデルの呼び出し回数についても、同じような傾向が見られました。1つのサブタスク内で、66.7パーセントのシステムがモデルの呼び出しを10回未満に抑えており、そのうち46.7パーセントは5回未満でした。実験中のシステムでは、数十回から数百回呼び出す例もありますが、本番環境ではコストや応答時間、エラーの連鎖を避けるために、かなり厳しく制限されていました。

エージェントの動き方、つまり制御の流れについても特徴がありました。80パーセントのシステムでは、あらかじめ定められた構造的なワークフローに沿って動いていました。たとえば保険の審査を行うエージェントであれば、「保障の範囲を確認してから、医療的な必要性をチェックし、リスクを判定する」というように、あらかじめ決められた手順で処理が進みます。各ステップでの判断はAIに任されていますが、全体の流れ自体はあらかじめ定義されているのです。

逆に、完全に自由に動けるエージェントは1件しかなく、そのシステムは本番環境ではなく、外部から隔離された安全なテスト環境でのみ動いていました。

ただし、もっと柔軟な設計への関心も高まってきています。4つのチームが、タスクを分割してそれぞれに最適なエージェントに割り振る「プランニングエージェント」の仕組みを試していました。今後はこうした設計が増えていく可能性もありそうです。

どんな開発フレームワークを使っているか

最後に、開発に使われているツールについて見ていきます。エージェント向けのフレームワークとは、エージェントの構築をサポートするためのプログラミング用ライブラリのことです。よく知られているものとしては、LangChainやCrewAI、LlamaIndexなどがあります。

調査の結果、60.7パーセントのシステムがこれらのフレームワークを使っていると回答していました。中でも利用率が最も高かったのはLangChainまたはLangGraphで25パーセント、続いてCrewAIが10.7パーセントという結果でした。

エージェント開発フレームワークの使用状況（N=29）。約6割がフレームワークを使用し、そのうちLangChain/LangGraphが25.0%で最多。ただし詳細インタビューでは85%が独自実装を選択

ところが、詳細インタビューで明らかになった実態は大きく異なっていました。インタビュー対象の20件のうち、実に17件、つまり85パーセントがフレームワークを使わずに独自実装をしていたのです。フレームワークを使っていたのは3件のみで、そのうち2件がLangChain、1件がBeeAIを利用していました。また、別の2チームは最初はCrewAIなどを試していたものの、本番環境で運用する段階では自前の実装に切り替えたと話していました。

では、なぜフレームワークを使わない選択がされているのでしょうか。インタビューを通じて、主に次の3つの理由が見えてきました。

柔軟性を確保したいという理由
本番環境では、企業独自のインフラや複雑なデータ処理との連携が必要な場面が多く、汎用的なフレームワークでは対応が難しいことがあるようです

シンプルな構成を好む傾向
たとえば、エージェントの動作を構成する基本的なループ（ReActループなど）は、APIを直接呼び出すことで十分に実装できるため、大がかりなフレームワークに頼るよりも、自分たちで必要な部分だけを軽量に組み立てるほうが効率的だと考えられていました

セキュリティ面の制約も一因
企業によっては、外部の特定ライブラリの使用がポリシーで禁止されていることがあり、導入自体が難しいケースもありました

調査結果とインタビュー結果の間に大きな違いがあるのは、とても興味深い点です。広く実施された調査には、まだ開発途中のシステムや実験中の取り組みも多く含まれているため、フレームワークを試しているケースも目立ちます。一方で、本番環境に実際に導入されたシステムに限って見ると、柔軟性や制御のしやすさを優先して、フレームワークを使わずに自分たちで実装するという選択が主流になっていることがわかりました。

関連記事：LLMエージェント開発の実態　主要10フレームワークの課題と選び方

企業ではAIエージェントがどのように評価されているか

実務者たちがどのような基準で評価し、どんな手法で品質を確認しているのかを調査しました。興味深いことに、評価の実践方法は極めて多様で、同じ業界内でも大きく異なっていました。

もう1つ重要な発見として、実務者たちは従来のソフトウェアで重視される「可用性99.999%」といった稼働率の指標よりも、エージェントの出力が正確で高品質かどうかに焦点を当てていることが分かりました。詳細インタビューを行った20チームのうち、標準的な信頼性指標を適用しているチームは1つもありませんでした。評価の中心は、あくまで「正しい答えを出せているか」だったのです。

比較対象とベンチマーク

まず、どんな方法と比べてエージェントを評価しているのかを見てみます。比較対象となるのは、既存のソフトウェア、人手の作業、従来型の自動化などです。

調査では、38.7パーセントのチームがこうしたベースラインと比較を行っていました。一方で61.3パーセントは比較しておらず、そのうちの約4割にあたる25.8パーセントは、そもそも代替手段が存在しない完全新規のユースケースでした。

比較が難しい理由として、人事サポートのように従来のプロセスが複数の仕組みにまたがっている例がありました。そのため、結果の一部（処理時間など）は測れても、技術単体での比較は困難でした。

次にベンチマークについて見てみます。これは、正解付きのテストデータで性能を評価する方法です。20チーム中5チームがカスタムベンチマークを作成しており、そのうち1チームはゼロから独自に設計、他の4チームは既存の社内データ（ログやサポート履歴など）を活用していました。また1チームだけ、開発初期に公開ベンチマークも併用していました。

残る75パーセントはベンチマークを使わず、A/Bテストやユーザーフィードバック、実際の運用データによる評価を行っていました。

ベンチマークを使っていたチームでは、共通の進め方が見られました。まず質問と正解のセットを作り、ユーザーとの対話やフィードバックを収集し、それをもとに正解データを拡充していく方法です。このプロセスは運用中も続き、LLMを評価者として使う手法にもつながっています。

このように、どのチームも似た方法を手作業で繰り返していることから、評価用データの自動収集やベンチマーク作成を支援する仕組みへのニーズがあることがうかがえます。

評価手法の実態

エージェントの品質をどのように評価しているかを見ていきます。

AIエージェントの評価手法。(a) 非エージェント型ソリューションとの比較実施率、(b) 評価手法の分布（N=31）、(c) 評価手法の組み合わせパターン。人間による評価（74.2%）が最も広く他の手法と併用されている
人間による評価

最も多く使われていたのが、人間による直接的な評価でした。全体の74.2パーセントが、専門家やオペレーター、エンドユーザーが出力内容を確認し、正確さや安全性、信頼性をチェックする仕組みを導入していました。

開発中には、エージェント開発者がドメインの専門家や想定ユーザーと連携しながら、実際の出力を確認して調整していきます。たとえば医療分野では、医師などの専門家が応答内容をチェックしていました。あるケースでは、自動評価を一切使わず、クライアントごとに専門家がフィードバックを出し、それをもとに手動で設定を見直す方法を取っていました。

また、人間の専門家はシステム運用中のチェック役としても重要な役割を果たしています。よくある流れとしては、エージェントが分析や提案を行い、その結果をもとに最終判断を人間が下すというものです。たとえば、サイト信頼性エンジニアリングのケースでは、エージェントが障害の原因を分析して対応案を出しますが、本番環境への変更はエンジニアが行います。エージェントが勝手に本番環境を操作することはありません。

モデルによる評価

LLM-as-a-judge（LLMを評価者として使う方法）は、2番目に多く使われており、全体の51.6パーセントが採用していました。開発時にも運用時にも活用されており、インタビュー対象のうち7チームは、本番環境でのオンライン評価に使っていると答えています。

ただし、モデルだけで評価を完結させているわけではありません。共に使われている手法を見てみると、LLM-as-a-judgeを導入しているチームの中で、38.7パーセントは人間による評価も併用していました。さらにインタビューでは、この手法を使っているすべてのチームが、人による確認も取り入れていました。

具体的な使い方としては、LLMが出力を評価し、信頼度スコアを算出します。そのスコアがあらかじめ決めた基準を上回れば自動的に承認され、下回れば人間に確認が回されます。また、スコアが高い場合でも、一定の割合（たとえば5パーセント）は人間がランダムにチェックする仕組みになっており、モデルの判断が正しいかを継続的に検証しています。

その他の評価手法

ルールベース評価は38.7パーセント、クロスリファレンス評価は41.9パーセントで使われていました。ルールベースは文法やコードの正しさをチェックする方法、クロスリファレンスは信頼できる情報源と照らして出力の正確性を確認する方法です。

評価パターンの分析

各評価手法の組み合わせを分析すると、人間による評価が最も広く他の手法と一緒に使われていることが分かりました。実務では、自動化された評価やルールベースの検証だけに頼らず、必ず人間の判断を加える姿勢が基本になっています。

また、人による評価（74.2パーセント）とLLM-as-a-judge（51.6パーセント）が、ルールベース評価（42.9パーセント）よりも大きく使われている点も特徴的です。本番で扱うタスクが単純な処理ではなく、繊細な判断や専門知識を必要とするものだからです。

たとえば、顧客対応の音声アシスタントや人事系の支援ツールでは、文脈やニュアンスの理解が重要になります。そのため、ルールだけでは不十分で、人やモデルによる柔軟な評価が欠かせないのです。

最大の課題は何か

AIエージェントはすでに多くの現場で活用されていますが、開発や運用には依然として大きな課題があります。なかでも調査を通じて最もはっきりしたのは、「信頼性の確保」が最優先されているという点でした。

この信頼性の課題を3つの観点から掘り下げています。評価の難しさ、レイテンシ（応答時間）、そしてセキュリティの問題です。

評価における課題

まずは、エージェントの品質をどう評価するかという問題です。前のセクションでも紹介したように、多くのチームが独自の評価方法を試みていますが、それ自体が大きなハードルとなっており、標準的な方法が確立されていないのが現状です。

①ベンチマークの構築が困難

インタビューでは5チームが独自のベンチマークを作っていましたが、作成には大きな壁がありました。まず、規制の厳しい分野ではデータが公開されていないため、専門家と協力してゼロから作る必要があります。次に、十分な量をそろえるには多くの時間とリソースが必要で、数十件のケースを作るだけでも数か月かかる例がありました。さらに、クライアントごとに要件が異なるケースでは、標準化されたベンチマーク自体が成立しません。

こうした理由から、75パーセントのチームはベンチマーク作成を断念し、A/Bテストや顧客からのフィードバックを中心に改善を進めていました。

②従来のソフトウェアテストが通用しない

3チームは既存のCI/CDパイプラインに組み込もうとしましたが、エージェントが非決定的であるためうまくいきませんでした。同じ入力でも結果が変わるうえ、出力の正しさをコードで判定する方法が見つからず、回帰テストも十分に機能しませんでした。

③検証メカニズムと効果測定の困難

インタビューでは、エージェント評価に関する二つの共通課題が見えてきました。

ひとつ目は、明確な検証手段がない用途が多いことです。コード生成のようにテストがそのまま正しさを示すケースは例外で、多くの業務では結果が後からしか分かりません。保険審査では、誤りが金銭的損失や承認遅延として現れるため、評価の自動化が難しくなります。

もうひとつは、導入効果の測定が簡単ではないことです。処理時間の短縮など数値化しやすい指標は扱いやすい一方、知識負担の軽減やリスク低下など、効果が間接的で長期にわたる用途は評価が難しいため、あまり取り組まれていませんでした。

レイテンシにおける課題

エージェントの実行には時間がかかりますが、調査ではレイテンシが大きな障壁になることは少ないとわかりました。レイテンシが展開の決定的な問題とされたのは14.8パーセントのみで、59.3パーセントは「十分許容範囲」と答えています。

レイテンシがデプロイに与える影響（N=27）。59.3%が『許容範囲』と回答し、致命的な問題とするのは14.8%にとどまる。非同期型設計の普及が背景にある

この理由として、15チームが非同期型の実行（すぐに応答しなくてもよい設計）を採用していたこと、また52.2パーセントが社内向けシステムであることが関係しています。たとえば、看護師が保険情報を調べる用途では、数分かかっても問題ないケースが多く、バッチ処理を活用しているチームもありました。また、開発初期からレイテンシの影響が小さいユースケースが選ばれている傾向も見られました。

リアルタイム対話では重要な課題

ただし、音声やチャットといったリアルタイム対話型エージェントでは話が別です。2チームは、自然な会話のテンポを保つために継続的な工夫が必要だと語っており、応答の遅延がユーザー体験を損なう大きな課題になっていました。

実用的なレイテンシ管理

対策として、多くのチームはステップ数やモデル呼び出し回数に上限を設けていました。また、あるチームはあらかじめ似たリクエストとアクションの組み合わせをデータベース化し、実行時には類似検索で対応することで、高速化を実現していました。

セキュリティとプライバシーの課題

調査とインタビューの結果、セキュリティとプライバシーは「重要だが優先度は高くない」という扱いでした。実務ではまず出力の正確性と品質が重視されています。

「コンプライアンスとユーザー信頼」は課題分類で4位でしたが、これは無視されているわけではなく、多くのシステムが社内利用や人の監視下で運用されているため、リスクが抑えやすい環境にあることを示しています。

データの取り扱い

89.7%のシステムがデータベースを利用し、65.5%がリアルタイムのユーザー入力を扱っています。また、69.0%が機密データを扱っており、公開データのみを使うケースは少数派でした。

こうした状況から、プライバシーへの配慮は欠かせません. たとえば医療用エージェントのチームでは、厳しい契約や取り扱いルールに従い、ユーザーデータがモデル学習に使われないようにしています。

本番エージェントが扱うデータの種類（N=29）。89.7%がデータベースを利用し、69.0%が機密データを扱う。公開データのみの使用は34.5%と少数派
セキュリティの実践方法

インタビューでは、エージェント設計でセキュリティを保つための4つの工夫が確認されました。

「読み取り専用」の動作に制限し、本番への直接変更を避ける（6チーム）
サンドボックス環境でエージェントを実行し、安全な検証の上で本番に反映（3チーム）
ラッパーAPIを通じて本番ツールと接続し、エージェントから内部構造が見えないようにする（1チーム）
ロールベースのアクセス制御を試みたが、ツールごとの権限設定のばらつきで制御が難しい（1チーム）
考察

調査結果から3つの重要なポイントが示されました。信頼性をどう確保しているか、現在のモデルでも十分な価値が出せるという発見、そして今後の研究開発の方向性です。

ポイント①信頼性の確保

約4割のチームが信頼性を最重要課題としつつ、多くがすでに本番環境でエージェントを運用しています。これは、技術的に完璧を目指すのではなく、制約を活用して信頼性を“管理”しているからです。制約とは、実行環境・自律性の制限、人の監視などです。

たとえば、読み取り専用で動かす、社内用に限定する、サンドボックス経由で本番に反映するなど、段階的に制御された導入パターンが見られました。重要なのは、エージェントが常に正しく動くかではなく、「最終出力が基準を満たしているか」をチェックする運用にシフトしていることです。

また、ツール使用や検索先などを意図的に制限し、特定の範囲内で安全に価値を出す設計が採られています。これは自律性とのバランスを意識した、現実的なエンジニアリング判断です。

とはいえ、将来的にエージェントの自律性を拡大しつつ、どう信頼性を保つかはまだ明確な答えがありません。

ひとつの方向性として、タスクの分割方法そのものを見直す動きがあります。たとえば、コーディングとテストを一体化した実行フローのように、サブタスクの切り方を変えることで、より自然で安全なエージェント制御が可能になるかもしれません。

今後求められるのは、2つ。ひとつは、単なる正解率ではなく、信頼性を示す新たな評価指標を整備すること。もうひとつは、異なる抽象度での制御境界を明示し、それを検証可能な仕組みにすることです。

ポイント②応用機会は豊富にある

今回の調査で特に心強かったのは、AIエージェントがすでに26以上の分野で使われていることです。チャットボットやコーディング支援だけじゃなく、もっと幅広い仕事で活躍しています。

AIエージェントの適用ドメイン（N=69）。金融・銀行（39.1%）が最多で、テクノロジー、企業サービスと続く。26以上の多様な分野で展開されている

注目すべきなのは、最新の大規模モデルをそのまま使って、プロンプトだけでしっかり成果を出している例が多かったこと。調査対象の7割はファインチューニングなしで動いていました。

つまり、モデルの性能アップを待つのではなく、「いま使える範囲で、いまできることをやる」という現場の工夫が、もうすでに実用につながっています。医療のサポート、業務の自動化、研究支援など、本番環境で使われている事例もたくさんありました。

ただ、少し意外だったのは、ソフトウェアの操作や保守のような“裏方作業”への応用はあまり見られなかったことです。ほとんどのエージェントは、ユーザーと直接やり取りするチャットや音声系のもの。人に寄り添う系の用途が中心でした。

とはいえ、ソフトウェアの自動管理のような領域は、これから伸びしろがありそうです。ただしそこに踏み込むには、やはり信頼性の課題をクリアすることが前提になってきます。

ポイント③今後の課題
サイレント失敗への対処

エージェントが失敗してもすぐに気づけない「サイレント失敗」が課題です。金銭的損失やユーザーの不満など、結果が出てからでないとわからないケースが多くあります。今は人の目によるチェックが頼りですが、失敗を早く検知・理解する仕組みはまだ未成熟です。失敗の見える化、リアルタイムでの対処、そしてベンチマークやテスト手法の整備が今後の重要なテーマです。

ポストトレーニングの実用化

モデルの追加学習に期待はあるものの、実際に使われることは少ないのが現状です。原因は、データや専門知識のハードル、そしてモデル更新のたびに再調整が必要になる複雑さです。少ないデータでも効果を出せて、モデルのアップグレードにも対応しやすい方法が求められます。

推論時スケーリングの活用

3割のシステムがすでに推論時スケーリング（複数モデルの使い分けなど）を活用していますが、まだ基本的な方法が中心です。今後は、生成・検証・探索を組み合わせたアプローチが、信頼性と柔軟性を両立させる手段として注目されそうです。ただし、それを支えるインフラ整備や実行環境の再設計が必要になります。

マルチモーダル化への展開

現在の多くのエージェントは、テキストや音声といった言語ベースの入力を扱っていますが、今後は画像や動画、センサー情報などにも対応できるよう期待が高まっています。まずはテキスト中心の環境で実績を積みつつ、将来的には多様なデータ形式に広がっていく流れが見込まれます。

現在サポートしているデータ形式（赤）と将来対応予定の形式（青）（N=29）。テキスト・言語は既に93.1%が対応済み。画像・動画・科学データなど非テキスト形式への拡張が今後の成長領域
まとめ

本記事ではAIエージェントが実際の現場でどう使われているのかを明らかにした、初めての大規模な調査を取り上げました。306人へのアンケートと、20件の詳細インタビューから、次の4つの問いに答えが出ました。

まず、なぜ企業がAIエージェントを導入するのか。その理由ははっきりしていて、73%が生産性の向上を狙っています。作業時間の短縮や人手削減といった、目に見える効率化が導入の大きな動機になっています。

次に、どうやって作られているのか。意外にも、現場で使われている手法はとてもシンプルでした。モデルのファインチューニングをしているのはわずかで、68%は10ステップ以内に人が関与する設計です。高度な仕組みより、管理しやすくて安定する方法が選ばれています。

そして、どう評価されているのか。全体の74%が人の目でのチェックを重視していて、自動評価はあくまで補助的な役割です。ベンチマークを作るのは難しく、多くのチームは運用を通じて少しずつ改善しています。

最後に、何が一番の課題か。やはり信頼性の確保が最も大きなテーマでした。エージェントが出す答えの正しさをどう保証するかは、今も多くのチームが悩んでいるポイントであり、展開のハードルになっています。

この調査からわかったのは、制約をかけてシンプルに設計し、人がしっかり見守る運用が、現時点での“ちょうどいい解”だということです。

本記事の関連研究

LLMエージェント開発の実態　主要10フレームワークの課題と選び方
Claude Code生成コードが実際の開発でどう扱われているかの調査結果
LLMエージェントの失敗パターン　計画と修正のつまづきポイント

クリップする
🔒 「Vibe Coding（バイブコーディング）」の脆弱性リスクについて実際の調査結果をもとに考える
🔒 AI時代の仕事再設計　19万職種の大規模分析が示す『自動化より生産性向上』の道筋