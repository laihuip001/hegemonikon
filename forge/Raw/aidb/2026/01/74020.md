---
source_url: https://ai-data-base.com/archives/74020
captured_at: 2026-01-19T07:34:20.780202
title: "「LLMはプロンプトから新しいタスクを学べるのか？」 という根本的な問いに対する3つの仮説を検証 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

本記事では、LLMの文脈内学習（In-context learning,
コンテキスト内学習）の仕組みに関する研究を紹介します。文脈内学習とは、LLMが少数の例示から新しいタスクを学習し実行する能力を指します。

研究者らは今回、LLMが新しいタスクを学習するメカニズムを解明するために、3つの仮説を検証しました。そしてLLMの学習能力の限界を探りました。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/08/AIDB_74020-1024x576.jpg)

**参照論文情報**

  * タイトル：What Do Language Models Learn in Context? The Structured Task Hypothesis

  * 著者：Jiaoda Li, Yifan Hou, Mrinmaya Sachan, Ryan Cotterell

  * 所属：ETH zurich

**本記事の関連研究**

  * [LLMのプロンプトに数百から数千の例を含める超長尺のコンテキスト内学習（In-context learning）とファインチューニングの性能比較](https://ai-data-base.com/archives/68564)

  * [Claude 3などのLLMはコンテキスト内学習によって線形回帰・非線形回帰問題タスクもこなす](https://ai-data-base.com/archives/67496)

  * [RAGとLong-Contextの比較、そしてハイブリッドで活用する新しい方法](https://ai-data-base.com/archives/73468)

  * [ロングコンテキストはRAGもText to SQLも解決するか Googleがケーススタディを実施](https://ai-data-base.com/archives/71486)

## 背景

LLMは、与えられた例示からタスクを学習し実行する能力、すなわち文脈内学習を示すと言われています。文脈内学習は、コード生成や教育、医療など幅広い分野で活用されています。しかし、文脈内学習がどのようなメカニズムで機能しているのかについては見解が分かれています。

文脈内学習の謎を解明するため、これまで研究者たちによってさまざまな仮説が提唱されてきました。仮説は大きく3つに分類されます。

1つ目の仮説は、「新しいことを学んでいるわけではなく、既に知っているタスクを識別しているだけ」というものです。つまり、LLMは訓練段階で多くのタスクを学習し、使用時には、与えられた例を見て、『これはどのタスクだろう？』と判断し、そのタスクを実行するのだという考え方です。

2つ目の仮説は、「LLMは訓練段階で「学び方」そのものを学習し、使用時には、「学び方」を使って新しいタスクを学習する」という考えです。LLMが本当の意味で新しいことを学べるという考え方です。

3つ目の仮説は、上記2つの中間的な考え方とも言えるもので「LLMは訓練段階で基本的なタスクを学習し、使用時には基本タスクを組み合わせて、新しく複雑なタスクを作り出す」という内容です。

今回、3つの仮説のどれが正しいのか、あるいは全て間違っているのかを確かめるべく、研究者らは一連の実験を行いました。

そして文脈内学習の本質や能力、限界についての新たな洞察が得られました。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信

[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

