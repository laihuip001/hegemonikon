---
source_url: https://ai-data-base.com/archives/75326
captured_at: 2026-01-19T07:34:38.311959
title: "マルチモーダルLLMの高難易度ベンチマーク『MMMU-Pro』で明らかになったこと - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

この記事では、MMMU-
Proという新しいベンチマークについて説明します。LLMが文章だけでなく画像を含めて問題どれだけ理解できるかをより正確にそして厳しく測るベンチマークです。

実際に最新のLLMでMMMU-
Proを試したところ、以前のベンチマーク（MMMU）より少ないスコアが出ました。MMMUの時点で「AGIを目指したベンチマーク」とされていたため、MMMU-
Proの格段の難しさを示しています。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/09/AIDB_75326-1024x576.jpg)

**参照論文情報**

  * タイトル：MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark

  * 著者：Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Ming Yin, Botao Yu, Ge Zhang, Huan Sun, Yu Su, Wenhu Chen, Graham Neubig

  * 所属：MMMU Team

**本記事の関連研究**

  * [AGIを見据えて専門家レベルの問題を集めたベンチマーク「MMMU」、GPT-4VやGemini Ultraでも正解率6割未満](https://ai-data-base.com/archives/61463)

  * [MMLUをアップデートしたベンチマーク『MMLU-Pro』Phi-3やLlama 3、Claude 3、GPT-4oなどの評価結果](https://ai-data-base.com/archives/70358)

  * [Appleが「LLMエージェントの評価」に特化したベンチマーク『MMAU』を開発 5領域5能力で測る](https://ai-data-base.com/archives/73656)

## 背景

LLMは画像と文章の組み合わせで難しい問題を解く力が大きく向上してきました。例えば、GPT-4oは[MMMU](https://ai-data-
base.com/archives/61463)というベンチマークで69.1%という高い正解率を出しました。MMMUとは、大学レベルのマルチモーダル問題で構成されたベンチマークで、どんどん優秀になるLLMが今後AGIに近づくことを見据えて難しい基準を設けたものです。

しかし、LLMは本当に深く理解して答えを出しているのでしょうか？それとも単に表面的な手がかりを使って正解を当てているだけなのでしょうか。

この疑問はとても重要です。なぜなら、もしLLMが本当の理解ではなく表面的な手がかりに頼っているだけなら、新しい状況では思わぬ間違いをする可能性があるからです。

そこで今回研究チームは、LLMの能力をより厳しくチェックする『MMMU-Pro』という新しいベンチマークを作りました。次の3つの特徴があります。

  1. 文章だけで答えられる問題は使わない

  2. 選択肢の数を増やして、当てずっぽうで正解する可能性を減らす

  3. 質問が画像の中に書かれていて、それを読み取る必要がある問題も含める

この中で、特に3つ目の特徴が大切とのことです。人間が自然に行っている「見ること」と「読むこと」を同時に行う能力をLLMがどれだけ持っているかを調べる必要があるためです。

実験では、最先端のLLMがこのような難しいベンチマークでどれほどの性能を見せるのかという点と、プロンプトのテクニックでどれほどスコアを伸ばせるのかという点が確かめられました。

以下で詳しく紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信

[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

