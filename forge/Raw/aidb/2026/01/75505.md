---
source_url: https://ai-data-base.com/archives/75505
captured_at: 2026-01-19T07:34:39.585735
title: "LLMの推論能力を戦略的に向上させる新しいプロンプト手法『SCoT』 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

この記事では、LLMの推論能力を向上させる新しいプロンプト手法、SCoT（戦略的な思考の連鎖）について説明します。SCoTは、まず問題を解く作戦を考え、作戦をベースとして考え方の道筋を作るといった2段階からなるアプローチです。

研究グループは、さまざまな課題でSCoTがうまくいくかを試し、通常のCoTと比べて多くの課題でより良い結果が出ることを明らかにしました。

この研究は、LLMの考える力をさらに高められる可能性を示しています。難しい課題にLLMを使う際の知見になるかもしれません。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/09/AIDB_75505-1024x576.jpg)

**参照論文情報**

  * タイトル：Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation

  * 著者：Yu Wang, Shiwan Zhao, Zhihu Wang, Heyuan Huang, Ming Fan, Yubo Zhang, Zhixing Wang, Haijun Wang, Ting Liu

  * 所属：Huawei Technologies Ltd., Xi’an Jiaotong University, Nankai University, Shanghai Jiao Tong University

**本記事の関連研究**

  * [CoTの推論ステップ数がLLMの推論能力に及ぼす影響を詳細に検証した結果](https://ai-data-base.com/archives/62364)

  * [LLMに非線形的な思考を与えてCoTを上回る性能を引き出す手法『IEP』と実行プロンプト CoTと組合せでさらに強力になる場合も](https://ai-data-base.com/archives/57628)

  * [GPT-4などのLLMに「自らの論理的な整合性をチェック」させるフレームワーク『LogiCoT』と実行プロンプト](https://ai-data-base.com/archives/55805)

## 背景

LLMの考える力を高めるプロンプト手法としてCoT（思考の連鎖）が注目されています。CoTはLLMに考え方の手順を示すことで、難しい問題を解けるようにするアプローチです。しかし、CoTには問題点があります。同じ問題でも、解き方によって答えの正確さが変わってしまうことがあるのです。つまり中間ステップが間違っていたらその先の答えがやはり間違ってしまうという問題です。

CoTの弱点を補強するために、これまでさまざまな方法が試されてきました。例えば、複数の解き方を試して、一番信頼できる答えを選ぶ方法や、外部の知識を使って考え方を強くする方法などです。しかし、計算に時間がかかりすぎたり、専門家の知識が必要だったりするアプローチは、実際に使うのが難しいです。

そこで今回新しいプロンプト手法「SCoT（Strategic Chain-of-
Thought）」が提案されました。SCoTは、「1回の指示で2つのことを行う」のがポイントのプロンプトフレームワークです。まず、問題を解くための最適な戦略を考え出し、次にその戦略を使って質の高い「考え方の道筋」を作り、最終的な答えを導き出します。

新手法SCoTの良いところは、質問を複数回行う必要はなく、外部の知識を必要とせず、1回の指示で効果的に考えられる点です。計算にかかる時間やコストを抑えつつ、LLMの推論能力を高められると期待されています。

さらに、SCoTを文脈内学習（プロンプト内に例を含んで学習させるプロンプト手法）に発展させ、最適な例を自動的に見つける方法も開発されました。実験によると、これでさらに性能が向上しています。

実験では、数学、常識、物理、空間、多段階の考え方など、さまざまな分野の8つのデータセットが使用されました。その結果、多くのモデルで大きな性能向上が確認されました。

以下でSCoTの方法論と実験結果について詳しく紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信

[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

