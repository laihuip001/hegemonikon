---
source_url: https://ai-data-base.com/archives/58540
captured_at: 2026-01-18T22:06:04.905341
title: "GPT-4、チューリングテストに一定の確率で成功"
publish_date: 2023.11.09
tags: ["実証", "LLM", "政治・社会", "手法\n426", "実証\n137", "分析\n54", "サーベイ\n37", "ベンチマーク・リソース\n22", "テクニカルレポート\n15", "ポジション\n8", "LLM\n659", "プロンプト技術\n156", "エージェント\n128", "コーディング\n56", "RAG\n50", "安全性\n39", "ペルソナ・シミュレーション\n36", "オープンソース\n25", "マルチモーダル\n23", "画像認識\n20", "セキュリティ\n16", "ハルシネーション\n16", "ファインチューニング\n16", "画像生成\n9", "音声\n8", "医療・ヘルスケア\n33", "政治・社会\n29", "エンタメ・アート\n23", "金融・経済\n10", "SE\n9", "教育・キャリア\n9", "製造・デザイン\n9", "ロボット\n6"]
conversion_method: browser_subagent_v1_parallel
batch_id: 1
is_premium: unknown
---

GPT-4、チューリングテストに一定の確率で成功
2023.11.09
2025.12.27
深堀り解説
クリップする
実証
LLM
政治・社会

GPT-4は、OpenAIが開発した大規模言語モデルで、ChatGPTなどで使用できるモデルの一種です。また、APIを通じて開発ツールとしても提供されています。

今回、GPT-4は「チューリングテスト」（AIが人間と区別できないほど自然に振る舞えるかどうかを調べる実験）において、一定の成績を達成したという報告がされています。この成績は、以前のモデルであるGPT-3.5や、初期のAIであるELIZAを上回っており、AIの進化を示す重要なデータといえます。ただし、人間のレベルにはまだ達していません。

本研究はカリフォルニア大学サンディエゴ校の研究チームによって実施されました。研究結果は、AI技術の発展だけでなく、社会におけるAIの役割や影響を理解するうえでも役立つものです。

ただし、これらの結果は特定の条件下でのものであり、すべての状況においてGPT-4が人間と同じように振る舞えるわけではありません。本記事では、以上のポイントを踏まえたうえで、GPT-4とチューリングテストに関する研究の概要を紹介します。

本研究の関連記事：LLMは世界モデルを持ち「物事がどのように位置づけられ、時間がどのように進行するか」を理解する可能性

背景

チューリングテストは、1950年にアラン・チューリングによって提案されたもので、「機械が人間と区別がつかないほど自然にコミュニケーションできるかどうか」を評価するために考案されました。

チューリングは、このテストを、質問に答えるゲーム形式で行うことを提案しました。ロマンチックな話題から数学まで、幅広いテーマに関するオープンな質問に機械が自然に回答できるかを試すことで、知能を測定できると考えたのです。

チューリングテストは発表以来、広く知られるようになりましたが、その一方で、知能の評価基準としての限界について批判も受けてきました。批評家の中には、「このテストだけでは知能の本質を完全に測ることはできない」と指摘する声もあります。

とはいえ、AI研究が盛んな現代においても、チューリングテストは、「自然なコミュニケーション能力」や「人間を欺く能力」を測定する手法として依然として有効とされています。

AIが人間のように振る舞えるようになれば、社会に与える影響は大きくなります。そのため、チューリングテストの評価基準としての有効性を改めて検討することも重要です。

また、チューリングテストは単に機械を評価するだけでなく、テストを行う人間（尋問者）自身についても、間接的に文化的・倫理的・心理的な背景を掘り下げることにつながっています。尋問者が質問を考え、それを洗練させる過程で、「人間らしさとは何か」「人間らしさのうち、最も模倣が難しい要素は何か」を暗黙的に明らかにするのです。

実験デザイン

研究者らは、チューリングテストの有効性を確かめるため、また現代におけるAIがどの程度人間に近いのかを知るために、GPT-4をチューリングテストで評価する実験を行いました。

以下で詳しく紹介します。

ここから限定コンテンツ
チューリングテスト実験のためのチャットインターフェース
チューリングテストの実装形式

本研究では、チューリングテストの2人プレイヤー形式を採用しました。質問者（インターロゲーター）が一人の証人に対して質問を行い、その証人が人間かAIかを判断する形式です。複数の人間参加者を各ゲームにオンラインで必要とするオリジナルの3人プレイヤー形式とは異なりますが、ゲームの標準的な解釈として採用されています。

チューリングテストの文脈でのゲーム会話からの抜粋
AI証人の選定

研究チームは、OpenAI APIを使用し、応答する側のAIとして25種類のLLM証人を作成しました。各LLM証人は、モデル（GPT-3.5またはGPT-4）、温度設定（0.2、0.5、または1.0）、および複数のプロンプトフレームワークで構成されていました。プロンプトには、インタラクションの文脈と、エージェントがどのように応答すべきかの指示が記述されていました。

インターフェースとゲームの流れ

参加者は、質問者または証人としてランダムに割り当てられ、各ゲームは5分間続きます。質問者は、制限時間内に証人がAIか人間かを判断し、その自信のレベルを報告する必要があります。

ELIZAの参加

ELIZAは、1966年にWeizenbaumによって開発されたルールベースのチャットボットで、本研究では比較のためのベースラインとして使用されました。ELIZAは、パターンマッチングと置換を組み合わせて、ユーザーの入力から抽出したテキストを織り交ぜたテンプレート応答を生成します。その単純さにもかかわらず、多くのユーザーがプログラムに人間の感情を感じたと報告されています。

実験の倫理的配慮

実験デザインには、参加者が他の参加者に対して攻撃的な発言をするリスクがありました。このリスクを軽減するために、攻撃的なメッセージの送信を防ぐコンテンツフィルターを使用しました。また、参加者が攻撃を報告できるシステムを作成しました。

本研究の関連記事：GPT-4をセラピストとして実行し、「認知の歪み」を診断させるためのフレームワーク『Diagnosis of Thought (DoT)』と実行プロンプト

実験結果
チューリングテストにおける様々な証人（人間、AI、GPTの異なるバージョン、ELIZA）の全体的な成功率（SR）
成功率の概要

この研究では、GPT-4、GPT-3.5、およびELIZAのチューリングテストにおける成功率が詳細に分析されました。以下は、それぞれのモデルが達成した成功率の概要です：

GPT-4: 最も効果的なプロンプトフレームワークを使用したGPT-4は、41%のゲームで人間と誤認されました。ELIZAやGPT-3.5を上回る結果ですが、人間の参加者（63%）の基準には及びませんでした。

GPT-3.5: GPT-3.5の成功率は14%で、GPT-4の成果に比べて大きく劣っています。

ELIZA: 1966年に開発されたルールベースのシステムであるELIZAは、27%のゲームで人間と誤認されました。驚くべきことに、GPT-4ベースのいくつかのプレイヤーと、GPT-3.5ベースのすべてのプレイヤーよりも高い成功率です。

選ばれた証人の成功率（SR）とゲーム数（n）に関する表
対話者が証人が人間かAIかを判断する正確さに関する図
対話者が証人に対して使用した戦略のトップ20を示す図
成功率の変動性

研究者たちは、使用されるプロンプトフレームワークによって成功率が大きく変動することを発見しました。GPT-4のパフォーマンスはプロンプトフレームワークによって大きく異なり、最高のもの（Sierra）は41%の成功率を示しましたが、最低のもの（Foxtrot）はわずか6%の成功率でした。GPT-3.5では、成功率は5%（Victor）から14%（Juliet）の範囲でした。

評価者の自信と精度

評価者の自信はAIに対するゲームでは比較的よく調整されており、自信が精度と正の相関を示していました。しかし、人間の証人に対する推測においては、自信と精度の間には関係がありませんでした。

尋問者の自信と、彼らが対話していた証人のタイプ（AIまたは人間）を識別する正確性とを比較
対話者が使用した戦略によるゲームの平均正確さを示す図
初回ゲームにおけるパフォーマンス

研究者たちは、評価者がまだ慣れていない初回のゲームにおいては、モデルの成功率は高まるだろうと仮説を立てました。最もパフォーマンスが良かった証人は、初回のゲームで全体の成功率と同様の結果を示しました。人間の証人は64%のゲームで成功し、SierraとNovemberのGPT-4プロンプトはそれぞれ40%と41%の成功率を達成しました。パフォーマンスが低かったGPT-4の証人は、初回のゲームで成功率が向上しましたが、ELIZAの成功率は13%に低下しました。

最も経験豊富な対話者と最も経験が少ない対話者が使用した戦略の平均ゲームインデックス（対話者がプレイしたゲームの数）を示す図

上記の結果は、人間の評価者がAIと人間の区別を行う際の難しさと、AIが自然なコミュニケーションを模倣する能力（の凄さおよび限界）を示しています。また、チューリングテストが現代のAIの能力を評価することにおいても有効なフレームワークであることを示唆しています。

本研究の関連記事：ポーカーなど不完全情報ゲームを「心の理論」で上手にプレイする GPT-4ベースの『Suspicion（疑心）-Agent』松尾研など開発

主な結論
1. GPT-4のチューリングテストにおけるパフォーマンス

GPT-4は、チューリングテストにおいて、最も効果的なプロンプトを使用した場合、41%のゲームで人間と誤認されました。ELIZAが27%、GPT-3.5が14%という結果を上回るものですが、人間の参加者（63%）や偶然の基準には及ばない結果でした。このことから、GPT-4がチューリングテストに「合格」したとは言えないと結論づけられています。

2. 人間の判断における言語的（テキスト）スタイルの重要性

参加者の判断は、主に言語的スタイル（35%）と社会感情的特性（27%）に基づいていました。つまり、知能だけではチューリングテストに合格するには不十分なのかもしれません。また、人々の教育レベルやAIについての知識が、AIを見抜く能力に直接関係していないことを示しています。つまり、AIについてよく知っている人でも、AIが人間であるかのように見せかける試みにだまされることがあるということです。

審問者がAIの証人が実際にAIであると判断した理由のトップ20
審問者が証人が人間であると判断した理由のトップ20
3. チューリングテストの有用性

チューリングテストは、知能のテストとして限界があるとも言われれきましたが、現代においても、依然として有用性があると主張されています。AIが人間に偽装する能力は、広範な社会的影響を持つ可能性があり、人間らしさを判断するさまざまな戦略や基準の有効性を分析することが重要です。

上記の結論は、GPT-4が特定の条件下で人間と見なされる可能性があること、成功率がまだ50%に達していないこと、人間の判断が言語的スタイルと社会感情的特性に大きく依存していること、そしてチューリングテストが知能だけを測るものではないことを示しています。チューリングテストは、自然なコミュニケーションや欺瞞に対する評価手段として有用であることが示唆される結果でした。

まとめ

本研究は、GPT-4がチューリングテストにおいて人間と誤認される可能性を探求するものでした。

実験結果は、GPT-4が特定の条件下で41%の確率で人間と見なされることを示しましたが、これは人間の参加者の63%には及ばず、完全な「合格」とは言えません。

人間の判断は言語的スタイルと社会感情的特性に大きく依存しており、教育水準やLLMに対する知識がAIの検出率に直接的な影響を与えるわけではないことが明らかになりました。
またチューリングテストは、知能の測定だけでなく、社会的交流や欺瞞を評価する手段としても有用であることが示されています。

本研究は、AIの進化と人間らしさの基準に関する議論に貢献するものとして発表されました。
なお、GPT-4の能力は本論文執筆当初のものであり、今後のアップデートによって状況が変わる可能性があることに注意ください。

参照論文情報

・タイトル：Does GPT-4 Pass the Turing Test?
・著者：Cameron Jones and Benjamin Bergen
・所属：UC San Diego
・URL：https://doi.org/10.48550/arXiv.2310.20216

クリップする
🔒 LLMなどの生成AIの背後にある思考プロセスは人間とは全く異なるかもしれないことを示す仮説『生成AIのパラドックス』
🔒 AGI（汎用人工知能）の原則6箇条とレベル5段階