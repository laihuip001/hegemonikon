---
source_url: https://ai-data-base.com/archives/62480
captured_at: 2026-01-18T22:02:09.568383
title: "最高水準のオープンソースLLM『Mixtral 8x7B』は内部で専門家が切り替わる高効率モデル"
publish_date: 2024.01.16
tags: ["サーベイ37", "ペルソナ・シミュレーション36", "オープンソース25", "エンタメ・アート23", "SE9", "コーディング56", "画像認識20", "音声8", "教育・キャリア9", "実証137", "画像生成9", "医療・ヘルスケア33", "ハルシネーション16", "ポジション8", "オープンソース", "ロボット6", "製造・デザイン9", "ファインチューニング16", "ベンチマーク・リソース22", "分析54", "テクニカルレポート15", "安全性39", "マルチモーダル23", "金融・経済10", "セキュリティ16", "テクニカルレポート", "LLM", "政治・社会29", "手法426", "LLM659", "RAG50", "エージェント128", "プロンプト技術156"]
conversion_method: browser_subagent_v1_parallel
batch_id: 4
is_premium: unknown
---

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F62480&text=%E6%9C%80%E9%AB%98%E6%B0%B4%E6%BA%96%E3%81%AE%E3%82%AA%E3%83%BC%E3%83%97%E3%83%B3%E3%82%BD%E3%83%BC%E3%82%B9LLM%E3%80%8EMixtral+8x7B%E3%80%8F%E3%81%AF%E5%86%85%E9%83%A8%E3%81%A7%E5%B0%82%E9%96%80%E5%AE%B6%E3%81%8C%E5%88%87%E3%82%8A%E6%9B%BF%E3%82%8F%E3%82%8B%E9%AB%98%E5%8A%B9%E7%8E%87%E3%83%A2%E3%83%87%E3%83%AB) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F62480&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F62480)

[テクニカルレポート](https://ai-data-base.com/archives/type-tag/technical-report)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)[オープンソース](https://ai-data-base.com/archives/tech-tag/%e3%82%aa%e3%83%bc%e3%83%97%e3%83%b3%e3%82%bd%e3%83%bc%e3%82%b9)

Mistral AIから、最新のモデルであるMixtral 8x7Bについての論文が公開されました。  
タスクに応じて専門家を選ぶ仕組みによって、大きなパラメータでも計算コストを効率よくするのが特徴とのことです。

Mixtral 8x7Bは、Llama 2 70BやGPT-3.5に匹敵あるいは上回る性能を示すとされています。また、商用利用も可能です。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2024/01/AIDB_62480-1024x576.jpg)
