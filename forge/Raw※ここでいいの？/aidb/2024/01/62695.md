---
source_url: https://ai-data-base.com/archives/62695
captured_at: 2026-01-18T22:02:09.573300
title: "外部からの攻撃で一度でも欺瞞を学んだLLMは現在の技術では完全回復が難しい"
publish_date: 2024.01.18
tags: ["サーベイ37", "ペルソナ・シミュレーション36", "オープンソース25", "エンタメ・アート23", "SE9", "コーディング56", "画像認識20", "セキュリティ", "音声8", "教育・キャリア9", "実証137", "画像生成9", "医療・ヘルスケア33", "ハルシネーション16", "ポジション8", "ロボット6", "製造・デザイン9", "ファインチューニング16", "ベンチマーク・リソース22", "分析54", "テクニカルレポート15", "安全性39", "マルチモーダル23", "金融・経済10", "セキュリティ16", "LLM", "分析", "政治・社会29", "手法426", "LLM659", "RAG50", "エージェント128", "プロンプト技術156"]
conversion_method: browser_subagent_v1_parallel
batch_id: 4
is_premium: unknown
---

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F62695&text=%E5%A4%96%E9%83%A8%E3%81%8B%E3%82%89%E3%81%AE%E6%94%BB%E6%92%83%E3%81%A7%E4%B8%80%E5%BA%A6%E3%81%A7%E3%82%82%E6%AC%BA%E7%9E%9E%E3%82%92%E5%AD%A6%E3%82%93%E3%81%A0LLM%E3%81%AF%E7%8F%BE%E5%9C%A8%E3%81%AE%E6%8A%80%E8%A1%93%E3%81%A7%E3%81%AF%E5%AE%8C%E5%85%A8%E5%9B%9E%E5%BE%A9%E3%81%8C%E9%9B%A3%E3%81%97%E3%81%84) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F62695&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F62695)

[分析](https://ai-data-base.com/archives/type-tag/analysis)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)[セキュリティ](https://ai-data-base.com/archives/tech-tag/%e3%82%bb%e3%82%ad%e3%83%a5%e3%83%aa%e3%83%86%e3%82%a3)

人間と似たようにLLMも欺瞞（隠れた目的を持ってごまかす）的な行動をとることがあることが実験で示されました。

加えて、一度でも欺瞞的な行動を学んだモデルは現状その特徴を取り除くことは通常できないとのことです。

本記事では研究報告の抜粋を紹介します。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2024/01/AIDB_62695-1024x576.jpg)
