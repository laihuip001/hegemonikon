---
source_url: https://ai-data-base.com/archives/63749
captured_at: 2026-01-18T22:02:09.600583
title: "複数LLMに議論させ、「回答に自信がないときは発言を控えさせ」て応答品質を向上する方法"
publish_date: 2024.02.06
tags: ["サーベイ37", "ペルソナ・シミュレーション36", "オープンソース25", "エンタメ・アート23", "SE9", "コーディング56", "画像認識20", "音声8", "教育・キャリア9", "実証137", "画像生成9", "医療・ヘルスケア33", "ハルシネーション16", "ポジション8", "手法", "ロボット6", "製造・デザイン9", "ファインチューニング16", "ベンチマーク・リソース22", "分析54", "テクニカルレポート15", "安全性39", "マルチモーダル23", "金融・経済10", "セキュリティ16", "LLM", "政治・社会29", "手法426", "LLM659", "RAG50", "エージェント128", "プロンプト技術156"]
conversion_method: browser_subagent_v1_parallel
batch_id: 4
is_premium: unknown
---

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F63749&text=%E8%A4%87%E6%95%B0LLM%E3%81%AB%E8%AD%B0%E8%AB%96%E3%81%95%E3%81%9B%E3%80%81%E3%80%8C%E5%9B%9E%E7%AD%94%E3%81%AB%E8%87%AA%E4%BF%A1%E3%81%8C%E3%81%AA%E3%81%84%E3%81%A8%E3%81%8D%E3%81%AF%E7%99%BA%E8%A8%80%E3%82%92%E6%8E%A7%E3%81%88%E3%81%95%E3%81%9B%E3%80%8D%E3%81%A6%E5%BF%9C%E7%AD%94%E5%93%81%E8%B3%AA%E3%82%92%E5%90%91%E4%B8%8A%E3%81%99%E3%82%8B%E6%96%B9%E6%B3%95) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F63749&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F63749)

[手法](https://ai-data-base.com/archives/type-tag/method)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)

知識は常に変化するため、どんなにLLMの知識を拡張しようと、欠落や古くなった情報が残ってしまう可能性があります。

既存手法は自己分析能力に欠け、データセットへの過度の依存があることから、今回ワシントン大学やUCバークレーなどの研究者らはLLM同士が互いの知識を検証する手法を提案しました。

3つのLLM、4つの質問応答タスクで実施した実験により、ベースラインに対して最大19.3%の精度向上を確認しました。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2024/02/AIDB_63749-1024x576.jpg)
