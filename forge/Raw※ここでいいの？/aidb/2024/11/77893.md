---
source_url: https://ai-data-base.com/archives/77893
captured_at: 2026-01-18T23:29:09.394532
title: "OpenAIが新しくLLMの事実性評価ベンチマーク『SimpleQA』をリリース 実用に役立つ知見も得られる"
publish_date: 2024.11.04
tags: ["画像認識 20", "サーベイ 37", "安全性 39", "政治・社会 29", "分析 54", "オープンソース 25", "マルチモーダル 23", "SE 9", "テクニカルレポート 15", "手法", "手法 426", "エージェント 128", "金融・経済 10", "RAG 50", "ベンチマーク・リソース 22", "ファインチューニング 16", "LLM", "ロボット 6", "プロンプト技術 156", "ハルシネーション 16", "コーディング 56", "LLM 659", "ペルソナ・シミュレーション 36", "ポジション 8", "セキュリティ 16", "実証 137", "エンタメ・アート 23", "製造・デザイン 9", "教育・キャリア 9", "画像生成 9", "音声 8", "医療・ヘルスケア 33"]
conversion_method: fast_collect_v1
batch_id: 1
---

# OpenAIが新しくLLMの事実性評価ベンチマーク『SimpleQA』をリリース 実用に役立つ知見も得られる

2024.11.052025.12.22

[深堀り解説](https://ai-data-base.com/archives/category/deep-dive)

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAQAAQMAAABF07nAAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAJZJREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAewEEHgABB9i6GAAAAABJRU5ErkJggg==) ![](https://ai-data-base.com/wp-content/uploads/2024/10/AIDB_77893_eye.jpeg)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F77893&text=OpenAI%E3%81%8C%E6%96%B0%E3%81%97%E3%81%8FLLM%E3%81%AE%E4%BA%8B%E5%AE%9F%E6%80%A7%E8%A9%95%E4%BE%A1%E3%83%99%E3%83%B3%E3%83%81%E3%83%9E%E3%83%BC%E3%82%AF%E3%80%8ESimpleQA%E3%80%8F%E3%82%92%E3%83%AA%E3%83%AA%E3%83%BC%E3%82%B9%E3%80%80%E5%AE%9F%E7%94%A8%E3%81%AB%E5%BD%B9%E7%AB%8B%E3%81%A4%E7%9F%A5%E8%A6%8B%E3%82%82%E5%BE%97%E3%82%89%E3%82%8C%E3%82%8B) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F77893&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F77893)

[手法](https://ai-data-base.com/archives/type-tag/method)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)

本記事では、LLMが事実に基づいて回答する能力を評価するための新しいベンチマークを紹介します。

LLMは「ハルシネーション（幻覚）」と呼ばれる問題を抱えており、根拠のない情報をしばしば出力してしまうことが問題となっています。そこで研究チームは、意図的に難しい質問を収集した新しい評価基準を開発しました。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2024/11/AIDB_77893-1024x576.png)

**本記事の関連研究**

  * [500以上の実世界のマルチモーダルタスクを含む、過去最大規模の評価ベンチマーク『MEGA-BENCH』登場](https://ai-data-base.com/archives/74837)

  * [複雑なプログラミングタスクに特化したベンチマーク『BigCodeBench』登場 最新モデルでも60%](https://ai-data-base.com/archives/76844)

  * [マルチモーダルLLMの高難易度ベンチマーク『MMMU-Pro』で明らかになったこと](https://ai-data-base.com/archives/75326)

  * [Appleが「LLMエージェントの評価」に特化したベンチマーク『MMAU』を開発 5領域5能力で測る](https://ai-data-base.com/archives/73656)




## 背景

LLMの「事実に基づいた正確な回答」の問題が大きな課題として注目されています。現在のLLMには、事実と異なる情報を出力してしまう問題があります。根拠のない回答や誤った情報を生成してしまうことがあり、この現象は「ハルシネーション（幻覚）」と呼ばれています。LLMの実用化における大きな障壁となっています。

LLMが生成する長い文章には、多くの事実に関する記述が含まれますが、それら1つ1つの記述が正しいかどうかを確認するのは非常に困難です。

このような背景から、研究チームは新しい評価基準を作ることにしました。短い質問に対する単一の明確な答えのみを扱い、答えが正しいかどうかを簡単に判定できる特徴を持っています。また、GPT-4にとって難しい質問を意図的に集めており、歴史、科学技術、芸術など幅広い分野から問題を収集しています。

以前にも「TriviaQA」や「Natural Questions」といった同様の評価基準が存在しましたが、現在のLLMにとっては簡単すぎる問題となっています。そのため、現代のLLMの性能をより正確に測れる新しい基準が必要とされていたのです。

なお、LLMが「短文における事実を確かめる質問」にどれだけ正確に答えられるかを測定することに特化しています。そのため、より長い文章での事実の正確性については、また別の研究課題として残されています。

研究チームは今回ベンチマークを公開することで、LLMの事実に基づく回答能力を測定する共通の基準を全員に提供すること、そしてより信頼性の高いLLMの開発を促進することを目指しています。

実験ではOpenAIのGPT-4o、GPT-4o-mini、o1-mini、o1-preview、そしてAnthropicのClaude-3-haiku、Claude-3-sonnet、Claude-3-opus、Claude-3.5-sonnetの能力が検証されました。その結果、質問を繰り返す中で最も頻繁に得られた回答の正解率が高いことなど、実用面で役立つ知見も得られています。

以下でベンチマークの詳細と評価結果を紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信



[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F77893&text=OpenAI%E3%81%8C%E6%96%B0%E3%81%97%E3%81%8FLLM%E3%81%AE%E4%BA%8B%E5%AE%9F%E6%80%A7%E8%A9%95%E4%BE%A1%E3%83%99%E3%83%B3%E3%83%81%E3%83%9E%E3%83%BC%E3%82%AF%E3%80%8ESimpleQA%E3%80%8F%E3%82%92%E3%83%AA%E3%83%AA%E3%83%BC%E3%82%B9%E3%80%80%E5%AE%9F%E7%94%A8%E3%81%AB%E5%BD%B9%E7%AB%8B%E3%81%A4%E7%9F%A5%E8%A6%8B%E3%82%82%E5%BE%97%E3%82%89%E3%82%8C%E3%82%8B) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F77893&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F77893)
