---
source_url: https://ai-data-base.com/archives/86276
captured_at: 2026-01-18T23:30:05.860548
title: "LLMはシステムプロンプトをどれほど守れるか"
publish_date: 2025.03.03
tags: ["画像認識 20", "サーベイ 37", "安全性 39", "政治・社会 29", "分析 54", "オープンソース 25", "プロンプト技術", "マルチモーダル 23", "SE 9", "テクニカルレポート 15", "手法", "手法 426", "エージェント 128", "金融・経済 10", "RAG 50", "ベンチマーク・リソース 22", "ファインチューニング 16", "LLM", "ロボット 6", "プロンプト技術 156", "ハルシネーション 16", "LLM 660", "コーディング 56", "ペルソナ・シミュレーション 36", "ポジション 8", "セキュリティ 16", "実証 137", "エンタメ・アート 23", "製造・デザイン 9", "教育・キャリア 9", "画像生成 9", "音声 8", "医療・ヘルスケア 33"]
conversion_method: fast_collect_v1
batch_id: 1
---

# LLMはシステムプロンプトをどれほど守れるか

2025.03.042025.12.22

[深堀り解説](https://ai-data-base.com/archives/category/deep-dive)

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAQAAQMAAABF07nAAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAJZJREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAewEEHgABB9i6GAAAAABJRU5ErkJggg==) ![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86276_eye.jpeg)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F86276&text=LLM%E3%81%AF%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E3%82%92%E3%81%A9%E3%82%8C%E3%81%BB%E3%81%A9%E5%AE%88%E3%82%8C%E3%82%8B%E3%81%8B) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F86276&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F86276)

[手法](https://ai-data-base.com/archives/type-tag/method)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)[プロンプト技術](https://ai-data-base.com/archives/tech-tag/prompt)

本記事では、皆さんご存じの「システムプロンプト」に関する新しい研究を紹介します。

研究者たちは、LLMがシステムプロンプトにどれくらい正確に従えるかを評価し、さらにその性能を高める方法を探しています。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2025/03/AIDB_86276-1024x576.png)

**本記事の関連研究**

  * [対話の中でユーザーの好みを学ぶ手法『CIPHER』 （プロンプトテンプレートあり）](https://ai-data-base.com/archives/76527)

  * [プロンプトに5つほど”価値観の例”を示すだけで、LLMは特定の文化に適応した回答ができるようになるとの報告](https://ai-data-base.com/archives/75111)

  * [「LLMはプロンプトから新しいタスクを学べるのか？」 という根本的な問いに対する3つの仮説を検証](https://ai-data-base.com/archives/74020)




## 背景

「システムプロンプト」とは、LLMアプリケーション（例えばChatGPTなど）の動作を制御するための特別な指示文です。もともとはOpenAIのGPT APIで小さな機能として導入されましたが、現在ではモデルの安全性や品質を保つために欠かせない重要な要素となっています。

主に次のような目的で使われています。

  * 不適切なコンテンツや悪意のある利用を防ぐ

  * LLMが従うべきルールやガイドラインを設定する

  * LLMが特定の性格やキャラクターとして振る舞えるようにする




一言でいうと、「ユーザーからの指示よりも優先される、特別な命令」として働きます。

しかし指示に従うのは、LLMが学習を通して身につけている振る舞いのため、完全に確実ではありません。そのため、意図しない誤りが起きたり、悪意ある攻撃によってセキュリティが破られる可能性もあります。

現在のLLMはシステムプロンプトにある程度従うことができますが、未知の状況や複雑な条件に直面した際にうまく対応できるかはまだよくわかっていません。また、従来の評価方法は「プロンプト攻撃」や「ロールプレイ」のように、限定的なケースでしか性能を検証できていません。

さらに、これまでの研究では質の高いデータが不足していたため、「なぜLLMがプロンプトに従えるのか」、あるいは「どうすればもっと正確に従えるようになるのか」を詳しく調査することが難しかったという経緯があります。

そこで研究者たちは今回、実際に使われている本物のシステムプロンプトを多数収集し、LLMが複数の制約を同時に扱えるかどうかを総合的に評価しました。そのうえで、LLMがシステムプロンプトにもっと忠実に従えるようになる方法を探っています。

以下では、その研究成果を詳しく紹介していきます。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信



[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F86276&text=LLM%E3%81%AF%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E3%82%92%E3%81%A9%E3%82%8C%E3%81%BB%E3%81%A9%E5%AE%88%E3%82%8C%E3%82%8B%E3%81%8B) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F86276&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F86276)
