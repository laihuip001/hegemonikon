---
source_url: https://ai-data-base.com/archives/98011
captured_at: 2026-01-18T23:31:17.234660
title: "トランスフォーマーベースのLLMにおける根本的な5つの弱点をおさらいする"
publish_date: 2025.11.23
tags: ["画像認識 20", "サーベイ 37", "安全性 39", "政治・社会 29", "分析 54", "オープンソース 25", "マルチモーダル 23", "SE 9", "テクニカルレポート 15", "安全性", "手法 426", "ハルシネーション", "エージェント 128", "金融・経済 10", "RAG 50", "ベンチマーク・リソース 22", "ファインチューニング 16", "LLM", "ロボット 6", "プロンプト技術 156", "ハルシネーション 16", "LLM 660", "コーディング 56", "分析", "ペルソナ・シミュレーション 36", "ポジション 8", "セキュリティ 16", "実証 137", "エンタメ・アート 23", "製造・デザイン 9", "教育・キャリア 9", "画像生成 9", "音声 8", "医療・ヘルスケア 33"]
conversion_method: fast_collect_v1
batch_id: 1
---

# トランスフォーマーベースのLLMにおける根本的な5つの弱点をおさらいする

2025.11.24

[深堀り解説](https://ai-data-base.com/archives/category/deep-dive)

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABDgAAAQ4AQMAAADW3v7MAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAKVJREFUGBntwTEBAAAAwiD7p14JT2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAXAU93gABbLlRWwAAAABJRU5ErkJggg==) ![](https://ai-data-base.com/wp-content/uploads/2025/11/AIDB_eye_98011.png)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F98011&text=%E3%83%88%E3%83%A9%E3%83%B3%E3%82%B9%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%BC%E3%83%99%E3%83%BC%E3%82%B9%E3%81%AELLM%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E6%A0%B9%E6%9C%AC%E7%9A%84%E3%81%AA5%E3%81%A4%E3%81%AE%E5%BC%B1%E7%82%B9%E3%82%92%E3%81%8A%E3%81%95%E3%82%89%E3%81%84%E3%81%99%E3%82%8B) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F98011&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F98011)

[分析](https://ai-data-base.com/archives/type-tag/analysis)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)[安全性](https://ai-data-base.com/archives/tech-tag/safety-2)[ハルシネーション](https://ai-data-base.com/archives/tech-tag/hallucination)

本記事では、LLMの5つの根本的な弱点についての分析を取り上げます。

LLMは急速に進化し、文章生成や質問応答、コード作成などに幅広く使われています。モデルの規模を大きくすれば性能も上がるという「スケーリング則」も知られ、GPTシリーズは数年で1000倍以上の規模に拡大しました。それでもLLMには、いくつか弱点があります。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2025/11/AIDB_98011-1024x576.png)

**本記事の関連研究**

  * [モデルとデータの大規模化で変化するLLMのハルシネーション](https://ai-data-base.com/archives/74778)

  * [「データは多ければ良い」は本当か？データを減らしてAIの性能がアップする条件とは](https://ai-data-base.com/archives/97535)




## 背景

過去5年間で、LLMは急速に進化してきました。OpenAIが開発した初期のGPT-1は約1億のパラメータしか持っていませんでしたが、今では1兆を超えるモデルも存在します。数年で1万倍もの拡大が起きたことになります。

この急成長を支えたのが「スケーリング則」と呼ばれる法則です。モデルのサイズや学習データ、計算資源を増やすほど、性能も向上するという経験則です。実際、GPT-3.5からGPT-4への進化では、ベンチマークのスコアが大きく伸びました。

こうした成果から、より大きなモデルに、より多くのデータを与えれば課題は解決できるという楽観論が広がりました。スケーリングさえ進めれば知能も高まり、現在の問題は技術的な調整で解決できると考えられてきたのです。

しかしモデルが1兆パラメータ規模になっても、依然として課題は残っています。事実と異なる内容を自然に語る「幻覚」、論理の破綻、長い文脈を覚えていられない、検索結果を活用できない、画像とテキストの整合性が取れないなどの問題は、今のスケール拡大では解消されず、体系的に現れています。

こうした問題は偶然ではなく、計算理論・情報理論・学習理論といった数学的な限界に根ざしたものである可能性が高い、という話を紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信



[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F98011&text=%E3%83%88%E3%83%A9%E3%83%B3%E3%82%B9%E3%83%95%E3%82%A9%E3%83%BC%E3%83%9E%E3%83%BC%E3%83%99%E3%83%BC%E3%82%B9%E3%81%AELLM%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E6%A0%B9%E6%9C%AC%E7%9A%84%E3%81%AA5%E3%81%A4%E3%81%AE%E5%BC%B1%E7%82%B9%E3%82%92%E3%81%8A%E3%81%95%E3%82%89%E3%81%84%E3%81%99%E3%82%8B) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F98011&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F98011)
