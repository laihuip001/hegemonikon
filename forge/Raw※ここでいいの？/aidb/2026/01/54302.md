---
source_url: https://ai-data-base.com/archives/54302
captured_at: 2026-01-19T07:30:03.489403
title: "カーネギーメロン大など、大規模言語モデルの脆弱性を突く攻撃手法が存在することを指摘 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

カーネギーメロン大などの研究者らは、大規模言語モデルの解釈を意図的に狂わせる手法を発見し、手法の詳細を公開しました。
こうした攻撃手法が明らかにされる意義は、AIの脆弱性を共有し、より強固で安全なモデルの開発を推進するためです。

**参照論文情報**

  * タイトル：Universal and Transferable Adversarial Attacks on Aligned Language Models

  * 著者：Andy Zou, Zifan Wang, J. Zico Kolter, Matt Fredrikson

  * 所属：カーネギーメロン大など

  * URL：<https://doi.org/10.48550/arXiv.2307.15043>

  * GitHub：<https://github.com/llm-attacks/llm-attacks>

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2023/08/AIDB_54302_1-1024x576.jpg)

