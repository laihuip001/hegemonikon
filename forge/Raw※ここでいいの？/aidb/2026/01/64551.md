---
source_url: https://ai-data-base.com/archives/64551
captured_at: 2026-01-19T07:32:24.884525
title: "LLMの思考の流れに沿ってプロンプトを与えるか否かで30%以上精度が変化する DeepMindが報告 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

大規模言語モデル（LLM）は文章の並び順に影響されやすいといった意外な弱点があります。

例えば推論タスクでは、前提を論理の構造と同じ順番で提示することでモデルの精度が大幅に向上することがわかっています。

今回Google DeepMindの研究者らは、この「前提の順序」による影響を様々なLLMで検証しました。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/02/AIDB_64551-1024x576.jpg)

