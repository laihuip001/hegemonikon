---
source_url: https://ai-data-base.com/archives/66502
captured_at: 2026-01-19T07:32:53.700714
title: "LLMが生成した長いテキストにおける「事実性」を自動で評価するLLMエージェントフレームワーク『SAFE』Google DeepMindが開発 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

Google DeepMindとスタンフォード大学の研究者らは、LLMの長文における事実性を評価するための新しい手法を提案しました。

なお事実性とは、言語モデルの出力が事実と矛盾していないことを意味します。

研究者らは、数千の質問からなるプロンプトセットLongFactと、長文の応答を個別の事実に分解して各事実の正確性をGoogle検索を用いた多段階の推論プロセスで評価する『SAFE』を開発しました。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/03/AIDB_-66502-1024x576.jpg)

