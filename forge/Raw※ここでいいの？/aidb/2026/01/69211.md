---
source_url: https://ai-data-base.com/archives/69211
captured_at: 2026-01-19T07:33:26.533383
title: "スタンフォード大学の研究者ら、GPT-4oとGemini1.5 Proで「マルチモーダルモデルにおける『Many-Shot』の効果」を検証 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

スタンフォード大学の研究者らは、画像とテキストを組み合わせたマルチモーダルモデルが、プロンプト内で例を大量に載せるとより賢くなるかを調査しました。

多くのデータセットで実験を行い、例示が少ない場合と多い場合での性能を比較しました。また、複数の質問を一度に処理する方法も検討し、その効果を評価しました。GPT-4oとGemini1.5
Proには、共通する傾向がある一方で、大きな違いも示されています。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/05/AIDB_69211-1024x576.jpg)

**参照論文情報**

  * タイトル：Many-Shot In-Context Learning in Multimodal Foundation Models

  * 著者：Yixing Jiang, Jeremy Irvin, Ji Hun Wang, Muhammad Ahmed Chaudhry, Jonathan H. Chen, Andrew Y. Ng

  * 所属：スタンフォード大学

**本記事の関連研究** ：

  * [プロンプトに例を多く載せるほど、どんなタスクでも性能が上がるのか？DeepMindによる『Many-shot Learning』の実験結果](https://ai-data-base.com/archives/67883)

  * [LLMにおける超長尺のコンテキスト内学習（In-context learning）とファインチューニングの性能比較](https://ai-data-base.com/archives/68564)

  * [マルチモーダルLLMにおけるハルシネーション（幻覚）の原因と対策](https://ai-data-base.com/archives/68720)

  * [マルチモーダルLLMにおける欠点と原因を明らかにする調査研究の結果](https://ai-data-base.com/archives/68367)

## 背景

LLMが少数の例示をコンテキスト内（プロンプト）に含めることでパフォーマンスを大幅に向上させる能力はコンテキスト内学習（In-Context
Learning）として広く知られるようになっています。LLMがモデルのパラメータを更新せずに少数のサンプルから学習し、新しいタスクに適応するものです。そして最近では、マルチモーダルモデルもコンテキスト内のサンプルから学習する能力を示しています。

しかし、モデルのコンテキストウィンドウ（モデルが一度に処理できる入力の長さ）が限られているために、例示の数を増やすことがどれほどパフォーマンスに与えるのか、その影響は今まで詳しくわかっていません。マルチモーダルモデルは画像表現に多数の視覚トークン（画像を表現するための単位）を使用するためなおさらです。

ところが最近、GPT-4oでは128,000トークン、Gemini 1.5
Proでは最大100万トークンという非常に長いコンテキストウィンドウが実現され、例示を大幅に増やすことの効果を調べることが可能になりました。

これまでのところ、コンテキスト内学習のスケーリング（大規模化）について、例示の数を増やすとLLMのパフォーマンスが向上することが研究で示されてきましたが、それでもテストされた例示の数は少なく、テキストのみのベンチマークに限定されています。とりわけマルチモーダルのコンテキスト内学習の研究はまだ初期段階にあり、巨大なコンテキストウィンドウを利用して例示の数を増やすことの効果は調べられていません。

そこで研究者らは、マルチモーダルモデルにおける多数の例示を用いたコンテキスト内学習の能力を調査するために、例示の数を数桁スケールアップしてモデルのパフォーマンスをベンチマークする大規模な実験を行いました。マルチモーダルモデルのアプリケーションやドメインへの適応可能性を探ることを目的としています。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信

[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

