---
source_url: https://ai-data-base.com/archives/76177
captured_at: 2026-01-19T07:34:47.634685
title: "OpenAIの新しいモデルo1-preview、従来のLLMと比べて「計画能力」で圧倒的な性能向上 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

本記事では、アリゾナ州立大の研究グループによるLLMの計画能力を評価した研究を紹介します。

研究チームは計画能力を測定するための自作のベンチマークであるPlanBenchを用いて、OpenAIのo1を含む最新モデルの性能を分析しました。様々な難易度の問題で、「精度」「効率性」「コスト」「結果の保証（正確性や信頼性）」を評価しています。

その結果、o1は大幅な性能向上を示しました。しかし、まだまだ課題も残されています。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/09/AIDB_76177-1024x576.jpg)

**参照論文情報**

  * タイトル：LLMs Still Can’t Plan; Can LRMs? A Preliminary Evaluation of OpenAI’s o1 on PlanBench

  * 著者：Karthik Valmeekam, Kaya Stechly, Subbarao Kambhampati

  * 研究機関：Arizona State University

**本記事の関連研究**

  * [CoT（思考の連鎖）は数学や論理で劇的に性能を向上させる一方、常識や知識のタスクでほとんど効果がない](https://ai-data-base.com/archives/75942)

  * [OpenAI、大規模言語モデルの数学能力を大きく向上させることに成功](https://ai-data-base.com/archives/52505)

  * [単純に生成回数を増やすとLLMの性能が大幅に向上する「推論時のスケーリング則」](https://ai-data-base.com/archives/75838)

## 背景

人工知能の分野では、目標を達成するための行動計画を立てる能力が非常に重要視されてきました。計画を立てる能力は人間の知性のコアな部分だと考えられているためです。

やがてLLMが登場し、研究者たちは、「LLMにも人間のような計画能力があるのではないか」と考えるようになりました。そして、2022年にPlanBenchというベンチマークが開発されました。LLMの計画能力を評価するためのテストです。

しかし、これまで多くの新しいモデルが登場してきたにもかかわらず、PlanBenchでの成績はあまり向上しませんでした。これは意外な結果でした。

そんな中、OpenAIが新しいモデル「o1」を発表しました。o1は従来のLLMとは異なり、推論に特化して設計・訓練されたモデルだとされています。OpenAIはこれを「大規模推論モデル（LRM）」と呼んでいます。

この新しいモデルの登場を機に、研究者たちは改めてPlanBenchを使って、最新のLLMやLRM（要するにo1）の計画能力を総合的に評価することにしました。

その結果、o1の性能は確かに従来のモデルを大きく上回っていました。しかし、まだ完璧とは言えない結果でした。

以下で詳しく紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信

[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

