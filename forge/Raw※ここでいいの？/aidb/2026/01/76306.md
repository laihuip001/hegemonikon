---
source_url: https://ai-data-base.com/archives/76306
captured_at: 2026-01-19T07:34:50.241742
title: "LLMの論理的推論能力をステップバイステップ以上に向上させる手法『Logic-of-Thought』プロンプティング（テンプレートつき） - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

本記事では、LLMがより上手く論理的な考え方ができるようにする新しい方法「Logic-of-
Thought（LoT）」を紹介します。LoTは、今までの方法で起こっていた「大切な情報が抜け落ちてしまう」という問題を解決しようとしています。

LoTの優れているポイントは、今まで使われてきたChain-of-Thought（CoT）やSelf-Consistency（SC）、Tree-of-
Thoughts（ToT）といった方法と一緒に使えることです。実験では、LoTを使うと確かにLLMの能力が上がることが分かりました。

この研究の主な成果は3つあります。1つ目は新しいLoTという方法を考え出したこと、2つ目は他の方法とLoTを組み合わせたこと、3つ目は様々な課題でLoTが役立つことを確かめたことです。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/09/AIDB_76306-1024x576.jpg)

**参照論文情報**

  * タイトル：Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in Large Language Models

  * 著者：Tongxuan Liu, Wenjiang Xu, Weizhe Huang, Xingyu Wang, Jiaxing Wang, Hailong Yang, Jing Li

  * 研究機関：University of Science and Technology of China, Institute of Automation, Chinese Academy of Sciences, Beihang University, JD.com

**本記事の関連研究**

  * [LLMの「自己対話」により複雑な問題の解決能力を飛躍的に向上させる手法『Iteration of Thought』](https://ai-data-base.com/archives/76134)

  * [LLMの推論能力を戦略的に向上させる新しいプロンプト手法『SCoT』](https://ai-data-base.com/archives/75505)

  * [CoT（思考の連鎖）は数学や論理で劇的に性能を向上させる一方、常識や知識のタスクでほとんど効果がない](https://ai-data-base.com/archives/75942)

  * [LLMの出力をJSON形式などに構造化すると「思考の柔軟性」や精度に影響することが示唆される](https://ai-data-base.com/archives/74336)

## 背景

多くのLLMは、数学や複雑な論理的な考え方が必要な問題になると、まだ人間には及びません。

よく使われるのが「Chain-of-
Thought（思考の連鎖）」というプロンプティング手法で、難しい問題を小さな段階に分けて考えていくアプローチです。人間が頭の中で「ここからこう考えて、次にこうなって…」と段階を踏んで考えるのと似ています。

Chain-of-Thoughtが考案された後、Tree-of-ThoughtsやGraph-of-
Thoughtsといった、より複雑な考え方の流れを真似る方法も生まれました。人間の頭の中でいろいろな考えが枝分かれしたり、つながったりする様子を模倣しようとする手法です。

ところが、これまでに考案されたどの方法を使っても「途中の考え方は正しいのに、最後の答えがそれと合わない」といった現象が起きます。これを「不忠実な推論」と呼びます。

この問題を解決しようと、今度は論理学の考え方を取り入れる試みも始まりました。例えば、文章から論理式という特別な形の式を取り出して、それを使って考えを進める方法などです。しかし、この方法にも弱点がありました。文章から論理式を作る時に、大切な情報が抜け落ちてしまうことがあるのです。そうすると、正しい答えにたどり着けません。

こういった事情から、研究者たちは今回、論理的な考え方の精度を上げながら、かつ大切な情報を落とさない新しい方法を考案しました。

以下で詳しく紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信

[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

