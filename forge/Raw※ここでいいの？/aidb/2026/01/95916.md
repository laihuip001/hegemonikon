---
source_url: https://ai-data-base.com/archives/95916
captured_at: 2026-01-19T07:26:58.225808
title: "人を支えるAIの現在地 働く・学ぶ・考えるの再設計 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

本企画では、[AIDBのX](https://x.com/ai_database)で紹介されたいくつかの最新AI研究を、ダイジェスト形式でお届けします。

普段の有料会員向け記事では、技術的な切り口から研究を詳しく紹介していますが、この企画では科学的な知識として楽しめるよう、テーマの概要をわかりやすくお伝えします。

今週は、仕事の成果や学びの体験、意思決定の進め方まで、人の力を底上げする使い方に焦点を当てました。実社会タスクでの到達度、教材の個別化、原始社会のふるまいの再現、音の“想像”による推論、多数決での精度向上、心の歪みの検出まで、生活に近い場面で効く工夫を追います。

研究に対する反応が気になる方は、ぜひAIDBのXアカウント
([@ai_database](https://x.com/ai_database))で紹介ポストもご覧ください。中には多くの引用やコメントが寄せられた話題もあります。

また、一部は[Posfie](https://posfie.com/@ai_database)にも掲載されており、読者のリアクションをまとめたページもあわせて公開しています。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2025/10/AIDB_science-1024x576.png)

## AIは今のところ仕事を奪わず、むしろ給料を押し上げた

シカゴ大学の研究者らの調査によると、  
多くの人が「AIが仕事を奪う」と心配していますが、今のところ、それが現実に起きているとは言えない状況のようです。

例として、LLMの影響を受けやすい職業、プログラマーや文章を書く仕事、ウェブ開発者などの人たちは、失業率はほとんど変わらずむしろ給料が上がっているそうです。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAlUAAAL0AQMAAAAfiFC6AAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAE5JREFUGBntwQENAAAAwiD7p34ON2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAcCjgcAAByilstQAAAABJRU5ErkJggg==)![](https://ai-
data-base.com/wp-content/uploads/2025/10/image.png)

なぜこんなことが起きているのかというと、AIが人間の代わりをするのではなく、人間の仕事を手助けする道具として機能しているからだと言います。

実際に、LLMを使えるようになった労働者は生産性が向上し、より価値の高い仕事ができるようになっています。

ただし、これは短期的な結果であり、長期的にどうなるかはまだ分からないと警告されています。  
また、すべての職業で同じことが起きるわけではないのも重要なポイントです。

AI技術が労働市場に与える影響は変化していく可能性があるため、引き続き注意していくべきと考えられています。

[この話題へのみんなの反応を見る (Xに移動)](https://x.com/ai_database/status/1970095131585052933)

#### 参考文献

The (Short-Term) Effects of Large Language Models on Unemployment and Earnings

<https://arxiv.org/abs/2509.15510>

Danqing Chen, Carina Kane, Austin Kozlowski, Nadav Kunievsky, James A. Evans

University of Chicago

* * *

## 自分専用に変わる教科書 学び方も内容も自動で最適化

GoogleのチームがLLMを使って教科書体験を根本的に作り変えるための実験を報告しています。  
一人ひとりに合わせた教科書を自動的に作ることで、実際に学習効果も高まることが示されたとのことです。

研究者たちが作ったのは、読む人の年齢や興味に合わせて内容を自動的に書き換えるシステムです。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAmIAAAM8AQMAAADOa16WAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAFVJREFUGBntwTEBAAAAwiD7p14KP2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHAQ/EgAAR9sRtkAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2025/10/image-1.png)

実際に高校生60人で実験したところ、このシステムで学んだグループは普通の教科書で学んだグループよりもテストの成績が良く、3日後に内容を覚えているかを確認したテストでも同様の結果が出ました。  
また、生徒たちの9割以上が「また使いたい」と答えました。

例えばニュートンの第三法則を説明する時に、バスケットボール好きな生徒にはバスケの例で説明するといった具合です。

さらに同じ内容を音声授業やスライド、マインドマップなど様々な形式で提供し、生徒は自分に合った学び方を選びます。

こうした技術を活用すると教育のパーソナライズがさらに一歩前進するかもしれないと期待されています。

（なお今回の実験における対照群は、教科書のPDFをAdobe Acrobatで読む生徒たちでした）

[この話題へのみんなの反応を見る (Xに移動)](https://x.com/ai_database/status/1970426636664471823)

#### 参考文献

Towards an AI-Augmented Textbook

<https://arxiv.org/abs/2509.13348>

LearnLM Team, Google: Alicia Martín, Amir Globerson, Amy Wang, Anirudh
Shekhawat, Anna Iurchenko, Anisha Choudhury, Avinatan Hassidim, Ayça Çakmakli,
Ayelet Shasha Evron, Charlie Yang, Courtney Heldreth, Diana Akrong, Gal
Elidan, Hairong Mu, Ian Li, Ido Cohen, Katherine Chou, Komal Singh, Lev
Borovoi, Lidan Hackmon, Lior Belinsky, Michael Fink, Niv Efron, Preeti Singh,
Rena Levitt, Shashank Agarwal, Shay Sharon, Tracey Lee-Joe, Xiaohong Hao, Yael
Gold-Zamir, Yael Haramaty, Yishay Mor, Yoav Bar Sinai, Yossi Matias

Google

#### 関連記事

> [🔒 「学ぶ人」に対してLLMが出すフィードバックの精度を高めるエージェント手法](https://ai-data-
> base.com/archives/89588)

* * *

## 生き残りに効く道徳は場面で変わる AIで原始社会を再現

カリフォルニア大学などの研究者らがLLMエージェントにさまざまな道徳観を持たせ「原始時代での生存競争」をシミュレートしたところ、その時代において生き残るために有利だった道徳観が状況ごとに示唆されました。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAxoAAAQAAQMAAABcZL1iAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAHpJREFUGBntwQENAAAAwiD7p34PBwwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADgXJQPAAFFjR5UAAAAAElFTkSuQmCC)![](https://ai-
data-base.com/wp-content/uploads/2025/10/image-2-794x1024.png)

仮想人間たちは、「完全に利己的な者」「家族だけを大切にする者」「協力的な仲間を重視する者」「誰に対しても優しい者」という異なる道徳観をセットされました  
限られた食料を巡って競争し、協力し、時には争いながら、子孫を残そうとします。

その結果、通常の環境では家族を大切にするタイプが最も生き残りやすかったのですが、他者との交流にコストがかかる環境では利己的なタイプが有利になりました。

また、誰にでも優しいタイプは、暴力を振るわないため信頼を得やすい利点がある一方で、悪意ある者に搾取されやすいという弱点も明らかになりました。

道徳が人類の進化においてどのような役割を果たしてきたのか、新しい視点から理解する手がかりとして興味深いアプローチです。

[この話題へのみんなの反応を見る (Xに移動)](https://x.com/ai_database/status/1970755518021960093)

#### 参考文献

An LLM-based Agent Simulation Approach to Study Moral Evolution

<https://arxiv.org/abs/2509.17703>

Zhou Ziheng, Huacong Tang, Mingjie Bi, Yipeng Kang, Wanying He, Fang Sun,
Yizhou Sun, Ying Nian Wu, Demetri Terzopoulos, Fangwei Zhong

University of California, Beijing Institute for General Artificial
Intelligence, Beijing Normal University

#### 関連記事

> [🔒 再現性のある人間行動シミュレーションへ LLMのふるまいを数値で制御する](https://ai-data-
> base.com/archives/95343)

* * *

## 聞こえない音を思い浮かべる “耳の想像”でことばのAIが賢くなる

研究者たちは、AIが「音を聞かずに音について考えることができるか」を考えています。

人間は、例えば「雷の音」と聞けば「ゴロゴロと大きな音」を頭の中で鳴らし、その結果「鳥の鳴き声より低くて重い音」といったことを考えられます。

現在のLLMには、そうした音の能力は欠けています。  
表面的な言語データを多少持っていたとしても、推論の材料や方法が足りないのです。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAvsAAAQAAQMAAABFygTtAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAHZJREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAM4FhA8AAajeamAAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2025/10/image-3-763x1024.png)

そこで研究者たちは、LLMが音について考える際に、音の情報を頭に浮かばせるように訓練してみました。すると、LLMの音に関する理解力がしっかり向上しました。

つまり、LLMがまだ人間のような感覚的な理解に欠けている側面がある一方で、適切な方法で訓練すれば新しいモダリティも「想像」して推論できるようになるという話です。

[この話題へのみんなの反応を見る (Xに移動)](https://x.com/ai_database/status/1971132808304394252)

#### 参考文献

AuditoryBench++: Can Language Models Understand Auditory Knowledge without
Hearing?

<https://arxiv.org/abs/2509.17641>

Hyunjong Ok, Suho Yoo, Hyeonjun Kim, Jaeho Lee

Pohang University of Science and Technology, HJ AILAB, Korea Advanced
Institute of Science and Technology

* * *

## 何度も答えさせて多数決 計算を抑えて精度を伸ばすコツ

ある問題に対してLLMに何回も答えを作らせて最も多かった回答を使うとよい、という話は有名ですが、

無限（∞）個の答えを作ると理論上極めて高い性能になることが明らかにされました。

日本人研究グループによる報告。

しかし、実行するには無限の計算量が必要になってしまいます。

そこで、  
研究者らは、「バラバラな答えが出てくる場合には多めに回答」させ、「同じ答えが出がちな時には少なめにする」方法を開発。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAugAAAQAAQMAAACJUz4GAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAHRJREFUGBntwYEAAAAAw6D7U0/gCNUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC4AngPAAFBk8FfAAAAAElFTkSuQmCC)![](https://ai-
data-base.com/wp-content/uploads/2025/10/image-4-744x1024.png)

この柔軟な考え方によって、計算量の増加はほどほどに抑えつつも精度を高く引き上げることに成功したそうです。

さらに、性能の低いモデルでも、得意分野が違えば強いモデルと組み合わせることで全体の性能が向上するという発見も得られたようです。  
どのモデル同士をどんな比率で混ぜるのかはとても難しい問題ですが、小規模な数であれば解が導き出せるとのこと。

この「最も多く出た答えを採用する」というシンプルなアイデアは、他の複雑な手法より優れる場合も多いようで、現実的に検討すべきアプローチかもしれません。

[この話題へのみんなの反応を見る (Xに移動)](https://x.com/ai_database/status/1971550077627117749)

#### 参考文献

Best-of-∞(\infty) — Asymptotic Performance of Test-Time Compute

<https://arxiv.org/abs/2509.21091>

Junpei Komiyama, Daisuke Oba, Masafumi Oyamada

Mohamed bin Zayed University of Artificial Intelligence, New York
University,RIKEN AIP, Institute of Science Tokyo, NEC Corporation

#### 関連記事

> [🔒 生成回数を増やすだけでLLMの性能が大幅に向上するシンプルな法則 実用上のポイント](https://ai-data-
> base.com/archives/75838)

> [🔒 LLMの推論能力は単純に文脈を繰り返し提示するだけでも大幅に向上 最大で30%改善](https://ai-data-
> base.com/archives/76967)

* * *

## 本物の仕事で実力測定 先端LLMは専門家に迫る

OpenAIが、今のLLMは「現実の仕事」をどれくらいできるか測定したところ、  
人間の業界の専門家にかなり近づいていることがわかりました。 そして仕事の失敗要因で最も多かったのは「指示をちゃんと理解できていない場合」でした。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAygAAAQAAQMAAAAwYu9nAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAHtJREFUGBntwQENAAAAwiD7p34PBwwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4FSYDwABfCv1SwAAAABJRU5ErkJggg==)![](https://ai-
data-base.com/wp-content/uploads/2025/10/image-6-808x1024.png)

今回研究者たちは、経済で重要な44の職種から、実際のプロが日々やっている仕事を1,320個集めました。  
平均14年の経験を持つベテランが普段やっている仕事をそのままテスト問題にしたのです。  
一つの仕事を終えるのに平均6.7時間かかるような、本格的な内容です。

結果は良好。詳しく見ると、  
Claude Opus 4.1が、OpenAIのGPT-5より平均的に良い成績を出していました。  
なお、Claudeは文書の見た目やレイアウトが得意で、GPT-5は指示通りに正確に作業することが得意という、それぞれの特徴も見えてきたそうです。

そしていずれもタスクの説明が短くて曖昧だと、性能は大きく落ちることもわかりました。

今後への示唆として、人間が「確認・修正する」役割に徹することで、時間とコストを節約できる場合もあることが述べられています。

[この話題へのみんなの反応を見る (Xに移動)](https://x.com/ai_database/status/1971821041078227180)

#### 参考文献

GDPVAL: EVALUATING AI MODEL PERFORMANCE ON REAL-WORLD ECONOMICALLY VALUABLE
TASKS

<https://openai.com/index/gdpval/>

PDF :
<https://cdn.openai.com/pdf/d5eb7428-c4e9-4a33-bd86-86dd4bcf12ce/GDPval.pdf>

Tejal Patwardhan, Rachel Dias, Elizabeth Proehl, Grace Kim, Michele Wang,
Olivia Watkins, Simon Posada Fishman, Marwan Aljubeh, Phoebe Thacker, Laurance
Fauconnet, Natalie S. Kim, Patrick Chao, Samuel Miserendino, Gildas Chabot,
David Li, Michael Sharman, Alexandra Barr, Amelia Glaese, Jerry Tworek

OpenAI

#### 関連記事

> [🔒 LLMが仕事のタスク・生産性・労働需要に与える影響](https://ai-data-base.com/archives/95498)

> [🔒 ビジネスプロセス評価におけるLLMの使いどころ](https://ai-data-base.com/archives/88825)

* * *

## 発言から“心のクセ”を見つける 感情・論理・行動で細かく判定

研究者たちは、人の発言から「認知の歪み」を自動的に見つけ出すシステムをLLMベースで作れると報告しています。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAqoAAAQAAQMAAAATHOmbAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAG1JREFUGBntwTEBAAAAwiD7p14JT2AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFwFXA8AAbXKsOEAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2025/10/image-5-682x1024.png)

また、まず感情、次に論理的な思考、そして行動と3つに分けて見ることで、こうした歪みをより正確に見つけられるということを発見したそうです。

認知の歪みというのは、例えば「一度失敗したからもう終わり」というような極端な考え方や、「みんなが私を嫌っているに違いない」という根拠のない思い込みのことです。

なお、モデルはそれぞれ異なる種類の認知の歪みを見つけ出す傾向があります。意見を組み合わせるとよい場合があります。

さらに、国と年齢が違うと、同じような認知の歪みでも表現の仕方が全く違うことも明らかになりました。これは検出精度に大きく影響します。

世界の人口の半分が生涯で何らかのメンタルヘルスの問題を経験するとも言われているため、こうした技術は活用が期待されます。

[この話題へのみんなの反応を見る (Xに移動)](https://x.com/ai_database/status/1972120195784470821)

#### 参考文献

Multi-View Attention Multiple-Instance Learning Enhanced by LLM Reasoning for
Cognitive Distortion Detection

<https://arxiv.org/abs/2509.17292>

Jun Seo Kim, Hyemi Kim, Woo Joo Oh, Hongjin Cho, Hochul Lee, Hye Hyeon Kim

Gachon University, Korea Telecom Research, Yonsei University

#### 関連記事

> [🔒 LLMをセラピストとして実行し、「認知の歪み」を診断させるためのプロンプト手法](https://ai-data-
> base.com/archives/56696)

## まとめ

見えてくるのは、人工知能が置き換えではなく後押しとして働く姿です。学習素材や支援は人ごとに作り直され、状況に合わせてふるまいを選び、欠けた感覚は思い描いて補い、計算は要所に配分して精度を稼ぐ。さらに、言葉の裏にある感情・論理・行動や文化差まで取り込むことで、人に寄り添う設計が現実味を帯びてきました。

このダイジェストでは、機能紹介にとどまらず、その背後の意図や運用上の注意点まで見渡します。次回も、広がる活用の中で私たちがどこで関与し、どんな手順で確かめて進めるのか——その境目を一緒に見極めていきましょう。

