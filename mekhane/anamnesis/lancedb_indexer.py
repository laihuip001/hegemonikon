#!/usr/bin/env python3
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] <- mekhane/anamnesis/
r"""
PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©]

P3 â†’ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æ¤œç´¢ãŒå¿…è¦
   â†’ LanceDB ã«ã‚ˆã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ç´¢å¼•
   â†’ lancedb_indexer ãŒæ‹…ã†

Q.E.D.

---

LanceDB ã‚¤ãƒ³ãƒ‡ã‚¯ã‚µãƒ¼ for ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«

M:\Brain\.hegemonikon\sessions\ ã«ä¿å­˜ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’
LanceDB ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã—ã€å…¨æ–‡æ¤œç´¢ãƒ»ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚
"""

import re
from pathlib import Path
from typing import List, Optional

import lancedb
from pydantic import BaseModel
from mekhane.anamnesis.lancedb_compat import get_table_names

# è¨­å®š
SESSIONS_DIR = Path(r"M:\Brain\.hegemonikon\sessions")
DB_PATH = Path(r"M:\Brain\.hegemonikon\lancedb")
TABLE_NAME = "sessions"

# Compiled Regexes
RE_COMMENT = re.compile(r"/\*.*?\*/", re.DOTALL)
RE_MEDIA = re.compile(r"@media\s*\([^)]*\)\s*\{[^}]*\}")
RE_MARKDOWN_CSS = re.compile(r"\.markdown[-\w]*\s*\{[^}]*\}")
RE_THOUGHT = re.compile(r"Thought for <?\d+s\s*")
RE_NEWLINES = re.compile(r"\n{3,}")
RE_EXPORTED = re.compile(r"\d{4}-\d{2}-\d{2}T[\d:.]+")
RE_MESSAGES = re.compile(r"(\d+)")


# PURPOSE: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚¹ã‚­ãƒ¼ãƒ
class SessionDocument(BaseModel):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚¹ã‚­ãƒ¼ãƒ"""

    filename: str
    title: str
    exported_at: str
    message_count: int
    content: str  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¨æ–‡
    content_preview: str  # æ¤œç´¢çµæœè¡¨ç¤ºç”¨


# PURPOSE: ã‚»ãƒƒã‚·ãƒ§ãƒ³ md ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¤‰æ›
def parse_session_file(filepath: Path) -> Optional[SessionDocument]:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ md ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¤‰æ›"""
    try:
        # Optimized single-pass streaming parser
        with filepath.open(encoding="utf-8") as f:
            title = "Untitled"
            exported_at = ""
            message_count = 0

            body_lines = []
            in_body = False
            line_count = 0

            for line in f:
                stripped = line.strip()

                if not in_body:
                    line_count += 1

                    # Metadata extraction (limited to first few lines)
                    if line_count <= 5:
                        if line.startswith("# "):
                            title = line[2:].strip()

                    if line_count <= 10:
                        if "**Exported**" in line and not exported_at:
                            match = RE_EXPORTED.search(line)
                            if match:
                                exported_at = match.group()

                        if "**Messages**" in line and message_count == 0:
                            match = RE_MESSAGES.search(line)
                            if match:
                                message_count = int(match.group(1))

                    if stripped == "---":
                        in_body = True
                    continue

                # In body
                if line.startswith("## ğŸ¤–") or line.startswith("## ğŸ‘¤"):
                    continue
                if stripped == "---":
                    continue
                if stripped:
                    body_lines.append(stripped)

        full_content = "\n".join(body_lines)

        # CSS ãƒã‚¤ã‚ºã‚’é™¤å»
        full_content = RE_COMMENT.sub("", full_content)
        full_content = RE_MEDIA.sub("", full_content)
        full_content = RE_MARKDOWN_CSS.sub("", full_content)
        full_content = RE_THOUGHT.sub("", full_content)

        # é€£ç¶šã™ã‚‹ç©ºè¡Œã‚’é™¤å»
        full_content = RE_NEWLINES.sub("\n\n", full_content).strip()

        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã® 500 æ–‡å­—ï¼‰
        preview = full_content[:500].replace("\n", " ")

        return SessionDocument(
            filename=filepath.name,
            title=title,
            exported_at=exported_at,
            message_count=message_count,
            content=full_content[:10000],  # æœ€å¤§ 10KB
            content_preview=preview,
        )

    except Exception as e:
        print(f"[!] Error parsing {filepath.name}: {e}")
        return None


# PURPOSE: å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
def index_sessions():
    """å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹"""
    print("[*] LanceDB Session Indexer")
    print(f"    Sessions: {SESSIONS_DIR}")
    print(f"    Database: {DB_PATH}")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    DB_PATH.mkdir(parents=True, exist_ok=True)
    db = lancedb.connect(str(DB_PATH))

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åé›†
    session_files = list(SESSIONS_DIR.glob("*.md"))
    print(f"[*] Found {len(session_files)} session files")

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
    documents: List[SessionDocument] = []

    for filepath in session_files:
        doc = parse_session_file(filepath)
        if doc and len(doc.content) > 50:
            documents.append(doc)

    print(f"[*] Parsed {len(documents)} valid documents")

    if not documents:
        print("[!] No documents to index")
        return

    # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å‰Šé™¤ã—ã¦å†ä½œæˆ
    if TABLE_NAME in get_table_names(db):
        db.drop_table(TABLE_NAME)
        print(f"[*] Dropped existing table: {TABLE_NAME}")

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
    data = [doc.model_dump() for doc in documents]

    # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    table = db.create_table(TABLE_NAME, data)
    print(f"[âœ“] Created table: {TABLE_NAME} ({len(documents)} rows)")

    # Full-Text Search ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
    try:
        table.create_fts_index("content", replace=True)
        print(f"[âœ“] Created FTS index on 'content'")
    except Exception as e:
        print(f"[!] FTS index creation failed: {e}")

    print("[âœ“] Indexing complete!")

    return db, table


# PURPOSE: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢
def search_sessions(query: str, limit: int = 5):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢"""
    db = lancedb.connect(str(DB_PATH))

    if TABLE_NAME not in get_table_names(db):
        print("[!] No sessions indexed. Run index_sessions() first.")
        return []

    table = db.open_table(TABLE_NAME)

    # Full-Text Search
    try:
        results = table.search(query, query_type="fts").limit(limit).to_list()
        return results
    except Exception as e:
        print(f"[!] Search error: {e}")
        return []


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "search":
        # æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰
        if len(sys.argv) < 3:
            print("Usage: python lancedb_indexer.py search <query>")
            sys.exit(1)

        query = " ".join(sys.argv[2:])
        print(f"[*] Searching for: {query}")

        results = search_sessions(query)

        if results:
            print(f"\n=== Found {len(results)} results ===\n")
            for i, r in enumerate(results, 1):
                print(f"[{i}] {r['title']}")
                print(f"    File: {r['filename']}")
                print(f"    Preview: {r['content_preview'][:100]}...")
                print()
        else:
            print("[!] No results found")
    else:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ¢ãƒ¼ãƒ‰
        index_sessions()
