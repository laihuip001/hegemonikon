#!/usr/bin/env python3
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] <- mekhane/anamnesis/ A0â†’Libraryæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ãŒå¿…è¦â†’library_searchãŒæ‹…ã†
"""
Library Search Engine â€” 3å±¤æ¤œç´¢ã§ Library 112ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç™ºå‹•ã™ã‚‹

Layer 1: activation_triggers ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ (é«˜é€Ÿãƒ»æ­£ç¢º)
Layer 2: hegemonikon_mapping ãƒ™ãƒ¼ã‚¹ WF é€£æº (æ§‹é€ çš„)
Layer 3: LanceDB ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ (ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯)

USAGE:
    from mekhane.anamnesis.library_search import LibrarySearch
    searcher = LibrarySearch()
    results = searcher.search_by_triggers("å“è³ª")
"""

import sys
from pathlib import Path
from typing import Optional

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from mekhane.anamnesis.models.prompt_module import PromptModule

# Library base path
LIBRARY_BASE = Path.home() / "Sync" / "10_ğŸ“š_ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï½œLibrary" / "prompts"

# LanceDB data path
LANCE_DIR = Path(__file__).parent / "data"

TABLE_NAME = "prompts"


# PURPOSE: Library ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³
class LibrarySearch:
    """Library ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³"""

    # PURPOSE: LibrarySearch ã®åˆæœŸåŒ– â€” LanceDB ã«é…å»¶æ¥ç¶š
    def __init__(self, lance_dir: Optional[str] = None):
        self._lance_dir = Path(lance_dir) if lance_dir else LANCE_DIR
        self._db = None
        self._table = None

    # PURPOSE: LanceDB ã«é…å»¶æ¥ç¶š
    def _connect(self):
        """LanceDB ã«é…å»¶æ¥ç¶š"""
        if self._db is None:
            import lancedb
            self._db = lancedb.connect(str(self._lance_dir))
            if TABLE_NAME in self._db.table_names():
                self._table = self._db.open_table(TABLE_NAME)
            else:
                raise RuntimeError(
                    f"ãƒ†ãƒ¼ãƒ–ãƒ« '{TABLE_NAME}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
                    f"å…ˆã« index_library.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
                )

    # â”€â”€ Layer 1: activation_triggers ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ â”€â”€

    # PURPOSE: activation_triggers ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰éƒ¨åˆ†ä¸€è‡´æ¤œç´¢
    def search_by_triggers(self, keyword: str, limit: int = 20) -> list[PromptModule]:
        """
        activation_triggers ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰éƒ¨åˆ†ä¸€è‡´æ¤œç´¢

        Args:
            keyword: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (éƒ¨åˆ†ä¸€è‡´ã€å¤§å°æ–‡å­—ç„¡è¦–)
            limit: æœ€å¤§ä»¶æ•°

        Returns:
            ãƒãƒƒãƒã—ãŸ PromptModule ã®ãƒªã‚¹ãƒˆ
        """
        self._connect()
        keyword_lower = keyword.lower()

        # LanceDB ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³
        all_rows = self._table.to_pandas()
        results = []

        for _, row in all_rows.iterrows():
            triggers_str = row.get("activation_triggers", "")
            name = row.get("name", "")
            mapping = row.get("hegemonikon_mapping", "")

            # triggers, name, mapping ã®ã„ãšã‚Œã‹ã«ãƒãƒƒãƒ
            searchable = f"{triggers_str} {name} {mapping}".lower()
            if keyword_lower in searchable:
                module = PromptModule.from_dict(row.to_dict())
                results.append(module)

            if len(results) >= limit:
                break

        return results

    # â”€â”€ Layer 2: hegemonikon_mapping ãƒ™ãƒ¼ã‚¹ WF é€£æº â”€â”€

    # PURPOSE: hegemonikon_mapping ãƒ™ãƒ¼ã‚¹ã® WF é€£æºæ¤œç´¢
    def search_by_mapping(self, wf_name: str) -> list[PromptModule]:
        """
        hegemonikon_mapping ãƒ™ãƒ¼ã‚¹ã® WF é€£æºæ¤œç´¢

        Args:
            wf_name: WF å (ä¾‹: "/dia", "A2 Krisis", "O1 NoÄ“sis")

        Returns:
            ãƒãƒƒãƒã—ãŸ PromptModule ã®ãƒªã‚¹ãƒˆ
        """
        self._connect()

        # WF åã‹ã‚‰ HGK ã‚·ãƒªãƒ¼ã‚ºã‚’æ¨å®š
        wf_to_series = {
            "/noe": "O1", "/bou": "O2", "/zet": "O3", "/ene": "O4",
            "/met": "S1", "/mek": "S2", "/sta": "S3", "/pra": "S4",
            "/pro": "H1", "/pis": "H2", "/ore": "H3", "/dox": "H4",
            "/kho": "P1", "/hod": "P2", "/tro": "P3", "/tek": "P4",
            "/euk": "K1", "/chr": "K2", "/tel": "K3", "/sop": "K4",
            "/pat": "A1", "/dia": "A2", "/gno": "A3", "/epi": "A4",
        }

        # å…¥åŠ›ã‚’æ­£è¦åŒ–
        search_terms = [wf_name]
        clean_wf = wf_name.lstrip("/").lower()

        # WF çŸ­ç¸®å â†’ ã‚·ãƒªãƒ¼ã‚º ID
        for wf, series in wf_to_series.items():
            if clean_wf == wf.lstrip("/") or clean_wf == series.lower():
                search_terms.append(series)
                search_terms.append(wf)
                break

        all_rows = self._table.to_pandas()
        results = []
        seen_ids = set()

        for _, row in all_rows.iterrows():
            mapping = row.get("hegemonikon_mapping", "").lower()
            for term in search_terms:
                if term.lower() in mapping:
                    module = PromptModule.from_dict(row.to_dict())
                    if module.id not in seen_ids:
                        results.append(module)
                        seen_ids.add(module.id)
                    break

        return results

    # â”€â”€ Layer 3: LanceDB ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ â”€â”€

    # PURPOSE: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ (LanceDB vector search)
    def search_semantic(self, query: str, limit: int = 5) -> list[dict]:
        """
        ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ (LanceDB vector search)

        Args:
            query: è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒª
            limit: æœ€å¤§ä»¶æ•°

        Returns:
            æ¤œç´¢çµæœã®è¾æ›¸ãƒªã‚¹ãƒˆ (score, module æƒ…å ±å«ã‚€)
        """
        self._connect()
        from mekhane.anamnesis.index import Embedder

        embedder = Embedder()
        query_vec = embedder.embed(query)

        raw_results = self._table.search(query_vec).limit(limit).to_list()

        results = []
        for r in raw_results:
            module = PromptModule.from_dict(r)
            results.append({
                "module": module,
                "score": r.get("_distance", 0.0),
                "name": module.name,
                "mapping": module.hegemonikon_mapping,
                "essence": module.essence[:200] if module.essence else "",
            })

        return results

    # â”€â”€ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€

    # PURPOSE: ID ã‹ã‚‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—
    def get_module(self, module_id: str) -> Optional[PromptModule]:
        """ID ã‹ã‚‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—"""
        self._connect()
        all_rows = self._table.to_pandas()

        for _, row in all_rows.iterrows():
            if row.get("id") == module_id:
                return PromptModule.from_dict(row.to_dict())
        return None

    # PURPOSE: ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°ã‚’è¿”ã™
    def list_categories(self) -> dict[str, int]:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ•°ã‚’è¿”ã™"""
        self._connect()
        all_rows = self._table.to_pandas()

        categories: dict[str, int] = {}
        for _, row in all_rows.iterrows():
            cat = row.get("category", "unknown")
            categories[cat] = categories.get(cat, 0) + 1

        return dict(sorted(categories.items()))

    # PURPOSE: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†…ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç·æ•°
    def count(self) -> int:
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†…ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç·æ•°"""
        self._connect()
        return self._table.to_pandas().shape[0]
