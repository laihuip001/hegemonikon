#!/usr/bin/env python3
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©]
"""
PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©]

P3 â†’ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æŒ¯ã‚Šè¿”ã‚ŠãŒå¿…è¦
   â†’ è‡ªå‹•ãƒŠã‚¤ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ
   â†’ night_review ãŒæ‹…ã†

Q.E.D.

---

Night Review Generator - HegemonikÃ³n M8 AnamnÄ“sis
==================================================

ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ã‹ã‚‰ãƒŠã‚¤ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã€‚

Usage:
    python -m mekhane.anamnesis.night_review generate           # æœ¬æ—¥ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼
    python -m mekhane.anamnesis.night_review generate --all     # å…¨å±¥æ­´é¡åŠ
    python -m mekhane.anamnesis.night_review list               # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§

Requirements:
    pip install google-genai python-dotenv
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime, date, timedelta
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, asdict

from mekhane.anamnesis.vault import VaultManager

# Load environment
from dotenv import load_dotenv

# Paths
PROJECT_ROOT = Path(__file__).parent.parent.parent
BRAIN_DIR = Path(r"C:\Users\makar\.gemini\antigravity\brain")
OUTPUT_DIR = Path(r"M:\Brain\.hegemonikon\session_summaries")
ENV_FILE = PROJECT_ROOT / ".env.local"

# Load API key
load_dotenv(ENV_FILE)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")


@dataclass
class SessionInfo:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±"""
    session_id: str
    title: str
    objective: str
    created_at: Optional[str]
    modified_at: Optional[str]
    artifacts: List[Dict[str, Any]]


@dataclass
class NightReview:
    """ãƒŠã‚¤ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼æ§‹é€ ä½“"""
    date: str
    summary: str  # 3-7è¡Œã®å¤‰æ›´ã‚µãƒãƒª
    learnings: List[str]  # å­¦ã³ãƒ»æ°—ã¥ã
    tasks: List[str]  # æ˜æ—¥ã«å¼•ãç¶™ãã‚¿ã‚¹ã‚¯å€™è£œ
    sessions_processed: int
    generated_at: str


def _process_session_dir(session_dir: Path, target_date: Optional[date]) -> Optional[SessionInfo]:
    """
    å˜ä¸€ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã€‚
    ä¸¦åˆ—å‡¦ç†ã®ãŸã‚ã«åˆ†é›¢ã€‚
    """
    if not session_dir.is_dir():
        return None
    if session_dir.name.startswith("_"):
        return None

    session_id = session_dir.name

    # Find metadata files
    artifacts = []
    title = ""
    objective = ""
    created_at = None
    modified_at = None

    for md_file in session_dir.glob("*.md"):
        meta_file = session_dir / f"{md_file.name}.metadata.json"

        if not meta_file.exists():
            continue

        try:
            with open(meta_file, "r", encoding="utf-8") as f:
                meta = json.load(f)

            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read()

            artifact_updated = meta.get("updatedAt", "")

            # Track latest modification
            if artifact_updated:
                if modified_at is None or artifact_updated > modified_at:
                    modified_at = artifact_updated
                if created_at is None or artifact_updated < created_at:
                    created_at = artifact_updated

            artifacts.append({
                "type": meta.get("artifactType", "unknown"),
                "summary": meta.get("summary", ""),
                "content": content[:2000],
                "updated_at": artifact_updated,
            })

            # Extract title from implementation_plan or task
            if not title and "plan" in md_file.name.lower():
                lines = content.split("\n")
                for line in lines:
                    if line.startswith("# "):
                        title = line[2:].strip()
                        break

        except Exception as e:
            print(f"Warning: Failed to read {meta_file}: {e}", file=sys.stderr)
            continue

    if not artifacts:
        return None

    # Filter by date if specified
    if target_date and modified_at:
        try:
            mod_date = datetime.fromisoformat(modified_at.replace("Z", "+00:00")).date()
            if mod_date != target_date:
                return None
        except Exception:
            pass

    return SessionInfo(
        session_id=session_id,
        title=title or f"Session {session_id[:8]}",
        objective=objective,
        created_at=created_at,
        modified_at=modified_at,
        artifacts=artifacts,
    )


def get_sessions(target_date: Optional[date] = None) -> List[SessionInfo]:
    """
    Antigravity brain ã‹ã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—ã€‚
    
    Args:
        target_date: æŒ‡å®šæ—¥ã®ã¿å–å¾—ã€‚Noneã®å ´åˆã¯å…¨ä»¶ã€‚
    """
    sessions = []
    
    # Use ProcessPoolExecutor to process sessions in parallel
    import concurrent.futures

    # Adjust max_workers based on the environment
    max_workers = min(32, (os.cpu_count() or 1) + 4)

    with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(_process_session_dir, p, target_date): p for p in BRAIN_DIR.iterdir()}
        
        for future in concurrent.futures.as_completed(futures):
            try:
                result = future.result()
                if result:
                    sessions.append(result)
            except Exception as e:
                print(f"Error processing session: {e}", file=sys.stderr)
    
    # Sort by modified_at descending
    sessions.sort(key=lambda s: s.modified_at or "", reverse=True)
    
    return sessions


def generate_review_prompt(sessions: List[SessionInfo], target_date: date) -> str:
    """Gemini APIç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
    
    session_summaries = []
    for s in sessions:
        artifact_list = "\n".join([
            f"  - [{a['type']}] {a['summary'][:100]}..." 
            for a in s.artifacts
        ])
        session_summaries.append(f"""
### {s.title}
- Session ID: {s.session_id[:8]}
- æ›´æ–°æ—¥æ™‚: {s.modified_at}
- ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ:
{artifact_list}
""")
    
    sessions_text = "\n".join(session_summaries)
    
    return f"""ã‚ãªãŸã¯ HegemonikÃ³n ã‚¹ãƒšãƒ¼ã‚¹ã®æŒ¯ã‚Šè¿”ã‚Šã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã«åŸºã¥ã„ã¦ã€{target_date.isoformat()} ã®ãƒŠã‚¤ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

# ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
{sessions_text}

# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå³å¯†ã«å¾“ã£ã¦ãã ã•ã„ï¼‰

## ä»Šæ—¥ã®å¤‰æ›´ã‚µãƒãƒª
ï¼ˆ3ã€œ7è¡Œã§ç°¡æ½”ã«ã€‚æŠ€è¡“çš„ãªè©³ç´°ã‚ˆã‚Šã‚‚ã€Œä½•ã‚’é”æˆã—ãŸã‹ã€ã«ç„¦ç‚¹ï¼‰

## å­¦ã³ãƒ»æ°—ã¥ã
- æ°—ã¥ã1ï¼ˆå…·ä½“çš„ã«ï¼‰
- æ°—ã¥ã2
- æ°—ã¥ã3

## æ˜æ—¥ã«å¼•ãç¶™ãã‚¿ã‚¹ã‚¯å€™è£œ
- [ ] ã‚¿ã‚¹ã‚¯1ï¼ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³å¯èƒ½ãªå½¢å¼ã§ï¼‰
- [ ] ã‚¿ã‚¹ã‚¯2
- [ ] ã‚¿ã‚¹ã‚¯3

# åˆ¶ç´„
- æ—¥æœ¬èªã§å‡ºåŠ›
- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ç°¡æ½”ã«
- æ¨æ¸¬ã‚„ä»®å®šã¯é¿ã‘ã€æä¾›ã•ã‚ŒãŸæƒ…å ±ã®ã¿ã«åŸºã¥ã
"""


def call_gemini_api(prompt: str) -> str:
    """Gemini API ã‚’å‘¼ã³å‡ºã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆ"""
    
    if not GEMINI_API_KEY:
        raise ValueError(
            "GEMINI_API_KEY not found. "
            "Set it in M:/Hegemonikon/.env.local"
        )
    
    try:
        from google import genai
        from google.genai import types
    except ImportError:
        raise ImportError(
            "google-genai not installed. "
            "Run: pip install google-genai"
        )
    
    client = genai.Client(api_key=GEMINI_API_KEY)
    
    response = client.models.generate_content(
        model="gemini-2.0-flash",
        contents=prompt,
        config=types.GenerateContentConfig(
            temperature=0.3,
            max_output_tokens=1500,
        )
    )
    
    return response.text


def parse_review_response(response_text: str, target_date: date, session_count: int) -> NightReview:
    """APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ§‹é€ åŒ–"""
    
    lines = response_text.strip().split("\n")
    
    summary_lines = []
    learnings = []
    tasks = []
    
    current_section = None
    
    for line in lines:
        line_stripped = line.strip()
        
        if "ä»Šæ—¥ã®å¤‰æ›´ã‚µãƒãƒª" in line or "å¤‰æ›´ã‚µãƒãƒª" in line:
            current_section = "summary"
            continue
        elif "å­¦ã³" in line or "æ°—ã¥ã" in line:
            current_section = "learnings"
            continue
        elif "ã‚¿ã‚¹ã‚¯" in line or "å¼•ãç¶™ã" in line:
            current_section = "tasks"
            continue
        
        if not line_stripped or line_stripped.startswith("#"):
            continue
        
        if current_section == "summary":
            summary_lines.append(line_stripped)
        elif current_section == "learnings":
            if line_stripped.startswith("- "):
                learnings.append(line_stripped[2:])
        elif current_section == "tasks":
            if line_stripped.startswith("- [ ] "):
                tasks.append(line_stripped[6:])
            elif line_stripped.startswith("- "):
                tasks.append(line_stripped[2:])
    
    return NightReview(
        date=target_date.isoformat(),
        summary="\n".join(summary_lines[:7]),
        learnings=learnings[:5],
        tasks=tasks[:5],
        sessions_processed=session_count,
        generated_at=datetime.now().isoformat(),
    )


def save_review(review: NightReview) -> Path:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    
    vault_root = OUTPUT_DIR.parent
    vault = VaultManager(vault_root)

    # Relative path from vault_root
    rel_dir = Path(OUTPUT_DIR.name)
    
    filename = f"review_{review.date}.md"
    rel_path = rel_dir / filename
    
    content = f"""# ğŸ“‹ Night Review ({review.date})

## ä»Šæ—¥ã®å¤‰æ›´ã‚µãƒãƒª

{review.summary}

## å­¦ã³ãƒ»æ°—ã¥ã

{chr(10).join(f'- {l}' for l in review.learnings)}

## æ˜æ—¥ã«å¼•ãç¶™ãã‚¿ã‚¹ã‚¯å€™è£œ

{chr(10).join(f'- [ ] {t}' for t in review.tasks)}

---
*Generated by HegemonikÃ³n M8 AnamnÄ“sis*
*Sessions processed: {review.sessions_processed}*
*Generated at: {review.generated_at}*
"""
    
    # Use VaultManager to write file (handles backup and atomic write)
    vault.write_file(rel_path, content)
    
    # Also save JSON for programmatic access
    json_filename = f"review_{review.date}.json"
    vault.write_json(rel_dir / json_filename, asdict(review))
    
    return vault_root / rel_path


def generate_night_review(
    target_date: Optional[date] = None,
    process_all: bool = False,
) -> NightReview:
    """
    ãƒŠã‚¤ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆã€‚
    
    Args:
        target_date: ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡æ—¥ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä»Šæ—¥ï¼‰
        process_all: å…¨å±¥æ­´ã‚’é¡åŠå‡¦ç†
    """
    
    if target_date is None:
        target_date = date.today()
    
    print(f"[Hegemonikon] M8 AnamnÄ“sis - Night Review Generator")
    print(f"  Target: {target_date.isoformat()}")
    print(f"  Mode: {'All history' if process_all else 'Single day'}")
    
    # Get sessions
    sessions = get_sessions(None if process_all else target_date)
    
    if not sessions:
        print(f"  Warning: No sessions found for {target_date}")
        return NightReview(
            date=target_date.isoformat(),
            summary="æœ¬æ—¥ã®æ´»å‹•è¨˜éŒ²ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
            learnings=[],
            tasks=[],
            sessions_processed=0,
            generated_at=datetime.now().isoformat(),
        )
    
    print(f"  Sessions found: {len(sessions)}")
    
    # Generate prompt
    prompt = generate_review_prompt(sessions, target_date)
    
    # Call API
    print("  Calling Gemini API...")
    response = call_gemini_api(prompt)
    
    # Parse response
    review = parse_review_response(response, target_date, len(sessions))
    
    # Save
    filepath = save_review(review)
    print(f"  Saved: {filepath}")
    
    return review


def list_sessions():
    """å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’è¡¨ç¤º"""
    sessions = get_sessions()
    
    print(f"\n[Hegemonikon] Session List")
    print("=" * 60)
    print(f"Total: {len(sessions)} sessions\n")
    
    for s in sessions[:20]:  # Show first 20
        print(f"[{s.session_id[:8]}] {s.title}")
        print(f"    Modified: {s.modified_at}")
        print(f"    Artifacts: {len(s.artifacts)}")
        print()


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Night Review Generator")
    subparsers = parser.add_subparsers(dest="command", required=True)
    
    # generate command
    gen_parser = subparsers.add_parser("generate", help="Generate night review")
    gen_parser.add_argument("--date", type=str, help="Target date (YYYY-MM-DD)")
    gen_parser.add_argument("--all", action="store_true", help="Process all history")
    
    # list command
    subparsers.add_parser("list", help="List all sessions")
    
    args = parser.parse_args()
    
    if args.command == "generate":
        target = None
        if args.date:
            target = date.fromisoformat(args.date)
        
        review = generate_night_review(target, args.all)
        
        print("\n" + "=" * 60)
        print(f"# Night Review ({review.date})")
        print("=" * 60)
        print(f"\n{review.summary}\n")
        print("## å­¦ã³ãƒ»æ°—ã¥ã")
        for l in review.learnings:
            print(f"- {l}")
        print("\n## ã‚¿ã‚¹ã‚¯å€™è£œ")
        for t in review.tasks:
            print(f"- [ ] {t}")
        
    elif args.command == "list":
        list_sessions()


if __name__ == "__main__":
    main()
