# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] <- mekhane/anamnesis/
"""
PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å­˜åœ¨ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„

P3 â†’ è¨˜æ†¶ã®æ°¸ç¶šåŒ–ãŒå¿…è¦
   â†’ æ°¸ç¶šåŒ–ã•ã‚ŒãŸçŸ¥è­˜ãŒã€Œè‡ªã‚‰èªã‚Šã‹ã‘ã¦ãã‚‹ã€å¿…è¦ãŒã‚ã‚‹
   â†’ proactive_push.py ãŒæ‹…ã†

Q.E.D.

---

Proactive Push â€” ã€Œãƒ‡ãƒ¼ã‚¿ãŒè‡ªã‚‰èªã‚Šã‹ã‘ã¦ãã‚‹ DBã€

Architecture:
  çŸ¥è­˜æ¨è–¦ã®3ã¤ã®ãƒˆãƒªã‚¬ãƒ¼:
    1. Context-Triggered: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ–‡è„ˆã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«è¿‘å‚ã‚’æ¨è–¦
    2. Graph-Triggered:   ãƒªãƒ³ã‚¯ã‚°ãƒ©ãƒ•ä¸Šã®ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯ãƒ»ãƒ–ãƒªãƒƒã‚¸ãƒãƒ¼ãƒ‰ã‚’æ¨è–¦
    3. Time-Triggered:    å®šæœŸçš„ã«æœªèª­/é«˜é–¢é€£çŸ¥è­˜ã‚’ãƒ—ãƒƒã‚·ãƒ¥

  Source:
    - NotebookLM ã® Source Grounding + Studio Mode
    - Obsidian ã® Bidirectional Links + Graph View
    - Mem0 ã®è‡ªå‹•é–¢é€£ä»˜ã‘
    - æ—¢å­˜ Proactive Recall (handoff_search.py) ã® LanceDB çµ±åˆç‰ˆ

  Ingestion:
    - /boot æ™‚: boot_recommendations() ã§ã€Œä»Šæ—¥ã®æ¨è–¦ã€ã‚’ 3 ä»¶è¡¨ç¤º
    - ãƒãƒ£ãƒƒãƒˆä¸­: context_recommendations() ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è–¦
"""

import re
import time
import logging
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional

logger = logging.getLogger(__name__)

# Paths
_MNEME_ROOT = Path.home() / "oikos" / "mneme" / ".hegemonikon"
_HEGEMONIKON_ROOT = Path(__file__).parent.parent.parent
LINK_GRAPH_PATH = _MNEME_ROOT / "indices" / "link_graph.json"


# PURPOSE: ã®çµ±ä¸€çš„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’å®Ÿç¾ã™ã‚‹
@dataclass
class Recommendation:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®çŸ¥è­˜æ¨è–¦ 1 ä»¶."""

    title: str
    source_type: str  # papers / knowledge / session / handoff
    relevance: float  # 0.0 - 1.0
    trigger: str  # context / graph / time
    benefit: str  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆèª¬æ˜
    content_snippet: str  # å…ˆé ­ 300 æ–‡å­—
    url: str = ""
    primary_key: str = ""
    distance: float = 0.0
    actions: list[str] = field(default_factory=lambda: ["/eat", "/jukudoku"])


# PURPOSE: ã®çµ±ä¸€çš„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’å®Ÿç¾ã™ã‚‹
@dataclass
class PushResult:
    """æ¨è–¦çµæœã®é›†ç´„."""

    recommendations: list[Recommendation]
    trigger_type: str  # boot / context / time
    query_used: str
    retrieval_time: float
    total_candidates: int


# PURPOSE: ã®çµ±ä¸€çš„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’å®Ÿç¾ã™ã‚‹
class ProactivePush:
    """ã€Œãƒ‡ãƒ¼ã‚¿ãŒè‡ªã‚‰èªã‚Šã‹ã‘ã¦ãã‚‹ DBã€ã®æ ¸å¿ƒå®Ÿè£….

    3 ã¤ã®ãƒˆãƒªã‚¬ãƒ¼ã‚’çµ±åˆ:
      1. Context-Triggered: ãƒãƒ£ãƒƒãƒˆæ–‡è„ˆã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«è¿‘å‚ã‚’æ¨è–¦
      2. Graph-Triggered: ãƒªãƒ³ã‚¯ã‚°ãƒ©ãƒ•ä¸Šã®é–¢é€£ãƒãƒ¼ãƒ‰ã‚’æ¨è–¦ (Phase 2 ã§å®Ÿè£…)
      3. Time-Triggered: å®šæœŸãƒ—ãƒƒã‚·ãƒ¥ (n8n é€£æºã§å®Ÿè£…)

    Layer æ§‹æˆ:
      GnosisIndex (LanceDB) â†’ Bi-encoder æ¤œç´¢
      â†’ Reranker (Cross-encoder) â†’ ç²¾åº¦å‘ä¸Š
      â†’ Benefit Generator â†’ ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆèª¬æ˜ç”Ÿæˆ
      â†’ æ¨è–¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡ºåŠ›
    """

    # æ¨è–¦é–¾å€¤ (LanceDB L2 distance, normalized)
    # 0 = identical, ~1.0 = unrelated
    DISTANCE_THRESHOLD = 0.85

    # Papers ã¯ cross-language gap ã‚’è€ƒæ…®ã—ã¦ç·©å’Œ
    PAPERS_DISTANCE_THRESHOLD = 0.95

    # é‡è¤‡é™¤å»: æ¨è–¦æ¸ˆã¿ã®ã‚­ãƒ¼ã‚’è¨˜éŒ² (ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ã¿)
    _seen_keys: set[str] = set()

    def __init__(
        self,
        max_recommendations: int = 3,
        use_reranker: bool = True,
        include_papers: bool = True,
        include_knowledge: bool = True,
    ):
        self.max_recommendations = max_recommendations
        self.use_reranker = use_reranker
        self.include_papers = include_papers
        self.include_knowledge = include_knowledge

        self._index = None
        self._reranker = None
        self._seen_keys: set[str] = set()

    def _load_index(self):
        """GnosisIndex ã‚’ãƒ­ãƒ¼ãƒ‰."""
        if self._index is not None:
            return
        from mekhane.anamnesis.index import GnosisIndex

        self._index = GnosisIndex()
        logger.info("[ProactivePush] Index loaded")

    def _load_reranker(self):
        """Reranker ã‚’ãƒ­ãƒ¼ãƒ‰ (optional)."""
        if not self.use_reranker or self._reranker is not None:
            return
        from mekhane.anamnesis.gnosis_chat import Reranker

        self._reranker = Reranker()
        logger.info("[ProactivePush] Reranker loaded")

    def _retrieve(self, query: str, k: int = 10) -> list[dict]:
        """LanceDB ã‹ã‚‰ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ + é–¾å€¤ãƒ•ã‚£ãƒ«ã‚¿ + Rerank.

        GnosisChat._retrieve() ã¨åŒç­‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã ãŒã€
        æ¨è–¦ç”¨ã«ç‹¬ç«‹ã•ã›ã‚‹ï¼ˆGnosisChat ã¨çµåˆåº¦ã‚’ä¸‹ã’ã‚‹ï¼‰ã€‚
        """
        self._load_index()
        from mekhane.anamnesis.lancedb_compat import get_table_names

        results = []
        fetch_k = k * 3 if self.use_reranker else k

        # Papers table
        if self.include_papers:
            try:
                paper_results = self._index.search(query, k=fetch_k)
                for r in paper_results:
                    r["_source_table"] = "papers"
                results.extend(paper_results)
            except Exception as e:
                logger.warning(f"[ProactivePush] Papers search failed: {e}")

        # Knowledge table
        if self.include_knowledge:
            try:
                if "knowledge" in get_table_names(self._index.db):
                    embedder = self._index._get_embedder()
                    table = self._index.db.open_table("knowledge")

                    from mekhane.anamnesis.index import _get_vector_dimension

                    table_dim = _get_vector_dimension(table)
                    embedder_dim = getattr(embedder, "_dimension", 0)

                    if table_dim and embedder_dim and table_dim != embedder_dim:
                        logger.warning(
                            f"[ProactivePush] Dimension mismatch: "
                            f"table={table_dim}, embedder={embedder_dim}. "
                            f"Skipping knowledge."
                        )
                    else:
                        qvec = embedder.embed(query)
                        k_results = table.search(qvec).limit(fetch_k).to_list()
                        for r in k_results:
                            r["_source_table"] = "knowledge"
                        results.extend(k_results)
            except Exception as e:
                logger.warning(f"[ProactivePush] Knowledge search failed: {e}")

        # Layer 1: Bi-encoder è·é›¢é–¾å€¤ãƒ•ã‚£ãƒ«ã‚¿
        results = [
            r
            for r in results
            if r.get("_distance", 999)
            < (
                self.PAPERS_DISTANCE_THRESHOLD
                if r.get("_source_table") == "papers"
                else self.DISTANCE_THRESHOLD
            )
        ]

        results.sort(key=lambda r: r.get("_distance", 999))

        # Layer 2: Reranker
        if self.use_reranker and results:
            self._load_reranker()
            if self._reranker:
                results = self._reranker.rerank(query, results, top_k=k)
        else:
            results = results[:k]

        return results

    def _generate_benefit(self, result: dict, query: str) -> str:
        """æ¤œç´¢çµæœã‹ã‚‰ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆèª¬æ˜ã‚’ç”Ÿæˆ.

        LLM ã‚’ä½¿ã‚ãšã€ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ç”Ÿæˆï¼ˆè»½é‡åŒ–ã®ãŸã‚ï¼‰ã€‚
        Phase 4 ã§ LLM ç”Ÿæˆã«åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ã€‚
        """
        title = result.get("title", "Untitled")
        source = result.get("source", result.get("_source_table", "unknown"))
        distance = result.get("_distance", 1.0)
        relevance = 1 - distance

        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ã®ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆ
        benefit_templates = {
            "papers": f"è«–æ–‡ '{title}' ãŒç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã« {relevance:.0%} ã®é–¢é€£æ€§",
            "arxiv": f"è«–æ–‡ '{title}' ãŒç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã« {relevance:.0%} ã®é–¢é€£æ€§",
            "handoff": f"éå»ã®å¼•ç¶™æ›¸ '{title}' ã«é¡ä¼¼ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚ã‚Š",
            "session": f"éå»ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ '{title}' ã«é–¢é€£ã™ã‚‹è­°è«–ã‚ã‚Š",
            "ki": f"çŸ¥è­˜é …ç›® '{title}' ãŒã“ã®æ–‡è„ˆã«é©ç”¨å¯èƒ½",
            "kernel": f"ã‚«ãƒ¼ãƒãƒ«å®šç¾© '{title}' ãŒã“ã®è¨­è¨ˆã«é–¢é€£",
            "doxa": f"ä¿¡å¿µè¨˜éŒ² '{title}' ãŒã“ã®åˆ¤æ–­ã«å½±éŸ¿",
            "workflow": f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ '{title}' ãŒã“ã®ã‚¿ã‚¹ã‚¯ã«æœ‰ç”¨",
            "research": f"ç ”ç©¶ãƒãƒ¼ãƒˆ '{title}' ã«é–¢é€£çŸ¥è¦‹ã‚ã‚Š",
        }

        return benefit_templates.get(
            source,
            f"'{title}' ãŒç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã« {relevance:.0%} ã®é–¢é€£æ€§",
        )

    def _to_recommendation(
        self, result: dict, query: str, trigger: str
    ) -> Recommendation:
        """æ¤œç´¢çµæœã‚’ Recommendation ã«å¤‰æ›."""
        distance = result.get("_distance", 1.0)
        source_table = result.get("_source_table", "unknown")

        # content or abstract
        if source_table == "knowledge":
            snippet = result.get("content", result.get("abstract", ""))[:300]
        else:
            snippet = result.get("abstract", "")[:300]

        actions = ["/eat", "/jukudoku"]
        if source_table == "papers":
            actions = ["/eat", "/sop"]

        return Recommendation(
            title=result.get("title", "Untitled")[:100],
            source_type=result.get("source", source_table),
            relevance=round(1 - distance, 4),
            trigger=trigger,
            benefit=self._generate_benefit(result, query),
            content_snippet=snippet,
            url=result.get("url", ""),
            primary_key=result.get("primary_key", ""),
            distance=round(distance, 4),
            actions=actions,
        )

    def _deduplicate(self, recs: list[Recommendation]) -> list[Recommendation]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®é‡è¤‡é™¤å»."""
        unique = []
        for rec in recs:
            key = rec.primary_key or rec.title
            if key not in self._seen_keys:
                self._seen_keys.add(key)
                unique.append(rec)
        return unique

    # ==========================================================
    # Public API
    # ==========================================================

    # PURPOSE: proactive_push ã® boot recommendations å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
    def boot_recommendations(
        self, context: Optional[str] = None
    ) -> PushResult:
        """/boot æ™‚ã®æ¨è–¦ â€” ã€Œä»Šæ—¥ã®æ¨è–¦ã€.

        Context-Triggered + Graph-Triggered ã‚’çµ±åˆ:
          1. ãƒ™ã‚¯ãƒˆãƒ«è¿‘å‚ã‹ã‚‰ Context-Triggered æ¨è–¦ã‚’å–å¾—
          2. LinkGraph ã‹ã‚‰ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯/ãƒ–ãƒªãƒƒã‚¸æ¨è–¦ã‚’å–å¾—
          3. é‡è¤‡é™¤å»ã—ã¦çµ±åˆ

        Args:
            context: ç›´è¿‘ã® Handoff ã® primary_task ã‚„ç›®çš„ãƒ†ã‚­ã‚¹ãƒˆã€‚
                     None ã®å ´åˆã€ç›´è¿‘ Handoff ã‹ã‚‰è‡ªå‹•æŠ½å‡ºã‚’è©¦ã¿ã‚‹ã€‚

        Returns:
            PushResult: æ¨è–¦çµæœ
        """
        t0 = time.time()

        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè‡ªå‹•æŠ½å‡º: ç›´è¿‘ã® Handoff ã‚’èª­ã‚€
        if context is None:
            context = self._extract_latest_context()

        if not context:
            return PushResult(
                recommendations=[],
                trigger_type="boot",
                query_used="",
                retrieval_time=0,
                total_candidates=0,
            )

        # Layer 1: Context-Triggered (ãƒ™ã‚¯ãƒˆãƒ«è¿‘å‚)
        results = self._retrieve(context, k=self.max_recommendations * 2)
        recs = [
            self._to_recommendation(r, context, trigger="context")
            for r in results
        ]

        # Layer 2: Graph-Triggered (ãƒªãƒ³ã‚¯ã‚°ãƒ©ãƒ•)
        graph_recs = self._graph_recommendations(context)
        recs.extend(graph_recs)

        retrieval_time = time.time() - t0

        # é‡è¤‡é™¤å» + ä¸Šé™é©ç”¨
        recs = self._deduplicate(recs)[: self.max_recommendations]

        total_candidates = len(results) + len(graph_recs)

        return PushResult(
            recommendations=recs,
            trigger_type="boot",
            query_used=context[:100],
            retrieval_time=round(retrieval_time, 3),
            total_candidates=total_candidates,
        )

    def _graph_recommendations(
        self, context: str, max_recs: int = 2
    ) -> list[Recommendation]:
        """Graph-Triggered æ¨è–¦: ãƒªãƒ³ã‚¯ã‚°ãƒ©ãƒ•ä¸Šã®æ§‹é€ çš„é–¢é€£ã‚’æ¨è–¦.

        LinkGraph ã®ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯ã¨ãƒ–ãƒªãƒƒã‚¸ãƒãƒ¼ãƒ‰ã‚’æ´»ç”¨:
          1. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®ãƒãƒ¼ãƒ‰åã‚’ãƒãƒƒãƒãƒ³ã‚°
          2. ãƒãƒƒãƒã—ãŸãƒãƒ¼ãƒ‰ã®è¿‘å‚ (2 hop) ã‚’å–å¾—
          3. ãƒ–ãƒªãƒƒã‚¸ãƒãƒ¼ãƒ‰ã‚’å„ªå…ˆçš„ã«æ¨è–¦

        Args:
            context: æ¤œç´¢ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            max_recs: æœ€å¤§æ¨è–¦æ•°

        Returns:
            Graph-Triggered Recommendation ã®ãƒªã‚¹ãƒˆ
        """
        try:
            from mekhane.anamnesis.link_graph import load_or_build_graph

            graph = load_or_build_graph()
            if not graph.nodes:
                return []

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒãƒ¼ãƒ‰åã‚’ãƒãƒƒãƒãƒ³ã‚°
            context_lower = context.lower()
            matched_nodes = []
            for node_id in graph.nodes:
                if node_id.lower() in context_lower:
                    matched_nodes.append(node_id)

            # ãƒãƒƒãƒã—ãªã‘ã‚Œã°ã€ãƒ–ãƒªãƒƒã‚¸ãƒãƒ¼ãƒ‰ã‚’æ¨è–¦
            if not matched_nodes:
                bridges = graph.find_bridge_nodes()[:max_recs]
                return [
                    self._graph_node_to_recommendation(graph, nid, "bridge")
                    for nid in bridges
                    if nid in graph.nodes
                ]

            # ãƒãƒƒãƒã—ãŸãƒãƒ¼ãƒ‰ã®è¿‘å‚ã‚’å–å¾—
            neighbor_ids: set[str] = set()
            for node_id in matched_nodes[:3]:  # æœ€å¤§ 3 ãƒãƒ¼ãƒ‰ã‹ã‚‰
                neighbors = graph.get_neighbors(node_id, hops=2)
                neighbor_ids.update(neighbors)

            # ãƒãƒƒãƒã—ãŸãƒãƒ¼ãƒ‰è‡ªèº«ã¯é™¤å¤–
            neighbor_ids -= set(matched_nodes)

            if not neighbor_ids:
                return []

            # ãƒ–ãƒªãƒƒã‚¸ãƒãƒ¼ãƒ‰ã‚’å„ªå…ˆ
            bridges = set(graph.find_bridge_nodes())
            bridge_neighbors = neighbor_ids & bridges
            other_neighbors = neighbor_ids - bridges

            # ãƒ–ãƒªãƒƒã‚¸å„ªå…ˆã§ã‚½ãƒ¼ãƒˆ
            sorted_neighbors = list(bridge_neighbors) + list(other_neighbors)

            return [
                self._graph_node_to_recommendation(graph, nid, "graph")
                for nid in sorted_neighbors[:max_recs]
                if nid in graph.nodes
            ]

        except Exception as e:
            logger.warning(f"[ProactivePush] Graph recommendations failed: {e}")
            return []

    def _graph_node_to_recommendation(
        self, graph, node_id: str, trigger: str
    ) -> Recommendation:
        """LinkGraph ãƒãƒ¼ãƒ‰ã‚’ Recommendation ã«å¤‰æ›."""
        node = graph.nodes[node_id]
        backlink_count = len(node.in_links)

        # æ¥ç¶šåº¦ã‹ã‚‰ relevance ã‚’æ¨å®š (å¤šãã®ãƒªãƒ³ã‚¯ã‚’æŒã¤ãƒãƒ¼ãƒ‰ã»ã©é‡è¦)
        degree = len(set(node.out_links + node.in_links))
        relevance = min(1.0, degree / 20.0)  # 20 ãƒªãƒ³ã‚¯ã§ 100%

        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—åˆ¥ã®ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆ
        if trigger == "bridge":
            benefit = (
                f"ãƒ–ãƒªãƒƒã‚¸ãƒãƒ¼ãƒ‰ '{node.title}' â€” "
                f"{backlink_count} å€‹ã®ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯ã€‚"
                f"è¤‡æ•°ã®çŸ¥è­˜é ˜åŸŸã‚’æ¥ç¶šã™ã‚‹ãƒãƒ–ã€‚"
            )
        else:
            benefit = (
                f"'{node.title}' ã¯ãƒªãƒ³ã‚¯ã‚°ãƒ©ãƒ•ä¸Šã§ "
                f"ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ {degree} ãƒ›ãƒƒãƒ—ã§æ¥ç¶šã€‚"
            )

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¹ãƒ‹ãƒšãƒƒãƒˆ: ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ã‚’èª­ã‚€
        snippet = ""
        try:
            content = Path(node.path).read_text(encoding="utf-8")
            # YAML ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼å¾Œã®æœ¬æ–‡
            body = re.sub(r"^---.*?---\s*", "", content, flags=re.DOTALL)
            snippet = body[:300].replace("\n", " ")
        except Exception:
            pass

        return Recommendation(
            title=node.title[:100],
            source_type=node.source_type,
            relevance=round(relevance, 4),
            trigger=trigger,
            benefit=benefit,
            content_snippet=snippet,
            url=f"file://{node.path}",
            primary_key=node_id,
            distance=round(1 - relevance, 4),
            actions=["/jukudoku", "/eat"],
        )

    # PURPOSE: proactive_push ã® context recommendations å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
    def context_recommendations(
        self, user_message: str, max_recs: int = 2
    ) -> PushResult:
        """ãƒãƒ£ãƒƒãƒˆä¸­ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è–¦.

        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«è¿‘å‚ã‚’æ¤œç´¢ã—ã€
        é–¢é€£çŸ¥è­˜ã‚’ã€Œãƒ‡ãƒ¼ã‚¿ãŒèªã‚Šã‹ã‘ã‚‹ã€å½¢å¼ã§æ¨è–¦ã™ã‚‹ã€‚

        Args:
            user_message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›´è¿‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            max_recs: æ¨è–¦ä¸Šé™ï¼ˆãƒãƒ£ãƒƒãƒˆä¸­ã¯æ§ãˆã‚ã«ï¼‰

        Returns:
            PushResult: æ¨è–¦çµæœ
        """
        t0 = time.time()

        # çŸ­ã™ãã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯æ¨è–¦ã—ãªã„
        if len(user_message.strip()) < 20:
            return PushResult(
                recommendations=[],
                trigger_type="context",
                query_used=user_message,
                retrieval_time=0,
                total_candidates=0,
            )

        results = self._retrieve(user_message, k=max_recs * 2)
        retrieval_time = time.time() - t0

        recs = [
            self._to_recommendation(r, user_message, trigger="context")
            for r in results
        ]

        recs = self._deduplicate(recs)[:max_recs]

        return PushResult(
            recommendations=recs,
            trigger_type="context",
            query_used=user_message[:100],
            retrieval_time=round(retrieval_time, 3),
            total_candidates=len(results),
        )

    def _extract_latest_context(self) -> str:
        """ç›´è¿‘ã® Handoff ã‹ã‚‰ primary_task ã‚’æŠ½å‡º."""
        sessions_dir = _MNEME_ROOT / "sessions"
        if not sessions_dir.exists():
            return ""

        handoffs = sorted(sessions_dir.glob("handoff_*.md"), reverse=True)
        if not handoffs:
            return ""

        latest = handoffs[0]
        try:
            content = latest.read_text(encoding="utf-8")

            # YAML ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‹ã‚‰ primary_task ã‚’æŠ½å‡º
            match = re.search(r"primary_task:\s*[\"']?(.+?)[\"']?\s*$", content, re.M)
            if match:
                return match.group(1)

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä¸»é¡Œè¡Œã‚’æ¢ã™
            match = re.search(r"\*\*ä¸»é¡Œ\*\*:\s*(.+)", content)
            if match:
                return match.group(1)

            # ã•ã‚‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ˆé ­ 200 æ–‡å­—
            return content[:200]
        except Exception as e:
            logger.warning(f"[ProactivePush] Failed to read handoff: {e}")
            return ""

    # PURPOSE: proactive_push ã® reset session å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
    def reset_session(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®é‡è¤‡é™¤å»ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒªã‚»ãƒƒãƒˆ."""
        self._seen_keys.clear()

    # ==========================================================
    # Format
    # ==========================================================

    # PURPOSE: recommendations ã‚’æ•´å½¢ã™ã‚‹
    @staticmethod
    def format_recommendations(result: PushResult) -> str:
        """æ¨è–¦çµæœã‚’äººé–“å‘ã‘ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›.

        /boot æ™‚ã‚„ãƒãƒ£ãƒƒãƒˆä¸­ã«è¡¨ç¤ºã™ã‚‹å½¢å¼ã€‚
        """
        if not result.recommendations:
            return ""

        header = {
            "boot": "ğŸ§  ã“ã®çŸ¥è­˜ãŒã‚ãªãŸã«èªã‚Šã‹ã‘ã¦ã„ã¾ã™",
            "context": "ğŸ’¡ é–¢é€£ã™ã‚‹çŸ¥è­˜ã‚’ç™ºè¦‹",
            "time": "ğŸ“¬ å®šæœŸæ¨è–¦",
        }.get(result.trigger_type, "ğŸ’¡ æ¨è–¦")

        lines = [f"\n{'=' * 50}", f"  {header}", f"{'=' * 50}"]

        for i, rec in enumerate(result.recommendations, 1):
            icon = {
                "papers": "ğŸ“„",
                "arxiv": "ğŸ“„",
                "knowledge": "ğŸ§ ",
                "session": "ğŸ’¬",
                "handoff": "ğŸ“‹",
                "ki": "ğŸ’",
                "kernel": "âš™ï¸",
                "doxa": "ğŸ›ï¸",
                "workflow": "ğŸ”§",
                "research": "ğŸ”¬",
            }.get(rec.source_type, "ğŸ“")

            lines.append(f"\n  [{i}] {icon} {rec.title}")
            lines.append(f"      é–¢é€£åº¦: {rec.relevance:.0%}")
            lines.append(f"      â†’ {rec.benefit}")
            if rec.content_snippet:
                snippet = rec.content_snippet[:120].replace("\n", " ")
                lines.append(f"      æ¦‚è¦: {snippet}...")
            actions_str = " | ".join(rec.actions + ["ç„¡è¦–"])
            lines.append(f"      ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {actions_str}")

        lines.append(f"\n  æ¤œç´¢æ™‚é–“: {result.retrieval_time:.2f}s")
        lines.append(f"  å€™è£œæ•°: {result.total_candidates}")
        lines.append(f"{'=' * 50}\n")

        return "\n".join(lines)

    # PURPOSE: compact ã‚’æ•´å½¢ã™ã‚‹
    @staticmethod
    def format_compact(result: PushResult) -> str:
        """ãƒãƒ£ãƒƒãƒˆä¸­ã®æ§ãˆã‚ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ.

        ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è–¦ã¯é‚ªé­”ã«ãªã‚‰ãªã„ã‚ˆã†çŸ­ãã€‚
        """
        if not result.recommendations:
            return ""

        lines = ["ğŸ’¡ **é–¢é€£çŸ¥è­˜**:"]
        for rec in result.recommendations:
            lines.append(
                f"  - [{rec.source_type}] {rec.title} "
                f"(é–¢é€£åº¦ {rec.relevance:.0%})"
            )
        return "\n".join(lines)


# ==========================================================
# Convenience functions
# ==========================================================

_push_instance: Optional[ProactivePush] = None


# PURPOSE: push ã‚’å–å¾—ã™ã‚‹
def get_push() -> ProactivePush:
    """ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ ProactivePush ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—."""
    global _push_instance
    if _push_instance is None:
        _push_instance = ProactivePush()
    return _push_instance


# PURPOSE: proactive_push ã® boot push å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
def boot_push(context: Optional[str] = None) -> str:
    """/boot æ™‚ã®æ¨è–¦ã‚’å®Ÿè¡Œã—ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿æ–‡å­—åˆ—ã‚’è¿”ã™.

    Usage:
        from mekhane.anamnesis.proactive_push import boot_push
        print(boot_push())
    """
    push = get_push()
    result = push.boot_recommendations(context)
    return ProactivePush.format_recommendations(result)


# PURPOSE: proactive_push ã® context push å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
def context_push(user_message: str) -> str:
    """ãƒãƒ£ãƒƒãƒˆä¸­ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è–¦ã‚’å®Ÿè¡Œã—ã€ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆæ–‡å­—åˆ—ã‚’è¿”ã™.

    Usage:
        from mekhane.anamnesis.proactive_push import context_push
        print(context_push("FEP ã®æ•°å­¦çš„å®šå¼åŒ–ã«ã¤ã„ã¦"))
    """
    push = get_push()
    result = push.context_recommendations(user_message)
    return ProactivePush.format_compact(result)


# ==========================================================
# CLI
# ==========================================================

# PURPOSE: proactive_push ã® main å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
def main():
    """CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ."""
    import argparse

    parser = argparse.ArgumentParser(
        description="Proactive Push â€” ãƒ‡ãƒ¼ã‚¿ãŒè‡ªã‚‰èªã‚Šã‹ã‘ã¦ãã‚‹ DB"
    )
    subparsers = parser.add_subparsers(dest="command")

    # boot
    boot_parser = subparsers.add_parser("boot", help="/boot æ™‚ã®æ¨è–¦")
    boot_parser.add_argument(
        "--context", "-c", default=None, help="ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆçœç•¥æ™‚: ç›´è¿‘ Handoffï¼‰"
    )
    boot_parser.add_argument(
        "--max", "-n", type=int, default=3, help="æ¨è–¦ä¸Šé™"
    )

    # context
    ctx_parser = subparsers.add_parser("context", help="ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è–¦")
    ctx_parser.add_argument("message", help="ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
    ctx_parser.add_argument(
        "--max", "-n", type=int, default=2, help="æ¨è–¦ä¸Šé™"
    )

    args = parser.parse_args()

    if args.command == "boot":
        push = ProactivePush(max_recommendations=args.max)
        result = push.boot_recommendations(args.context)
        print(ProactivePush.format_recommendations(result))
    elif args.command == "context":
        push = ProactivePush(max_recommendations=args.max)
        result = push.context_recommendations(args.message, max_recs=args.max)
        print(ProactivePush.format_recommendations(result))
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
