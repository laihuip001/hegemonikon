# PROOF: [L1/å®šç†] <- mekhane/basanos/ VISION.md ç¬¬3æ®µéš: äºˆå…†ã‚’å¯ŸçŸ¥ã™ã‚‹å…ç–«
# PURPOSE: GitMetrics â€” git å±¥æ­´ã‹ã‚‰ãƒªã‚¹ã‚¯äºˆå…†ã‚’æ¤œå‡ºã™ã‚‹ã€‚
"""
GitMetrics â€” git å±¥æ­´ã‹ã‚‰ãƒªã‚¹ã‚¯äºˆå…†ã‚’æ¤œå‡ºã™ã‚‹ã€‚

å£Šã‚Œã¦ã‹ã‚‰ç›´ã™ â†’ å£Šã‚Œã‚‹å‰ã«æ°—ã¥ãã€‚

FEP è§£é‡ˆ:
- commit frequency = ç’°å¢ƒã®å¤‰å‹•é€Ÿåº¦ (é«˜ = äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ›´æ–°é »åº¦ã‚’ä¸Šã’ã‚‹ã¹ã)
- file churn = ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã®äºˆæ¸¬èª¤å·®è“„ç© (é«˜churn = ä¸å®‰å®š = è¦ç›£è¦–)
- author switching = ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ä¸€è²«æ€§ãƒªã‚¹ã‚¯ (å¤šäººæ•° = æš—é»™çŸ¥ã®æ–­è£‚)
"""

import logging
import subprocess
from collections import Counter
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


# PURPOSE: ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰å‹•(churn)æƒ…å ±ã€‚
@dataclass
class FileChurn:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰å‹•(churn)æƒ…å ±ã€‚"""

    path: str
    commits: int = 0          # total commits touching this file
    lines_added: int = 0
    lines_deleted: int = 0
    authors: int = 0          # unique author count
    last_modified: str = ""
    days_active: int = 0      # days with at least 1 commit

    # PURPOSE: å¤‰å‹•ç‡: (added + deleted) / commitsã€‚é«˜ã„ = ä¸å®‰å®šã€‚
    @property
    def churn_rate(self) -> float:
        """å¤‰å‹•ç‡: (added + deleted) / commitsã€‚é«˜ã„ = ä¸å®‰å®šã€‚"""
        if self.commits == 0:
            return 0.0
        return (self.lines_added + self.lines_deleted) / self.commits

    # PURPOSE: ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: churn_rate Ã— authors Ã— recencyã€‚
    @property
    def risk_score(self) -> float:
        """ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: churn_rate Ã— authors Ã— recencyã€‚

        é«˜ã„ = å£Šã‚Œã‚„ã™ã„ã€‚
        """
        author_factor = 1.0 + (self.authors - 1) * 0.3  # multi-author penalty
        return self.churn_rate * author_factor


# PURPOSE: æ—¥åˆ¥ã®ã‚³ãƒŸãƒƒãƒˆçµ±è¨ˆã€‚
@dataclass
class CommitStats:
    """æ—¥åˆ¥ã®ã‚³ãƒŸãƒƒãƒˆçµ±è¨ˆã€‚"""

    date: str
    count: int = 0
    files_changed: int = 0
    insertions: int = 0
    deletions: int = 0


# PURPOSE: git å±¥æ­´ã‹ã‚‰ãƒªã‚¹ã‚¯äºˆå…†ã‚’æ¤œå‡ºã™ã‚‹ã€‚
class GitMetrics:
    """git å±¥æ­´ã‹ã‚‰ãƒªã‚¹ã‚¯äºˆå…†ã‚’æ¤œå‡ºã™ã‚‹ã€‚

    Usage:
        gm = GitMetrics(repo_root)
        churn = gm.file_churn(days=14)
        risky = gm.risky_files(top_n=10)
        daily = gm.daily_stats(days=14)
    """

    def __init__(self, repo_root: Optional[Path] = None, days: int = 14):
        self.repo_root = repo_root or Path.home() / "oikos/hegemonikon"
        self.days = days
        self._churn_cache: Optional[Dict[str, FileChurn]] = None

    def _git(self, *args: str) -> str:
        """git ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ stdout ã‚’è¿”ã™ã€‚"""
        try:
            result = subprocess.run(
                ["git"] + list(args),
                capture_output=True,
                text=True,
                cwd=self.repo_root,
                timeout=10,
            )
            if result.returncode != 0:
                logger.debug(f"git {' '.join(args)} failed: {result.stderr.strip()}")
                return ""
            return result.stdout
        except (subprocess.TimeoutExpired, FileNotFoundError) as e:
            logger.warning(f"git command failed: {e}")
            return ""

    # PURPOSE: ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã® churn (å¤‰å‹•) ã‚’ç®—å‡ºã€‚
    def file_churn(self) -> Dict[str, FileChurn]:
        """ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã® churn (å¤‰å‹•) ã‚’ç®—å‡ºã€‚"""
        if self._churn_cache is not None:
            return self._churn_cache

        since = (datetime.now() - timedelta(days=self.days)).strftime("%Y-%m-%d")
        churns: Dict[str, FileChurn] = {}

        # git log: per-file commit count + numstat
        log_output = self._git(
            "log",
            f"--since={since}",
            "--format=%H|%ad|%an",
            "--date=short",
            "--numstat",
            "--diff-filter=ACDMR",
            "--",
            "*.py",
        )
        if not log_output:
            self._churn_cache = churns
            return churns

        current_commit = ""
        current_date = ""
        current_author = ""
        file_authors: Dict[str, set] = {}
        file_dates: Dict[str, set] = {}

        for line in log_output.strip().split("\n"):
            line = line.strip()
            if not line:
                continue

            if "|" in line and line.count("|") >= 2:
                # Commit header: HASH|DATE|AUTHOR
                parts = line.split("|", 2)
                current_commit = parts[0]
                current_date = parts[1]
                current_author = parts[2]
            elif "\t" in line:
                # numstat: added\tdeleted\tfilename
                parts = line.split("\t", 2)
                if len(parts) == 3 and parts[0] != "-":
                    try:
                        added = int(parts[0])
                        deleted = int(parts[1])
                    except ValueError:
                        continue
                    filepath = parts[2]

                    if filepath not in churns:
                        churns[filepath] = FileChurn(path=filepath)
                        file_authors[filepath] = set()
                        file_dates[filepath] = set()

                    fc = churns[filepath]
                    fc.commits += 1
                    fc.lines_added += added
                    fc.lines_deleted += deleted
                    fc.last_modified = max(fc.last_modified, current_date) if fc.last_modified else current_date

                    file_authors[filepath].add(current_author)
                    file_dates[filepath].add(current_date)

        # Fill in author count and days_active
        for filepath, fc in churns.items():
            fc.authors = len(file_authors.get(filepath, set()))
            fc.days_active = len(file_dates.get(filepath, set()))

        self._churn_cache = churns
        return churns

    # PURPOSE: ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ä¸Šä½ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™ã€‚
    def risky_files(self, top_n: int = 10) -> List[FileChurn]:
        """ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ä¸Šä½ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™ã€‚"""
        churns = self.file_churn()
        ranked = sorted(churns.values(), key=lambda fc: fc.risk_score, reverse=True)
        return ranked[:top_n]

    # PURPOSE: æ—¥åˆ¥ã‚³ãƒŸãƒƒãƒˆçµ±è¨ˆã€‚
    def daily_stats(self) -> List[CommitStats]:
        """æ—¥åˆ¥ã‚³ãƒŸãƒƒãƒˆçµ±è¨ˆã€‚"""
        since = (datetime.now() - timedelta(days=self.days)).strftime("%Y-%m-%d")

        log_output = self._git(
            "log",
            f"--since={since}",
            "--format=%ad",
            "--date=short",
        )
        if not log_output:
            return []

        date_counts = Counter(line.strip() for line in log_output.strip().split("\n") if line.strip())
        stats = []
        for date, count in sorted(date_counts.items()):
            stats.append(CommitStats(date=date, count=count))

        return stats

    # PURPOSE: TrendAnalyzer ã® hot files ã¨ git churn ã®äº¤å·®ç‚¹ã‚’æ¤œå‡ºã€‚
    def hotspot_overlaps(self, trend_hot_files: List[str]) -> List[str]:
        """TrendAnalyzer ã® hot files ã¨ git churn ã®äº¤å·®ç‚¹ã‚’æ¤œå‡ºã€‚

        ä¸¡æ–¹ã§é«˜ã‚¹ã‚³ã‚¢ = æœ€å„ªå…ˆã§æ³¨æ„ã™ã¹ããƒ•ã‚¡ã‚¤ãƒ«ã€‚
        """
        churns = self.file_churn()
        risky_set = {fc.path for fc in self.risky_files(top_n=20)}

        overlaps = []
        for file_path in trend_hot_files:
            # ãƒ‘ã‚¹ã®æ­£è¦åŒ– (trend ã¯ç›¸å¯¾ãƒ‘ã‚¹)
            if file_path in risky_set:
                overlaps.append(file_path)
            else:
                # basename match
                for risky_path in risky_set:
                    if risky_path.endswith(file_path) or file_path.endswith(risky_path):
                        overlaps.append(file_path)
                        break

        return overlaps

    # PURPOSE: ç›´è¿‘ã®ã‚³ãƒŸãƒƒãƒˆé€Ÿåº¦ (commits/day)ã€‚
    def commit_velocity(self) -> float:
        """ç›´è¿‘ã®ã‚³ãƒŸãƒƒãƒˆé€Ÿåº¦ (commits/day)ã€‚"""
        stats = self.daily_stats()
        if not stats:
            return 0.0
        total = sum(s.count for s in stats)
        return total / max(len(stats), 1)

    # PURPOSE: åˆ†æçµæœã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã€‚
    def summary(self) -> str:
        """åˆ†æçµæœã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã€‚"""
        churns = self.file_churn()
        if not churns:
            return f"ğŸ“Š Git Metrics: No commits in the past {self.days} days."

        risky = self.risky_files(top_n=3)
        velocity = self.commit_velocity()
        stats = self.daily_stats()

        lines = [
            f"ğŸ“Š Git Metrics ({self.days} days, {len(churns)} files, {sum(s.count for s in stats)} commits)",
            f"   Velocity: {velocity:.1f} commits/day",
        ]

        if risky:
            lines.append("   âš ï¸ High-churn files:")
            for fc in risky:
                lines.append(
                    f"      {fc.path} (churn={fc.churn_rate:.0f}, "
                    f"authors={fc.authors}, commits={fc.commits})"
                )

        return "\n".join(lines)
