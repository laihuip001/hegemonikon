# PROOF: [L2/ãƒ†ã‚¹ãƒˆ] <- mekhane/ergasterion/digestor/ selectorå“è³ªæ”¹å–„ã®æ¤œè¨¼
"""
Digestor Selector å“è³ªãƒ†ã‚¹ãƒˆ

3å±¤é˜²å¾¡ (v3) ã®åŠ¹æœã‚’æ¤œè¨¼ã™ã‚‹ã€‚
- MockPaper ã«ã‚ˆã‚‹å˜ä½“ãƒ†ã‚¹ãƒˆ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
- --live ãƒ•ãƒ©ã‚°ã§ arXiv API å®Ÿç’°å¢ƒãƒ†ã‚¹ãƒˆ

Usage:
    python -m pytest mekhane/ergasterion/digestor/tests/test_selector_quality.py -v
    python mekhane/ergasterion/digestor/tests/test_selector_quality.py --live
"""

import sys
from dataclasses import dataclass, field
from typing import Optional

import pytest


# â”€â”€â”€ Mock Paper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class MockPaper:
    """ãƒ†ã‚¹ãƒˆç”¨ã®è»½é‡ Paper"""
    id: str
    title: str
    abstract: str = ""
    source: str = "arxiv"
    categories: list = field(default_factory=list)
    published: Optional[str] = None
    url: Optional[str] = None


# â”€â”€â”€ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# æ˜ã‚‰ã‹ã«ç„¡é–¢ä¿‚ãªè«–æ–‡ (å±¤1ã§æ’é™¤ã•ã‚Œã‚‹ã¹ã)
IRRELEVANT_PAPERS = [
    MockPaper(
        id="dark1",
        title="Dark Matter Distribution in Galaxy Clusters",
        abstract="We study the spatial distribution of dark matter halos "
                 "using N-body simulations. Gravitational lensing effects.",
        categories=["astro-ph.CO"],
    ),
    MockPaper(
        id="chem1",
        title="Synthesis of Novel Organic Compounds for Drug Delivery",
        abstract="We report the synthesis of a new class of organic molecules "
                 "with pharmaceutical applications in targeted cancer therapy.",
        categories=["chem-ph"],
    ),
    MockPaper(
        id="bio1",
        title="Genome-Wide Association Study of Diabetes Risk Factors",
        abstract="A comprehensive GWAS analysis of genetic variants associated "
                 "with type 2 diabetes mellitus in East Asian populations.",
        categories=["q-bio.GN"],
    ),
    MockPaper(
        id="math1",
        title="Prime Number Distribution in Arithmetic Progressions",
        abstract="We prove new bounds on the distribution of primes in "
                 "arithmetic progressions using sieve methods.",
        categories=["math.NT"],
    ),
]

# é–¢é€£ã™ã‚‹è«–æ–‡ (é€šéã™ã¹ã)
RELEVANT_PAPERS = [
    MockPaper(
        id="ai1",
        title="Self-Reflective Agents: Metacognition in Large Language Models",
        abstract="We propose a framework for metacognitive self-reflection "
                 "in LLM-based autonomous agents. Our approach uses chain-of-thought "
                 "prompting for improved reasoning and decision making capabilities "
                 "with transformer architectures and attention mechanisms.",
        categories=["cs.AI", "cs.CL"],
    ),
    MockPaper(
        id="fep1",
        title="Active Inference and Free Energy Minimization in Artificial Agents",
        abstract="We formalize active inference using variational free energy "
                 "principle and Bayesian inference for autonomous planning in "
                 "AI agents. The framework connects predictive coding with "
                 "reinforcement learning for cognitive control.",
        categories=["cs.AI", "stat.ML"],
    ),
    MockPaper(
        id="cot1",
        title="Improving Chain-of-Thought Reasoning with Self-Consistency",
        abstract="We present a method for enhancing chain-of-thought reasoning "
                 "in large language models through self-consistency decoding. "
                 "Our approach improves reasoning accuracy and inference quality.",
        categories=["cs.CL"],
    ),
    MockPaper(
        id="stoic1",
        title="Stoic Philosophy and Rational Agent Decision Making",
        abstract="We explore connections between Stoic hegemonikon (ruling faculty) "
                 "and modern AI agent architectures. Virtue ethics provides a "
                 "framework for autonomous agent decision making and moral reasoning.",
        categories=["cs.AI"],
    ),
]

# å¢ƒç•Œç·šä¸Šã®è«–æ–‡ (ã‚«ãƒ†ã‚´ãƒªã¯è¨±å¯ã ãŒãƒ‰ãƒ¡ã‚¤ãƒ³é©åˆåº¦ã¯ä¸­ç¨‹åº¦)
BORDERLINE_PAPERS = [
    MockPaper(
        id="border1",
        title="Neural Networks for Particle Physics Event Classification",
        abstract="Deep learning applied to high-energy physics experiments. "
                 "We use neural networks and machine learning for event detection.",
        categories=["hep-ex", "cs.LG"],
    ),
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å±¤1: arXiv ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ ãƒ†ã‚¹ãƒˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestCategoryFilter:
    """å±¤1: arXiv ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ã®æ¤œè¨¼"""

    def test_irrelevant_papers_rejected(self):
        """ç„¡é–¢ä¿‚åˆ†é‡ã¯å…¨ã¦é™¤å¤–ã•ã‚Œã‚‹"""
        from mekhane.ergasterion.digestor.selector import _is_relevant_domain

        for paper in IRRELEVANT_PAPERS:
            assert not _is_relevant_domain(paper), (
                f"{paper.id} ({paper.categories}) should be rejected"
            )

    def test_relevant_papers_accepted(self):
        """é–¢é€£åˆ†é‡ã¯å…¨ã¦é€šéã™ã‚‹"""
        from mekhane.ergasterion.digestor.selector import _is_relevant_domain

        for paper in RELEVANT_PAPERS:
            assert _is_relevant_domain(paper), (
                f"{paper.id} ({paper.categories}) should be accepted"
            )

    def test_no_category_passes(self):
        """ã‚«ãƒ†ã‚´ãƒªãªã—ã¯é€šã™ (å½é™½æ€§ > å½é™°æ€§)"""
        from mekhane.ergasterion.digestor.selector import _is_relevant_domain

        paper = MockPaper(id="nocat", title="Unknown Source Paper", categories=[])
        assert _is_relevant_domain(paper)

    def test_borderline_cs_lg_passes(self):
        """cs.LG ã‚’æŒã¤è«–æ–‡ã¯é€šéã™ã‚‹"""
        from mekhane.ergasterion.digestor.selector import _is_relevant_domain

        for paper in BORDERLINE_PAPERS:
            assert _is_relevant_domain(paper), (
                f"{paper.id} with cs.LG should pass"
            )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å±¤3: ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ ãƒ†ã‚¹ãƒˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestDomainRelevance:
    """å±¤3: ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é©åˆåº¦ã®æ¤œè¨¼"""

    def test_irrelevant_low_score(self):
        """ç„¡é–¢é€£è«–æ–‡ã¯ãƒ‰ãƒ¡ã‚¤ãƒ³é©åˆåº¦ãŒä½ã„"""
        from mekhane.ergasterion.digestor.selector import _domain_relevance

        for paper in IRRELEVANT_PAPERS:
            score = _domain_relevance(paper)
            assert score < 0.34, (
                f"{paper.id} domain_relevance={score:.2f} should be < 0.34"
            )

    def test_relevant_high_score(self):
        """é–¢é€£è«–æ–‡ã¯ãƒ‰ãƒ¡ã‚¤ãƒ³é©åˆåº¦ãŒé«˜ã„"""
        from mekhane.ergasterion.digestor.selector import _domain_relevance

        for paper in RELEVANT_PAPERS:
            score = _domain_relevance(paper)
            assert score >= 0.67, (
                f"{paper.id} domain_relevance={score:.2f} should be >= 0.67"
            )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# çµ±åˆãƒ†ã‚¹ãƒˆ: select_candidates (keyword mode)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestSelectCandidatesIntegration:
    """çµ±åˆãƒ†ã‚¹ãƒˆ: keyword ãƒ¢ãƒ¼ãƒ‰ã§ã®å€™è£œé¸å®š"""

    def test_irrelevant_never_selected(self):
        """ç„¡é–¢ä¿‚è«–æ–‡ã¯å€™è£œã«é¸ã°ã‚Œãªã„"""
        from mekhane.ergasterion.digestor.selector import DigestorSelector

        selector = DigestorSelector(mode="keyword")
        candidates = selector.select_candidates(
            IRRELEVANT_PAPERS, min_score=0.0
        )
        assert len(candidates) == 0, (
            f"Irrelevant papers should produce 0 candidates, got {len(candidates)}: "
            f"{[c.paper.id for c in candidates]}"
        )

    def test_mixed_only_relevant_selected(self):
        """æ··åˆãƒªã‚¹ãƒˆã‹ã‚‰é–¢é€£è«–æ–‡ã®ã¿ãŒé¸ã°ã‚Œã‚‹"""
        from mekhane.ergasterion.digestor.selector import DigestorSelector

        all_papers = IRRELEVANT_PAPERS + RELEVANT_PAPERS
        selector = DigestorSelector(mode="keyword")
        candidates = selector.select_candidates(all_papers, min_score=0.0)

        selected_ids = {c.paper.id for c in candidates}
        irrelevant_ids = {p.id for p in IRRELEVANT_PAPERS}

        # ç„¡é–¢é€£ãŒæ··å…¥ã—ã¦ã„ãªã„ã‹
        leaked = selected_ids & irrelevant_ids
        assert len(leaked) == 0, (
            f"Irrelevant papers leaked into candidates: {leaked}"
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Live ãƒ†ã‚¹ãƒˆ (--live ãƒ•ãƒ©ã‚°ã§å®Ÿè¡Œ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_live_test():
    """å®Ÿ arXiv API ã§å€™è£œã‚’å†ç”Ÿæˆã—ã¦å“è³ªã‚’ç¢ºèª"""
    print("=" * 60)
    print("ğŸ”¬ Digestor Live Quality Test")
    print("=" * 60)

    from mekhane.ergasterion.digestor.selector import (
        DigestorSelector,
        _is_relevant_domain,
        _domain_relevance,
    )
    from mekhane.ergasterion.digestor.pipeline import DigestorPipeline

    pipeline = DigestorPipeline()
    print("\n[1] Fetching papers from arXiv...")
    papers = pipeline._fetch_from_gnosis(max_papers=30)
    print(f"    Fetched: {len(papers)} papers")

    # å±¤1 ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å‰å¾Œã®æ¯”è¼ƒ
    before = len(papers)
    filtered = [p for p in papers if _is_relevant_domain(p)]
    after = len(filtered)
    rejected = before - after
    print(f"\n[2] Category Filter: {before} â†’ {after} ({rejected} rejected)")

    for p in papers:
        if not _is_relevant_domain(p):
            cats = getattr(p, "categories", [])
            print(f"    âŒ {p.title[:60]}... ({', '.join(cats)})")

    # å€™è£œé¸å®š
    print(f"\n[3] Selecting candidates (keyword mode)...")
    selector = DigestorSelector(mode="keyword")
    candidates = selector.select_candidates(filtered, min_score=0.0)

    print(f"    Candidates: {len(candidates)}")
    for i, c in enumerate(candidates, 1):
        dr = _domain_relevance(c.paper)
        cats = getattr(c.paper, "categories", [])
        print(f"    {i}. [{c.score:.2f}] (domain={dr:.2f}) {c.paper.title[:55]}...")
        print(f"       Topics: {', '.join(c.matched_topics)} | Cat: {', '.join(cats)}")

    # å“è³ªã‚µãƒãƒª
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š Quality Summary")
    print(f"    Total fetched:    {before}")
    print(f"    Category filter:  -{rejected}")
    print(f"    Candidates:       {len(candidates)}")
    if candidates:
        avg_score = sum(c.score for c in candidates) / len(candidates)
        avg_domain = sum(_domain_relevance(c.paper) for c in candidates) / len(candidates)
        print(f"    Avg score:        {avg_score:.2f}")
        print(f"    Avg domain_rel:   {avg_domain:.2f}")
    print(f"{'=' * 60}")


if __name__ == "__main__":
    if "--live" in sys.argv:
        run_live_test()
    else:
        pytest.main([__file__, "-v"])
