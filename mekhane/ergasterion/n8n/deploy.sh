#!/bin/bash
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] <- mekhane/ergasterion/n8n/ A0â†’è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«ç¾¤ã®ç®¡ç†ãŒå¿…è¦â†’deploy.shãŒæ‹…ã†
#
# n8n Workflow Deploy Helper (Local Process Edition)
#
# n8n ãŒãƒ­ãƒ¼ã‚«ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ã¨ã—ã¦ç¨¼åƒã™ã‚‹ç’°å¢ƒã«å¯¾å¿œã€‚
# JSON â†’ SQLite ç›´æŽ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ + ãƒ—ãƒ­ã‚»ã‚¹å†èµ·å‹•ã€‚
#
# Usage:
#   ./deploy.sh                     # å…¨ WF ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ + restart
#   ./deploy.sh wf05_health_alert   # ç‰¹å®š WF ã®ã¿
#   ./deploy.sh --status            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
#   ./deploy.sh --test              # å…¨ webhook ãƒ†ã‚¹ãƒˆ
#   ./deploy.sh --no-restart        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®ã¿ (å†èµ·å‹•ã—ãªã„)

set -uo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
DB_PATH="$SCRIPT_DIR/data/database.sqlite"
N8N_PORT="${N8N_PORT:-5678}"
N8N_HOST="${N8N_HOST:-localhost}"
N8N_URL="http://${N8N_HOST}:${N8N_PORT}"

# ã‚«ãƒ©ãƒ¼
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m'

ok()   { echo -e "${GREEN}âœ… $1${NC}"; }
warn() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }
err()  { echo -e "${RED}âŒ $1${NC}"; }
info() { echo -e "${CYAN}â„¹ï¸  $1${NC}"; }

# â”€â”€ n8n ãƒ—ãƒ­ã‚»ã‚¹ç®¡ç† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

find_n8n_pid() {
    pgrep -f "node.*n8n" | head -1
}

is_n8n_running() {
    local pid
    pid=$(find_n8n_pid)
    [ -n "$pid" ] && kill -0 "$pid" 2>/dev/null
}

restart_n8n() {
    local pid
    pid=$(find_n8n_pid)

    if [ -n "$pid" ]; then
        info "Stopping n8n (PID: $pid)..."
        kill "$pid" 2>/dev/null
        sleep 3

        # ç¢ºå®Ÿã«åœæ­¢ã‚’ç¢ºèª
        if kill -0 "$pid" 2>/dev/null; then
            warn "Force killing n8n..."
            kill -9 "$pid" 2>/dev/null
            sleep 2
        fi
    fi

    info "Starting n8n..."
    N8N_HOST="$N8N_HOST" N8N_PORT="$N8N_PORT" N8N_PROTOCOL=http \
        nohup node /usr/local/bin/n8n start > /tmp/n8n_deploy_restart.log 2>&1 &

    # èµ·å‹•å¾…ã¡
    local retries=0
    while [ $retries -lt 15 ]; do
        if curl -s "${N8N_URL}/healthz" >/dev/null 2>&1 || \
           curl -s "${N8N_URL}/signin" >/dev/null 2>&1; then
            ok "n8n started (PID: $(find_n8n_pid))"
            return 0
        fi
        sleep 1
        ((retries++))
    done

    err "n8n failed to start within 15s"
    return 1
}

# â”€â”€ SQLite ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ“ä½œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

deploy_workflow() {
    local json_file="$1"
    local basename=$(basename "$json_file" .json)
    local filepath="$SCRIPT_DIR/${basename}.json"

    if [ ! -f "$filepath" ]; then
        err "File not found: $filepath"
        return 1
    fi

    info "Deploying: $basename"

    python3 -c "
import sqlite3, json, sys

DB = '$DB_PATH'
WF_FILE = '$filepath'

with open(WF_FILE) as f:
    wf = json.load(f)

name = wf.get('name', '$basename')
nodes = json.dumps(wf['nodes'])
connections = json.dumps(wf['connections'])
settings = json.dumps(wf.get('settings', {}))
import uuid
# versionId ã¯å¿…ãš UUID ã‚’ç”Ÿæˆ (JSON ã®å€¤ã¯ç„¡è¦–)
version_id = str(uuid.uuid4())
active = 1 if wf.get('active', True) else 0
tags = json.dumps(wf.get('tags', []))

conn = sqlite3.connect(DB)
cur = conn.cursor()

# æ—¢å­˜ WF ã‚’åå‰ã§æ¤œç´¢
cur.execute('SELECT id FROM workflow_entity WHERE name = ?', (name,))
existing = cur.fetchone()

if existing:
    wf_id = existing[0]
    cur.execute('''
        UPDATE workflow_entity
        SET nodes = ?, connections = ?, settings = ?, \"versionId\" = ?,
            active = ?, \"updatedAt\" = datetime('now')
        WHERE id = ?
    ''', (nodes, connections, settings, version_id, active, wf_id))
    print(f'  Updated: {name} (ID: {wf_id})')
else:
    # æ–°è¦ä½œæˆ â€” ID ã¯ n8n å½¢å¼ã®ãƒ©ãƒ³ãƒ€ãƒ æ–‡å­—åˆ—
    import string, random
    wf_id = ''.join(random.choices(string.ascii_letters + string.digits, k=16))
    cur.execute('''
        INSERT INTO workflow_entity (id, name, nodes, connections, settings, \"versionId\", active, \"createdAt\", \"updatedAt\")
        VALUES (?, ?, ?, ?, ?, ?, ?, datetime('now'), datetime('now'))
    ''', (wf_id, name, nodes, connections, settings, version_id, active))
    print(f'  Created: {name} (ID: {wf_id})')

# workflow_history ã«ã‚‚ç™»éŒ² (publish ã¨åŒç­‰)
cur.execute('''
    INSERT OR REPLACE INTO workflow_history (workflowId, versionId, nodes, connections, name, authors, \"createdAt\", \"updatedAt\")
    VALUES (?, ?, ?, ?, ?, 'deploy.sh', datetime('now'), datetime('now'))
''', (wf_id, version_id, nodes, connections, name))

# webhook_entity ã«ã‚‚ç™»éŒ² (webhook ãƒŽãƒ¼ãƒ‰ã‚’è‡ªå‹•æ¤œå‡º)
for node in wf['nodes']:
    if node.get('type', '') in ('n8n-nodes-base.webhook',):
        wh_path = node.get('parameters', {}).get('path', '')
        wh_method = node.get('parameters', {}).get('httpMethod', 'POST')
        wh_id = node.get('webhookId', '')
        node_name = node.get('name', '')
        if wh_path:
            # æ—¢å­˜ webhook ã‚’å‰Šé™¤ã—ã¦å†ç™»éŒ²
            cur.execute('DELETE FROM webhook_entity WHERE "workflowId" = ? AND "webhookPath" = ?', (wf_id, wh_path))
            cur.execute('''
                INSERT INTO webhook_entity ("workflowId", "webhookPath", method, node, "webhookId", "pathLength")
                VALUES (?, ?, ?, ?, ?, 1)
            ''', (wf_id, wh_path, wh_method, node_name, wh_id or wh_path))
            print(f'  Webhook: {wh_method} /{wh_path}')

# shared_workflow ãŒç„¡ã‘ã‚Œã°è¿½åŠ  (ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–¢é€£ä»˜ã‘)
cur.execute('SELECT COUNT(*) FROM shared_workflow WHERE \"workflowId\" = ?', (wf_id,))
if cur.fetchone()[0] == 0:
    cur.execute('SELECT role, \"projectId\" FROM shared_workflow LIMIT 1')
    ref = cur.fetchone()
    if ref:
        cur.execute('''
            INSERT INTO shared_workflow (role, \"workflowId\", \"projectId\", \"createdAt\", \"updatedAt\")
            VALUES (?, ?, ?, datetime('now'), datetime('now'))
        ''', (ref[0], wf_id, ref[1]))

conn.commit()
conn.close()
" 2>&1

    if [ $? -eq 0 ]; then
        ok "$basename deployed"
    else
        err "$basename failed"
        return 1
    fi
}

# â”€â”€ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

status() {
    echo "=== n8n Process ==="
    local pid
    pid=$(find_n8n_pid)
    if [ -n "$pid" ]; then
        ok "Running (PID: $pid)"
        ps -o pid,etime,rss,%cpu -p "$pid" 2>/dev/null | tail -1 | awk '{printf "  Uptime: %s | RSS: %s KB | CPU: %s%%\n", $2, $3, $4}'
    else
        err "Not running"
    fi

    echo ""
    echo "=== Workflows in DB ==="
    python3 -c "
import sqlite3
conn = sqlite3.connect('$DB_PATH')
cur = conn.cursor()
cur.execute('SELECT id, name, active FROM workflow_entity ORDER BY name')
for row in cur.fetchall():
    status = 'ðŸŸ¢' if row[2] else 'âšª'
    print(f'  {status} {row[1]} (ID: {row[0]})')
conn.close()
" 2>&1

    echo ""
    echo "=== Health Check ==="
    if curl -s "${N8N_URL}/healthz" >/dev/null 2>&1; then
        ok "HTTP OK"
    elif curl -s "${N8N_URL}/signin" >/dev/null 2>&1; then
        ok "HTTP OK (signin redirect)"
    else
        err "HTTP unreachable"
    fi
}

# â”€â”€ Webhook ãƒ†ã‚¹ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

test_webhooks() {
    echo "=== Testing Webhooks ==="
    local pass=0 fail=0

    echo -n "WF-02 bye-handoff: "
    R=$(curl -s -X POST "${N8N_URL}/webhook/bye-handoff" -H 'Content-Type: application/json' -d '{"subject":"deploy-test"}' 2>&1)
    if echo "$R" | grep -q "slack\|skipped\|success"; then ok "OK"; ((pass++)) || true; else err "FAIL: $R"; ((fail++)) || true; fi

    echo -n "WF-05 health (HIGH): "
    R=$(curl -s -X POST "${N8N_URL}/webhook/health-alert" -H 'Content-Type: application/json' -d '{"items":[{"name":"X","status":"error"}],"score":0.4}' 2>&1)
    if echo "$R" | grep -q "HIGH"; then ok "severity=HIGH"; ((pass++)) || true; else err "FAIL: $R"; ((fail++)) || true; fi

    echo -n "WF-05 health (LOW): "
    R=$(curl -s -X POST "${N8N_URL}/webhook/health-alert" -H 'Content-Type: application/json' -d '{"items":[{"name":"X","status":"ok"}],"score":1.0}' 2>&1)
    if echo "$R" | grep -q "LOW"; then ok "severity=LOW"; ((pass++)) || true; else err "FAIL: $R"; ((fail++)) || true; fi

    echo -n "WF-06 session-start: "
    R=$(curl -s -X POST "${N8N_URL}/webhook/session-start" -H 'Content-Type: application/json' -d '{"mode":"test","agent":"deploy.sh"}' 2>&1)
    if echo "$R" | grep -q "active"; then ok "session active"; ((pass++)) || true; else err "FAIL: $R"; ((fail++)) || true; fi

    echo -n "WF-06 session-end: "
    R=$(curl -s -X POST "${N8N_URL}/webhook/session-end" -H 'Content-Type: application/json' -d '{"subject":"deploy-test"}' 2>&1)
    if echo "$R" | grep -q "ended"; then ok "session ended"; ((pass++)) || true; else err "FAIL: $R"; ((fail++)) || true; fi

    echo -n "WF-03 heartbeat: "
    R=$(curl -s -X POST "${N8N_URL}/webhook/heartbeat" -H 'Content-Type: application/json' -d '{}' 2>&1)
    if echo "$R" | grep -q "heartbeat\|timestamp\|ok"; then ok "OK"; ((pass++)) || true; else warn "SKIP: $R"; fi

    echo ""
    echo "Results: ${pass} passed, ${fail} failed"
    return "${fail}"
}

# â”€â”€ é‡è¤‡å‰Šé™¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

deduplicate_workflows() {
    echo "=== Checking for duplicates ==="
    python3 -c "
import sqlite3
conn = sqlite3.connect('$DB_PATH')
cur = conn.cursor()

# åŒåWFã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
cur.execute('''
    SELECT name, GROUP_CONCAT(id), COUNT(*)
    FROM workflow_entity
    GROUP BY name
    HAVING COUNT(*) > 1
''')

dups = cur.fetchall()
if not dups:
    print('  No duplicates found âœ…')
    conn.close()
    exit(0)

for name, ids_str, count in dups:
    ids = ids_str.split(',')
    keep = ids[-1]  # æœ€æ–°ã‚’ä¿æŒ
    remove = ids[:-1]
    print(f'  Duplicate: {name} ({count} copies, keeping {keep})')
    for old_id in remove:
        cur.execute('DELETE FROM workflow_entity WHERE id = ?', (old_id,))
        try:
            cur.execute('DELETE FROM webhook_entity WHERE \"workflowId\" = ?', (old_id,))
        except: pass
        print(f'    Removed: {old_id}')

conn.commit()
conn.close()
" 2>&1
}

# â”€â”€ ãƒ‡ãƒ—ãƒ­ã‚¤å…¨ä½“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

deploy_all() {
    local should_restart=true
    [ "${1:-}" = "--no-restart" ] && should_restart=false

    echo "=== Deploying all workflows ==="

    local count=0
    for json in "$SCRIPT_DIR"/*.json; do
        [ -f "$json" ] || continue
        [[ "$json" == *docker-compose* ]] && continue
        deploy_workflow "$(basename "$json" .json)"
        ((count++))
    done

    echo ""
    ok "Deployed $count workflows"

    echo ""
    deduplicate_workflows

    if $should_restart; then
        echo ""
        restart_n8n
    else
        info "Skipping restart (--no-restart)"
    fi
}

# â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

case "${1:-all}" in
    --status)
        status
        ;;
    --test)
        test_webhooks
        ;;
    --dedup)
        deduplicate_workflows
        ;;
    --no-restart)
        deploy_all --no-restart
        ;;
    all)
        deploy_all
        ;;
    *)
        deploy_workflow "$1"
        echo ""
        restart_n8n
        ;;
esac
