"""
Prompt Literacy â€” Feedback Analyzer

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒªãƒ†ãƒ©ã‚·ãƒ¼ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æå™¨
AIãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è§£æã—ã€æ”¹å–„ææ¡ˆã¨æŠ€æ³•ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

Usage:
    from mekhane.ergasterion.prompt_literacy.feedback_analyzer import analyze_history
    
    result = analyze_history(chat_text)
    print(result.to_markdown())
"""

from __future__ import annotations

import re
from dataclasses import dataclass, field
from typing import List, Dict, Optional
from datetime import datetime

from .pattern_db import (
    IMPROVEMENT_PATTERNS,
    TECHNIQUE_RECOMMENDATIONS,
    Pattern,
    Technique,
)


@dataclass
class Improvement:
    """æ”¹å–„ææ¡ˆ"""
    original: str
    suggestion: str
    reason: str
    mechanism: str
    line_number: Optional[int] = None


@dataclass
class TechniqueRecommendation:
    """æŠ€æ³•ææ¡ˆ"""
    name: str
    situation: str
    example: str
    mechanism: str


@dataclass
class FeedbackReport:
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¬ãƒãƒ¼ãƒˆ"""
    session_id: str
    utterance_count: int
    analysis_date: str
    improvements: List[Improvement] = field(default_factory=list)
    techniques: List[TechniqueRecommendation] = field(default_factory=list)
    actions: List[str] = field(default_factory=list)
    
    def to_markdown(self) -> str:
        """Markdownå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        lines = [
            "# ğŸ“Š ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ãƒ¬ãƒãƒ¼ãƒˆ",
            "",
            "## åˆ†æå¯¾è±¡",
            f"- ã‚»ãƒƒã‚·ãƒ§ãƒ³: {self.session_id}",
            f"- ç™ºè©±æ•°: {self.utterance_count}",
            f"- åˆ†ææ—¥: {self.analysis_date}",
            "",
        ]
        
        # æ”¹å–„ã™ã¹ãè¡¨ç¾
        if self.improvements:
            lines.append("## ğŸ”´ æ”¹å–„ã™ã¹ãè¡¨ç¾")
            lines.append("")
            lines.append("| # | å…ƒã®è¡¨ç¾ | æ”¹å–„æ¡ˆ | ç†ç”± (ä½œç”¨æ©Ÿåº) |")
            lines.append("|:--|:---------|:-------|:----------------|")
            for i, imp in enumerate(self.improvements, 1):
                lines.append(
                    f"| {i} | {imp.original[:30]}... | {imp.suggestion} | {imp.reason} |"
                )
            lines.append("")
        else:
            lines.append("## âœ… æ”¹å–„ã™ã¹ãè¡¨ç¾: ãªã—")
            lines.append("")
        
        # å–ã‚Šå…¥ã‚Œã‚‹ã¹ãæŠ€æ³•
        if self.techniques:
            lines.append("## ğŸŸ¢ å–ã‚Šå…¥ã‚Œã‚‹ã¹ãæŠ€æ³•")
            lines.append("")
            lines.append("| æŠ€æ³• | é©ç”¨å ´é¢ | åŠ¹æœ |")
            lines.append("|:-----|:---------|:-----|")
            for tech in self.techniques:
                lines.append(f"| {tech.name} | {tech.situation} | {tech.mechanism} |")
            lines.append("")
        
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        if self.actions:
            lines.append("## ğŸ“ˆ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
            for i, action in enumerate(self.actions, 1):
                lines.append(f"{i}. {action}")
            lines.append("")
        
        return "\n".join(lines)


def extract_user_utterances(text: str) -> List[str]:
    """
    ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã‚’æŠ½å‡º
    
    å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
    - "User: ..." / "USER: ..."
    - "<USER_REQUEST>...</USER_REQUEST>"
    - ">>>" prefix
    """
    utterances = []
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: User: ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
    pattern1 = re.findall(r'(?:User|USER):\s*(.+?)(?:\n|$)', text, re.MULTILINE)
    utterances.extend(pattern1)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: XMLå½¢å¼
    pattern2 = re.findall(r'<USER_REQUEST>(.*?)</USER_REQUEST>', text, re.DOTALL)
    utterances.extend(pattern2)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³3: >>> ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
    pattern3 = re.findall(r'>>>\s*(.+?)(?:\n|$)', text, re.MULTILINE)
    utterances.extend(pattern3)
    
    return [u.strip() for u in utterances if u.strip()]


def analyze_utterance(utterance: str, patterns: List[Pattern]) -> List[Improvement]:
    """å˜ä¸€ç™ºè©±ã‚’åˆ†æã—ã€æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
    improvements = []
    
    for pattern in patterns:
        if re.search(pattern.regex, utterance, re.IGNORECASE):
            # è¿½åŠ ã®æ–‡è„ˆãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if pattern.context_check:
                # å°†æ¥: ã‚ˆã‚Šé«˜åº¦ãªæ–‡è„ˆåˆ¤å®šã‚’å®Ÿè£…
                pass
            
            improvements.append(Improvement(
                original=utterance,
                suggestion=pattern.suggestion,
                reason=pattern.reason,
                mechanism=pattern.mechanism,
            ))
    
    return improvements


def detect_missing_techniques(utterances: List[str]) -> List[TechniqueRecommendation]:
    """ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„æŠ€æ³•ã‚’æ¤œå‡ºã—ã€æ¨å¥¨"""
    recommendations = []
    combined = " ".join(utterances)
    
    for key, tech in TECHNIQUE_RECOMMENDATIONS.items():
        # æŠ€æ³•ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if not re.search(tech.detection_pattern, combined, re.IGNORECASE):
            recommendations.append(TechniqueRecommendation(
                name=tech.name,
                situation=tech.situation,
                example=tech.example,
                mechanism=tech.mechanism,
            ))
    
    return recommendations


def generate_actions(
    improvements: List[Improvement],
    techniques: List[TechniqueRecommendation],
) -> List[str]:
    """æ”¹å–„ææ¡ˆã¨æŠ€æ³•ææ¡ˆã‹ã‚‰å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
    actions = []
    
    # æœ€ã‚‚é »å‡ºã™ã‚‹å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
    if improvements:
        # å•é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        pattern_counts: Dict[str, int] = {}
        for imp in improvements:
            key = imp.suggestion
            pattern_counts[key] = pattern_counts.get(key, 0) + 1
        
        # ä¸Šä½2ã¤ã‚’ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åŒ–
        sorted_patterns = sorted(pattern_counts.items(), key=lambda x: -x[1])
        for pattern, count in sorted_patterns[:2]:
            actions.append(f"ã€Œ{pattern}ã€ã®ä½¿ç”¨ã‚’æ„è­˜ã™ã‚‹ ({count}ä»¶æ¤œå‡º)")
    
    # æŠ€æ³•æ¨å¥¨ã‹ã‚‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
    if techniques:
        for tech in techniques[:2]:
            actions.append(f"{tech.name} ã‚’è©¦ã™ï¼ˆä¾‹: {tech.example}ï¼‰")
    
    return actions


def analyze_history(
    text: str,
    session_id: str = "unknown",
) -> FeedbackReport:
    """
    ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’åˆ†æã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    
    Args:
        text: ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãƒ†ã‚­ã‚¹ãƒˆ
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³è­˜åˆ¥å­
    
    Returns:
        FeedbackReport: åˆ†æçµæœ
    """
    # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã‚’æŠ½å‡º
    utterances = extract_user_utterances(text)
    
    # 2. å„ç™ºè©±ã‚’åˆ†æ
    all_improvements: List[Improvement] = []
    for utterance in utterances:
        improvements = analyze_utterance(utterance, IMPROVEMENT_PATTERNS)
        all_improvements.extend(improvements)
    
    # 3. ä¸è¶³æŠ€æ³•ã‚’æ¤œå‡º
    techniques = detect_missing_techniques(utterances)
    
    # 4. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
    actions = generate_actions(all_improvements, techniques)
    
    # 5. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    return FeedbackReport(
        session_id=session_id,
        utterance_count=len(utterances),
        analysis_date=datetime.now().strftime("%Y-%m-%d"),
        improvements=all_improvements,
        techniques=techniques,
        actions=actions,
    )


# --- CLI Interface ---

def main():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python -m mekhane.ergasterion.prompt_literacy.feedback_analyzer <file>")
        sys.exit(1)
    
    filepath = sys.argv[1]
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read()
    
    report = analyze_history(text, session_id=filepath)
    print(report.to_markdown())


if __name__ == "__main__":
    main()
