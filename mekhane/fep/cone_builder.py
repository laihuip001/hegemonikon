# PROOF: [L2/ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£] <- mekhane/fep/
"""
PROOF: [L2/ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£] ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å­˜åœ¨ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„

A0 â†’ Hub Peras WF (@converge) ã§ Cone ã‚’è¨ˆç®—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
   â†’ V[outputs] (åˆ†æ•£åº¦) ã‚’è‡ªå‹•è¨ˆç®—ã—ã€è§£æ¶ˆæ³•ã‚’ææ¡ˆã™ã‚‹
   â†’ C0: Precision Weighting ã§å„å®šç†ã®é‡ã¿ã‚’å‹•çš„ã«æ±ºå®šã™ã‚‹
   â†’ cone_builder.py ãŒæ‹…ã†

Q.E.D.

---

Cone Builder â€” Hub Peras @converge C0-C3 æ”¯æ´ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

Hub WF (/o, /s, /h, /p, /k, /a) ã® @converge C0-C3 ã‚’æ”¯æ´ã™ã‚‹ã€‚
C0: PW æ±ºå®š â†’ C1: Cone æ§‹ç¯‰ + V[outputs] â†’ C2: PW åŠ é‡èåˆ â†’ C3: æ™®éæ€§æ¤œè¨¼

Usage:
    from mekhane.fep.cone_builder import converge

    result = converge(
        series=Series.O,
        outputs={"O1": "æ·±ã„èªè­˜", "O2": "å¼·ã„æ„å¿—", "O3": "é‹­ã„å•ã„", "O4": "ç¢ºå®Ÿãªè¡Œå‹•"},
        pw={"O1": 1.0, "O3": 0.5},  # O1 ã‚’æœ€é‡è¦–ã€O3 ã‚„ã‚„é‡è¦–
    )
    print(result.apex)               # çµ±åˆåˆ¤æ–­
    print(result.dispersion)         # V[outputs]
    print(result.resolution_method)  # simple/pw_weighted/root
    print(result.pw)                 # {'O1': 1.0, 'O3': 0.5}
    print(result.pw_weights)         # æ­£è¦åŒ–æ¸ˆã¿é‡ã¿
"""

from __future__ import annotations

import re
from difflib import SequenceMatcher
from typing import Dict, List, Optional

from mekhane.fep.category import Cone, Series, build_cone


# å¦å®šèªãƒ‘ã‚¿ãƒ¼ãƒ³ (æ—¥æœ¬èª + è‹±èª)
_NEGATION_RE = re.compile(
    r"(?:ãªã„|ã—ãªã„|ã§ããªã„|ä¸å¯|å¦å®š|åå¯¾|æ‹’å¦|ä¸­æ­¢"
    r"|stop|no|not|never|don'?t|won'?t|reject|cancel)",
    re.IGNORECASE,
)
# æ–¹å‘æ€§: GO ç³»
_DIR_GO = re.compile(
    r"(?:ã™ã‚‹|é€²ã‚€|é–‹å§‹|GO|yes|accept|approve|keep|continue|å®Ÿè¡Œ|è¿½åŠ )",
    re.IGNORECASE,
)
# æ–¹å‘æ€§: WAIT ç³»
_DIR_WAIT = re.compile(
    r"(?:ã—ãªã„|æ­¢ã‚ã‚‹|ä¸­æ­¢|WAIT|no|reject|cancel|stop|remove|å‰Šé™¤|å»ƒæ­¢)",
    re.IGNORECASE,
)


# =============================================================================
# C0: Precision Weighting (PW)
# =============================================================================


# PURPOSE: C0 â€” PW ã®æ­£è¦åŒ–ã€‚raw pw [-1, +1] â†’ èåˆç”¨é‡ã¿ [0, 2]
def normalize_pw(
    outputs: Dict[str, str],
    pw: Optional[Dict[str, float]] = None,
) -> Dict[str, float]:
    """Normalize Precision Weighting for fusion.

    Formula: weight_i = 1 + pw_i
    - pw_i = 0  â†’ weight = 1.0 (neutral, uniform)
    - pw_i = +1 â†’ weight = 2.0 (double emphasis)
    - pw_i = -1 â†’ weight = 0.0 (fully suppressed)

    Returns:
        Dict[str, float]: normalized weights (0.0 - 2.0)
    """
    if pw is None:
        pw = {}

    return {
        tid: 1.0 + max(-1.0, min(1.0, pw.get(tid, 0.0)))
        for tid in outputs
    }


# PURPOSE: PW ãŒå‡ç­‰ã‹ã©ã†ã‹åˆ¤å®šã™ã‚‹
def is_uniform_pw(pw: Optional[Dict[str, float]]) -> bool:
    """Check if precision weighting is uniform (all zero or not specified)."""
    if not pw:
        return True
    return all(abs(v) < 1e-9 for v in pw.values())


# =============================================================================
# C1: å°„ã®å¯¾æ¯” (Contrast) â€” V[outputs]
# =============================================================================


# PURPOSE: @converge C1 â€” å°„ã®å¯¾æ¯” (Contrast): V[outputs] ã‚’è¨ˆç®—ã™ã‚‹
def compute_dispersion(outputs: Dict[str, str]) -> float:
    """Compute V[outputs] â€” the dispersion of theorem outputs.

    Uses pairwise text similarity + negation detection + direction coding
    to estimate how much the 4 outputs agree or contradict.

    Components:
        1. SequenceMatcher similarity â†’ base dispersion
        2. Negation contradiction â†’ bonus (ãƒ†ã‚­ã‚¹ãƒˆé–“ã§å¦å®šãŒæ··åœ¨)
        3. Direction contradiction â†’ bonus (GO vs WAIT ãŒæ··åœ¨)

    Returns:
        float: dispersion score (0.0-1.0)
        0.0 = all outputs identical
        1.0 = all outputs completely different
    """
    if not outputs or len(outputs) <= 1:
        return 0.0

    values = list(outputs.values())
    similarities: List[float] = []

    for i in range(len(values)):
        for j in range(i + 1, len(values)):
            ratio = SequenceMatcher(None, values[i], values[j]).ratio()
            similarities.append(ratio)

    if not similarities:
        return 0.0

    avg_similarity = sum(similarities) / len(similarities)
    base = 1.0 - avg_similarity

    # å¦å®šçŸ›ç›¾ãƒœãƒ¼ãƒŠã‚¹: ä¸€éƒ¨ã ã‘å¦å®šèªãŒã‚ã‚‹ = çŸ›ç›¾
    neg_flags = [bool(_NEGATION_RE.search(v)) for v in values]
    neg_bonus = 0.0
    if any(neg_flags) and not all(neg_flags):
        neg_bonus = 0.15  # å¦å®šã®æ··åœ¨ã§ +0.15

    # æ–¹å‘æ€§çŸ›ç›¾ãƒœãƒ¼ãƒŠã‚¹: GO ã¨ WAIT ãŒæ··åœ¨
    dir_bonus = 0.0
    dirs = []
    for v in values:
        go = bool(_DIR_GO.search(v))
        wait = bool(_DIR_WAIT.search(v))
        if go and not wait:
            dirs.append(1)
        elif wait and not go:
            dirs.append(-1)
        else:
            dirs.append(0)
    non_zero = [d for d in dirs if d != 0]
    if non_zero and any(d > 0 for d in non_zero) and any(d < 0 for d in non_zero):
        dir_bonus = 0.2  # æ–¹å‘æ€§çŸ›ç›¾ã§ +0.2

    return round(min(1.0, base + neg_bonus + dir_bonus), 3)


# =============================================================================
# C2: Cone ã®é ‚ç‚¹æ¢ç´¢ (Resolve) â€” PW åŠ é‡èåˆ
# =============================================================================


# PURPOSE: @converge C2 â€” è§£æ¶ˆæ³•ã‚’åˆ¤å®šã™ã‚‹ (PW è€ƒæ…®)
def resolve_method(
    dispersion: float,
    pw: Optional[Dict[str, float]] = None,
) -> str:
    """Determine resolution method based on V[outputs] + PW.

    | V[outputs] | PW     | Method         |
    |:-----------|:-------|:---------------|
    | > 0.3      | any    | root           |
    | > 0.1      | any    | pw_weighted    |
    | â‰¤ 0.1      | â‰  0    | pw_weighted    |
    | â‰¤ 0.1      | = 0    | simple         |

    Returns:
        str: "simple", "pw_weighted", or "root"
    """
    if dispersion > 0.3:
        return "root"
    elif dispersion > 0.1:
        return "pw_weighted"
    elif not is_uniform_pw(pw):
        return "pw_weighted"
    else:
        return "simple"


# PURPOSE: PW åŠ é‡èåˆãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¨ˆç®—ã™ã‚‹
def compute_pw_table(
    outputs: Dict[str, str],
    pw: Optional[Dict[str, float]] = None,
) -> List[Dict]:
    """Compute the PW weighting table for each theorem.

    Returns a list of dicts with:
    - theorem_id: str
    - output: str (truncated)
    - pw_raw: float (-1 to +1)
    - weight: float (0 to 2, normalized)
    - weight_pct: float (percentage contribution)
    """
    weights = normalize_pw(outputs, pw)
    total = sum(weights.values())
    if total == 0:
        total = 1.0  # avoid division by zero

    table = []
    for tid, output in outputs.items():
        raw = (pw or {}).get(tid, 0.0)
        w = weights[tid]
        table.append({
            "theorem_id": tid,
            "output": output[:50] + "..." if len(output) > 50 else output,
            "pw_raw": raw,
            "weight": w,
            "weight_pct": round(w / total * 100, 1),
        })
    return table


# =============================================================================
# Main: converge() â€” C0-C3 ä¸€æ‹¬å®Ÿè¡Œ
# =============================================================================


# PURPOSE: @converge C0-C3 ã‚’ä¸€æ‹¬å®Ÿè¡Œã™ã‚‹
def converge(
    series: Series,
    outputs: Dict[str, str],
    pw: Optional[Dict[str, float]] = None,
    apex: Optional[str] = None,
    confidence: float = 0.0,
) -> Cone:
    """Execute @converge C0-C3 and return a fully populated Cone.

    This is the main entry point for Hub Peras workflows.

    Args:
        series: Which series (O/S/H/P/K/A)
        outputs: Dict mapping theorem_id -> output string
        pw: Precision Weighting dict {theorem_id: weight}.
            weight âˆˆ [-1, +1]. 0 = neutral, +1 = emphasize, -1 = suppress.
            None or empty = uniform weighting (equivalent to +/- operators).
        apex: Optional pre-computed integrated judgment
        confidence: Optional confidence score (0-100)

    Returns:
        Cone with C0 pw, C1 projections, C2 resolution, C3 universality

    Formula (C2 weighted fusion):
        çµ±åˆå‡ºåŠ› = Î£(å®šç†_i Ã— (1 + pw_i)) / Î£(1 + pw_i)
    """
    # C0: Precision Weighting
    cone_pw = pw or {}

    # C1: Build Cone with projections
    cone = build_cone(series, outputs)
    cone.pw = {k: max(-1.0, min(1.0, v)) for k, v in cone_pw.items()}

    # C1: Compute dispersion
    cone.dispersion = compute_dispersion(outputs)

    # C2: Determine resolution method (PW-aware)
    cone.resolution_method = resolve_method(cone.dispersion, cone_pw)

    # C2: Set apex if provided
    if apex:
        cone.apex = apex

    # C3: Cone å“è³ªè©•ä¾¡ (è‡ªå‹•è¨ˆç®—)
    if confidence > 0:
        cone.confidence = confidence  # å¤–éƒ¨æŒ‡å®šã‚’å„ªå…ˆ
    else:
        # è‡ªå‹•è¨ˆç®—: base = (1 - dispersion) * 100
        base_conf = (1.0 - cone.dispersion) * 100.0
        # å¦å®šãƒšãƒŠãƒ«ãƒ†ã‚£: apex ã¨ projection ã®çŸ›ç›¾
        penalty = 0.0
        if cone.apex:
            apex_neg = bool(_NEGATION_RE.search(cone.apex))
            for proj in cone.projections:
                if proj.output and bool(_NEGATION_RE.search(proj.output)) != apex_neg:
                    penalty += 5.0
        cone.confidence = max(0.0, min(100.0, base_conf - penalty))

    cone.is_universal = cone.dispersion <= 0.1 and cone.confidence >= 70.0

    return cone


# =============================================================================
# Display
# =============================================================================


# PURPOSE: å…¨ Series ã®åœè«–çš„ä½ç½®ã‚’è¡¨ç¤ºã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
def describe_cone(cone: Cone) -> str:
    """Format a Cone as human-readable text for WF output."""
    has_pw = not is_uniform_pw(cone.pw)

    # Header
    lines = [
        f"## Cone: {cone.series.value}-series",
        "",
    ]

    # C0: PW section (if non-uniform)
    if has_pw:
        lines.extend([
            "### C0: Precision Weighting",
            "",
        ])
        table = compute_pw_table(
            {p.theorem_id: p.output for p in cone.projections},
            cone.pw,
        )
        lines.append("| Theorem | pw | Weight | % |")
        lines.append("|:--------|:--:|:------:|:--:|")
        for row in table:
            pw_str = f"+{row['pw_raw']}" if row["pw_raw"] > 0 else str(row["pw_raw"])
            lines.append(
                f"| {row['theorem_id']} | {pw_str} | {row['weight']:.1f} | {row['weight_pct']}% |"
            )
        lines.append("")

    # C1: Projections
    lines.extend([
        "### C1: å°„ã®å¯¾æ¯”",
        "",
        "| Theorem | Hom Label | Output |",
        "|:--------|:----------|:-------|",
    ])
    for proj in cone.projections:
        lines.append(f"| {proj.theorem_id} | {proj.hom_label} | {proj.output} |")

    # C2: Resolution
    lines.extend([
        "",
        f"**V[outputs]** = {cone.dispersion:.3f}"
        + (" âœ…" if cone.dispersion <= 0.1
           else " âš ï¸" if cone.dispersion <= 0.3
           else " ğŸ”´"),
        f"**Resolution** = {cone.resolution_method}",
        f"**Apex** = {cone.apex or '(æœªè¨­å®š)'}",
    ])

    # C3: Cone å“è³ªè©•ä¾¡
    lines.extend([
        f"**Confidence** = {cone.confidence:.0f}%",
        f"**Universal** = {'âœ… Yes' if cone.is_universal else 'âŒ No'}",
    ])
    if cone.series == Series.S and cone.dispersion > 0.1:
        lines.append("âš ï¸ **Devil's Advocate æ¨å¥¨** (S-series, V > 0.1)")

    return "\n".join(lines)
