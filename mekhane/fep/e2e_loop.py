# PROOF: [L1/FEP] <- mekhane/fep/
# PURPOSE: Active Inference ã® E2E ãƒ«ãƒ¼ãƒ—ã‚’çµ±åˆå®Ÿè¡Œã™ã‚‹
"""
FEP E2E Loop â€” å‹•ãèªçŸ¥ä½“ã®è¨¼æ˜

å…¨ FEP ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’çµ±åˆã—ã€é–‰ã˜ãŸ Active Inference ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ã€‚

## æ§‹é€ 

               å…¥åŠ›
              â•±    â•²
        FEP Agent   Attractor
        (act/obs)   (Series/WF)
              â•²    â•±
             çµ±åˆåˆ¤æ–­
                â†“
          Dispatch + Cone
                â†“
              å­¦ç¿’ (A-matrix)
                â†“
            æ¬¡ã‚µã‚¤ã‚¯ãƒ«ã¸

## ä½¿ç”¨ä¾‹

    from mekhane.fep.e2e_loop import run_loop
    results = run_loop("ãªãœã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯å­˜åœ¨ã™ã‚‹ã®ã‹", cycles=2)
    print(results.summary)
"""

from __future__ import annotations

import tempfile
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional


# =============================================================================
# Data Classes
# =============================================================================


@dataclass
class CycleResult:
    """1ã‚µã‚¤ã‚¯ãƒ«ã® E2E çµæœ"""
    cycle: int
    # Encoding
    observation: tuple[int, int, int]
    obs_decoded: Dict[str, str]
    # FEP inference
    fep_action: str = "act"  # "act" or "observe"
    fep_entropy: float = 0.0
    fep_confidence: float = 0.0
    fep_raw: Dict[str, Any] = field(default_factory=dict)
    # Attractor / Dispatch
    dispatch_wf: Optional[str] = None
    dispatch_series: Optional[str] = None
    dispatch_reason: Optional[str] = None
    dispatch_oscillation: Optional[str] = None
    dispatch_alternatives: List[str] = field(default_factory=list)
    # Cone
    cone_apex: Optional[str] = None
    cone_dispersion: Optional[float] = None
    cone_method: Optional[str] = None
    # Learning
    a_matrix_updated: bool = False
    should_epoche: bool = False


@dataclass
class E2EResult:
    """E2E ãƒ«ãƒ¼ãƒ—ã®å…¨ã‚µã‚¤ã‚¯ãƒ«çµæœ"""
    input_text: str
    cycles: List[CycleResult]
    learning_proof: Optional[str] = None

    @property
    def summary(self) -> str:
        """äººé–“å‘ã‘ã‚µãƒãƒªãƒ¼"""
        lines = [
            f"â•â•â• FEP E2E Loop: {len(self.cycles)} cycle(s) â•â•â•",
            f"Input: {self.input_text[:60]}",
        ]
        for c in self.cycles:
            meta = "ğŸ”´ observe" if c.fep_action == "observe" else "ğŸŸ¢ act"
            wf = c.dispatch_wf or "(none)"
            lines.append(
                f"  Cycle {c.cycle}: {meta} â†’ {wf} "
                f"(entropy={c.fep_entropy:.2f}, conf={c.fep_confidence:.0%})"
            )
        if self.learning_proof:
            lines.append(f"ğŸ“ˆ Learning: {self.learning_proof}")
        return "\n".join(lines)


# =============================================================================
# Core Loop
# =============================================================================


def run_loop(
    user_input: str,
    *,
    cycles: int = 2,
    a_matrix_path: Optional[str] = None,
    force_cpu: bool = False,
) -> E2EResult:
    """FEP E2E ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ã€‚

    Active Inference ã®å®Œå…¨ãªã‚µã‚¤ã‚¯ãƒ«ã‚’æŒ‡å®šå›æ•°å®Ÿè¡Œã—ã€
    å­¦ç¿’ã«ã‚ˆã‚‹Aè¡Œåˆ—ã®æ”¹å–„ã‚’è¨¼æ˜ã™ã‚‹ã€‚

    Args:
        user_input: è‡ªç„¶è¨€èªå…¥åŠ›
        cycles: å®Ÿè¡Œã‚µã‚¤ã‚¯ãƒ«æ•° (default: 2 â€” å­¦ç¿’è¨¼æ˜ã®ãŸã‚)
        a_matrix_path: Aè¡Œåˆ—ã®ä¿å­˜å…ˆ (None=ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«)
        force_cpu: Attractor ã® CPU å¼·åˆ¶
    """
    # Lazy imports (heavy dependencies)
    from mekhane.fep.encoding import (
        encode_input,
        decode_observation,
        run_fep_with_learning,
    )
    from mekhane.fep.attractor_dispatcher import AttractorDispatcher
    from mekhane.fep.cone_builder import converge
    from mekhane.fep.category import Series

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã§Aè¡Œåˆ—ã‚’ç®¡ç† (ãƒ†ã‚¹ãƒˆæ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³æ€§)
    if a_matrix_path is None:
        _tmp = tempfile.NamedTemporaryFile(suffix="_e2e_A.npy", delete=False)
        a_matrix_path = _tmp.name
        _tmp.close()
        Path(a_matrix_path).unlink(missing_ok=True)  # ç©ºã®çŠ¶æ…‹ã‹ã‚‰é–‹å§‹

    try:
        dispatcher = AttractorDispatcher(force_cpu=force_cpu)
    except (FileNotFoundError, OSError, ImportError):
        dispatcher = None
    results: List[CycleResult] = []

    for i in range(cycles):
        cycle = CycleResult(cycle=i, observation=(0, 0, 0), obs_decoded={})

        # â”€â”€ Step 1: Encode â”€â”€
        obs = encode_input(user_input)
        cycle.observation = obs
        cycle.obs_decoded = decode_observation(obs)

        # â”€â”€ Step 2: Parallel Judgment â”€â”€

        # 2a. FEP Agent (meta-level: act or observe?)
        fep_result = run_fep_with_learning(
            obs, a_matrix_path=a_matrix_path, learning_rate=50.0,
        )
        cycle.fep_action = fep_result.get("action_name", "act")
        cycle.fep_entropy = fep_result.get("entropy", 0.0)
        cycle.fep_confidence = 1.0 - min(fep_result.get("entropy", 0.0) / 3.0, 1.0)
        cycle.fep_raw = fep_result
        cycle.a_matrix_updated = True
        cycle.should_epoche = fep_result.get("should_epoche", False)

        # 2b. Attractor (content-level: which WF?)
        plan = None
        if dispatcher is not None:
            try:
                plan = dispatcher.dispatch(user_input)
            except (FileNotFoundError, OSError) as e:
                # Embedding model unavailable (CI/test env)
                plan = None

        if plan is not None:
            cycle.dispatch_wf = plan.primary.workflow
            cycle.dispatch_series = plan.primary.series
            cycle.dispatch_reason = plan.primary.reason
            cycle.dispatch_oscillation = plan.oscillation.value if hasattr(plan.oscillation, 'value') else str(plan.oscillation)
            cycle.dispatch_alternatives = [
                d.workflow for d in plan.alternatives
            ]

        # â”€â”€ Step 3: Meta-judgment integration â”€â”€
        # FEP says "observe" â†’ suppress dispatch (don't act)
        if cycle.fep_action == "observe" and plan is not None:
            cycle.dispatch_reason = (
                f"[SUPPRESSED by FEP: observe mode] {cycle.dispatch_reason}"
            )

        # â”€â”€ Step 4: Cone (simulated WF output) â”€â”€
        if plan is not None and cycle.fep_action != "observe":
            simulated_cone = _simulate_cone(plan.primary.series, user_input)
            cycle.cone_apex = simulated_cone.get("apex")
            cycle.cone_dispersion = simulated_cone.get("dispersion")
            cycle.cone_method = simulated_cone.get("method")

        results.append(cycle)

    # â”€â”€ Learning proof â”€â”€
    learning_proof = None
    if len(results) >= 2:
        e0 = results[0].fep_entropy
        e1 = results[-1].fep_entropy
        if e0 > 0:
            change = ((e1 - e0) / e0) * 100
            if e1 < e0:
                learning_proof = (
                    f"ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ¸›å°‘: {e0:.3f} â†’ {e1:.3f} "
                    f"({change:+.1f}%) â€” ãƒ¢ãƒ‡ãƒ«ã®ç¢ºä¿¡åº¦ãŒå‘ä¸Š"
                )
            elif e1 == e0:
                learning_proof = (
                    f"ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å®‰å®š: {e0:.3f} â†’ {e1:.3f} â€” "
                    f"1ã‚µã‚¤ã‚¯ãƒ«ç›®ã‹ã‚‰å®‰å®š (ååˆ†ãªãƒ‡ãƒ¼ã‚¿ã§å¤‰åŒ–ãŒæœŸå¾…ã•ã‚Œã‚‹)"
                )
            else:
                learning_proof = (
                    f"ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å¢—åŠ : {e0:.3f} â†’ {e1:.3f} "
                    f"({change:+.1f}%) â€” æ¢ç´¢ãƒ•ã‚§ãƒ¼ã‚º"
                )

    return E2EResult(
        input_text=user_input,
        cycles=results,
        learning_proof=learning_proof,
    )


# =============================================================================
# Simulated Cone
# =============================================================================


_SERIES_THEOREMS = {
    "O": ["O1", "O2", "O3", "O4"],
    "S": ["S1", "S2", "S3", "S4"],
    "H": ["H1", "H2", "H3", "H4"],
    "P": ["P1", "P2", "P3", "P4"],
    "K": ["K1", "K2", "K3", "K4"],
    "A": ["A1", "A2", "A3", "A4"],
}

_THEOREM_TEMPLATES = {
    "O1": "ã“ã®å•ã„ã®æœ¬è³ªã¯ã€Œ{topic}ã€ã®æ ¹æºçš„ãªæ„å‘³ã«ã‚ã‚‹",
    "O2": "ç›®æ¨™: {topic} ã‚’æ˜ç¢ºåŒ–ã—ã€å„ªå…ˆé †ä½ã‚’æ±ºå®šã™ã‚‹",
    "O3": "å•ã†ã¹ãã¯ã€Œãªãœ {topic} ãªã®ã‹ã€ã§ã¯ãªãã€Œä½•ã‚’è¦‹è½ã¨ã—ã¦ã„ã‚‹ã‹ã€",
    "O4": "å®Ÿè¡Œè¨ˆç”»: {topic} ã«å¯¾ã—æ®µéšçš„ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã™ã‚‹",
    "S1": "ã‚¹ã‚±ãƒ¼ãƒ«: {topic} ã¯ Micro/Meso/Macro ã®ã©ã®ç²’åº¦ã‹",
    "S2": "æ‰‹æ³•: {topic} ã«ã¯ä»¥ä¸‹ã®æ–¹æ³•è«–ãŒé©ç”¨å¯èƒ½",
    "S3": "åŸºæº–: {topic} ã®æˆåŠŸåŸºæº–ã‚’å®šé‡åŒ–ã™ã‚‹",
    "S4": "å®Ÿè·µ: {topic} ã®ä¾¡å€¤ã¯å®Ÿè¡Œã•ã‚Œã‚‹ã“ã¨ã§åˆã‚ã¦ç™ºæ®ã•ã‚Œã‚‹",
    "H1": "ç›´æ„Ÿçš„åå¿œ: {topic} ã«å¯¾ã™ã‚‹åˆæœŸæ„Ÿæƒ…ã¯è‚¯å®šçš„",
    "H2": "ç¢ºä¿¡åº¦: {topic} ã«ã¤ã„ã¦ 70% ã®ç¢ºä¿¡ãŒã‚ã‚‹",
    "H3": "æ¬²æ±‚: {topic} ã‚’è¿½æ±‚ã™ã‚‹å‹•æ©Ÿã¯ååˆ†ã«å¼·ã„",
    "H4": "ä¿¡å¿µ: {topic} ã¯ HegemonikÃ³n ã®æ–¹å‘æ€§ã¨ä¸€è‡´ã™ã‚‹",
    "P1": "ã‚¹ã‚³ãƒ¼ãƒ—: {topic} ã®å¢ƒç•Œã‚’å®šç¾©ã™ã‚‹",
    "P2": "çµŒè·¯: {topic} ã¸ã®åˆ°é”ãƒ‘ã‚¹ã‚’è¨­è¨ˆã™ã‚‹",
    "P3": "è»Œé“: {topic} ã®é€²æ—ã‚µã‚¤ã‚¯ãƒ«ã‚’å®šç¾©ã™ã‚‹",
    "P4": "æŠ€æ³•: {topic} ã«æœ€é©ãªæŠ€æ³•ã‚’é¸æŠã™ã‚‹",
    "K1": "ã‚¿ã‚¤ãƒŸãƒ³ã‚°: ä»Šã¯ {topic} ã«å–ã‚Šçµ„ã‚€å¥½æ©Ÿã‹",
    "K2": "æœŸé™: {topic} ã®æ™‚é–“åˆ¶ç´„ã‚’è©•ä¾¡ã™ã‚‹",
    "K3": "ç›®çš„: {topic} ã®ç©¶æ¥µçš„ãªç›®çš„ã‚’å•ã„ç›´ã™",
    "K4": "çŸ¥æµ: {topic} ã«é–¢ã™ã‚‹å…ˆè¡Œç ”ç©¶ã‚’å‚ç…§ã™ã‚‹",
    "A1": "æ„Ÿæƒ…: {topic} ã«å¯¾ã™ã‚‹æ„Ÿæƒ…çš„åå¿œã‚’è©•ä¾¡ã™ã‚‹",
    "A2": "åˆ¤æ–­: {topic} ã‚’æ‰¹åˆ¤çš„ã«è©•ä¾¡ã™ã‚‹",
    "A3": "æ ¼è¨€: {topic} ã‹ã‚‰æŠ½å‡ºã•ã‚Œã‚‹åŸå‰‡ã¯ä½•ã‹",
    "A4": "çŸ¥è­˜: {topic} ã«é–¢ã™ã‚‹ç¢ºç«‹ã•ã‚ŒãŸçŸ¥è­˜ã‚’ç¢ºèªã™ã‚‹",
}


def _simulate_cone(series: str, user_input: str) -> Dict[str, Any]:
    """WF å®Ÿè¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€Cone æ§‹ç¯‰ã®å‹•ä½œã‚’è¨¼æ˜ã™ã‚‹ã€‚

    NOTE: ã“ã‚Œã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚å®Ÿéš›ã® WF å®Ÿè¡Œã¯è¡Œã‚ãªã„ã€‚
    å°†æ¥ã€HermÄ“neus ã¨æ¥ç¶šã™ã‚Œã°å®Ÿ WF å‡ºåŠ›ã‚’ä½¿ãˆã‚‹ã€‚
    """
    try:
        from mekhane.fep.cone_builder import (
            compute_dispersion,
            resolve_method,
        )
    except ImportError:
        return {"apex": "(cone_builder unavailable)", "dispersion": 0.0, "method": "n/a"}

    theorems = _SERIES_THEOREMS.get(series, ["T1", "T2", "T3", "T4"])
    topic = user_input[:30]

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‡ºåŠ›ã‚’ç”Ÿæˆ
    outputs = {}
    for t in theorems:
        template = _THEOREM_TEMPLATES.get(t, "{topic} ã«é–¢ã™ã‚‹åˆ†æ")
        outputs[t] = template.format(topic=topic)

    # Dispersion ã¨ resolve method ã‚’è¨ˆç®—
    dispersion = compute_dispersion(outputs)
    method = resolve_method(dispersion)

    # Apex = æœ€ã‚‚ä»£è¡¨çš„ãªå‡ºåŠ› (primary theorem)
    apex = outputs.get(theorems[0], "")

    return {
        "apex": apex,
        "dispersion": dispersion,
        "method": method,
        "outputs": outputs,
    }
