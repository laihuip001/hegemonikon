"""
Text-to-Observation Encoding for Hegemonik√≥n Active Inference

Converts natural language input into observation indices for the FEP agent.

Observation modalities:
- context: [ambiguous, clear] ‚Üí 2 values
- urgency: [low, medium, high] ‚Üí 3 values
- confidence: [low, medium, high] ‚Üí 3 values

References:
- Anti-Skip Protocol (context clarity)
- K-series Kairos (urgency)
- A-series Akribeia (confidence)
"""

from typing import Dict, Tuple, Optional, List
import re

from .state_spaces import OBSERVATION_MODALITIES


# =============================================================================
# Keyword Patterns for Analysis
# =============================================================================

# Context clarity indicators (Anti-Skip Protocol)
CONTEXT_PATTERNS: Dict[str, List[str]] = {
    "clear": [
        r"(ÊòéÁ¢∫|ÂÖ∑‰ΩìÁöÑ|„ÅØ„Å£„Åç„Çä|clear|specific|detailed|explicitly)",
        r"(„Éï„Ç°„Ç§„É´|„Éë„Çπ|„Ç≥„Éº„Éâ|Èñ¢Êï∞|„ÇØ„É©„Çπ)",  # References to specific code
        r"\.py",  # Python files
        r"```",  # Code blocks indicate specificity
        r"file://",  # File paths
    ],
    "ambiguous": [
        r"(„Å™„Çì„Åã|‰Ωï„Åã|„Å©„ÅÜ|„Å™„Å´|something|somehow|maybe)",
        r"(ÊõñÊòß|‰∏çÊòé|unclear|vague|uncertain)",
        r"\?{2,}",  # Multiple question marks
        r"^\s*\?\s*$",  # Just a question mark
    ],
}

# Urgency indicators (K-series Kairos)
URGENCY_PATTERNS: Dict[str, List[str]] = {
    "high": [
        r"(Á∑äÊÄ•|ÊÄ•„Åé|„Åô„Åê„Å´|‰ªä„Åô„Åê|urgent|asap|immediately|now)",
        r"(deadline|ÊúüÈôê|Á∑†„ÇÅÂàá„Çä)",
        r"!{2,}",  # Multiple exclamation marks
        r"(„Éê„Ç∞|„Ç®„É©„Éº|Â£ä„Çå|crashed|broken|error|bug)",
    ],
    "medium": [
        r"(Êó©„ÇÅ|„Åß„Åç„Çå„Å∞|soon|when.*possible)",
        r"(‰ªäÊó•|Êú¨Êó•|today)",
    ],
    "low": [
        r"(„ÅÑ„Å§„Åß„ÇÇ|‰ΩôË£ï|eventually|whenever|later)",
        r"(„Ç¢„Ç§„Éá„Ç¢|Ê§úË®é|ËÄÉ„Åà|think|consider|explore)",
    ],
}

# Confidence indicators (A-series Akribeia)
CONFIDENCE_PATTERNS: Dict[str, List[str]] = {
    "high": [
        r"^\s*y\s*$",  # Simple "y" approval
        r"\b(„ÅØ„ÅÑ|yes|Á¢∫‰ø°|certain|definitely|ÊâøË™ç|approve)\b",
        r"\b(„ÇÑ„Å£„Å¶|ÂÆüË°å|do it|execute|proceed)\b",
    ],
    "medium": [
        r"\b(„Åü„Å∂„Çì|„Åä„Åù„Çâ„Åè|probably|maybe|think so)\b",
        r"\b(Á∂ö„Åë„Çà„ÅÜ|continue|ÈÄ≤„ÇÅ„Çà„ÅÜ)\b",
    ],
    "low": [
        r"\b(„Çè„Åã„Çâ„Å™„ÅÑ|‰∏çÊòé|unsure|don't know|unclear)\b",
        r"\b(„Å©„ÅÜÊÄù„ÅÜ|what do you think|ÊÑèË¶ã|opinion)\b",
        r"\?$",  # Ends with question mark
    ],
}


# =============================================================================
# Encoding Functions
# =============================================================================

def analyze_context(text: str) -> str:
    """Analyze text for context clarity.
    
    Args:
        text: Input text to analyze
        
    Returns:
        'clear' or 'ambiguous'
    """
    clear_score = 0
    ambiguous_score = 0
    
    for pattern in CONTEXT_PATTERNS["clear"]:
        if re.search(pattern, text, re.IGNORECASE):
            clear_score += 1
    
    for pattern in CONTEXT_PATTERNS["ambiguous"]:
        if re.search(pattern, text, re.IGNORECASE):
            ambiguous_score += 1
    
    # Length heuristic: longer messages tend to be clearer
    if len(text) > 100:
        clear_score += 1
    
    return "clear" if clear_score > ambiguous_score else "ambiguous"


def analyze_urgency(text: str) -> str:
    """Analyze text for urgency level.
    
    Args:
        text: Input text to analyze
        
    Returns:
        'low', 'medium', or 'high'
    """
    scores = {"low": 0, "medium": 0, "high": 0}
    
    for level, patterns in URGENCY_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, text, re.IGNORECASE):
                scores[level] += 1
    
    # Default to low if no patterns match
    if sum(scores.values()) == 0:
        return "low"
    
    return max(scores, key=scores.get)


def analyze_confidence(text: str) -> str:
    """Analyze text for confidence level.
    
    Args:
        text: Input text to analyze
        
    Returns:
        'low', 'medium', or 'high'
    """
    scores = {"low": 0, "medium": 0, "high": 0}
    
    for level, patterns in CONFIDENCE_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, text, re.IGNORECASE):
                scores[level] += 1
    
    # Default to medium if no patterns match
    if sum(scores.values()) == 0:
        return "medium"
    
    return max(scores, key=scores.get)


def encode_input(text: str) -> Tuple[int, int, int]:
    """Convert text input to observation indices.
    
    This is the main entry point for text-to-observation encoding.
    
    Args:
        text: Natural language input
        
    Returns:
        Tuple of observation indices:
        - context_idx: 0 (ambiguous) or 1 (clear)
        - urgency_idx: 0 (low), 1 (medium), or 2 (high)
        - confidence_idx: 0 (low), 1 (medium), or 2 (high)
    
    Example:
        >>> encode_input("Á∑äÊÄ•Ôºö„Éï„Ç°„Ç§„É´„Çí‰øÆÊ≠£„Åó„Å¶")
        (1, 2, 1)  # clear context, high urgency, medium confidence
        
        >>> encode_input("y")
        (0, 0, 2)  # ambiguous context, low urgency, high confidence
    """
    context = analyze_context(text)
    urgency = analyze_urgency(text)
    confidence = analyze_confidence(text)
    
    # Convert to indices
    context_idx = OBSERVATION_MODALITIES["context"].index(context)
    urgency_idx = OBSERVATION_MODALITIES["urgency"].index(urgency)
    confidence_idx = OBSERVATION_MODALITIES["confidence"].index(confidence)
    
    return (context_idx, urgency_idx, confidence_idx)


def encode_to_flat_index(text: str) -> int:
    """Convert text input to flat observation index.
    
    For use with single-modality pymdp agents.
    
    Args:
        text: Natural language input
        
    Returns:
        Flat observation index (0-7)
    """
    context_idx, urgency_idx, confidence_idx = encode_input(text)
    
    # Compute flat index (context * 6 + urgency * 3 + confidence)
    # But current A matrix uses: context(2) + urgency(3) + confidence(3) = 8
    # So we return the primary indicator based on context
    return context_idx + 2 * urgency_idx + confidence_idx


def decode_observation(obs: Tuple[int, int, int]) -> Dict[str, str]:
    """Convert observation indices back to human-readable format.
    
    Args:
        obs: Tuple of (context_idx, urgency_idx, confidence_idx)
        
    Returns:
        Dict with human-readable observation values
    """
    return {
        "context": OBSERVATION_MODALITIES["context"][obs[0]],
        "urgency": OBSERVATION_MODALITIES["urgency"][obs[1]],
        "confidence": OBSERVATION_MODALITIES["confidence"][obs[2]],
    }


# =============================================================================
# Structured Input Encoding
# =============================================================================

def encode_structured_input(
    context: Optional[str] = None,
    urgency: Optional[str] = None,
    confidence: Optional[str] = None,
) -> Tuple[int, int, int]:
    """Encode explicitly specified observation values.
    
    Use this when observation values are known programmatically
    rather than needing to be inferred from text.
    
    Args:
        context: 'ambiguous' or 'clear' (default: 'ambiguous')
        urgency: 'low', 'medium', or 'high' (default: 'low')
        confidence: 'low', 'medium', or 'high' (default: 'medium')
        
    Returns:
        Tuple of observation indices
    """
    context = context or "ambiguous"
    urgency = urgency or "low"
    confidence = confidence or "medium"
    
    context_idx = OBSERVATION_MODALITIES["context"].index(context)
    urgency_idx = OBSERVATION_MODALITIES["urgency"].index(urgency)
    confidence_idx = OBSERVATION_MODALITIES["confidence"].index(confidence)
    
    return (context_idx, urgency_idx, confidence_idx)


# =============================================================================
# Workflow Output Encoding
# =============================================================================

def encode_noesis_output(
    confidence_score: float,
    uncertainty_zones: List[Dict],
) -> Tuple[int, int, int]:
    """Encode O1 Noƒìsis PHASE 5 output to observation indices.
    
    Converts the structured output from Noƒìsis (deep thinking) workflow
    into observation indices for the FEP agent.
    
    Args:
        confidence_score: Confidence level from PHASE 5 (0.0-1.0)
        uncertainty_zones: List of uncertainty zone dicts from PHASE 5
    
    Returns:
        Tuple of (context_idx, urgency_idx, confidence_idx)
    
    Mapping Logic:
        - context_clarity = 1.0 - (len(uncertainty_zones) * 0.2)
          More uncertainty zones ‚Üí more ambiguous context
        - urgency = 'low' (Noƒìsis is a deliberative process)
        - confidence = mapped from confidence_score
    
    Example:
        >>> encode_noesis_output(0.87, [{"zone": "A", "doubt_score": 0.4}])
        (1, 0, 2)  # clear context, low urgency, high confidence
    """
    # Context clarity: more uncertainty zones = more ambiguous
    context_clarity = max(0.0, min(1.0, 1.0 - len(uncertainty_zones) * 0.2))
    
    # Map to categorical values
    context = "clear" if context_clarity >= 0.5 else "ambiguous"
    urgency = "low"  # Noƒìsis is always deliberative, low urgency
    
    if confidence_score >= 0.7:
        confidence = "high"
    elif confidence_score >= 0.4:
        confidence = "medium"
    else:
        confidence = "low"
    
    return encode_structured_input(context=context, urgency=urgency, confidence=confidence)


def encode_boulesis_output(
    impulse_score: float,
    feasibility_score: float,
) -> Tuple[int, int, int]:
    """Encode O2 Boulƒìsis PHASE 5 output to observation indices.
    
    Converts the structured output from Boulƒìsis (will clarification) workflow
    into observation indices for the FEP agent.
    
    Args:
        impulse_score: Impulse score (0-100), higher = more impulsive
        feasibility_score: Feasibility score (0-100)
    
    Returns:
        Tuple of (context_idx, urgency_idx, confidence_idx)
    
    Mapping Logic:
        - context = based on feasibility (>=50 = clear)
        - urgency = based on impulse score (high impulse = high urgency)
        - confidence = based on feasibility score
    
    Example:
        >>> encode_boulesis_output(impulse_score=25, feasibility_score=80)
        (1, 0, 2)  # clear context, low urgency (deliberate), high confidence
    """
    # Urgency from impulse: high impulse ‚Üí high urgency
    if impulse_score >= 70:
        urgency = "high"
    elif impulse_score >= 40:
        urgency = "medium"
    else:
        urgency = "low"
    
    # Confidence from feasibility
    if feasibility_score >= 70:
        confidence = "high"
    elif feasibility_score >= 40:
        confidence = "medium"
    else:
        confidence = "low"
    
    # Context clarity from feasibility
    context = "clear" if feasibility_score >= 50 else "ambiguous"
    
    return encode_structured_input(context=context, urgency=urgency, confidence=confidence)


def generate_fep_feedback_markdown(
    agent_result: Dict,
    observation_description: str,
) -> str:
    """Generate Markdown-formatted FEP cognitive feedback.
    
    Creates a human-readable summary of the FEP agent's analysis,
    suitable for inclusion in workflow outputs.
    
    Args:
        agent_result: Result dict from Hegemonik√≥nFEPAgent.step()
        observation_description: Human-readable observation description
            e.g., "context=clear, urgency=low, conf=high"
    
    Returns:
        Markdown-formatted FEP feedback block
    
    Example:
        >>> result = agent.step(observation=0)
        >>> print(generate_fep_feedback_markdown(result, "context=clear"))
        ‚îÅ‚îÅ‚îÅ FEP Cognitive Feedback ‚îÅ‚îÅ‚îÅ
        ‚îå‚îÄ[Active Inference Layer]‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Ë¶≥ÂØüÂÄ§: context=clear                      ‚îÇ
        ...
    """
    # Extract values with safe defaults
    action_name = agent_result.get("action_name", "unknown")
    action = agent_result.get("action", 0)
    q_pi = agent_result.get("q_pi", [0.5, 0.5])
    entropy = agent_result.get("entropy", 0.0)
    map_state = agent_result.get("map_state_names", {})
    
    # Calculate action probability
    if isinstance(q_pi, (list, tuple)) and len(q_pi) > action:
        action_prob = q_pi[action] * 100
    else:
        action_prob = 50.0
    
    # Interpret entropy
    if entropy < 1.0:
        entropy_desc = "‰Ωé„ÅÑ‰∏çÁ¢∫ÂÆüÊÄß"
    elif entropy < 2.0:
        entropy_desc = "‰∏≠Á®ãÂ∫¶„ÅÆ‰∏çÁ¢∫ÂÆüÊÄß"
    else:
        entropy_desc = "È´ò„ÅÑ‰∏çÁ¢∫ÂÆüÊÄß (Epochƒì Êé®Â•®)"
    
    # Extract belief states
    phantasia = map_state.get("phantasia", "?")
    assent = map_state.get("assent", "?")
    horme = map_state.get("horme", "?")
    
    # Generate action guidance
    if action_name == "act":
        guidance = "‚Üí ÁµêË´ñ„Å´Á¢∫‰ø°„ÅÇ„Çä„ÄÅË°åÂãï„Å´ÁßªË°åÂèØËÉΩ"
    elif action_name == "observe":
        guidance = "‚Üí ËøΩÂä†Ë™øÊüª (/zet) „Åæ„Åü„ÅØÂà§Êñ≠ÂÅúÊ≠¢ (/epo) „ÇíÊé®Â•®"
    else:
        guidance = f"‚Üí {action_name}"
    
    return f"""‚îÅ‚îÅ‚îÅ FEP Cognitive Feedback ‚îÅ‚îÅ‚îÅ
‚îå‚îÄ[Active Inference Layer]‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Ë¶≥ÂØüÂÄ§: {observation_description}
‚îÇ ‰ø°ÂøµÁä∂ÊÖã:
‚îÇ   phantasia: {phantasia}
‚îÇ   assent: {assent}
‚îÇ   horme: {horme}
‚îÇ „Ç®„É≥„Éà„É≠„Éî„Éº: {entropy:.2f} ({entropy_desc})
‚îÇ Êé®Â•®: {action_name} ({action_prob:.0f}%)
‚îÇ   {guidance}
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"""


# =============================================================================
# FEP with Learning & Persistence
# =============================================================================

def run_fep_with_learning(
    obs_tuple: Tuple[int, int, int],
    a_matrix_path: str = "/home/laihuip001/oikos/mneme/.hegemonikon/fep/learned_A.npy",
    learning_rate: float = 50.0,
) -> Dict:
    """Execute FEP inference + Dirichlet learning + persistence in one flow.
    
    This function handles the complete FEP cycle:
    1. Load learned A-matrix (if exists)
    2. Run inference step
    3. Update A-matrix with Dirichlet learning
    4. Save updated A-matrix
    
    Args:
        obs_tuple: Observation tuple (context_idx, urgency_idx, confidence_idx)
        a_matrix_path: Path to save/load learned A-matrix
        learning_rate: Dirichlet update learning rate (default: 50.0)
    
    Returns:
        Dict with step() results + should_epoche flag
    
    Example:
        >>> from mekhane.fep.encoding import encode_noesis_output, run_fep_with_learning
        >>> obs = encode_noesis_output(0.85, [{"zone": "A"}])
        >>> result = run_fep_with_learning(obs)
        >>> print(result["action_name"], result["should_epoche"])
    """
    from mekhane.fep import Hegemonik√≥nFEPAgent
    import os
    
    agent = Hegemonik√≥nFEPAgent(use_defaults=True)
    
    # 1. Load learned A-Matrix if exists
    agent.load_learned_A(a_matrix_path)
    
    # 2. Run inference
    flat_obs = obs_tuple[0] + 2 * obs_tuple[1] + obs_tuple[2]
    result = agent.step(observation=flat_obs)
    
    # 3. Dirichlet update
    agent.update_A_dirichlet(observation=flat_obs, learning_rate=learning_rate)
    
    # 4. Save
    os.makedirs(os.path.dirname(a_matrix_path), exist_ok=True)
    agent.save_learned_A(a_matrix_path)
    
    # 5. Add Auto-Epochƒì flag
    result["should_epoche"] = result.get("entropy", 0) >= 2.0
    
    return result


def should_trigger_epoche(agent_result: Dict, threshold: float = 2.0) -> bool:
    """Check if Epochƒì should be triggered based on entropy.
    
    High entropy indicates high uncertainty in beliefs, suggesting
    that judgment should be suspended (/epo).
    
    Args:
        agent_result: Result dict from Hegemonik√≥nFEPAgent.step()
        threshold: Entropy threshold (default: 2.0)
    
    Returns:
        True if entropy >= threshold (Epochƒì recommended)
    
    Example:
        >>> if should_trigger_epoche(result):
        ...     print("‚ö†Ô∏è È´ò„Ç®„É≥„Éà„É≠„Éî„Éº ‚Üí /epo Êé®Â•®")
    """
    return agent_result.get("entropy", 0.0) >= threshold


# =============================================================================
# Feature 3: Auto-Encode Noƒìsis (PHASE 5 Ëá™ÂãïÂ§âÊèõ)
# =============================================================================

def auto_encode_noesis(phase5_output: dict) -> Tuple[int, int, int]:
    """PHASE 5 JSON Âá∫Âäõ„Çí FEP Ë¶≥ÂØü„Å´Ëá™ÂãïÂ§âÊèõ.
    
    /noe „ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÅÆ PHASE 5 Âá∫Âäõ„ÇíÂèó„ÅëÂèñ„Çä„ÄÅ
    FEP Agent Áî®„ÅÆË¶≥ÂØüÂÄ§„Å´Ëá™ÂãïÂ§âÊèõ„Åô„Çã„ÄÇ
    
    Args:
        phase5_output: PHASE 5 „ÅÆÊßãÈÄ†ÂåñÂá∫Âäõ (JSON)
            ÂøÖÈ†à„Ç≠„Éº: confidence_score, uncertainty_zones
    
    Returns:
        Tuple of (context_idx, urgency_idx, confidence_idx)
    
    Example:
        >>> phase5 = {"confidence_score": 0.78, "uncertainty_zones": [{"zone": "A"}]}
        >>> auto_encode_noesis(phase5)
        (1, 0, 2)  # clear, low, high
    """
    confidence = phase5_output.get("confidence_score", 0.5)
    zones = phase5_output.get("uncertainty_zones", [])
    return encode_noesis_output(confidence, zones)


# =============================================================================
# Feature 2: Learning Progress Visualization
# =============================================================================

def format_learning_progress(
    before_A: Optional["np.ndarray"] = None,
    after_A: Optional["np.ndarray"] = None,
    observation: Optional[Tuple[int, int, int]] = None,
    inference_count: int = 1,
) -> str:
    """AË°åÂàó„ÅÆÂ≠¶ÁøíÈÄ≤Êçó„Çí Markdown „ÅßÂèØË¶ñÂåñ.
    
    FEP Agent „ÅÆË¶≥ÂØü„É¢„Éá„É´ (AË°åÂàó) „Åå„Å©„ÅÆ„Çà„ÅÜ„Å´Êõ¥Êñ∞„Åï„Çå„Åü„Åã„Çí
    ‰∫∫Èñì„ÅåË™≠„ÇÅ„ÇãÂΩ¢Âºè„ÅßË°®Á§∫„Åô„Çã„ÄÇ
    
    Args:
        before_A: Êõ¥Êñ∞Ââç„ÅÆ AË°åÂàó (optional)
        after_A: Êõ¥Êñ∞Âæå„ÅÆ AË°åÂàó (optional)
        observation: ‰ªäÂõû„ÅÆË¶≥ÂØüÂÄ§ (optional)
        inference_count: Á¥ØË®àÊé®Ë´ñÂõûÊï∞
    
    Returns:
        Markdown formatted learning progress
    
    Example:
        >>> print(format_learning_progress(inference_count=5))
        ‚îå‚îÄ[FEP Learning Progress]‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Êé®Ë´ñÂõûÊï∞: 5                                  ‚îÇ
        ‚îÇ AË°åÂàóÊõ¥Êñ∞: „Å™„Åó (before/after Êú™Êèê‰æõ)        ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    """
    lines = [
        "‚îå‚îÄ[FEP Learning Progress]‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê",
        f"‚îÇ Êé®Ë´ñÂõûÊï∞: {inference_count}",
    ]
    
    if observation:
        obs_decoded = decode_observation(observation)
        lines.append(
            f"‚îÇ Ë¶≥ÂØüÂÄ§: context={obs_decoded['context']}, "
            f"urgency={obs_decoded['urgency']}, conf={obs_decoded['confidence']}"
        )
    
    if before_A is not None and after_A is not None:
        try:
            import numpy as np
            delta = np.abs(after_A - before_A).sum()
            lines.append(f"‚îÇ AË°åÂàóÂ§âÂåñÈáè: {delta:.4f}")
            if delta > 0.01:
                lines.append("‚îÇ üìà ÊúâÊÑè„Å™Â≠¶Áøí„ÅåÁô∫Áîü")
            else:
                lines.append("‚îÇ üìä ÂÆâÂÆöÁä∂ÊÖãÔºàÂæÆÂ∞èÂ§âÂåñÔºâ")
        except ImportError:
            lines.append("‚îÇ AË°åÂàóÂ§âÂåñ: numpy Êú™„Ç§„É≥„Éù„Éº„Éà")
    else:
        lines.append("‚îÇ AË°åÂàóÊõ¥Êñ∞: „Å™„Åó (before/after Êú™Êèê‰æõ)")
    
    lines.append("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
    return "\n".join(lines)


# =============================================================================
# Feature 1: X-Series Navigation Constants
# =============================================================================

# X-series 36Èñ¢‰øÇ„Éû„Éà„É™„ÇØ„ÇπÂÆöÁæ©
X_SERIES_MATRIX = {
    "O": {"O": "X-OO", "S": "X-OS", "H": "X-OH", "P": "X-OP", "K": "X-OK", "A": "X-OA"},
    "S": {"O": "X-SO", "S": "X-SS", "H": "X-SH", "P": "X-SP", "K": "X-SK", "A": "X-SA"},
    "H": {"O": "X-HO", "S": "X-HS", "H": "X-HH", "P": "X-HP", "K": "X-HK", "A": "X-HA"},
    "P": {"O": "X-PO", "S": "X-PS", "H": "X-PH", "P": "X-PP", "K": "X-PK", "A": "X-PA"},
    "K": {"O": "X-KO", "S": "X-KS", "H": "X-KH", "P": "X-KP", "K": "X-KK", "A": "X-KA"},
    "A": {"O": "X-AO", "S": "X-AS", "H": "X-AH", "P": "X-AP", "K": "X-AK", "A": "X-AA"},
}

# ‰ª£Ë°®ÁöÑ„Å™ÈÅ∑ÁßªÁµåË∑Ø
X_SERIES_REPRESENTATIVE_PATHS = {
    "X-OS": ("O1", "S1"),  # Ë™çË≠ò‚Üí„Çπ„Ç±„Éº„É´
    "X-OA": ("O1", "A2"),  # Ë™çË≠ò‚ÜíÊ§úË®º
    "X-OH": ("O1", "H1"),  # Ë™çË≠ò‚ÜíÂÇæÂêë
    "X-OP": ("O4", "P4"),  # Ë°åÁÇ∫‚ÜíÊäÄÊ≥ï
    "X-SO": ("S4", "O4"),  # ÂÆüË∑µ‚ÜíË°åÁÇ∫
    "X-HO": ("H2", "O4"),  # Á¢∫‰ø°‚ÜíË°åÁÇ∫
    "X-KO": ("K4", "O1"),  # Áü•ÊÅµ‚ÜíË™çË≠ò
    "X-AO": ("A4", "O1"),  # Áü•Ë≠ò‚ÜíË™çË≠ò
}


def get_x_series_recommendations(
    current_series: str,
    confidence: float = 0.5,
) -> List[Dict[str, str]]:
    """ÁèæÂú®„ÅÆ„Ç∑„É™„Éº„Ç∫„Åã„Çâ X-series Êé®Â•®Ê¨°„Çπ„ÉÜ„ÉÉ„Éó„ÇíÂèñÂæó.
    
    Args:
        current_series: ÁèæÂú®„ÅÆ„Ç∑„É™„Éº„Ç∫ (O, S, H, P, K, A)
        confidence: ÁèæÂú®„ÅÆÁ¢∫‰ø°Â∫¶ (0.0-1.0)
    
    Returns:
        List of recommendation dicts with keys: x_id, target, workflow, reason
    
    Example:
        >>> get_x_series_recommendations("O", 0.78)
        [{'x_id': 'X-OS', 'target': 'S', 'workflow': '/s', 'reason': 'Ë™çË≠ò‚ÜíË®≠Ë®à„Å∏'}, ...]
    """
    WORKFLOW_MAP = {
        "O": "/noe", "S": "/s", "H": "/pro", 
        "P": "/kho", "K": "/euk", "A": "/dia"
    }
    REASON_MAP = {
        "O": "Êú¨Ë≥™", "S": "Ë®≠Ë®à", "H": "ÂÇæÂêë",
        "P": "Áí∞Â¢É", "K": "ÊñáËÑà", "A": "Ê§úË®º"
    }
    
    if current_series not in X_SERIES_MATRIX:
        return []
    
    recommendations = []
    connections = X_SERIES_MATRIX[current_series]
    
    # È´òÁ¢∫‰ø° ‚Üí Ë°åÂãïÁ≥ª (S, P) „ÇíÂÑ™ÂÖà
    # ‰ΩéÁ¢∫‰ø° ‚Üí Ê§úË®ºÁ≥ª (A, K) „ÇíÂÑ™ÂÖà
    if confidence >= 0.7:
        priority = ["S", "P", "O", "H", "K", "A"]
    else:
        priority = ["A", "K", "S", "O", "H", "P"]
    
    for target in priority[:3]:  # ‰∏ä‰Ωç3„Å§
        if target == current_series:
            continue
        x_id = connections[target]
        recommendations.append({
            "x_id": x_id,
            "target": target,
            "workflow": WORKFLOW_MAP.get(target, f"/{target.lower()}"),
            "reason": f"{REASON_MAP.get(current_series, current_series)}‚Üí{REASON_MAP.get(target, target)}„Å∏",
        })
    
    return recommendations

