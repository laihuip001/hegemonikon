#!/usr/bin/env python3
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] <- mekhane/fep/ A0â†’WFãƒ•ãƒ­ãƒ³ãƒˆãƒžã‚¿ãƒ¼ã®category_theoryã‚’æ¶ˆè²»ã™ã‚‹å¿…è¦â†’wf_category_parserãŒæ‹…ã†
"""
WF Category Theory Frontmatter Parser

WF (.md) ã® YAML ãƒ•ãƒ­ãƒ³ãƒˆãƒžã‚¿ãƒ¼ã«æ›¸ã‹ã‚ŒãŸ category_theory: ãƒ–ãƒ­ãƒƒã‚¯ã‚’
ãƒ‘ãƒ¼ã‚¹ã—ã€category.py ã®åž‹ã«å¤‰æ›ã™ã‚‹ **æœ€åˆã®æ¶ˆè²»è€…ã‚³ãƒ¼ãƒ‰**ã€‚

Origin: /zet+ Q2 (2026-02-08)
Problem: ãƒ•ãƒ­ãƒ³ãƒˆãƒžã‚¿ãƒ¼ã« category_theory: ãŒã‚ã‚‹ãŒã€èª­ã‚€ã‚³ãƒ¼ãƒ‰ãŒãªã‹ã£ãŸã€‚
         ã“ã‚Œã¯å®£è¨€ã¨å®Ÿè£…ã®ä¹–é›¢ (Q16 Layer C) ã§ã‚ã‚Šã€ãƒã‚°ã¨åŒç­‰ã€‚

Supported frontmatter patterns:
    Pattern A â€” Peras WF (o.md, s.md, h.md, p.md, k.md, a.md):
        category_theory:
          yoneda: "Hom(-, Tn) â‰… F(Tn)"
          limit: "Cone ã®é ‚ç‚¹"
          converge_as_cone: "C0=PW, C1=å°„, C2=èžåˆ, C3=æ¤œè¨¼"
          cone_builder: "mekhane/fep/cone_builder.py"

    Pattern B â€” Monad WF (zet.md):
        category_theory:
          core: "ãƒ¢ãƒŠãƒ‰ T: Cog â†’ Cog"
          unit: "Î·: X â†’ T(X)"
          join: "Î¼: T(T(X)) â†’ T(X)"
          kleisli: "anom >==> hypo >==> eval"
          laws: {left_unit, right_unit, associativity}

Usage:
    from mekhane.fep.wf_category_parser import parse_wf_category, scan_all_wfs
    info = parse_wf_category(Path(".agent/workflows/o.md"))
    report = scan_all_wfs()
"""

from __future__ import annotations

import re
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional

import yaml


# PURPOSE: category_theory ãƒ•ãƒ­ãƒ³ãƒˆãƒžã‚¿ãƒ¼ã®ãƒ‘ãƒ¼ã‚¹çµæžœ
@dataclass
class WFCategoryInfo:
    """Parsed category_theory block from a WF frontmatter."""

    wf_path: Path                          # WF ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    wf_name: str = ""                      # WF å (/o, /zet, etc.)
    pattern: str = ""                      # "peras" | "monad" | "adjunction" | "unknown"
    raw: Dict = field(default_factory=dict) # ç”Ÿã® YAML dict

    # Peras pattern fields
    yoneda: str = ""
    limit: str = ""
    converge_as_cone: str = ""
    cone_builder_path: str = ""

    # Monad pattern fields
    core: str = ""
    unit: str = ""
    join: str = ""
    kleisli: str = ""
    laws: Dict[str, str] = field(default_factory=dict)

    # Common
    description: str = ""                   # 1è¡Œè¦ç´„

    # PURPOSE: wf_category_parser ã® is valid å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
    @property
    def is_valid(self) -> bool:
        """æœ€ä½Žé™ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒåŸ‹ã¾ã£ã¦ã„ã‚‹ã‹ã€‚"""
        if self.pattern == "peras":
            return bool(self.converge_as_cone)
        elif self.pattern == "monad":
            return bool(self.core)
        return bool(self.raw)

    # PURPOSE: wf_category_parser ã® coverage score å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹
    @property
    def coverage_score(self) -> float:
        """ãƒ•ãƒ­ãƒ³ãƒˆãƒžã‚¿ãƒ¼ã®å……å®Ÿåº¦ (0.0-1.0)ã€‚"""
        if self.pattern == "peras":
            fields = [self.yoneda, self.limit, self.converge_as_cone, self.cone_builder_path]
            return sum(1.0 for f in fields if f) / len(fields)
        elif self.pattern == "monad":
            fields = [self.core, self.unit, self.join, self.kleisli]
            law_score = min(len(self.laws) / 3, 1.0) if self.laws else 0.0
            base = sum(1.0 for f in fields if f) / len(fields)
            return (base + law_score) / 2
        return 0.0


# PURPOSE: YAML ãƒ•ãƒ­ãƒ³ãƒˆãƒžã‚¿ãƒ¼ã‚’æŠ½å‡º
def _extract_frontmatter(wf_path: Path) -> Optional[Dict]:
    """Extract YAML frontmatter from a WF markdown file."""
    text = wf_path.read_text(encoding="utf-8")
    match = re.match(r"^---\s*\n(.*?)\n---", text, re.DOTALL)
    if not match:
        return None
    try:
        return yaml.safe_load(match.group(1))
    except yaml.YAMLError:
        return None


# PURPOSE: category_theory ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ¤å®š
def _detect_pattern(ct: Dict) -> str:
    """Detect which category_theory pattern this is."""
    if "core" in ct or "unit" in ct or "join" in ct:
        return "monad"
    if "yoneda" in ct or "limit" in ct or "converge_as_cone" in ct:
        return "peras"
    if "left" in ct or "right" in ct or "adjunction" in ct:
        return "adjunction"
    return "unknown"


# PURPOSE: å˜ä¸€ã® WF ã‹ã‚‰category_theory æƒ…å ±ã‚’ãƒ‘ãƒ¼ã‚¹
def parse_wf_category(wf_path: Path) -> Optional[WFCategoryInfo]:
    """Parse category_theory block from a single WF file.

    Returns None if the WF has no category_theory frontmatter.
    """
    fm = _extract_frontmatter(wf_path)
    if not fm or "category_theory" not in fm:
        return None

    ct = fm["category_theory"]
    if not isinstance(ct, dict):
        return None

    pattern = _detect_pattern(ct)
    wf_name = "/" + wf_path.stem

    info = WFCategoryInfo(
        wf_path=wf_path,
        wf_name=wf_name,
        pattern=pattern,
        raw=ct,
    )

    if pattern == "peras":
        info.yoneda = ct.get("yoneda", "")
        info.limit = ct.get("limit", "")
        info.converge_as_cone = ct.get("converge_as_cone", "")
        info.cone_builder_path = ct.get("cone_builder", "")
        info.description = f"Peras WF: {info.converge_as_cone[:60]}"

    elif pattern == "monad":
        info.core = ct.get("core", "")
        info.unit = ct.get("unit", "")
        info.join = ct.get("join", "")
        info.kleisli = ct.get("kleisli", "")
        info.laws = ct.get("laws", {})
        info.description = f"Monad WF: {info.core[:60]}"

    return info


# PURPOSE: å…¨ WF ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ category_theory æƒ…å ±ã‚’é›†ç´„
def scan_all_wfs(wf_dir: Optional[Path] = None) -> Dict[str, WFCategoryInfo]:
    """Scan all WF files and extract category_theory info.

    Returns:
        Dict mapping WF name â†’ WFCategoryInfo
    """
    if wf_dir is None:
        wf_dir = Path(__file__).parent.parent.parent / ".agent" / "workflows"

    results = {}
    if not wf_dir.exists():
        return results

    for wf_path in sorted(wf_dir.glob("*.md")):
        info = parse_wf_category(wf_path)
        if info is not None:
            results[info.wf_name] = info

    return results


# PURPOSE: category_theory coverage ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
def coverage_report(wf_dir: Optional[Path] = None) -> str:
    """Generate a coverage report of category_theory frontmatter.

    Shows which WFs have category_theory, their pattern, and coverage score.
    """
    if wf_dir is None:
        wf_dir = Path(__file__).parent.parent.parent / ".agent" / "workflows"

    all_wfs = sorted(wf_dir.glob("*.md")) if wf_dir.exists() else []
    parsed = scan_all_wfs(wf_dir)

    lines = [
        "Category Theory Frontmatter Coverage Report",
        "=" * 50,
        f"Total WFs: {len(all_wfs)} | With category_theory: {len(parsed)}",
        "",
    ]

    # By pattern
    patterns: Dict[str, List[str]] = {}
    for name, info in parsed.items():
        patterns.setdefault(info.pattern, []).append(name)

    for pat, names in sorted(patterns.items()):
        lines.append(f"\nðŸ“ Pattern: {pat} ({len(names)} WFs)")
        for name in names:
            info = parsed[name]
            score = info.coverage_score
            icon = "âœ…" if score >= 0.75 else "ðŸŸ¡" if score >= 0.5 else "ðŸ”´"
            lines.append(f"  {icon} {name:8s} coverage={score:.0%} â€” {info.description}")

    # Missing
    missing = [
        "/" + wf.stem for wf in all_wfs
        if "/" + wf.stem not in parsed
    ]
    if missing:
        lines.append(f"\nâšª No category_theory ({len(missing)} WFs):")
        # Show first 10
        for name in missing[:10]:
            lines.append(f"  Â· {name}")
        if len(missing) > 10:
            lines.append(f"  ... and {len(missing) - 10} more")

    return "\n".join(lines)


if __name__ == "__main__":
    print(coverage_report())
