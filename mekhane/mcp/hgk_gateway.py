#!/usr/bin/env python3
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] <- mekhane/mcp/ å‡ºå¼µ HGK MCP Gateway
"""
å‡ºå¼µ HGK MCP Gateway â€” ãƒ¢ãƒã‚¤ãƒ«ã‹ã‚‰ã® HGK ã‚¢ã‚¯ã‚»ã‚¹

FastMCP + Streamable HTTP ã§ã€Claude/ChatGPT ã®ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã‹ã‚‰
MCP çµŒç”±ã§ HGK ã®èªçŸ¥æ©Ÿèƒ½ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãƒªãƒ¢ãƒ¼ãƒˆã‚µãƒ¼ãƒãƒ¼ã€‚

Usage:
    # ãƒ­ãƒ¼ã‚«ãƒ«èµ·å‹• (é–‹ç™º)
    python -m mekhane.mcp.hgk_gateway

    # Tailscale Funnel ã§å…¬é–‹
    tailscale funnel 8765
    python -m mekhane.mcp.hgk_gateway

Architecture:
    [ã‚¹ãƒãƒ› Claude/ChatGPT] â†’ MCP (Streamable HTTP) â†’ [ã“ã®ã‚µãƒ¼ãƒãƒ¼] â†’ [HGK ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«]
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

# Project root
PROJECT_ROOT = Path(__file__).resolve().parents[2]  # hegemonikon/
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from mcp.server.fastmcp import FastMCP
from mcp.server.transport_security import TransportSecuritySettings

# =============================================================================
# Configuration
# =============================================================================

GATEWAY_HOST = os.getenv("HGK_GATEWAY_HOST", "127.0.0.1")
GATEWAY_PORT = int(os.getenv("HGK_GATEWAY_PORT", "8765"))

# Allowed hosts for DNS rebinding protection
_default_hosts = "localhost,127.0.0.1,hegemonikon.tail3b6058.ts.net"
ALLOWED_HOSTS = os.getenv("HGK_GATEWAY_ALLOWED_HOSTS", _default_hosts).split(",")

# =============================================================================
# Gateway Server
# =============================================================================

mcp = FastMCP(
    "hgk-gateway",
    host=GATEWAY_HOST,
    port=GATEWAY_PORT,
    transport_security=TransportSecuritySettings(
        enable_dns_rebinding_protection=True,
        allowed_hosts=ALLOWED_HOSTS,
    ),
    instructions=(
        "HegemonikÃ³n å‡ºå¼µ MCP Gatewayã€‚"
        "ãƒ¢ãƒã‚¤ãƒ«ã‹ã‚‰ HGK ã®èªçŸ¥æ©Ÿèƒ½ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã€‚"
        "/sop èª¿æŸ»ä¾é ¼æ›¸ã®ç”Ÿæˆã€KI/GnÅsis æ¤œç´¢ã€"
        "CCL ãƒ‘ãƒ¼ã‚¹ã€Doxa/Handoff å‚ç…§ã€ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ¡ãƒ¢ä¿å­˜ãŒå¯èƒ½ã€‚"
    ),
)

# Paths
MNEME_DIR = PROJECT_ROOT.parent / "mneme" / ".hegemonikon"
SESSIONS_DIR = MNEME_DIR / "sessions"
DOXA_DIR = MNEME_DIR / "doxa"
SOP_OUTPUT_DIR = MNEME_DIR / "workflows"
IDEA_DIR = MNEME_DIR / "ideas"


# =============================================================================
# P1: /sop èª¿æŸ»ä¾é ¼æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ
# =============================================================================

@mcp.tool()
def hgk_sop_generate(
    topic: str,
    decision: str = "",
    hypothesis: str = "",
) -> str:
    """
    /sop èª¿æŸ»ä¾é ¼æ›¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚

    Gemini Deep Research ã‚„ Perplexity ã«ã‚³ãƒ”ãƒšã—ã¦ä½¿ã†ã€‚
    HegemonikÃ³n /sop ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ¢ãƒã‚¤ãƒ«ç‰ˆã€‚

    Args:
        topic: èª¿æŸ»å¯¾è±¡ã®ãƒ†ãƒ¼ãƒ (ä¾‹: "FEP ã¨ Active Inference ã®æœ€æ–°å‹•å‘")
        decision: ã“ã®èª¿æŸ»ã®çµæœã€ä½•ã‚’æ±ºå®šã™ã‚‹ã‹
        hypothesis: äº‹å‰ä»®èª¬ (ã‚ã‚Œã°)
    """
    now = datetime.now().strftime("%Y-%m-%d")

    template = f"""# èª¿æŸ»ä¾é ¼æ›¸ï¼ˆæ·±æ˜ã‚Šç‰ˆï¼‰

> ãƒ†ãƒ¼ãƒ: {topic}
> ç”Ÿæˆæ—¥: {now}
> ç”Ÿæˆå…ƒ: HGK /sop (å‡ºå¼µç‰ˆ)

---

## å‡ºåŠ›å½¢å¼

ä»¥ä¸‹ã®4åˆ—ãƒ†ãƒ¼ãƒ–ãƒ«ã§æ§‹é€ åŒ–ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š

| é …ç›® | å€¤ | æ ¹æ‹ ï¼ˆå‡ºå…¸ï¼‰ | URL |
|:-----|:---|:-----------|:----|

---

## ã‚¿ã‚¹ã‚¯å®šç¾©

{topic}ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è«–ç‚¹ã‚’**ç¶²ç¾…çš„ã‹ã¤æœ€æ–°ã®æƒ…å ±**ã«åŸºã¥ã„ã¦èª¿æŸ»ã—ã¦ãã ã•ã„ã€‚

## æ™‚é–“åˆ¶ç´„

- **éå»6ãƒ¶æœˆã®æƒ…å ±ã‚’å„ªå…ˆ**
- 2025å¹´ä»¥é™ã®è«–æ–‡ãƒ»è¨˜äº‹ã‚’é‡è¦–

## æ±ºå®šäº‹é …

{decision if decision else "ï¼ˆèª¿æŸ»çµæœã«åŸºã¥ã„ã¦æ±ºå®šã™ã‚‹ï¼‰"}

## ä»®èª¬

{hypothesis if hypothesis else "ï¼ˆä»®èª¬ãªã— â€” æ¢ç´¢çš„èª¿æŸ»ï¼‰"}

---

## è«–ç‚¹ï¼ˆå¿…é ˆé …ç›®ï¼‰

A. {topic}ã®ç¾çŠ¶
- A1: æœ€æ–°ã®å®šç¾©ãƒ»åˆ†é¡ã¯ã©ã†ãªã£ã¦ã„ã‚‹ã‹ï¼Ÿ
- A2: ä¸»è¦ãªç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»å®Ÿè£…ã¯ï¼Ÿ
- A3: 2025å¹´ä»¥é™ã®é‡è¦ãªå¤‰åŒ–ãƒ»ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼ã¯ï¼Ÿ

B. å®Ÿè·µãƒ»å¿œç”¨
- B1: ç¾æ™‚ç‚¹ã§æœ€ã‚‚æœ‰åŠ¹ãªæ‰‹æ³•ãƒ»ãƒ„ãƒ¼ãƒ«ã¯ï¼Ÿ
- B2: æˆåŠŸäº‹ä¾‹ã¨å¤±æ•—äº‹ä¾‹ã¯ï¼Ÿ
- B3: ã‚³ã‚¹ãƒˆãƒ»å®Ÿè£…ã®ç¾å®Ÿçš„ãªåˆ¶ç´„ã¯ï¼Ÿ

C. å°†æ¥å±•æœ›
- C1: ä»Šå¾Œ6-12ãƒ¶æœˆã§äºˆæƒ³ã•ã‚Œã‚‹å¤‰åŒ–ã¯ï¼Ÿ
- C2: ãƒªã‚¹ã‚¯ã‚„æ³¨æ„ã™ã¹ãç‚¹ã¯ï¼Ÿ

---

> ã“ã®èª¿æŸ»ä¾é ¼æ›¸ã¯ HegemonikÃ³n /sop ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ (å‡ºå¼µç‰ˆ) ã§ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚
> Gemini Deep Research ã¾ãŸã¯ Perplexity ã«ã‚³ãƒ”ãƒšã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
"""

    # Save to file
    SOP_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    safe_topic = topic[:30].replace("/", "_").replace(" ", "_")
    output_path = SOP_OUTPUT_DIR / f"sop_{safe_topic}_{now}.md"
    output_path.write_text(template, encoding="utf-8")

    return f"## âœ… èª¿æŸ»ä¾é ¼æ›¸ã‚’ç”Ÿæˆã—ã¾ã—ãŸ\n\nä¿å­˜å…ˆ: `{output_path}`\n\n---\n\n{template}"


# =============================================================================
# P1: KI / GnÅsis æ¤œç´¢
# =============================================================================

@mcp.tool()
def hgk_search(query: str, max_results: int = 5) -> str:
    """
    HGK ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ (KI / GnÅsis / Sophia) ã‚’æ¤œç´¢ã™ã‚‹ã€‚

    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª (ä¾‹: "FEP ç²¾åº¦åŠ é‡", "èªçŸ¥ãƒã‚¤ã‚¢ã‚¹")
        max_results: æœ€å¤§çµæœæ•°
    """
    results = []

    # 1. KI (Knowledge Items) â€” ãƒ•ã‚¡ã‚¤ãƒ«åæ¤œç´¢
    ki_base = Path.home() / ".gemini" / "antigravity" / "knowledge"
    if ki_base.exists():
        ki_dirs = sorted(ki_base.iterdir())
        query_lower = query.lower()
        for ki_dir in ki_dirs:
            if ki_dir.is_dir():
                metadata_path = ki_dir / "metadata.json"
                if metadata_path.exists():
                    try:
                        meta = json.loads(metadata_path.read_text(encoding="utf-8"))
                        summary = meta.get("summary", "")
                        title = meta.get("title", ki_dir.name)
                        if query_lower in title.lower() or query_lower in summary.lower():
                            results.append(f"ğŸ“š **KI: {title}**\n   {summary[:150]}...")
                    except Exception:
                        pass

    # 2. Doxa (ä¿¡å¿µ)
    if DOXA_DIR.exists():
        for doxa_file in sorted(DOXA_DIR.glob("*.json")):
            try:
                doxa = json.loads(doxa_file.read_text(encoding="utf-8"))
                content = json.dumps(doxa, ensure_ascii=False)
                if query.lower() in content.lower():
                    results.append(f"ğŸ’¡ **Doxa: {doxa_file.stem}**\n   {content[:150]}...")
            except Exception:
                pass

    # 3. Handoff â€” æœ€æ–°3ä»¶ã‚’æ¤œç´¢
    if SESSIONS_DIR.exists():
        handoffs = sorted(SESSIONS_DIR.glob("handoff_*.md"), reverse=True)[:3]
        for hf in handoffs:
            try:
                content = hf.read_text(encoding="utf-8")
                if query.lower() in content.lower():
                    # Find matching context
                    lines = content.split("\n")
                    matches = [l.strip() for l in lines if query.lower() in l.lower()][:3]
                    match_text = " / ".join(matches) if matches else "(ãƒãƒƒãƒç®‡æ‰€çœç•¥)"
                    results.append(f"ğŸ“‹ **Handoff: {hf.stem}**\n   {match_text[:150]}")
            except Exception:
                pass

    if not results:
        return f"ğŸ” `{query}` ã«ä¸€è‡´ã™ã‚‹çµæœã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n> ãƒ’ãƒ³ãƒˆ: ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ (GnÅsis) ã¯ PC ã§ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚"

    header = f"## ğŸ” HGK æ¤œç´¢çµæœ: `{query}`\n\n**{len(results)} ä»¶**\n\n"
    return header + "\n\n".join(results[:max_results])


# =============================================================================
# P2: CCL Dispatch
# =============================================================================

@mcp.tool()
def hgk_ccl_dispatch(ccl: str) -> str:
    """
    CCL (Cognitive Control Language) å¼ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã€æ§‹é€ ã‚’è§£æã™ã‚‹ã€‚

    Args:
        ccl: CCL å¼ (ä¾‹: "/noe+", "/dia+~*/noe", "/sop")
    """
    try:
        from hermeneus.src.dispatch import dispatch

        result = dispatch(ccl)

        if not result["success"]:
            return f"## âŒ CCL ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼\n\n**CCL**: `{ccl}`\n**ã‚¨ãƒ©ãƒ¼**: {result['error']}"

        return f"""## âœ… CCL ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒçµæœ

**CCL**: `{ccl}`

### AST æ§‹é€ 
```
{result['tree']}
```

### é–¢é€£ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
{', '.join(f'`{wf}`' for wf in result['workflows'])}

### å®Ÿè¡Œè¨ˆç”»
{result['plan_template']}"""
    except Exception as e:
        return f"## âŒ ã‚¨ãƒ©ãƒ¼\n\n`{e}`"


# =============================================================================
# P2: Doxa èª­ã¿å–ã‚Š
# =============================================================================

@mcp.tool()
def hgk_doxa_read() -> str:
    """
    Doxa (ä¿¡å¿µã‚¹ãƒˆã‚¢) ã®å†…å®¹ã‚’ä¸€è¦§è¡¨ç¤ºã™ã‚‹ã€‚
    HGK ã§è“„ç©ã•ã‚ŒãŸæ³•å‰‡ãƒ»æ•™è¨“ãƒ»ä¿¡å¿µã‚’å‚ç…§ã™ã‚‹ã€‚
    """
    if not DOXA_DIR.exists():
        return "## âš ï¸ Doxa ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

    doxa_files = sorted(DOXA_DIR.glob("*.json"))
    if not doxa_files:
        return "## ğŸ“­ Doxa ã¯ç©ºã§ã™"

    lines = ["## ğŸ’¡ Doxa (ä¿¡å¿µã‚¹ãƒˆã‚¢)\n"]
    for df in doxa_files:
        try:
            data = json.loads(df.read_text(encoding="utf-8"))
            if isinstance(data, list):
                for item in data:
                    strength = item.get("strength", "?")
                    text = item.get("text", item.get("law", str(item)))
                    lines.append(f"- **[{strength}]** {text}")
            elif isinstance(data, dict):
                for key, value in data.items():
                    lines.append(f"- **{key}**: {value}")
        except Exception:
            lines.append(f"- âš ï¸ {df.name}: èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼")

    return "\n".join(lines)


# =============================================================================
# P3: Handoff å‚ç…§
# =============================================================================

@mcp.tool()
def hgk_handoff_read(count: int = 1) -> str:
    """
    æœ€æ–°ã® Handoff (ã‚»ãƒƒã‚·ãƒ§ãƒ³å¼•ãç¶™ãæ›¸) ã‚’èª­ã‚€ã€‚
    å‰å›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ä½•ã‚’ã—ãŸã‹ã€æ¬¡ã«ä½•ã‚’ã™ã¹ãã‹ã‚’ç¢ºèªã™ã‚‹ã€‚

    Args:
        count: èª­ã‚€ Handoff ã®æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1)
    """
    if not SESSIONS_DIR.exists():
        return "## âš ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

    handoffs = sorted(SESSIONS_DIR.glob("handoff_*.md"), reverse=True)
    if not handoffs:
        return "## ğŸ“­ Handoff ãŒã‚ã‚Šã¾ã›ã‚“"

    lines = [f"## ğŸ“‹ æœ€æ–° Handoff ({min(count, len(handoffs))}/{len(handoffs)} ä»¶)\n"]

    for hf in handoffs[:count]:
        try:
            content = hf.read_text(encoding="utf-8")
            # First 50 lines
            summary = "\n".join(content.split("\n")[:50])
            lines.append(f"### {hf.stem}\n\n{summary}\n\n---")
        except Exception:
            lines.append(f"### {hf.stem}\n\nâš ï¸ èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼")

    return "\n".join(lines)


# =============================================================================
# P3: ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ¡ãƒ¢ä¿å­˜
# =============================================================================

@mcp.tool()
def hgk_idea_capture(idea: str, tags: str = "") -> str:
    """
    ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ¡ãƒ¢ã‚’ä¿å­˜ã™ã‚‹ã€‚å¤–å‡ºå…ˆã§ã®é–ƒãã‚’é€ƒã•ãªã„ã€‚
    æ¬¡å› /boot ã§è‡ªå‹•çš„ã«èª­ã¿è¾¼ã¾ã‚Œã‚‹ã€‚

    Args:
        idea: ã‚¢ã‚¤ãƒ‡ã‚¢ã®å†…å®¹
        tags: ã‚¿ã‚° (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€ä¾‹: "FEP, è¨­è¨ˆ, å®Ÿé¨“")
    """
    IDEA_DIR.mkdir(parents=True, exist_ok=True)

    now = datetime.now()
    filename = f"idea_{now.strftime('%Y%m%d_%H%M%S')}.md"
    filepath = IDEA_DIR / filename

    content = f"""# ğŸ’¡ ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ¡ãƒ¢

> **æ—¥æ™‚**: {now.strftime('%Y-%m-%d %H:%M:%S')}
> **ã‚¿ã‚°**: {tags if tags else 'æœªåˆ†é¡'}
> **ã‚½ãƒ¼ã‚¹**: HGK å‡ºå¼µç‰ˆ (ãƒ¢ãƒã‚¤ãƒ«)

---

{idea}

---

*Captured via HGK Gateway*
"""
    filepath.write_text(content, encoding="utf-8")

    return f"## âœ… ã‚¢ã‚¤ãƒ‡ã‚¢ä¿å­˜å®Œäº†\n\nä¿å­˜å…ˆ: `{filepath}`\nã‚¿ã‚°: {tags if tags else 'æœªåˆ†é¡'}\n\næ¬¡å› `/boot` ã§è‡ªå‹•çš„ã«ç¢ºèªã•ã‚Œã¾ã™ã€‚"


# =============================================================================
# HGK Status (ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯)
# =============================================================================

@mcp.tool()
def hgk_status() -> str:
    """
    HGK ã‚·ã‚¹ãƒ†ãƒ ã®æ¦‚è¦ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’è¡¨ç¤ºã™ã‚‹ã€‚
    ãƒ¢ãƒã‚¤ãƒ«ã‹ã‚‰ç¾åœ¨ã®çŠ¶æ…‹ã‚’ç¢ºèªã™ã‚‹ã€‚
    """
    status_items = []

    # Handoff count
    handoff_count = len(list(SESSIONS_DIR.glob("handoff_*.md"))) if SESSIONS_DIR.exists() else 0
    status_items.append(f"ğŸ“‹ Handoff: {handoff_count} ä»¶")

    # KI count
    ki_base = Path.home() / ".gemini" / "antigravity" / "knowledge"
    ki_count = len([d for d in ki_base.iterdir() if d.is_dir()]) if ki_base.exists() else 0
    status_items.append(f"ğŸ“š KI: {ki_count} ä»¶")

    # Doxa count
    doxa_count = len(list(DOXA_DIR.glob("*.json"))) if DOXA_DIR.exists() else 0
    status_items.append(f"ğŸ’¡ Doxa: {doxa_count} ä»¶")

    # Ideas count
    idea_count = len(list(IDEA_DIR.glob("*.md"))) if IDEA_DIR.exists() else 0
    status_items.append(f"ğŸŒŸ Ideas: {idea_count} ä»¶")

    # Latest handoff
    if SESSIONS_DIR.exists():
        handoffs = sorted(SESSIONS_DIR.glob("handoff_*.md"), reverse=True)
        if handoffs:
            status_items.append(f"ğŸ“… æœ€æ–° Handoff: `{handoffs[0].name}`")

    return f"## ğŸ  HGK ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹\n\n" + "\n".join(status_items)


# =============================================================================
# Entry Point
# =============================================================================

if __name__ == "__main__":
    mcp.run(transport="streamable-http")
