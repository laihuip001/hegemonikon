---
source_url: https://ai-data-base.com/archives/69354
captured_at: 2026-01-18T22:02:09.835498
title: "GPT-4o、Gemini、Claude 3などにおける「長いプロンプトのマルチモーダルタスク」性能を測定した結果"
publish_date: 2024.05.21
tags: ["サーベイ37", "ペルソナ・シミュレーション36", "マルチモーダル", "オープンソース25", "エンタメ・アート23", "SE9", "コーディング56", "画像認識20", "音声8", "教育・キャリア9", "実証137", "画像生成9", "医療・ヘルスケア33", "ハルシネーション16", "ポジション8", "ロボット6", "製造・デザイン9", "ファインチューニング16", "ベンチマーク・リソース22", "分析54", "テクニカルレポート15", "安全性39", "マルチモーダル23", "金融・経済10", "セキュリティ16", "LLM", "政治・社会29", "手法426", "LLM659", "RAG50", "ベンチマーク・リソース", "エージェント128", "プロンプト技術156"]
conversion_method: browser_subagent_v1_parallel
batch_id: 4
is_premium: unknown
---

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F69354&text=GPT-4o%E3%80%81Gemini%E3%80%81Claude+3%E3%81%AA%E3%81%A9%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E3%80%8C%E9%95%B7%E3%81%84%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E3%81%AE%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E3%82%BF%E3%82%B9%E3%82%AF%E3%80%8D%E6%80%A7%E8%83%BD%E3%82%92%E6%B8%AC%E5%AE%9A%E3%81%97%E3%81%9F%E7%B5%90%E6%9E%9C) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F69354&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F69354)

[ベンチマーク・リソース](https://ai-data-base.com/archives/type-tag/resource)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)[マルチモーダル](https://ai-data-base.com/archives/tech-tag/multimodal)

有望なマルチモーダルモデルが多く登場する一方で、モデルの能力を測定するためのベンチマークが不足しています。そこで今回研究者らは、情報検索能力と妨害要因の排除能力、そして現実世界の条件に近い長いコンテキスト処理性能を測定するための新しいベンチマークデータセットを作成し、実験しました。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2024/05/AIDB_69354-1024x576.jpg)

**参照論文情報**

  * タイトル：MileBench: Benchmarking MLLMs in Long Context

  * 著者：Dingjie Song, Shunian Chen, Guiming Hardy Chen, Fei Yu, Xiang Wan, Benyou Wang

  * 所属：The Chinese University of Hong Kong, Shenzhen Research Institute of Big Data




**本記事の関連研究** ：

  * [スタンフォード大学の研究者ら、GPT-4oとGemini1.5 Proで「マルチモーダルモデルにおける『Many-Shot』の効果」を検証](https://ai-data-base.com/archives/69211)

  * [マルチモーダルLLMにおけるハルシネーション（幻覚）の原因と対策](https://ai-data-base.com/archives/68720)

  * [マルチモーダルLLMにおける欠点と原因を明らかにする調査研究の結果](https://ai-data-base.com/archives/68367)

  * [LLMに心の目を与える『Visualization-of-Thought』プロンプティング マルチモーダルモデルに匹敵する空間推論性能を達成](https://ai-data-base.com/archives/67128)




## 背景

マルチモーダルの大規模言語モデルが優れた性能を示しています。それに伴い、モデルの性能評価のためのベンチマークも登場してきました。その多くは、一般的な能力や特定のタスクにおける能力について測るものです。単一の画像と短いテキストで構成されるものが多く、現実世界の複雑さや多様性を捉えきれていないという問題点が指摘されています。

複数の画像を扱うタスクを評価するベンチマークも存在しますが、サンプルごとに提供される画像数が限られていたり、時系列のキャプション生成タスクに特化していたりと、まだ課題があります。

複数の画像を扱い、かつ長いコンテキストを扱う場合におけるハルシネーションの発生は危惧されるものであり、その点における評価が足りていません。

こうした背景を受けて、研究者らはMILEBENCHという新しいベンチマークを作成しました。マルチモーダルモデルの長いコンテキスト処理能力をテストするために特別に設計されたベンチマークです。「診断評価」と「現実的評価」の2つの異なる評価セットが用意されています。長いコンテキストでのタスク完了能力をテストするものです。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信



[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F69354&text=GPT-4o%E3%80%81Gemini%E3%80%81Claude+3%E3%81%AA%E3%81%A9%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E3%80%8C%E9%95%B7%E3%81%84%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E3%81%AE%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A2%E3%83%BC%E3%83%80%E3%83%AB%E3%82%BF%E3%82%B9%E3%82%AF%E3%80%8D%E6%80%A7%E8%83%BD%E3%82%92%E6%B8%AC%E5%AE%9A%E3%81%97%E3%81%9F%E7%B5%90%E6%9E%9C) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F69354&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F69354)
