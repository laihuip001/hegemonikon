---
source_url: https://ai-data-base.com/archives/71486
captured_at: 2026-01-18T22:02:09.905820
title: "ロングコンテキストはRAGもText to SQLも解決するか　Googleがケーススタディを実施"
publish_date: 2024.06.24
tags: ["サーベイ37", "ペルソナ・シミュレーション36", "オープンソース25", "エンタメ・アート23", "SE9", "コーディング56", "画像認識20", "音声8", "教育・キャリア9", "実証137", "画像生成9", "医療・ヘルスケア33", "ハルシネーション16", "ポジション8", "RAG", "ロボット6", "実証", "ファインチューニング16", "製造・デザイン9", "ベンチマーク・リソース22", "分析54", "テクニカルレポート15", "安全性39", "マルチモーダル23", "金融・経済10", "セキュリティ16", "プロンプト技術", "LLM", "政治・社会29", "手法426", "LLM659", "RAG50", "エージェント128", "プロンプト技術156"]
conversion_method: browser_subagent_v1_parallel
batch_id: 4
is_premium: unknown
---

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F71486&text=%E3%83%AD%E3%83%B3%E3%82%B0%E3%82%B3%E3%83%B3%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%81%AFRAG%E3%82%82Text+to+SQL%E3%82%82%E8%A7%A3%E6%B1%BA%E3%81%99%E3%82%8B%E3%81%8B%E3%80%80Google%E3%81%8C%E3%82%B1%E3%83%BC%E3%82%B9%E3%82%B9%E3%82%BF%E3%83%87%E3%82%A3%E3%82%92%E5%AE%9F%E6%96%BD) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F71486&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F71486)

[実証](https://ai-data-base.com/archives/type-tag/empirical)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)[プロンプト技術](https://ai-data-base.com/archives/tech-tag/prompt)[RAG](https://ai-data-base.com/archives/tech-tag/rag)

ロングコンテキストのLLMは、単体でも多様なタスクをこなせる可能性が示唆されています。DeepMindの研究チームは、100万トークンという膨大なコンテキストを一度に処理するLLMが、情報検索や質問応答、さらにはデータベース操作までをこなせるかどうかを検証しました。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2024/06/AIDB_71486-1024x576.jpg)

**参照論文情報**

  * タイトル：Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?

  * 著者：Jinhyuk Lee, Anthony Chen, Zhuyun Dai, Dheeru Dua, Devendra Singh Sachan, Michael Boratko, Yi Luan, Sébastien M. R. Arnold, Vincent Perot, Siddharth Dalmia, Hexiang Hu, Xudong Lin, Panupong Pasupat, Aida Amini, Jeremy R. Cole, Sebastian Riedel, Iftekhar Naim, Ming-Wei Chang, Kelvin Guu

  * 所属：Google DeepMind




**本記事の関連研究** ：

  * [スタンフォード大学の研究者ら、GPT-4oとGemini1.5 Proで「マルチモーダルモデルにおける『Many-Shot』の効果」を検証](https://ai-data-base.com/archives/69211)

  * [プロンプトに例を多く載せるほど、どんなタスクでも性能が上がるのか？DeepMindによる『Many-shot Learning』の実験結果](https://ai-data-base.com/archives/67883)




## 背景

LLMのコンテキスト長が大幅に拡大し、これまで外部ツールに頼っていたタスクをLLMが直接処理できるようになってきています。例えば、従来は膨大な文書から情報を抽出するために専用の検索エンジンが必要だった情報検索や質問応答システムも、長文コンテキストを扱えるLLMなら文書全体を一度に処理できる可能性があります。また、専門的なSQLを使わずに、自然言語でデータベースを操作できるようになるかもしれません。

長いコンテキストを扱えるロングコンテキストLLMには、使いやすさ向上、エラーの減少、柔軟性の向上など、多くの利点が期待されています。

しかしどのような可能性が現実的なのか、長文コンテキストを扱えるLLMの性能を厳密に評価する必要があります。そこで今回、最大100万トークンのコンテキストを扱えるベンチマークLOFTが開発されました。情報検索、質問応答、SQL風の推論など、実用的なタスクを含みます。

そしてLOFTを用いた評価により、長文コンテキストを扱えるLLMの可能性と限界が明らかになってきました。例えば、情報検索ではLLMが専用システムに匹敵する性能を示す一方で、複雑な推論タスクではまだ課題があることがわかりました。

以下で詳しく紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信



[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F71486&text=%E3%83%AD%E3%83%B3%E3%82%B0%E3%82%B3%E3%83%B3%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%81%AFRAG%E3%82%82Text+to+SQL%E3%82%82%E8%A7%A3%E6%B1%BA%E3%81%99%E3%82%8B%E3%81%8B%E3%80%80Google%E3%81%8C%E3%82%B1%E3%83%BC%E3%82%B9%E3%82%B9%E3%82%BF%E3%83%87%E3%82%A3%E3%82%92%E5%AE%9F%E6%96%BD) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F71486&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F71486)
