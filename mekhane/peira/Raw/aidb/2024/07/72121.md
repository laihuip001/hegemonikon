---
source_url: https://ai-data-base.com/archives/72121
captured_at: 2026-01-18T22:02:09.945358
title: "RAGシステムの最適な構築を探る"
publish_date: 2024.07.04
tags: ["サーベイ37", "ペルソナ・シミュレーション36", "オープンソース25", "エンタメ・アート23", "SE9", "コーディング56", "画像認識20", "音声8", "教育・キャリア9", "実証137", "画像生成9", "医療・ヘルスケア33", "ハルシネーション16", "ポジション8", "RAG", "ロボット6", "実証", "ファインチューニング16", "製造・デザイン9", "ベンチマーク・リソース22", "分析54", "テクニカルレポート15", "安全性39", "マルチモーダル23", "金融・経済10", "セキュリティ16", "LLM", "政治・社会29", "手法426", "LLM659", "RAG50", "エージェント128", "プロンプト技術156"]
conversion_method: browser_subagent_v1_parallel
batch_id: 4
is_premium: unknown
---

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F72121&text=RAG%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AE%E6%9C%80%E9%81%A9%E3%81%AA%E6%A7%8B%E7%AF%89%E3%82%92%E6%8E%A2%E3%82%8B) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F72121&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F72121)

[実証](https://ai-data-base.com/archives/type-tag/empirical)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)[RAG](https://ai-data-base.com/archives/tech-tag/rag)

本記事では、RAGの最適実装を探る研究を紹介します。

研究者らはRAGの構成要素を洗い出し、最適なアプローチを考察しています。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72121-1024x576.jpg)

**参照論文情報**

  * タイトル：Searching for Best Practices in Retrieval-Augmented Generation

  * 著者：Xiaohua Wang, Zhenghua Wang, Xuan Gao, Feiran Zhang, Yixin Wu, Zhibo Xu, Tianyuan Shi, Zhengyuan Wang, Shizheng Li, Qi Qian, Ruicheng Yin, Changze Lv, Xiaoqing Zheng, Xuanjing Huang

  * 所属：School of Computer Science, Fudan University, Shanghai Key Laboratory of Intelligent Information Processing




**本記事の関連研究** ：

  * [LLMはRAGコンテキストと事前知識のどちらに依存する？](https://ai-data-base.com/archives/71857)

  * [RAGにおいて長文を検索することで一気に効率を上げるアプローチ『LongRAG』](https://ai-data-base.com/archives/71774)

  * [RAGの失敗パターン7選と教訓9箇条](https://ai-data-base.com/archives/69154)

  * [表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法](https://ai-data-base.com/archives/65583)




## 背景

検索拡張生成（RAG）技術が注目されています。外部知識ベースから関連文書を取得し、LLMに提供することで、最新の情報を含む正確な応答を生成する手法です。  
特定の組織や分野向けのアプリケーションを展開する際に、モデルのパラメータを更新せずに、クエリに関連する文書を提供するだけで対応できるという利点があります。

これまで多くのRAGアプローチが提案されてきましたが、実装が複雑で応答時間が長くなるという課題があります。クエリ分類、検索、再ランク付け、再パッケージング、要約など、複数の処理ステップがあり、各ステップには様々な実行方法があるため、最適なRAGの構造を決めるのは難しいと言わざるを得ません。

そこで今回研究者らは、既存のRAGアプローチを徹底的に調査し、ベストな組み合わせを探すことにしました。

その結果、パフォーマンスと効率性の両方のバランスを取るRAG戦略がいくつか提案されています。

以下で詳しくみていきます。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信



[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F72121&text=RAG%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E3%81%AE%E6%9C%80%E9%81%A9%E3%81%AA%E6%A7%8B%E7%AF%89%E3%82%92%E6%8E%A2%E3%82%8B) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F72121&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F72121)
