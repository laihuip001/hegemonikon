---
source_url: https://ai-data-base.com/archives/72401
captured_at: 2026-01-18T22:00:11.466039
title: "LLMの価値観は一貫しているのか？"
publish_date: 2024.07.09
tags: ["実証", "LLM"]
conversion_method: browser_subagent_v1_parallel
batch_id: 5
is_premium: unknown
---

# LLMの価値観は一貫しているのか？

2024.07.092025.03.08

[深堀り解説](https://ai-data-base.com/archives/category/deep-dive)

 ![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAQAAQMAAABF07nAAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAJZJREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAewEEHgABB9i6GAAAAABJRU5ErkJggg==)

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72401_eye.jpg)

クリップする[](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F72401&text=LLM%E3%81%AE%E4%BE%A1%E5%80%A4%E8%A6%B3%E3%81%AF%E4%B8%80%E8%B2%AB%E3%81%97%E3%81%A6%E3%81%84%E3%82%8B%E3%81%AE%E3%81%8B%EF%BC%9F)[](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F72401&src=sdkpreparse)[](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F72401)

[実証](https://ai-data-base.com/archives/type-tag/empirical)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)

本記事では、LLMにおける「価値観の一貫性」を評価した研究を紹介します。

トピックの比較やベースモデルと微調整モデルの比較が行われ、様々な角度からモデルの一貫性が評価されました。

![](https://ai-data-base.com/wp-content/uploads/2024/07/AIDB_72401-1024x576.jpg)

**参照論文情報**

*   タイトル：Are Large Language Models Consistent over Value-laden Questions?
*   著者：Jared Moore, Tanvi Deshpande, Diyi Yang
*   所属：Stanford University

## 背景

LLMは価値観を含む出力を求められる場面もあります。しかし、特定の地域の人々の価値観に偏っている傾向があることなど、不安要素が指摘されてきました。そこで研究者らは、LLMが本当に一貫した価値観を持っているのかを検証しました。

llama-3やgpt-4oを含む大規模モデルを対象に、300以上のトピックに関する8000問以上の質問を用いて評価が行われました。その結果、一貫性が低いトピックの存在や、モデルによる一貫性の違いが明らかになりました。