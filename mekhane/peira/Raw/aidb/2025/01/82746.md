---
source_url: https://ai-data-base.com/archives/82746
captured_at: 2026-01-18T23:29:33.879643
title: "三段論法でLLMの推論能力を高める プロンプト手法の新提案"
publish_date: 2025.01.26
tags: ["画像認識 20", "サーベイ 37", "安全性 39", "政治・社会 29", "分析 54", "オープンソース 25", "プロンプト技術", "マルチモーダル 23", "SE 9", "テクニカルレポート 15", "手法", "手法 426", "エージェント 128", "金融・経済 10", "RAG 50", "ベンチマーク・リソース 22", "ファインチューニング 16", "LLM", "ロボット 6", "プロンプト技術 156", "ハルシネーション 16", "コーディング 56", "LLM 659", "ペルソナ・シミュレーション 36", "ポジション 8", "セキュリティ 16", "実証 137", "エンタメ・アート 23", "製造・デザイン 9", "教育・キャリア 9", "画像生成 9", "音声 8", "医療・ヘルスケア 33"]
conversion_method: fast_collect_v1
batch_id: 1
---

# 三段論法でLLMの推論能力を高める プロンプト手法の新提案

2025.01.272025.12.22

[深堀り解説](https://ai-data-base.com/archives/category/deep-dive)

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAQAAQMAAABF07nAAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAJZJREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAewEEHgABB9i6GAAAAABJRU5ErkJggg==) ![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_eye.png)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F82746&text=%E4%B8%89%E6%AE%B5%E8%AB%96%E6%B3%95%E3%81%A7LLM%E3%81%AE%E6%8E%A8%E8%AB%96%E8%83%BD%E5%8A%9B%E3%82%92%E9%AB%98%E3%82%81%E3%82%8B%E3%80%80%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E6%89%8B%E6%B3%95%E3%81%AE%E6%96%B0%E6%8F%90%E6%A1%88) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F82746&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F82746)

[手法](https://ai-data-base.com/archives/type-tag/method)

[LLM](https://ai-data-base.com/archives/tech-tag/llm)[プロンプト技術](https://ai-data-base.com/archives/tech-tag/prompt)

本記事では、LLMに三段論法による推論能力を付与する新しいフレームワークを紹介します。

LLMは豊富な事前学習により推論能力を持っていますが、その推論過程には厳密性が欠けることがあります。

そこで研究者らは人間の三段論法による推論プロセスを参考に、LLMの推論をより厳密にし、複雑な知識ベースの推論タスクでの性能向上を目指しました。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-data-base.com/wp-content/uploads/2025/01/AIDB_82746_thum2-1024x576.png)

**本記事の関連研究**

  * [8つの質問で自分自身の答えを批評する哲学的手法を活用したLLMのプロンプティング技術](https://ai-data-base.com/archives/81166)

  * [直感に頼るようなタスクだとLLMに「ステップバイステップで考えて」は逆効果](https://ai-data-base.com/archives/78145)

  * [LLMには正解例だけでなく、「よくある間違い例」と理由も一緒に教えるのが有効](https://ai-data-base.com/archives/77507)




## 背景

人間の重要な能力に「演繹推論」があります。演繹推論とは、既存の知識を基に複雑な問題を解決する思考方法です。最近のLLMは豊富な事前学習によって演繹的な推論能力を身につけ、Chain-of-Thoughtプロンプト（ステップバイステップの思考を促すプロンプト）の導入によってさらにその能力が向上しました。

しかし、LLMによる推論には厳密性が欠けることがあり、正しい推論経路から外れてしまう場合があります。また、形式言語に基づく推論エンジンや自動定理証明は厳密な推論を可能にしますが、日常的な質問応答などの知識ベースの推論タスクには適用が困難です。

そこで、人間が行う三段論法による推論が注目されます。三段論法とは、大前提と小前提から結論を導く厳密な演繹推論の一つです。

今回研究者らは、LLMにこの三段論法による推論を行わせることで、推論の厳密性を高め、錯覚を減らし、複雑なタスクでのパフォーマンスを向上させられると考えました。そして三段論法をLLMに実行させるためのプロンプト手法を考案しました。  
問題の解釈から始まり、大前提の提案、小前提の生成と回答、最終的な三段論法による推論という合計5段階で構成される手法です。各段階で必要な情報のみを参照することで、推論の厳密性を保ちながら、様々な知識ベースの推論タスクに対応することが目指されています。

以下で詳しく紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信



[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

クリップする [](https://twitter.com/share?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F82746&text=%E4%B8%89%E6%AE%B5%E8%AB%96%E6%B3%95%E3%81%A7LLM%E3%81%AE%E6%8E%A8%E8%AB%96%E8%83%BD%E5%8A%9B%E3%82%92%E9%AB%98%E3%82%81%E3%82%8B%E3%80%80%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E6%89%8B%E6%B3%95%E3%81%AE%E6%96%B0%E6%8F%90%E6%A1%88) [](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fai-data-base.com%2Farchives%2F82746&src=sdkpreparse) [](https://note.com/intent/post?url=https%3A%2F%2Fai-data-base.com%2Farchives%2F82746)
