---
source_url: https://ai-data-base.com/archives/98974
captured_at: 2026-01-18T22:28:59.351697
title: "マルチエージェントは万能薬ではない　180パターンの実験が明かすマルチエージェントの適材適所"
publish_date: 2025.12.12
tags: ["分析", "LLM", "エージェント", "金融・経済", "SE", "手法\n426", "実証\n137", "分析\n54", "サーベイ\n37", "ベンチマーク・リソース\n22", "テクニカルレポート\n15", "ポジション\n8", "LLM\n659", "プロンプト技術\n156", "エージェント\n128", "コーディング\n56", "RAG\n50", "安全性\n39", "ペルソナ・シミュレーション\n36", "オープンソース\n25", "マルチモーダル\n23", "画像認識\n20", "セキュリティ\n16", "ハルシネーション\n16", "ファインチューニング\n16", "画像生成\n9", "音声\n8", "医療・ヘルスケア\n33", "政治・社会\n29", "エンタメ・アート\n23", "金融・経済\n10", "SE\n9", "教育・キャリア\n9", "製造・デザイン\n9", "ロボット\n6"]
conversion_method: browser_subagent_v1_parallel
batch_id: 1
is_premium: unknown
---

マルチエージェントは万能薬ではない　180パターンの実験が明かすマルチエージェントの適材適所
2025.12.12
2025.12.27
深堀り解説
クリップする
分析
LLM
エージェント
金融・経済
SE

この記事では、「LLMエージェントシステムのスケーリング原理」に関する研究を紹介します。

最近では、複数のLLMエージェントが協力してタスクをこなす「マルチエージェントシステム」が注目を集めています。しかし、単純に「エージェントの数を増やせば性能が向上する」というわけではありません。

今回の研究では、180通りの実験を通して、マルチエージェントの効果がどのような条件で高まり、逆にどのような場合に悪影響を及ぼすのかが、定量的に示されました。

本記事の関連研究

ソフトウェア開発におけるLLMマルチエージェントの設計パターン
「マルチエージェント」は必要か　精度とコストのバランスをとるLLMエージェント構成判断の考え方
背景

最近は、複数のLLMエージェントを協力させてタスクを解決するやり方が注目を集めています。たしかに、うまくいくときもありますが、どんなタスクでも効果的とは限りません。むしろ、タスクの内容によっては、エージェントを増やすことで性能が大きく下がってしまうこともあるのです。

たとえば、数学のように一度で答えを出せるタスクでは、複数のエージェントで意見を集めることで精度が上がる可能性があります。でも、コードのデバッグのように、何度も試行錯誤を重ねながら進めていくようなタスクでは、かえってエージェント同士のやり取りが負担になり、うまくいかないこともあります。

これまでの研究の多くは、比較的単純なタスクを対象にしてきたため、「マルチエージェントは効果がある」という結果が出やすかったのですが、実際の現場で求められるのはもっと複雑な作業です。そこにズレがあったため、現場では混乱が生じていたわけです。

さらに、最近のLLMは1つのエージェントでもかなり高性能になってきています。長い文脈を扱えたり、ツールを使いこなしたり、自分の出力を見直したりすることもできるようになってきました。そうなると、わざわざ複数のエージェントに分けて使う意味があるのかという疑問も出てきます。

そこで本記事では、そうした疑問に答えるために、多くのパターンで実験を行い、マルチエージェントの効果が出る条件とそうでない条件を整理しようとしている事例を取り上げます。実務でLLMを活用するうえで、「どういうときにマルチエージェントを使うべきか」を判断するヒントになる内容です。

ここから限定コンテンツ
忙しい人向けに、重要なポイント5選
マルチエージェントの効果はタスク次第で、金融分析では+81%向上するが、順序立てた計画タスクでは-70%悪化する
ツール数が多いタスクほど、マルチエージェントの調整コストが重くのしかかり、性能が劣化する
単一エージェントの正解率が45%を超えると、マルチエージェント化は改善ではなく悪化をもたらす
エージェント間で情報を共有しない構成ではエラーが17倍に増幅されるが、中央管理型では4倍に抑えられる
タスクの分解可能性、ツール数、難易度から最適なアーキテクチャを87%の精度で予測できる数理モデルを開発した

参照文献情報

タイトル：Towards a Science of Scaling Agent Systems
URL：https://doi.org/10.48550/arXiv.2512.08296
著者：Yubin Kim, Ken Gu, Chanwoo Park, Chunjong Park, Samuel Schmidgall, A. Ali Heydari, Yao Yan, Zhihan Zhang, Yuchen Zhuang, Mark Malhotra, Paul Pu Liang, Hae Won Park, Yuzhe Yang, Xuhai Xu, Yilun Du, Shwetak Patel, Tim Althoff, Daniel McDuff, Xin Liu
所属：Google Research, Google DeepMind, Massachusetts Institute of Technology
エージェントシステムとタスクの定義

本題に入る前に、この研究でどのようにエージェントシステムを分類し、どんなタスクを使って効果を検証したのかをあらかじめ整理しておきましょう。

単一エージェントと5種類のシステム構成

研究チームはまず、エージェントシステムというものを形式的に定義しています。エージェントシステムは次の四つの要素で構成されています。

エージェントの集まり
エージェントが共有する環境
エージェント間のやり取りの構造
行動を調整するための方針

エージェントはそれぞれ、LLMによる推論機能を中心に、使えるツール群や記憶領域、そして意思決定を行う仕組みを備えています。

また、代表的な五つのシステム構成が比較対象となりました。そのうち一つが基準となる「単一エージェントシステム」で、残りの四つは異なる形式のマルチエージェント構成です。

１、単一エージェントシステム（SAS）

一人のエージェントがすべてを担当するもっとも基本的な構成です。認識、推論、行動までを一貫して行うため、処理はシンプルで通信コストもかかりません。一方で、タスクを複数に分けたり、複数視点で検証したりといった柔軟性には欠けます。計算量は試行回数に応じて増えていきます。

２、独立型

複数のエージェントが、それぞれ完全に独立してタスクに取り組み、最後にその結果だけをまとめる構成です。エージェント同士のやり取りは一切なく、完全に並列で動作します。処理効率は高いですが、協調や調整といった働きはほとんど期待できません。

３、中央集権型

この構成では、一つのエージェントが指揮役を務め、ほかのエージェントを管理します。タスクは指揮役が細かく分けて各エージェントに割り振り、途中の成果や進捗を確認しながら最終的に全体をまとめ上げます。全体の方向性をコントロールしやすい一方で、指揮役に負荷が集中するため、そこが処理のネックになりやすいという課題もあります。

４、分散型

全てのエージェントが対等な立場で、自由に意見を交わしながら進める構成です。ラウンドごとに討論を繰り返し、合意形成を目指します。柔軟な情報共有ができる利点がありますが、エージェントに求められる記憶量が多くなり、システムの負担も増えます。

５、ハイブリッド型

中央集権型のように一つの指揮役を持ちつつ、必要に応じて一部のエージェント同士が直接やり取りできるようにした構成です。上下の制御を維持しながらも、場面によっては柔軟な連携もできるため、複雑なタスクに対応しやすいのが特徴です。

5つのエージェント構成を、通信の形と計算コストの観点で並べて比較したもの（独立型、分散型、中央集権型、ハイブリッド型、単一エージェント）

研究チームがこの五つの構成を選んだのは、それぞれ異なる調整の仕組みや通信のあり方が明確に比較できるからです。独立型では並列処理の効果、分散型では階層を持たない連携の可能性、中央集権型では指揮による統制とその限界、ハイブリッド型では制御と柔軟性の両立が、それぞれ検証できるようになっています。

通信と調整は異なる働きとして考える

ここで注目したいのが、エージェント間の「通信」と「調整」という二つの要素の違いです。

通信はエージェント同士が情報をやり取りする行為そのものを指します。
一方で調整は、そうしたやり取りを通じて各エージェントの行動を戦略的に統一し、チーム全体として効果的に動けるよう方向づける働きです。

たとえば中央集権型では、調整はタスクをどう分けるか、進捗をどう管理するかといった形でオーケストレーターによって行われ、通信はそれを支える情報伝達の手段となります。分散型の場合は、討論の中で通信と調整が同時に進んでいくため、この二つの境界がより曖昧になります。

「エージェント的タスク」とは何か

次に考えるべきなのは、どのようなタスクでエージェントが本領を発揮するのかという点です。どのような条件を満たせば「エージェント的なタスク」と呼べるのか。その答えを簡単に言えば、環境とのやり取りを何度も繰り返すアプローチのほうが、一度きりの回答よりも明らかに良い結果を出せるようなタスクのことです。

このようなタスクには三つの特徴があります。
第一に、行動が順番に依存していることです。あとで取るべき行動は、それ以前の観察の結果によって変わるため、最初からすべてを見通した計画を立てることができません。
第二に、観察できる情報が限られていることです。重要な情報の一部は最初は見えないため、質問を投げたり、ツールを使ったりして、自分から情報を取りにいく必要があります。
第三に、柔軟に戦略を変えられることです。新しく得た情報に応じて、自分の中の考え方や前提を更新し、行動方針を変えていく力が求められます。

このような条件を満たさないタスクもあります。たとえば数学の文章題や一般常識クイズのような問題は、基本的に知識を引き出すものであり、エージェントが持つような探究的な力を測るものではありません。

それに対して、コーディングアシスタントや金融分析、実世界で動くロボットのようなタスクは、不確実性や環境の変化に対応する必要があります。こうした場面では、状況に応じて探索したり、柔軟に対応したり、うまく調整したりといった知性のプロセスそのものが求められるのです。

また、研究チームは評価に使うベンチマークの設計にも細かいルールを設けています。
すべてのエージェント構成において、同じツールAPIと観察の仕組みを使い、外部からのフィードバックの違いによって結果がぶれないようにしています。さらに、すべてのタスクでは少なくとも三つ以上のステップを必要とする行動と観察のループが組み込まれており、一度で完了するような処理ではなく、順を追って推論を進めることが前提になっています。そしてスコアは、最も優秀な単一エージェントの成績を基準として正規化されており、そこからの増減によって、マルチエージェント構成による純粋な効果を評価できるようにしています。

ここでひとつ注意が必要なのは、「エージェント的」という概念は、モデルの性能との関係によって決まる相対的なものだということです。たとえば、今のLLMには電卓が必要だと思われる計算問題でも、モデルが十分に賢ければ電卓なしで解けてしまうかもしれません。逆に、現在はエージェント的とされるタスクであっても、将来的には単発の推論だけでこなせるようになる可能性もあります。

この研究では、あくまでも現時点において、複数ステップの相互作用が不可欠であり、単一の思考だけではうまく解けないタスクに焦点を当てています。

評価に使われた4つのベンチマーク

実験では、タスクの構造や難しさの違いを幅広くカバーするため、性質の異なる4つのベンチマークが使われました。決まりきった処理が求められるものから、状況に応じた柔軟な対応が必要なタスクまで含まれています。

ベンチマーク名	主な内容	タスクの特徴
Workbench	コード実行やツール使用を扱うタスク	正解がはっきり決まっていて、決定論的な処理が中心になる
Finance-Agent	金融分野の分析タスク	複数ステップの数値推論やリスク評価が必要で、情報の読み取りと見通し作りが重要になる
PlanCraft	制約付きの計画立案タスク	Minecraftのような環境で、アイテムの収集や組み合わせ方を考えながら時空間的な計画を立てる
BrowseComp-Plus	ウェブ情報の探索タスク	複数のページを行き来して情報を集め、必要な内容を抜き出して整理し、統合した結果をまとめる

この4つの中で、BrowseComp-Plusは最も結果のばらつきが大きく、安定性に欠ける傾向が見られました。タスクの性質そのものが、マルチエージェント構成による効果に大きく影響していることが示唆されます。動的で情報密度の高いタスクでは、構成や調整方法の違いがより大きな差となって現れる可能性があります。

実験設計と結果

ここでは、180通りの実験がどのように構成され、そこから何が見えてきたのかを見ていきます。

実験の設計について

アーキテクチャごとの効果を正確に測るため、研究チームは細かい点まで条件をそろえ、公平な比較ができるように設計しました。

まず使用されたLLMは、OpenAI、Google、Anthropicの3社から選ばれています。それぞれのモデルファミリーから、性能の異なる3種類ずつを用意しました。

OpenAI→GPT-5、GPT-5-mini、GPT-5-nano
Google→Gemini 2.5 Pro、2.5 Flash、2.0 Flash
Anthropic→Claude Sonnet 4.5、4.0、3.7

推論の回数（イテレーション数）を揃えることで、フェアな条件が保たれました。マルチエージェント構成では処理が並列で進むため、各エージェントの試行回数は少なくなりますが、全体としての計算量は単一エージェントと同じになるように調整されています。また、単一エージェントには並列処理の利点がない分、それを補うために多めの推論ステップが与えられました。

測定された指標とその目的

評価は多面的に行われています。タスクの成功率や正答率といった直接的な指標に加えて、次のような観点も測定されています。

事実誤りの発生率
新しい情報をどれだけ獲得できたか
出力内でのトークンの繰り返し傾向
1000トークンあたりの成功回数による効率性
トークンコストを加味した正規化スコア

これらの指標はすべて、推論ターン単位やトークン単位で正規化されており、異なる構成同士でも比較が可能です。

さらに、エージェント間の調整に関する特徴を測るため、調整関連のメトリクスも定義されました。

指標名	意味
調整オーバーヘッド	単一エージェントと比べて、マルチエージェント構成がどれだけ余分な推論ターンを消費しているかを示す指標
メッセージ密度	一回の推論ターンのあいだに、エージェント同士でどれくらいメッセージをやり取りしているかを表す指標
冗長性率	複数のエージェントが出力した内容がどの程度似通っているかを、埋め込みベクトルの平均コサイン類似度で測った指標
調整効率	使った推論ターンの数で割った成功率を用いて、どれだけ効率よく成果を出せているかを表す指標
エラー増幅	単一エージェントと比べたとき、マルチエージェント構成で失敗する確率がどれだけ増えているかを示す指標
タスクによって劇的に異なる結果

実験の結果は、予想以上に多様性がありました。

タスクによって、マルチエージェントが効く場合と逆効果になる場合がはっきり分かれる（4ベンチマーク比較）

まず顕著な成功例となったのがFinance-Agentです。ここでは、すべてのマルチエージェント構成が単一エージェントを大きく上回りました。中央集権型は平均成功率が0.631となり、単一エージェントの0.349に比べて80.9%も向上しました。分散型は74.5%の改善で成功率は0.609、ハイブリッド型も73.2%増の0.604という結果でした。複雑な金融タスクにおいて、複数エージェントによる分散型の推論が有効に機能することを示しています。

一方で、Workbenchのような決まった手順があるタスクでは、マルチエージェントによる改善はわずかでした。分散型では5.7%の向上（0.664 vs 0.629）が見られたものの、中央集権型とハイブリッド型はどちらも1.2%程度の低下という結果でした。

BrowseComp-Plusでも、効果は限定的でした。分散型は9.2%の改善（0.347 vs 0.318）とやや良好な結果となったものの、中央集権型はほとんど差がなく、0.2%の微増にとどまりました。

そして最も意外だったのがPlanCraftの結果です。すべてのマルチエージェント構成で性能が大きく落ち込みました。中央集権型は-50.4%（0.282 vs 0.568）、分散型は-41.4%（0.332）、ハイブリッド型は-39.0%（0.346）と深刻な低下が見られました。特に独立型は-70.0%（0.170）と、ほぼ機能しない結果となりました。

全体を通して見ると、すべてのベンチマークとアーキテクチャを平均した場合の改善率は-3.5%でした。95%信頼区間では-18.6%から+25.7%の幅があり、標準偏差は45.2%と非常に大きくなっています。つまり、結果は大きくぶれることがあり、マルチエージェントが必ずしも常に効果的とは限らないことが明らかになったのです。

研究チームはこの背景に「調整飽和効果」があると指摘しています。つまり、一定の段階までは調整によって性能が向上しますが、それを超えると、調整そのものがかえって推論を妨げてしまうという現象です。この飽和を超えると、通信が過剰になり、むしろ性能が落ちるという限界が見えてきます。

タスクの複雑さが効果を左右する

分析の結果、タスクがどれくらい複雑かによって、マルチエージェントの効果が大きく変わることが分かりました。簡単なタスクならうまく連携できても、複雑すぎると逆効果になることがあるのです。

たとえばFinance-Agentのように、タスクをうまく分けられる場合は、各エージェントが自分の担当をこなしてから情報を共有することで、全体の精度がぐっと上がります。実際、+80.9%の改善という大きな成果が出ています。

逆にPlanCraftのように、ひとつの動きが次の動きに直結しているタスクでは、推論に手いっぱいで、エージェント同士のやり取りに割く余裕がありません。その結果、情報共有がうまくいかず、かえって性能が下がってしまいました。最悪の場合は-70%という大幅な悪化も見られました。

研究チームは、タスクの複雑さを「どれくらい段階的に考えないといけないか」で数値化しました。Finance-Agentはそこそこ複雑（0.41）で、PlanCraftも似たスコア（0.42）なのに結果が真逆だったのは、タスクを分担できるかどうかの違いにあります。

ベンチマーク	ドメイン複雑さ D	タスクの特徴
Workbench	0.000	逐次的な制約がほとんどない。手順がよく構造化されていてサブタスクの境界が明確。調整の必要性が低い
Finance Agent	0.407	分解可能性は中程度。構造化された領域で、各エージェントが局所的に推論しやすい
PlanCraft	0.419	逐次依存が強い。制約充足のため、順序立った推論ステップが必要
BrowseComp-Plus	0.839	状態が動的に変化する。操作や相互作用が多い環境で、複雑な視覚空間推論が必要

Financeのように、部分的に切り分けてそれぞれが動けるタスクでは連携がうまくいきます。でもPlanCraftでは、一つ一つの動きが後の展開に影響するので、連携よりも慎重な一人作業のほうが向いていたわけです。

さらに、エージェント同士がやり取りして得られた「情報の価値」を比べると、Financeではしっかり成果につながっていましたが、PlanCraftではあまり意味のある情報が共有されていませんでした。つまり、タスクが複雑でも「分けられるかどうか」が、マルチエージェントが機能するかどうかのカギになるということです。

LLMごとの違いもくっきり見えた

モデルの種類によって、マルチエージェント構成との相性に違いがあることも分かりました。
どのタスクでも常に強い構成はなく、相性の良し悪しはタスクごとに変わります。

成果が出たタスクでは、分散型や中央集権型が強さを見せました。たとえばFinanceでは中央集権型が+80.9%、分散型が+74.5%。BrowseComp-Plusでも分散型が一番よく、Workbenchも同様でした。

逆にPlanCraftでは、すべての構成で性能が落ち、どれを選んでも厳しい結果に。少しでもマシだったのはハイブリッド型（-39.0%）でした。

モデルごとの特徴もあります。FinanceではGoogleモデルの中央集権型がとくに好成績（+164.3%）。Anthropicは安定性が高く、OpenAIは高精度ながらやや控えめといった印象です。

ただしPlanCraftのような難しいタスクになると、どのモデルでも効果は出ません. 通信の工夫だけでは、タスクの順序依存性を乗り越えられなかったからです。

まとめると、マルチエージェントが効くかどうかは、モデルの違いよりも「タスクの構造」がカギになります。万能なやり方はなく、状況に応じた使い分けが必要だということです。

予測できるモデルが作れた

マルチエージェントの効果は、大きく良くなることもあれば、逆に悪くなることもありました。そこで研究チームは、「結果を見て終わり」ではなく、事前にうまくいくかどうかを予測できないかを考えました。

そのために、いくつかの分かりやすい要素を組み合わせた統計モデルを作りました。モデルの賢さ、エージェントの数、タスクの難しさ、そして調整にどれくらいコストがかかっているか、といった情報から性能を見積もります。
このモデルは、実際の結果の約半分を説明できました。単に「どの構成か」や「モデルがどれくらい賢いか」だけを見るよりも、かなり当たりが良かったのです。

大事なのは、このモデルが特定のタスクに依存していない点です。新しいタスクでも、条件が分かれば「マルチエージェントにする価値がありそうか」を事前に判断できる可能性があります。

つまり、勘や経験に頼らず、使う前に見通しを立てられるようになったということです。

マルチエージェントの効果が抑制されてしまう３つの要因

マルチエージェントの効果を予測するモデルから、影響を及ぼしてしまう3つの要素が明らかになりました。

まず1つ目は、「効率 × ツールの多さ」。
ツールが多いタスクでは、マルチエージェント構成の効率の悪さが足を引っぱります。単一エージェントはそこそこ効率的（0.466）ですが、マルチ構成はかなり非効率（ハイブリッドで0.074など）。ツールが多いほどこの差は拡大し、Workbenchのような重めのタスクではマルチ化が裏目に出やすくなります。
逆に、ツールが少ないシンプルなタスクではこの問題はほぼ起きません。マルチエージェントは「複雑すぎないタスク」でこそ効果を発揮するのです。

2つ目は、「エラーの増幅」。
エージェント同士が連携しない構成（とくに独立型）では、間違いがそのまま重なっていき、大きな失敗につながります。独立型では、なんとエラーの影響が単一エージェントの17倍にもなりました。
ツールが多いタスクではその影響が大きく、失敗が広がりやすくなります。連携なしで動く独立型が全体的に低性能なのは、こうした「直せないまま進む構造」が原因です。

3つ目は、「オーバーヘッド × タスクの複雑さ」。
マルチエージェント構成は、処理量が単一の1.6倍〜6倍になることもあり、重たいタスクではそのコストが大きな負担になります。とくにハイブリッド型では、オーバーヘッドがとても大きく、複雑なタスクでは失敗の原因になります。
目安として、ツールが多いタスクでオーバーヘッドが150%を超えると、マルチ構成は使わない方がよいという指標も導かれています。

まとめると、「ツールが多い」「ミスの修正が難しい」「処理が重い」この3つが重なると、マルチエージェントはかえって邪魔になる可能性が高くなります。逆に言えば、軽めで整理されたタスクこそが、マルチ構成に向いているというわけです。

注目すべき3つのポイント

そのほか、３つのポイントが注目されています。

まず1つ目は、モデルの知能レベルが高くなると、性能の伸びもどんどん加速するという点です。知能が2倍になったとき、性能も単純に2倍ではなく、それ以上に良くなります。特に優秀なモデル（知能スコア60以上）は、平均よりも約23％も高い性能を発揮していました。

2つ目は、作業の「かぶり（冗長性）」が少しだけ助けになるという点です。エージェントの数が多くなると、似たような作業をすることが増えますが、それがエラーを補う役割をわずかに果たします。たとえば4つのエージェントがいるとき、冗長性によって性能が8％ほど向上する計算です。

ただしこの効果は小さく、効率の悪さや処理の重さと比べると目立ちません。つまり、冗長性には少し意味があるけれど、それだけで全体の問題はカバーできないということです。

そして3つ目は、冗長性が効くかどうかはタスク次第ということ。たとえばWorkbenchのようにツールが多くて間違いが起きやすいタスクでは、分散型エージェント（冗長性が高い）が最も良い成績を出しました。でもPlanCraftのように手順が厳密なタスクでは、冗長性がただの無駄になってしまいました。

冗長性は「ベースライン性能が低く、まだ改善の余地があるタスク」では役立ちますが、すでに単一エージェントで十分に強いタスクでは、むしろ足を引っぱる可能性があるということです。

調整の効率やエラー、情報伝達に関する細かな分析

研究チームはこれまでのスケーリング原理に加えて、マルチエージェントの「調整そのもの」がどう働いているかを詳しく調べました。

まず、エージェントの数が増えるほど、やり取りにかかるターン数（やり取りの回数）は大きく増えていきます。とくにハイブリッド型では、単一エージェントの6倍以上のターン数が必要になりました。つまり、3〜4体を超えると、1体あたりの推論能力が大きく下がってしまい、通信コストが足を引っぱるようになります。

メッセージのやり取りも限界があります。ある程度までは成功率が上がりますが、密度が一定以上になると効果は頭打ちになり、やりすぎると意味のない重複が増えていきます。これは仕組みの失敗ではなく、情報に限界があるためです。

また、エラーの修正についても明らかになりました。

中央集権型やハイブリッド型では、出力を集める前に他のエージェントが出した答えを見直す仕組みがあり、平均で約23％のエラーを減らせた
分散型では、エージェント同士が意見をぶつけ合う形で検証が行われ、こちらも効果があった
独立型にはそうした検証がないため、エラーはそのまま結果に反映されてしまい、逆に悪化する傾向が見られた（エラーが17倍に増幅）

情報の中身も分析されています。成功したやり取りでは、エージェント同士が同じ情報にたどり着いていて、答えに一貫性がある一方、失敗した場合は意見が食い違っていたり、同じ内容をただ繰り返しているだけというケースが目立ちました。

冗長性（同じことを複数エージェントがやる割合）もポイントです。適度な重なりは保険のように働きますが、やりすぎるとパフォーマンスが下がります。最適なのは中央集権型で見られた「やや重なる」くらいの状態でした。

エラーのタイプも分類されました。

論理矛盾（同じことについて正反対の主張をする）
数値のズレ（四捨五入や単位変換のミスが連鎖する）
文脈の抜け落ち（前提となる情報の参照を忘れる）
調整の失敗（連携ミスや情報の食い違い）

アーキテクチャごとに特徴もあります。たとえば文脈の抜け落ちは、中央集権型では大幅に減る一方、独立型ではほぼ変化なしでした。調整の失敗は、構造が複雑なハイブリッド型で特に多く見られました。

こうしたパターンから、調整の状態は3つに分けられます。

調整不足では、まだ仕組みが動いておらず、成果も小さい
最適な帯域では、中央集権型や分散型が高い成功率と効率を発揮
調整しすぎると、プロトコルが複雑になり、かえって失敗が増える

マルチエージェントによる「情報の獲得量」も分析されました。構造化されたタスクでは、実際に意味のある情報がやり取りされ、それが成功につながっています。一方、BrowseComp-Plusのようなあいまいな環境では、やり取りがあっても成果に結びつきにくいことが分かりました。

これらの傾向は、異なるタスクでも一貫しており、調整の原理が普遍的に通用することも確認されました。特定の1つを除いたクロスバリデーションでも、高い再現性が得られています。

エージェントを6体以上に増やすと、ターン数は一気に増え、推論の質は大きく下がります。特に予算が決まっている中では、3〜4体を超えると逆効果になることが多いという結果が出ています。

コスト面でも違いがあります。単一エージェントがもっとも効率的で、1000トークンあたりの成功数は約68。マルチ構成ではこれが下がり、ハイブリッド型では13.6まで落ちました。

同じ1％の性能向上を得るのにかかる費用もモデルによって異なります。OpenAIのハイブリッドは比較的コストを抑えられていますが、Anthropicは3倍近くかかることがありました. Googleは中間的で、最もバランスの取れた結果を示しました。

このような違いは、単なる設定の差ではなく、モデルごとの根本的な構造や処理の特徴に由来しています。たとえば、OpenAIモデルは構造化されたタスクで特に強く、Anthropicは安定性が高く、Googleはどの構成でもバランスよく動くという特徴が見られました。

まとめ

この記事では、3つのLLMと4種類のタスクを使って、合計180通りの実験を行い、マルチエージェントシステムのスケーリング原理を定量的に検証した研究を取り上げました。

最も重要な発見は、マルチエージェントの効果がタスクの内容によって大きく変わるという点です。たとえば、金融分析のように作業を分けやすいタスクでは、最大で約81パーセントの性能向上が見られました。一方で、計画を順番通りに進める必要があるようなタスクでは、最大で約70パーセントも性能が下がるケースがありました。この違いの背景には、「タスクの複雑さ」が強く関係していることが、統計的にも確認されています。

さらに、計算資源が限られている状況では、エージェントの数が増えるほどターン数が急激に伸びることも分かりました。具体的には、エージェント数が1.7乗のペースで計算コストに影響するため、現実的には3〜4体が上限だと考えられます。これ以上エージェントを増やすと、かえって効率が落ちてしまうのです。

マルチエージェントは決して万能ではなく、成功の鍵はタスクの種類と構成の相性にあるという結論になっています。

本記事の関連研究

ソフトウェア開発におけるLLMマルチエージェントの設計パターン
「マルチエージェント」は必要か　精度とコストのバランスをとるLLMエージェント構成判断の考え方

クリップする
🔒 AI時代の仕事再設計　19万職種の大規模分析が示す『自動化より生産性向上』の道筋
AIが就活して成長する市場で強かったのは「自己理解が深い」AIエージェント