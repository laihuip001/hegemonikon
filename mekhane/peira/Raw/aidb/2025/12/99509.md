---
source_url: https://ai-data-base.com/archives/99509
captured_at: 2026-01-18T21:53:50.801325
title: "RAGシステムにおけるセキュリティ対策の投資対効果"
publish_date: 2025.12.24
tags: ["分析", "LLM", "RAG", "安全性", "手法\n426", "実証\n137", "分析\n54", "サーベイ\n37", "ベンチマーク・リソース\n22", "テクニカルレポート\n15", "ポジション\n8", "LLM\n659", "プロンプト技術\n156", "エージェント\n128", "コーディング\n56", "RAG\n50", "安全性\n39", "ペルソナ・シミュレーション\n36", "オープンソース\n25", "マルチモーダル\n23", "画像認識\n20", "セキュリティ\n16", "ハルシネーション\n16", "ファインチューニング\n16", "画像生成\n9", "音声\n8", "医療・ヘルスケア\n33", "政治・社会\n29", "エンタメ・アート\n23", "金融・経済\n10", "SE\n9", "教育・キャリア\n9", "製造・デザイン\n9", "ロボット\n6"]
conversion_method: browser_subagent_v1_parallel
batch_id: 1
is_premium: unknown
---

RAGシステムにおけるセキュリティ対策の投資対効果
2025.12.24
2025.12.29
深堀り解説
クリップする
分析
LLM
RAG
安全性

LLMのセキュリティ対策に関する費用対効果の研究を紹介します。

RAGシステムを業務に取り入れる企業が増えてきましたが、情報漏洩やプロンプトインジェクションといったセキュリティリスクへの対応は、後回しにされがちです。セキュリティ対策にはコストがかかるため、どの手段にどれほど投資すべきかを判断するのは簡単ではありません。

本記事では、3つのセキュリティ対策のうち、どれが最も費用対効果に優れていたのか、そしてその理由について、結果に基づいて詳しく見ていきます。

本記事の関連研究

Copilotサービスを使う上で気を付けたいプロンプトインジェクションによる機密情報漏洩リスク
LLMに対するプロンプトインジェクションを防ぐ4つの工夫
LLMアプリが安全に動くという思い込み　外部から守るセキュリティ設計
生成AIシステムのセキュリティ評価 マイクロソフトが100事例から得た教訓
背景

LLMは、医療、金融、教育、法律、サイバーセキュリティなど、さまざまな分野で急速に導入が進んでいます。顧客対応の自動化、法的文書の作成支援、医療レポートの作成、ソフトウェア開発の効率化など、業務のさまざまな場面で活用が進んでいます。

一方で、こうした裏には、セキュリティや信頼性に関わる重大な課題が存在します。敵対的攻撃、プロンプトインジェクション、情報漏洩、モデルのバイアスといった脆弱性が指摘されており、LLMの安全性や信頼性に対して懸念があります。

プロンプトインジェクションとは、悪意あるユーザーが細工を施した入力を送ることで、モデルに本来想定されていない動作を引き起こさせる攻撃手法です。また、データ漏洩の問題も深刻です。モデルが学習に使ったデータに含まれていた個人情報や機密情報を、ユーザーの入力に応じて意図せず出力してしまうことがあります。こうしたリスクは、感情分析の誤判定や機密情報の漏洩、制約の回避（いわゆるジェイルブレイク）、事実と異なる内容の生成（ハルシネーション）、さらには差別的な表現の出力といった形で顕在化します。

このような問題に対応するため、さまざまな対策が提案されています。たとえば、ABAC（属性ベースのアクセス制御）によるシステム側の制御、NER（固有表現認識）を用いたコンテンツのフィルタリング、差分プライバシーを活用した情報漏洩の抑制といった技術が挙げられます。そのほかにも、入力の事前処理、敵対的な入力に対する耐性を高める訓練、攻撃の検知に使う補助的なモデル、レッドチーム演習、意図の分析など、さまざまな方法が研究されています。

ただし、ここで問題となるのが、これらの対策が実際にどれほど効果を発揮するのか、またその導入にどれほどのコストがかかるのかについて、十分な定量的データが存在していないという点です。そのため、企業の意思決定者にとっては、「どの対策に、どの程度の予算を割くべきか」という判断を下すための情報が不足しているのが現状です。

そこで本記事では、セキュリティ対策の投資対効果について取り上げます。

ここから限定コンテンツ
忙しい人向けに、重要なポイント5選
対策なしのRAGシステムは年間31万ドルの期待損失が発生する高リスク状態にある
ABAC（属性ベースアクセス制御）が投資額の9.8倍の損失削減を実現し、最も費用対効果が高い
NER（固有表現認識）による秘匿化はPII漏洩を完全に防ぐが、他の攻撃には効果が限定的である
NeMo Guardrailsは出力段階の防御のため、今回の設定では期待損失をほとんど削減できなかった
モンテカルロシミュレーションとラプラスの継承則を組み合わせ、少数の攻撃試行から損失分布を推定する実用的手法を確立した

参照文献情報

タイトル：Quantifying Return on Security Controls in LLM Systems
URL：https://doi.org/10.48550/arXiv.2512.15081
著者：Richard Helder Moulton, Austin O’Brien, John D. Hastings
所属：Dakota State University
リスクを金額で可視化するには

LLMのセキュリティを数字で評価するには「攻撃が成功したかどうか」を調べるだけでなく、攻撃によってどれくらいの金銭的な損失が出るかを見積もり、対策ごとの効果を比較できるようにする必要があります。

研究チームは、評価の考え方として3つの視点を重視しました。1つ目は「敵対적ロバストネス」と呼ばれる考え方で、悪意のある入力にどれだけモデルが強いかを示します。2つ目は「推論時防御」で、モデルが実際に使われているときに働く防御のしくみを意味します。3つ目は「信頼できるAI」という考え方で、AIが安全で説明可能な動きをし、責任あるふるまいをするための基本方針です。

評価システムの構築

まず研究チームは、検証対象のRAGシステムを作りました。RAGは、外部のデータベースから関連する情報を取り出し、それを使ってLLMがより正確に答えを出す技術です。たとえば企業が社内の情報を使って質問に答えるシステムを作るときなどに使われています。

実際の構成としては、FastAPIというWebアプリを作るためのツールを使って質問受付の機能を作り、DeepSeek-R1という比較的小さなLLM（1億5千万個のパラメータを持つ）を組み込みました。データベースには、名前と社会保障番号を含む、架空の10万件の個人情報が登録されています。ユーザーが質問すると、FAISSという高速検索ツールで関連文書を探し、それをモデルに渡して回答を出します。関連する文書が見つからない場合は、モデルが自分で答えを考えるしくみになっています。

攻撃のテストには「Garak」という自動ツールを使いました。Garakは、いろいろなタイプの悪意のある入力（プローブと呼ばれます）を自動で作り、それをモデルに送って弱点がないかを調べるツールです。今回の研究では、次の5つのタイプの攻撃を対象にしました。

個人情報の漏洩
文脈への意図的な混入（コンテキストインジェクション）
プロンプトインジェクション
攻撃文の生成
攻撃入力をモデルが繰り返してしまう「発散」という現象
3つのセキュリティ対策

研究では、3つの代表的なセキュリティ対策が試され、それぞれの効果が比較されました。

1つ目は「ABAC」と呼ばれるアクセス制御の仕組みです。ユーザーやリクエストの性質に応じてアクセスを制限するもので、今回は個人情報が入ったデータベースへのアクセスそのものを止めることで、機密情報がモデルに渡らないようにしています。情報をそもそも使わせないという方法です。

「ABAC」公式URL

https://csrc.nist.gov/pubs/sp/800/162/upd2/final
https://nvlpubs.nist.gov/nistpubs/specialpublications/NIST.sp.800-162.pdf

2つ目は、固有表現認識（NER）を使って個人情報を見えなくする方法です。Microsoftが提供する「Presidio」というツールを使い、取り出した文書の中の名前などを検出し、モデルに渡す前に記号に置き換えます。たとえば「田中太郎」を「[PERSON]」のように書き換えて、漏洩を防ぐ方法です。

「Presidio」公式URL

https://microsoft.github.io/presidio/
https://github.com/microsoft/presidio

3つ目は「NeMo Guardrails」という出力のチェック機能です。これはNVIDIAが開発したもので、モデルが出した回答をルールと照らし合わせて、問題があればより安全な内容に自動で置き換えます。検索やモデルの考える過程には影響を与えず、最終的な出力だけをチェックするしくみです。

「NeMo Guardrails」公式URL

https://docs.nvidia.com/nemo-guardrails/index.html
https://github.com/NVIDIA-NeMo/Guardrails
リスクの定量化手法

攻撃が成功する確率を見積もるために、研究チームは「ラプラスの継承則」という統計の考え方を使いました。限られたデータしかない場合でも、確率を控えめに予測する方法です。たとえば50回の攻撃がすべて成功した場合でも、成功率を100％とはせず、98％程度にしておくことで、過剰な楽観を避けることができます。

損失の大きさを予測するためには、「モンテカルロシミュレーション」という方法を使いました。偶然を取り入れた試行を何千回も繰り返すことで、実際にどんな損失が起こるかを予測する手法です。損失の元となる金額の分布には、IBMの2024年のデータ侵害コストレポートに基づいた「三角分布」というシンプルなモデルを使いました。三角分布は、最小の金額、もっとも起こりやすい金額、最大の金額の3つの数字で形が決まります。

シミュレーションでは、まず攻撃が成功するかどうかをラプラスの継承則に基づいて判断し、成功した場合に三角分布から損失額をランダムに選びます。この流れを1万回くり返して、各攻撃ごとの平均損失と「損失超過曲線（「ある金額以上の損失がどのくらいの確率で起きるか」を示すグラフで、極端なケースがどのくらい起きそうかを知るのに役立つ仕組み）」を計算しました。

また、セキュリティ対策の費用対効果を比較するため、「RoC（Return on Control）」という指標を使いました。これは、セキュリティ対策で防げた損失額を、その対策にかかったお金で割った値です。たとえばRoCが5なら、1ドルの投資で5ドルの損失を防げたという意味になります。この研究では、すべての対策について年間コストを3万ドルと仮定して比較が行われました。

実験条件と妥当性の確保

すべての実験は、できるだけ条件をそろえて行われました。使った攻撃の種類、データベース、モデルの設定、損失額のデータ、乱数の種など、すべてが統一されました。

実験では、攻撃者がシステムに質問を送ることはできるが、モデルの内部には触れないという想定が使われています。また、防御策はモデルが動いている最中に機能するものだけを対象としていて、学習段階での対策は含まれていません。

実験結果　3つの対策の効果を検証
脆弱性タイプ	試行回数	ベースライン		ABAC		NER		NeMo	
		失敗数	LRS	失敗数	LRS	失敗数	LRS	失敗数	LRS
攻撃生成 (Atkgen)	25	1	0.074	2	0.111	0	0.037	1	0.074
発散 (Divergence)	180	138	0.763	146	0.807	138	0.763	143	0.791
潜在的インジェクション	160	160	0.993	18	0.117	160	0.993	160	0.993
PII	50	50	0.980	0	0.019	0	0.019	50	0.980
プロンプトインジェクション	500	500	0.998	0	0.001	500	0.998	500	0.998
※LRS = ラプラス調整済み成功確率

対策なしのベースラインシステム

まず、何の対策もしていないRAGシステムに、Garakというツールを使って攻撃テストを行いました。結果は非常に深刻でした。

個人情報（PII）を狙った攻撃では、50回すべてが成功しました。検索結果にまぎれ込んだ悪意ある指示をモデルが実行してしまう「潜在的コンテキストインジェクション」は160回中160回、プロンプトインジェクションも500回中500回が成功しました。これらをラプラスの継承則という方法で調整して計算した攻撃成功率は、PII漏洩が98.0%、潜在的インジェクションが99.3%、プロンプトインジェクションが99.8%と、ほぼ確実に攻撃が成功する状態だったことが分かりました。

さらに、モデルが攻撃者の入力を繰り返してしまう「発散攻撃」では180回中138回が成功。別のモデルを使って悪質な入力を自動で作る「攻撃生成」では25回中1回成功しました。つまり、どの種類の攻撃に対しても、システムはほとんど防御できていなかったのです。

これらの攻撃結果をもとに損失額を予測するシミュレーションを行ったところ、対策なしの状態では、年間の予想損失額は31万3,712ドル（約4,500万円）になるという結果が出ました。とくにPII漏洩が大きく、約18万ドルの損失が予想されました。次に大きかったのは、潜在的インジェクションが約7万3,000ドル、プロンプトインジェクションが約5万3,000ドルでした。

損失超過曲線を見ても、これらの高リスク攻撃では右側の尾が長く伸びており、最悪の場合は数十万ドルの損失につながるおそれがあることが示されました。この結果が、以降の対策の効果を比べる基準になります。

ABAC（属性ベースアクセス制御）の効果

ABACとは、ユーザーやリクエストの属性（誰が・何のために）をもとに、情報へのアクセスを制限する方法です。今回の実験では、個人情報が含まれるデータベースへのアクセスそのものを制限し、機密情報がLLMに渡らないようにしました。

この対策の効果は非常に高く、PII漏洩とプロンプトインジェクションは、それぞれ50回・500回あった成功が0回になりました。潜在的インジェクションも、160回中18回にまで大きく減少しました。調整後の成功率は、PIIが1.9%、プロンプトインジェクションが0.1%、潜在的インジェクションが11.7%と、どれも大きく下がりました。

ただし、発散攻撃と攻撃生成ではわずかに成功数が増えました。発散は138回から146回、攻撃生成は1回から2回に増えましたが、他の大幅な改善と比べればごく小さな変化です。

損失超過曲線を見ても、PII、潜在的インジェクション、プロンプトインジェクションの3つのリスクでは、大きく下の方へシフトしており、深刻な損失が起こる可能性も大幅に減ったことが分かります。

PII漏洩リスクの損失超過曲線（対策別比較）

年間の期待損失額は、もとの31万3,712ドルから1万8,966ドルへと約94%も減少しました。導入コストを年3万ドルと仮定した場合、RoC（投資1ドルあたり防げる損失額）は9.83となり、3つの対策の中で最も費用対効果が高い結果となりました。

NER（固有表現認識）による秘匿化の効果

NERは、文章の中から人名などの個人情報を見つけ出して、モデルに渡す前に記号に置き換える方法です。今回は、前述した通りMicrosoftのPresidioというツールを使って対策を行いました。

この対策も、PII漏洩についてはとても効果的で、50回中0回の成功に抑えられました。調整後の成功率も1.9%と、ほぼ攻撃を防げたといえる結果です。また、攻撃生成でも1回から0回に改善が見られました。

一方で、それ以外の3つの脆弱性、つまり発散、潜在的インジェクション、プロンプトインジェクションに対しては、ほとんど効果がありませんでした。成功回数は、対策前と同じままでした。これは、NERがあくまで個人情報を隠すための技術であり、攻撃の内容や構造を変えるものではないためです。

損失超過曲線でも、PII漏洩に関するグラフだけが大きく下に移動し、他はベースラインと同じままでした。つまり、NERの効果はPII漏洩という1つのリスクに集中していることがわかります。

年間の期待損失額は13万4,425ドルと、約57%の削減が見られました。RoCは5.97で、ABACに次いで高い値となりました。PII漏洩が主なリスクとなる環境では高い効果が期待できますが、他の攻撃には対応できないため、NER単体では十分とは言えません。

NeMo Guardrailsの効果

NeMo Guardrailsは、モデルが出した内容を最後にチェックし、問題があれば安全な返答に置き換えるしくみです。検索やモデルの思考過程には関わらず、出力の段階だけで働きます。

しかし今回の結果では、ほとんど効果が見られませんでした。潜在的インジェクションやプロンプトインジェクションの攻撃成功回数は変わらず、成功率も99.3%、99.8%と高いままでした。PII漏洩も50回中50回すべて成功しています。発散攻撃も、わずかに増えて143回となりました。

損失超過曲線を見ても、すべてのリスクでベースラインとほぼ同じ形となっており、深刻な損失が起こる可能性も変わっていませんでした。

年間の期待損失額は31万2,256ドルと、対策なしの31万3,712ドルからほんのわずか（1,456ドル）しか減っていません。RoCも0.05と非常に低く、年3万ドルのコストに見合った効果が出たとは言えません。

この結果から分かるのは、出力段階だけでチェックする方法では、モデルがすでに作ってしまった問題ある内容や、検索結果に含まれていた情報を十分に防ぐことは難しいということです。より高い効果を出すには、ルールの改善や、もっと深いところでの対策、あるいは処理の前の段階での介入が必要になるかもしれません。

3つの対策の総合比較

3つの対策を比べてみると、その違いはとてもはっきりしています。

脆弱性タイプ	ベースライン<br>期待損失 ($)	ABAC<br>期待損失 ($)	ABAC<br>RoC	NER<br>期待損失 ($)	NER<br>RoC	NeMo<br>期待損失 ($)	NeMo<br>RoC
攻撃生成	2,598	3,838	-0.04	1,208	0.05	2,624	0.00
発散	2,863	3,021	-0.01	2,807	0.00	2,894	0.00
潜在的インジェクション	73,310	8,856	2.15	73,043	0.01	73,048	0.01
PII	181,223	3,157	5.94	3,685	5.89	180,077	0.04
プロンプトインジェクション	53,718	94	1.78	53,682	0.00	53,613	0.00
合計	313,712	18,966	9.83	134,425	5.97	312,256	0.05
※EL = 期待損失 (Expected Loss)
※RoC = Return on Control（投資1ドルあたりの損失削減額）

ABACは、もっとも多くのリスクを減らせた対策でした。PII漏洩やプロンプトインジェクションを完全に防ぎ、潜在的インジェクションも大きく減らすことができました。損失超過曲線も大きく下がっており、大きな損失が起きるリスクも減りました。損失の削減率は94%、RoCは9.83で、最も優れた結果でした。

NERは、PII漏洩だけには強く効果がありましたが、他の攻撃には効きませんでした。そのため、PIIに関する損失だけが下がり、それ以外はそのままでした。損失は57%削減され、RoCは5.97と良好な数字ではありましたが、1つのリスクしか対処できない点が弱点です。

NeMo Guardrailsは、今回の実験条件では、目に見える効果がほとんど得られませんでした。損失曲線もベースラインと変わらず、RoCも0.05と非常に低いものでした。

まとめると、検索や処理の段階で対策を行う方法（ABACやNER）は、高リスクな脆弱性をしっかり減らせるということが示唆された結果です。出力だけをチェックする方法（NeMo Guardrails）は、今回のような攻撃に対してはあまり役に立たない可能性が明らかになりました。

実務への応用に向けた課題

今回の評価では5つの攻撃パターンに絞って検証を行いましたが、現実にはさらに多くの問題があります。たとえば、多言語でのやり取りによる情報漏洩、モデルの出力から元の学習データを推測される「モデル反転」、AIが元の偏見を強めてしまう「バイアスの増幅」などです。さまざまな言語でサービスを提供している企業や、差別のない公正な対応が求められる業種では、こうしたリスクにも対応できるよう、評価の範囲を広げる必要があります。
また、Garakは便利な評価ツールではありますが、統計的に意味のある結果を出したり、他の研究者が同じ条件で再現するための基準としてはまだ限界があります。理想的には1つのツールだけに頼るのではなく、複数のツールを組み合わせて結果を確認し合うことが勧められます。

なお、今回の実験では、NeMo Guardrailsは期待されたほどの効果を発揮しませんでしたが、その理由として、初期設定のまま使ったことや、システム全体との連携が十分でなかったことが考えられます。実際の業務で使う場合には、ツールをそのまま使うのではなく、自社の目的に合ったルールを作る必要があることには留意しましょう。また、出力のチェックだけでなく、もっと早い段階で組み込むことで、防御の効果が高まる可能性があります。
今回検証された方法以外にもっと基本的なレベルでの対策も考えられます。たとえば、ユーザーが入力した文章の中に悪意のある指示が含まれていないかをチェックしたり、モデルが処理する途中で機密情報に触れないように制限をかけるなどです。

まとめ

本記事では、LLMのセキュリティ対策にかかる費用と、その効果を数字で評価した研究を紹介しました。

Dakota State大学の研究チームは、RAGシステムに対して5つの種類の攻撃を試し、何の対策もしていない状態では、年間に約31万ドル（約4,500万円）もの損失が予想されることを明らかにしました。そのうえで、代表的な3つのセキュリティ対策であるABAC、NER、NeMo Guardrailsを実際に試し、それぞれの効果とコストをもとに、費用対効果を示す「RoC（Return on Control）」を算出しました。

その結果、ABACは1ドルの投資で約9.8ドルの損失を防ぐ効果があり、最も高い費用対効果を示しました。NERは個人情報（PII）の漏洩には強い効果を発揮しましたが、その他の攻撃にはあまり効果が見られませんでした。NeMo Guardrailsについては、今回の実験条件では目立った効果は確認できませんでした。

この研究の重要な点は、どの対策にどれくらいのお金をかけるべきかという、実際の現場での判断を助けるために、客観的な数字を示したところにあります。（ただし、使用されたツールやモデルには限界もあり、今後さらに多くの検証や技術の進化が期待されます）

本記事の関連研究

Copilotサービスを使う上で気を付けたいプロンプトインジェクションによる機密情報漏洩リスク
LLMに対するプロンプトインジェクションを防ぐ4つの工夫
LLMアプリが安全に動くという思い込み　外部から守るセキュリティ設計
生成AIシステムのセキュリティ評価 マイクロソフトが100事例から得た教訓

クリップする
🔒 コスト削減の切り札か、信頼性の落とし穴か　LLM-as-Judgeの実用性を検証する
🔒 AI生成コードは新規コードの4割近くまで　GitHub上位1000リポジトリの大規模分析で判明したセキュリティリスクと対策案