---
source_url: https://ai-data-base.com/archives/68720
captured_at: 2026-01-19T07:33:19.927377
title: "マルチモーダルLLMにおける幻覚（ハルシネーション）の原因と対策 クリエイティブでの活用も推奨 AWSなどが網羅的に調査 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

テキストだけでなく画像や動画などの視覚情報も理解し、それらを組み合わせて高度なタスクを遂行するマルチモーダルの大規模言語モデル（マルチモーダルLLM）が注目を集めています。

そんな中、モデルが生成した内容が入力された情報と矛盾したり、事実とかけ離れたりする現象である「ハルシネーション」の問題が、マルチモーダルLLMにおいても問題となっています。

そこで今回Amazon Prime
Videoなどの研究者らは、マルチモーダルLLMにおけるハルシネーションの原因や評価方法、対策などについて詳しく調査しています。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/05/AIDB_68720_thum2-1024x576.jpg)

