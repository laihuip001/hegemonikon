---
source_url: https://ai-data-base.com/archives/70850
captured_at: 2026-01-19T07:33:42.108726
title: "包括的なRAG評価ベンチマーク『CRAG』Metaなどが開発 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

Metaなどの研究者らは、RAGシステムが多様な質問応答タスクにどの程度正確に対応できるかを評価するためのベンチマーク『CRAG』を作りました。  
データマイニングや知識発見の分野で毎年開催される有名な国際コンペティションKDD Cup 2024で使用されています。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/06/AIDB_70850-1024x576.jpg)

**参照論文情報**

  * タイトル：CRAG — Comprehensive RAG Benchmark

  * 著者：Xiao Yang, Kai Sun, Hao Xin, Yushi Sun, Nikita Bhalla, Xiangsen Chen, Sajal Choudhary, Rongze Daniel Gui, Ziran Will Jiang, Ziyu Jiang, Lingkun Kong, Brian Moran, Jiaqi Wang, Yifan Ethan Xu, An Yan, Chenyu Yang, Eting Yuan, Hanwen Zha, Nan Tang, Lei Chen, Nicolas Scheffer, Yue Liu, Nirav Shah, Rakesh Wanga, Anuj Kumar, Wen-tau Yih, Xin Luna Dong

  * 所属：Meta Reality Labs, FAIR Meta, HKUST, HKUST (GZ)

**本記事の関連研究** ：

  * [グラフニューラルネットワークを活用したRAG手法『GNN-RAG』 7BのLLMでも最先端性能](https://ai-data-base.com/archives/70237)

  * [RAGの失敗パターン7選と教訓9箇条](https://ai-data-base.com/archives/69154)

  * [小さなRetrieverとLLMの組み合わせによる実用的なワークフロー生成システム またはRAGで幻覚を減らす手法](https://ai-data-base.com/archives/68219)

  * [RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成](https://ai-data-base.com/archives/66269)

## 背景

LLMは事実に基づかない回答を生成してしまうことがある問題が指摘されています。例えばGPT-4を用いた実験では、急速に変化する事実に関する質問の正答率が15%以下であったことが報告されています。また、静的な事実であっても、マイナーな知識に関する質問の正答率は35%以下だったと言います。そのため、幻覚的な回答を行わず、信頼性の高い質問応答システムを構築することが急務となっています。

この問題を解決するアプローチの1つとして、検索拡張生成（RAG：Retrieval-Augmented
Generation）が注目を集めています。RAGは、質問に対して外部のソースから関連情報を検索し、その情報を活用して回答を生成する手法です。しかし、RAGにも下記のような課題が残されています。

  * 関連情報の選択精度を向上させる

  * 質問応答の遅延時間の削減する

  * 複雑な質問に答える

これまでのところ、RAGの包括的なベンチマークが存在しませんでした。通常の質問応答のベンチマークは、RAGが直面している課題をカバーしていません。また、LLMやRAGの特定の能力にのみ焦点を当て、数百程度のクエリしか含んでいないものもあります。

そこで今回研究者らは、RAGの研究開発を推進するための包括的なベンチマーク「CRAG」を構築しました。現実のユースケースを最もよく反映し、一般的なユースケースだけでなく複雑で高度なユースケースも含み、さまざまなタイプの課題で評価できるとされています。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信

[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

