---
source_url: https://ai-data-base.com/archives/76609
captured_at: 2026-01-19T07:34:54.418883
title: "「o1-preview」は従来のモデルとは明確に異なり「珍しいタイプの問題」にも強い - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

本記事では、OpenAIが開発した新しいモデル「o1」に関する最新の研究結果を紹介します。

LLMは、これまで主に「次の単語を予測する」という方法で訓練されてきました。しかし、この手法には問題があることが指摘されています。

そこでo1は推論能力の向上に特化した新しいアプローチで開発されました。ただし、従来のモデルが抱えていた課題をどこまで克服できているのか、という疑問も生まれています。

今回、イエール大学やOpenAIなどの研究者らが共同でこの謎の解明に取り組みました。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2024/10/AIDB_76609-1024x576.jpg)

**参照論文情報**

  * タイトル：When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1

  * 著者：R. Thomas McCoy, Shunyu Yao, Dan Friedman, Mathew D. Hardy, Thomas L. Griffiths

  * 研究機関：Yale University, OpenAI, Princeton University, Roundtable

**本記事の関連研究**

  * [OpenAIの新しいモデルo1、従来のLLMと比べて「計画能力」で圧倒的な性能向上](https://ai-data-base.com/archives/76177)

## 背景

LLMは、次の単語を予測するように訓練されています。「自己回帰」と呼ばれる方法です。しかし、この訓練方法には限界があるのではないかと考えられています。

例えば、LLMは、よく見られる文章を生成する方が、珍しい文章を生成するよりも得意です。同様に、LLMは、よくあるタスクの方が、珍しいタスクよりも上手に処理できます。

このようなメモリ依存の性能は、LLMが次の単語を予測するように訓練を受けた結果だと考えられています。

一方で、OpenAIが開発した新しいシステム「o1」は、推論能力を高めるように特別に最適化されています。これは、従来のLLMとは異なるアプローチです。

今回研究者たちは、o1が従来のLLMとは違う挙動を示すのではないかと予想しました。なぜなら、o1は単に次の単語を予測するだけでなく、推論を行うように訓練されているからです。

しかし、o1の訓練過程にも次の単語を予測する要素が含まれている可能性があります。そのため、従来のLLMと同じような特徴を示す可能性もあります。

そこで、イエール大学、OpenAI、プリンストン大学などの研究者らはこのテーマで検証実験を行いました。

以下に実験内容と結果を紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信

[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

