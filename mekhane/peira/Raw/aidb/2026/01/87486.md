---
source_url: https://ai-data-base.com/archives/87486
captured_at: 2026-01-19T07:27:44.895587
title: "LLMに「意図」を含んだ回答をさせる方法の効果 - AIDB"
publish_date: 2026.01.19
tags: []
conversion_method: restoration_script
is_premium: unknown
---

LLMに回答させる際に「意図」も含めて出力するよう促すことで、数学・質問応答・長文要約などさまざまな能力が大幅に向上することが示唆されました。

さらに、思考プロセスの提示は、回答を見る人の解釈を助けることにもつながります。

人間が難しい問題を任されたときに、過程も提示することからこの試みが発想されたようです。

最先端の推論モデルは思考プロセスを提示するような仕組みになっているものの、回答と整合性がとれない場合もあると報告されています。  
そんな中、出力に思考プロセスを明記させるのは有効なアプローチだと言えるかもしれません。

![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAJAAQMAAAApW4aWAAAAA1BMVEUAAACnej3aAAAAAXRSTlMAQObYZgAAAF5JREFUGBntwQEBAAAAgqD+r3ZIwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHsBIk8AAeBiYYYAAAAASUVORK5CYII=)![](https://ai-
data-base.com/wp-content/uploads/2025/03/AIDB_87486-1-1024x576.png)

**本記事の関連研究**

  * [推論時のトークン数を80%以上削減しながら出力精度を保つプロンプト手法](https://ai-data-base.com/archives/86361)

  * [LLMにおける「計画立案能力」を高めるプロンプト手法](https://ai-data-base.com/archives/82983)

  * [三段論法でLLMの推論能力を高めるプロンプト手法](https://ai-data-base.com/archives/82746)

## 背景

LLMは問題が複雑になると、回答の精度や正確性が下がることがあります。

そこで、段階的な思考を行わせるChain-of-Thought（思考の連鎖）というプロンプト手法がよく使用されています。

しかし、最も効果を出すためにはユーザーが思考のステップをLLMに教示する必要があります。

そこで、Chain-of-Thoughtが自動的に発動するo1などの推論型モデルも好んで使われています。

推論型モデルにおいては思考のステップは自動探索されます。

ただし、そのプロセスがすべて明らかにされるわけではありません。

また、推論型モデルが示す考え方と実際の回答とがずれている場合もあり、ユーザーがその回答を十分に理解・納得できないことがあります。

このような問題は数学、文章読解、要約、常識的な判断など幅広いタスクに共通しています。

そこで「モデルがどのような意図で答えを導き出すのかを明らかにさせるように徹底すれば、回答の品質も、根拠の透明性も向上するだろう」と考えられました。

このような背景を受けて研究者らは、モデル自身が自らの「意図」を明確に文章で示して回答を導き出すことの効果を入念に検証しました。

以下で詳しく紹介します。

プレミアム会員限定コンテンツです

閲覧には、アカウント作成後の決済が必要です。

  * 全記事・論文コンテンツを無制限で閲覧可能
  * 平日毎日更新、専門家による最新リサーチを配信

[まずはアカウントを作成](/membership-join)

[ログイン](/membership-login)

[プレミアム会員について](/premium-visitor)

