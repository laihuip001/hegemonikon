---
created: 2026-01-01T09:29:43 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/58361
author: AIDB Research
---

# ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 - AIDB

> ## Excerpt
> ChatGPTなどのLLMは、自然言語を理解し、人間のように対話する能力を持っており、多くの場面でその能力を発揮しています。しかし、これらのモデルが最大限のパフォーマンスを発揮するためには、適切なプロンプト（指示テキスト）を使用することが不可欠です。 本記事では、ChatGPTをはじめとするLLMの効果的なプロンプト手法に焦点を当てた論文をもとに、「基本のキ」を紹介します。モデルに、より正確かつ効…

---
ChatGPTなどのLLMは、自然言語を理解し、人間のように対話する能力を持っており、多くの場面でその能力を発揮しています。しかし、これらのモデルが最大限のパフォーマンスを発揮するためには、適切なプロンプト（指示テキスト）を使用することが不可欠です。

本記事では、ChatGPTをはじめとするLLMの効果的なプロンプト手法に焦点を当てた論文をもとに、「基本のキ」を紹介します。モデルに、より正確かつ効果的な回答を引き出すための原則と、現時点での主要なプロンプトエンジニアリングの知見を整理しました。

![[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 - AIDB/AIDB_58361-1024x576.jpg]]

**参照論文情報**

・タイトル：Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review  
・著者：Banghao Chen, Zhaofeng Zhang, Nicolas Langrené, Shengxin Zhu  
・所属：BNU-HKBU United International College, Beijing Normal University  
・URL：[https://doi.org/10.48550/arXiv.2310.14735](https://doi.org/10.48550/arXiv.2310.14735)

**本記事の関連研究：**[LLMに非線形的な思考を与えてCoTを上回る性能を引き出す手法『IEP』と実行プロンプト　CoTと組合せでさらに強力になる場合も](https://ai-data-base.com/archives/57628)

## 従来の課題や背景

### “プロンプト”に対する関心の高まり

大規模言語モデル（LLM）の登場は、人工知能技術における一大転換点となりました。膨大なデータセットから学習し、人間との対話を可能とし、多くの応用分野においてその価値を証明しています。

しかし、LLMがポテンシャルを発揮するためには、適切なプロンプトを使用することが重要です。プロンプト技術（エンジニアリング）は、モデルに対する質問や指示の形式を指し、モデルのパフォーマンスを最適化するためのカギとなります。

現在、LLMを最大限に活用するためのプロンプト技術に関する方法論は、まだ完全には体系的に理解されていません。モデルの応答品質を向上させるための具体的な手順や原則が、ユーザー間、研究者間で十分には共有されていないことに起因しています。そのため、効果的なプロンプトの設計は、しばしば試行錯誤に依存する傾向にあります。

![[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 - AIDB/AIDB_58631_5-1024x401.png]]

普通のプロンプトと出力結果の例

### 研究の再調査

この問題に対処するため、ある研究者たちは既存の文献を基に、プロンプト技術に関する原則と手法を再調査しました。この再調査は、原則からベーシックな手法、高度な手法に至るまで、LLMのパフォーマンスを最適化するためのアプローチを包括的に検討することを目的としています。

**本記事の関連研究：**[GPT-4などLLMのコード生成能力にデバッグ機能を追加する『SELF-DEBUGGING（セルフデバッギング）』と実行プロンプト](https://ai-data-base.com/archives/57709)

## 原則

### 1\. 詳細な説明の提供

LLMに対して、詳細な説明を提供することは、その能力を最大限に引き出す上で不可欠です。この観点は、モデルが与えられたタスクを理解し、適切なコンテキスト内で情報を処理するための基盤を築くために重要なポイントです。モデルがより精度高く、目的に沿った回答を生成するのを助けます。

### 2\. 明確かつ正確な指示

明確かつ正確な指示をモデルに与えることで、期待される出力に近づけることができます。この点を徹底すると、モデルは与えられた問題に対して、より関連性の高い回答を生成することが可能になります。逆に指示が不明瞭だと、モデルは誤った方向に進む可能性があり、結果として品質の低い出力を生むことになります。

![[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 - AIDB/AIDB_58631_2-1024x551.png]]

### 3\. 繰り返して最適な回答を選択

LLMは、同じプロンプトに対しても異なる出力を生成することがあります。モデルが持つ複数の解釈や回答の可能性を反映しています。そのため、プロンプトを何度か繰り返し、モデルの応答を繰り返し確認すると、最適な出力を得られる場合もあります。

**本記事の関連研究：**[LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト](https://ai-data-base.com/archives/56671)

## ベーシックな手法

### 1\. ロールプロンプト（Role-prompting）

ロールプロンプトは、モデルに特定の役割を与えることで、その役割に応じた回答の品質を向上させる手法です。例えば、モデルに教師、批評家、または学生の役割を与えることで、それぞれの視点からの回答を引き出すことができます。このアプローチは、モデルが特定のコンテキストや目的に沿ったより適切な回答を生成するのを助けます。

テンプレート：「〇〇として振る舞ってください」

![[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 - AIDB/AIDB_58631_3-1024x268.png]]

参考：Aobo Kong et al., “**Better Zero-Shot Reasoning with Role-Play Prompting**”

**関連記事：**[タスクに応じてロールプレイさせるとChatGPTなどLLMの推論能力は普遍的に向上する](https://ai-data-base.com/archives/54536)

### 2\. トリプルクオートの活用

トリプルクオート（”’または”””）を使用することで、プロンプトを要素ごとに分離し、より複雑な指示を明確にすることができます。この方法は特に複雑なタスクを解決する際に、モデルが各部分を個別の情報として処理しやすくするために有効です。

### 3\. ワンショット/フューショットプロンプト

ワンショットやフューショットプロンプトは、指示の前に一つまたは複数の例を与えることで、モデルが学習済みのタスクを思い出し、新しいタスクに適用するのを助ける手法です。例の数はタスクやモデルの能力に応じて調整され、モデルが過去の学習を活用して新しい問題に取り組むのに役立ちます。

![[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 - AIDB/AIDB_58631_4-1024x630.png]]

**本記事の関連研究：**[GPT-4などのLLMに「自らの論理的な整合性をチェック」させるフレームワーク『LogiCoT』と実行プロンプト](https://ai-data-base.com/archives/55805)

## 高度な手法

以下では、複数の高度な手法を紹介します。下記をケースに応じて使い分けることでLLMの実用性がさらに向上します。

ここから限定コンテンツ

### 1\. チェーン・オブ・ソート（Chain of Thought: CoT）

チェーン・オブ・ソートは、推論プロセスに中間ステップを導入し、問題解決を段階的に行う手法です。このアプローチでは、「ステップバイステップで考えよう」といったプロンプトを用いて、モデルに複数の推論ステップを踏むよう指示します。  
本手法を用いると推論の過程が明確になり、結果の精度が向上します。

なお、特に複雑な問題においては、推論ステップの例を与えるテクニックも有効で、「Golden Chain of Thought」と呼ばれています。

テンプレート：「ステップバイステップで考えてください」

![[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 - AIDB/AIDB_58631_6-1024x719.jpg]]

参考：Jason Wei et al., “**Chain-of-Thought Prompting Elicits Reasoning in Large Language Models**”, 2022/1/28

### 2\. 自己整合（Self-consistency）

自己整合は、チェーン・オブ・ソートをさらに発展させた手法で、複数の推論パスを生成し、それらの一貫性を評価することで、最も信頼性の高い解決策を選択します。そして異なる推論パスが同じ結論に至るかを検証し、一貫性のある回答を導き出すことを目指します。本手法によって、モデルの出力の信頼性が大幅に向上します。

なお、特定の問題に対するいくつかの対処法を模索する際にも有効かもしれません。

テンプレート：  
「上記の問題について異なる推論パスで回答してください」

参考：Xuezhi Wang et al., “**Self-Consistency Improves Chain of Thought Reasoning in Language Models**”

### 3\. 生成知識（Generated knowledge）

生成知識は、モデルが関連するデータや主要な要素を分析し、その情報を基に最終的な質問に答える手法です。特に常識の推論タスクにおいて効果的で、モデルは自身が生成された知識を活用して、より精度の高い回答を提供します。  
このアプローチは、モデルが既存の知識を超えて、新たな情報を組み合わせ、問題に対する深い理解を示すことを可能にします。

テンプレート：「まずは上記の問題についての関連データや主な要素を分析してください」

![[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 - AIDB/AIDB_58631_7-1024x897.jpg]]

参考：Jiacheng Liu et al., “**Generated Knowledge Prompting for Commonsense Reasoning**”, 2021/10/15

### 4\. 最小最大プロンプト（Least-to-most prompting）

最小最大プロンプトは、複雑な問題をより扱いやすい基本的なサブ問題に分解し、それらを順番に解決していく手法です。本アプローチでは、しばしば、各サブ問題の解決策が次のサブ問題の解決に役立つこともあります。連鎖的な解決プロセスが、モデルが全体の問題に対するより良い理解を構築するのに役立ちます。

テンプレート：「まずは上記の問題を複数のサブ問題に分解してください」

![[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 - AIDB/AIDB_58631_8-1024x997.jpg]]

参考：Denny Zhou et al., “**Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**”, 2022/5/21

### 5\. 思考の木（Tree of Thoughts: ToT）

思考の木は、問題解決のためのステップを初めに説明させ、その後、各ステップをさらに詳細に掘り下げる手法です。この手法は、モデルに問題の構造を理解させ、各ステップを通じて意図的な問題解決を促します。本手法により、モデルはより複雑な問題に対しても、体系的かつ効率的なアプローチを取ることができます。

テンプレート：  
「上記の問題を解決するためのステップを教えてください」  
「各ステップから、さらに細かいステップを教えてください」

![[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 - AIDB/AIDB_58631_9-1024x226.png]]

参考：Shunyu Yao et al., “**Tree of Thoughts: Deliberate Problem Solving with Large Language Models**”, 2023/5/17

### 6\. 思考のグラフ（Graph of Thoughts: GoT）

思考のグラフは、基本的な問題を定義し、解決のために必要な要素を列挙させ、それらの要素間の依存関係を明確にする手法です。このプロセスを通じて、モデルは具体的なアクションプランを生成し、体系的な情報から総合的な解決策を導き出します。本手法は、複数の要素が絡み合う問題に対して特に有効で、モデルが全体像を把握しやすくなります。

テンプレート：  
「問題解決のために必要な要素を挙げてください」  
「要素同士の依存関係を説明してください」  
「上記の分析から具体的なアクションプランを生成してください」

**本記事の関連研究：**[LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト](https://ai-data-base.com/archives/55711)

参考：Maciej Besta et al., “**Graph of Thoughts: Solving Elaborate Problems with Large Language Models**“, 2023/8/18

## その他の工夫について

論文では、上記の他に、外部ツールを使用したプロンプトの磨き上げが提案されています。

最近開発された外部のプロンプトエンジニアリング支援ツールは、直接プロンプトを洗練させるのに役立つとのことです。

例えば、OpenAIのプラットフォーム上で提供されるいくつかのプラグインも役に立ちます。プラグインは、モデルがユーザーの要求に対してより精度良く対応するのを助け、詳細なプロンプトを必要とせずに済みます。

例えば、「Prompt Enhancer」や「Prompt Perfect」というプラグインがあり、プロンプトを自動的に強化することができると述べられています。

## まとめ

この記事では、ChatGPT（GPT-4）を活用したプロンプトエンジニアリングの基本から高度な手法までを網羅する論文を紹介しました。

原則から始まり、ベーシックな手法、そして高度な手法を通じて、モデルのパフォーマンスを最適化するための様々なアプローチを確認しました。今回列挙した手法は、モデルがより複雑な問題に対しても、洞察力と精度をもって対応できるようにするためのものです。

ただし、これらの手法を適用する際には、継続的な研究と実践が必要であることに注意してくださいね。

**本記事の関連研究：**[メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」](https://ai-data-base.com/archives/54435)
