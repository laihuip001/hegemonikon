---
created: 2026-01-01T09:37:06 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/64594
author: AIDB Research
---

# GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』 - AIDB

> ## Excerpt
> 言語は常に変化している一方で、LLMは定型的なデータセットに基づいているため、モデルが新しい言葉の意味を知る機会は通常、自動的には発生しません。 そこでカリフォルニア大学などの研究者らは、LLMを継続的に再学習するコストをかけず、新しい言葉の概念をLLMに理解させる方法を考案しました。さらに評価ベンチマーク「SLANG」を導入しています。 現実世界の言葉の変化を捉え、それらを手がかりに新しい表現と…

---
言語は常に変化している一方で、LLMは定型的なデータセットに基づいているため、モデルが新しい言葉の意味を知る機会は通常、自動的には発生しません。

そこでカリフォルニア大学などの研究者らは、LLMを継続的に再学習するコストをかけず、新しい言葉の概念をLLMに理解させる方法を考案しました。さらに評価ベンチマーク「SLANG」を導入しています。

現実世界の言葉の変化を捉え、それらを手がかりに新しい表現とその意味を正確に結びつけます。実験結果から、従来の手法よりも精度と関連性の面で優れていることが示されました。

![[GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』 - AIDB/AIDB_64594-1024x576.jpg]]

**参照論文情報**

-   タイトル：SLANG: New Concept Comprehension of Large Language Models
-   機関：CAS Key Laboratory of AI Security Institute of Computing Technology Chinese Academy of Sciences, University of California Los Angeles, University of Chinese Academy of Sciences
-   著者：Lingrui Mei, Shenghua Liu, Yiwei Wang, Baolong Bi, Xueqi Cheng

**本記事の関連研究**：

-   [LLMの思考の流れに沿ってプロンプトを与えるか否かで30%以上精度が変化する　DeepMindが報告](https://ai-data-base.com/archives/64551)
-   [LLMに敢えて間違わせてルールを覚えさせるプロンプト手法　Google DeepMindなどが考案](https://ai-data-base.com/archives/64057)
-   [GPT-4のコード生成能力を飛躍的に向上させるプロンプトフレームワーク『AlphaCodium』](https://ai-data-base.com/archives/63003)
-   [わずか2行のプロンプトでも実効性のある新しいアライメント手法『URIAL』](https://ai-data-base.com/archives/60678)

## 背景

近年、ウェブの発展の影響もあって言葉の変化が加速し、新たな形で言葉が変化するようになっています。こうした急速な変化は、大規模言語モデル（LLM）が新しい概念を理解する上で大きな課題となっています。通常、LLMは静的なデータで学習しているため、常に変化する言語に適応することは簡単ではありません。

また、LLMは往々にして表面的なパターンに基づいて判断を下し、根拠のある推論ができていません。例えば、Chain-of-Thought (CoT) プロンプティングでは、「The sunset is beautiful, isn’t it? （夕日がきれいですね）」というフレーズを単純に解釈してしまい、複雑な会話の中で「物事の終わり」の象徴など、より深い隠喩的な意味を見逃してしまう可能性があります。

![[GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』 - AIDB/AIDB_64594_1-1-1024x828.jpg]]

既存の知識更新技術としては、パラメータの微調整（ファインチューニング）が一般的です。しかし、計算コストの問題、タスク固有の性能低下といった課題があります。また、データセットの質への依存性も指摘されています。また、外部情報の取得を活用する方法（RAG）では、深い理解よりも事実の検索に重きが置かれています。

そのため、継続的なアップデートや外部データ無しに、LLMが言葉の変化や新しい概念を理解できるようになることが重要です。

そこで研究者らは、言語変化へのLLMの適応力を評価するベンチマーク「SLANG」と、新しい概念理解を促進する因果推論に基づくアプローチ「FOCUS」を提案しています。

## SLANGの方法論

ここから限定コンテンツ

研究者らは、新しく生まれるインターネット上の概念を理解するLLMの能力を評価するベンチマーク「SLANG」を作成しました。

### SLANGの特徴

SLANGは急速に変化する言語に対応して作られています。インターネットスラングやイディオムといった型にはまらない言葉を、LLMがうまく解釈できるかを評価します。

また事実に関するデータと、事実に反するデータの両方を用意している点がユニークです。LLMの適応力を測る上で、この両方のデータは欠かせません。

### SLANGの定義とデータセットの作り方

**問題の定義**

インターネットで使われる流動的な俗語やイディオムは、常に変化するため的確に定義できません。SLANGでは、この言語の流動性を「あるフレーズ W が文脈 X の中で使われた際に、それに対する説明 Y が生まれる確率 P(Y | W, X; M)」として数学的に定義し、LLMの解釈力を評価します。

なお本研究の実験とベンチマークはインターネットミームに焦点を当てていますが、方法論は新しい言葉の習得に対して普遍的に応用できるものです。

**データセットの作り方**

今回研究者らはインターネットスラングを中心としたオンライン辞書 UrbanDictionaryからデータを抽出しました。UrbanDictionaryは最新の言語トレンドを反映しており常に更新されるため、新しいインターネット言語の宝庫です。また、フレーズやその定義、使用例、さらにユーザー評価（upvoteとdownvote）も収集します。

**データのフィルタリング**

まず、データが新しく生まれたものであることを確認します。UrbanDictionaryに載っているフレーズでも、一般的に使われるようになったものはGPTの学習データに含まれている可能性があります（例：ghosting、flex）。 LLMがデータの内容を記憶していないことを確認し、不適切な内容も取り除きました。

**Factual dataset (事実に関するデータセット)**

UrbanDictionaryのデータはややカジュアルなため、まずは辞書のように形式を整えました。説明や例をわかりやすく書き換え、元の意味はそのまま残します。また、類義語を使った説明を4種類追加し、様々な回答に対応できるようにしました。モデルの予測を評価する際には、元の説明と類義語を含めた5つのバージョンと比較して、最も近い結果を選びます。

**Counterfactual dataset (事実と異なるデータセット)**

意味は同じでも言い回しを変えることで、LLMの適応力や理解力を深く評価することができます。そこで元のFactual datasetの意味を残しながら、新しいフレーズを作りました。新しいフレーズは、言葉の言い回しは変えても、言っている内容は同じ意味になるように工夫します。

![[GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』 - AIDB/AIDB_64594_2-1024x549.png]]

データセット内コンテンツにおけるアップボート（左）と絶対アップボート（右）の分布を示す比較ヒストグラム  
アップボード：ポジティブな評価

### 評価指標

従来の指標であるF1スコア、再現率、精度に加え、より厳格な品質チェックのためにBLEU (3-gram)とROUGEを用いました。

言語モデルは、意味は同じでも言い回しを変えて解釈を出力する可能性があるため、句子レベルの類似度やSimCSE (Gao et al., 2021)、句子類似度 (Team, 2023) などの文類似度指標も導入しました。

文類似度は、文をall-mpnet-base-v2モデルに入力し、埋め込みベクトルのコサイン類似度を計算することで算出します。SimCSEスコアが0.7を超える場合、そのサンプルは正解とみなされます。

各データセットのエントリに対して、意味は同じで、単語の言い換えのみを行った5つの解釈を生成しました。最終的な指標として、BLEUスコアが最も高い解釈を選択しました。

新しい言葉の概念を理解するための手法「FOCUS」について説明します。

### 因果分析によるアプローチ

言語の仕組みを「因果関係」のモデルで考えます。

![[GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』 - AIDB/AIDB_64594_3-1-1024x412.png]]

新しいフレーズを解釈するための大規模言語モデルの構造因果モデル

-   X: 文脈
-   W: フレーズ
-   E: 文脈に含まれる他のフレーズ・単語（交絡因子）
-   R: 言語的要因（言語構造、スタイル、テーマ、文化的背景など）
-   Y: 説明
-   矢印: 因果関係を示す

この図では、文脈XとフレーズWがLLMに入力され、説明Yが出力されます。このとき、図中の「交絡因子」である他のフレーズ（E）が邪魔をしている可能性があります。

そこで以下の手順で、LLMが新しいフレーズを正しく理解できるよう導きます。

**（１）交絡因子の特定**

文脈Xの中に含まれる他のフレーズE（交絡因子）の影響を取り除きます。

**（２）言語的要因の分析**

文脈Xには、言語構造、スタイル、テーマ、文化的背景などの要素（R）が含まれます。Xを各要素を考慮して分析します。

### 因果モデルの調整

![[GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』 - AIDB/AIDB_64594_4-1024x472.png]]

**（１）交絡因子の調整**

文脈Xに含まれる他のフレーズE（交絡因子）の影響をさらに取り除くため、EをE˜に、XをX˜に置き換えます。

**（２）フレーズ内の実体のバイアス排除**

フレーズW内の固有の表現に左右されないよう、WをWˆという記号に置き換えます。

### FOCUSの4つのステップ

FOCUSは以下の4つのステップで構成されています（下図）。

![[GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』 - AIDB/AIDB_64594_5-1024x563.jpg]]

**（１）Direct Inquiry (DI)**

文脈XとフレーズWをそのままLLMに入力し、説明YDIを出力させます。フレーズの文法や文脈に沿った自然な意味を調べます。

****（２）**Masked Entity Inquiry (MEI)**

文脈X中のフレーズWをマスク（隠すこと）して、説明YMEAを出力させます。これにより、Wに頼らず、文脈Xからフレーズの意味を類推させることができます。

****（３）**Entity Replacement Inquiry (ERI)**

文脈X中の他のフレーズを一部入れ替えて、説明YERIを出力させます。元の文脈と変更後の文脈で、フレーズの意味がどのように変化するかを調べます。

****（４）**Synthesis (SY)**

DI、MEI、ERIで得られた結果を統合し、最終的な説明YF Sを出力させます。

以上のステップを経て、文脈やフレーズの様々な側面から、LLMがどのように解釈を行っているかを調べます。

## 実験

### 各種設定

**モデル**

実験では、7,220個の（言葉の）概念からなる初期データセットから 408 個のサンプルを抽出し、GPT-3.5とGPT-4に対する評価を行いました。

**ベースライン**

ベースラインとして、直接的なプロンプト、思考の連鎖（CoT）、CauView（二段階の質問形式）とFOCUSアプローチを比較しました。

**評価指標**

F1スコア、再現率、精度、BLEUスコア、ROUGEスコアを用いて、モデルの解釈能力と生成能力を評価しました。

### 結果

**Factual dataset（実際にある言葉）の結果**

![[GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』 - AIDB/AIDB_64594_6-1024x276.png]]

FOCUSは全ての評価指標で最も良い結果になりました。GPT-3.5では、F1スコア0.4292、精度0.4153、再現率0.4524、BLEU、ROUGE、文類似度、SimCSEスコア、そして正解率 84.5%を達成しています。

GPT-4でもFOCUSが最も良い結果で、F1スコアが0.4446、精度0.4280、再現率 0.4714、正解率88.2%を達成しています。

**Counterfactual dataset（仮想の言葉）の結果**

FOCUSはここでも全ての評価指標で最も良い結果になりました。

![[GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』 - AIDB/AIDB_64594_7-1024x264.png]]

GPT-4では、F1スコア0.4532、精度 0.4598、再現率 0.4551、正解率 84.9%を達成しています。

本手法が、文脈を少し変えた言葉（現実にはない言葉）を正しく解釈することにも使えることを示しています。

## まとめ

本記事では、言語の変化に対してLLMが適応する方法を模索する研究を紹介しました。

今回研究者たちは、インターネットスラングやミームの理解度を測る新しい指標「SLANG」を開発しました。SLANGは、UrbanDictionaryなどの辞書やソーシャルメディアデータに基づいて、特定の言葉やフレーズがネット上でどのように使われているかを分析するためのデータセットです。

さらに、因果推論に基づく手法「FOCUS」も提案しました。FOCUSは、LLMが新しい概念をより迅速に理解し、文脈に応じて適切な解釈を導き出すことを可能にするものです。

実験の結果、FOCUSを使用することで、LLMがインターネット言語のトレンドに迅速に適応し、新しいスラングやミームの意味を正確に理解できるようになることが示されました。

ただし、現時点では課題も残されています。FOCUSの性能は、使用されるデータセットの質と多様性に依存しています。今後は広範なデータを用いた実験が必要とされています。

-   参照論文URL：[https://doi.org/10.48550/arXiv.2401.12585](https://doi.org/10.48550/arXiv.2401.12585)
