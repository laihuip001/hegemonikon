---
created: 2026-01-01T09:30:14 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/54690
author: AIDB Research
---

# GPT-4に選択肢を与えるとき、順序を入れ替えるだけで性能に大きな変化があることが明らかに - AIDB

> ## Excerpt
> 今回紹介する研究は、大規模言語モデル（LLM）であるGPT-4が、多肢選択問題（MCQ）において選択肢の順序に敏感であるという事実を明らかにしています。 この研究は、リクルートのAI研究所であるMegagon Labsのグループによって発表されました。研究者たちは、GPT-4とInstructGPTの2種類のモデルを用いて、5つの異なるMCQベンチマークで実験を行いました。その結果、選択肢の順序を…

---
今回紹介する研究は、大規模言語モデル（LLM）であるGPT-4が、多肢選択問題（MCQ）において選択肢の順序に敏感であるという事実を明らかにしています。

この研究は、リクルートのAI研究所であるMegagon Labsのグループによって発表されました。研究者たちは、GPT-4とInstructGPTの2種類のモデルを用いて、5つの異なるMCQベンチマークで実験を行いました。その結果、選択肢の順序を単純に入れ替えるだけで、モデルの性能に13%から75%もの大きな変動が生じることが確認されました。

この記事では、この研究の詳細とその意義、そして今後どのような対策が考えられるのかについて、深く掘り下げていきます。

**参照論文情報**

-   タイトル：Large Language Models Sensitivity to The Order of Options in Multiple-Choice Questions
-   著者：Pouya Pezeshkpour, Estevam Hruschka
-   所属：Megagon Labs（リクルートのAI研究所）
-   URL：[https://doi.org/10.48550/arXiv.2308.11483](https://doi.org/10.48550/arXiv.2308.11483)

**関連研究**

-   [タスクに応じてロールプレイさせるとChatGPTなどLLMの推論能力は普遍的に向上する](https://ai-data-base.com/archives/54536)
-   [メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」](https://ai-data-base.com/archives/54435)
-   [大規模言語モデルのセーフガードを故意に突破する「脱獄プロンプト」とは](https://ai-data-base.com/archives/54468)

## LLMと多肢選択問題

### 大規模言語モデル（LLM）の台頭とその影響

近年、大規模言語モデル（LLM）は自然言語処理（NLP）の分野で多くの注目を集めています。特に、GPT-4やInstructGPTなどのモデルは、質問応答、文章生成、翻訳など、多くのタスクで高い性能を示しています。

LLMは、多肢選択問題（MCQ）においても非常に高い性能を発揮しています。MCQは、教育、医療、ビジネスなど、多くの分野で用いられる形式であり、モデルの「正確な選択肢を選ぶ能力」には非常に価値があります。

### 選択肢の順序に対するバイアス

しかし、これらのモデルが高い性能を示す一方で、選択肢の順序に対するバイアスが存在するという現象が観測されています。

この選択肢の順序に対するバイアスは、実用上非常に重要な問題です。選択肢の順序が変わるだけで正解を導く力が弱まるのであれば、対策が欠かせません。このような現象は、教育、医療、ビジネスなど、多くの分野での応用に影響を与える可能性があります。

### 研究者の取り組みと目的

Megagon Labsの研究者たちは、この性能変動を詳細に評価するために、GPT-4とInstructGPTの2種類のモデルを対象とし、5つの異なるMCQベンチマークを用いて実験を行いました。この研究の目的は、選択肢の順序による性能変動のメカニズムを理解し、その対策を考えることです。

![[GPT-4に選択肢を与えるとき、順序を入れ替えるだけで性能に大きな変化があることが明らかに - AIDB/AIDB_54690_1-1024x555.png]]

GPT-4が選択肢の順序に影響を受けてしまうことを例示する図

## 実験の詳細

### 実験の対象：GPT-4とInstructGPT

この研究では、GPT-4とInstructGPTの2種類の大規模言語モデルが実験の対象とされました。GPT-4は、OpenAIによって開発された大規模なトランスフォーマーモデルであり、多くのNLPタスクで高い性能を示しています。一方、InstructGPTは、指示に基づいたタスクを解決する能力に特化したモデルです。

GPT-4とInstructGPTは、多肢選択問題（MCQ）において高い性能を示すことが知られています。しかし、それぞれのモデルが選択肢の順序にどれだけ敏感であるのかを比較することで、この問題に対する一般的な理解を深めることができます。

### 使用されたベンチマーク：5つの異なるMCQベンチマーク

研究者たちは、5つの異なるMCQベンチマークを用いて実験を行いました。複数のベンチマークを使用することで、選択肢の順序に対するバイアスが一般的な現象なのか、特定のベンチマークに依存するものなのかを評価することができます。

選ばれたベンチマークは、教育、医療、ビジネスなど、多様な分野での応用が考えられるものです。研究の結果が多くの分野での応用に直結する可能性を高めるために工夫がされた形です。

### 選択肢の順序変更に伴う正解率の変化

この実験の主なポイントは、選択肢の順序を変更することで、モデルの正解率にどれだけの影響が出るのかを計測したことです。

研究者たちは、各モデルが選択肢の順序が変更された場合と変更されない場合で、どれだけの性能変動があるのかを詳細に計測しました。

## 実験結果

### 選択肢の順序と性能変動

ここから限定コンテンツ

この研究の最も衝撃的な結果は、選択肢の順序が変更されることで、モデルの性能に13%から75%もの大きな変動が生じたという点です。

この数字は非常に重要です。なぜなら、これは単なる数値以上の意味を持っているからです。例えば、医療診断や教育評価などでこのような大きな変動が生じた場合、その影響は計り知れません。

### 性能変動の範囲

また、性能変動範囲は13%から75%と非常に幅広いです。これは、選択肢の順序によってモデルの性能が大きく変わる可能性があるということを示しています。

## この問題についての考察

研究者たちは、特定の選択肢の配置が性能に与える影響も詳細に調査しました。これにより、どのようなケースで性能変動が大きくなるのか、その傾向と対策が明らかになりました。

### 選択肢の順序に対する敏感性の根底にある要因

この研究では、大規模言語モデル（LLM）が選択肢の順序に対して敏感であることが明らかにされました。この敏感性の根底にある要因を特定することが、研究者たちの一つの目的でした。

研究者たちは、デモンストレーション（例示）を用いた場合でも、この敏感性は僅かしか減少しないことを指摘しています。これは、モデルが選択肢の順序に対する敏感性を完全に克服するためには、単にデモンストレーションを追加するだけでは不十分であることを示しています。

![[GPT-4に選択肢を与えるとき、順序を入れ替えるだけで性能に大きな変化があることが明らかに - AIDB/AIDB_54690_2-1024x555.png]]

Few-Shot設定における選択肢順序の影響

### モデルのロバスト性向上のための提案

研究者たちは、この敏感性を減らすためのいくつかの解決策を提案しています。具体的には、多数決（majority vote）や多重証拠調整（MEC: multiple evidence calibration）といった手法が挙げられています。

しかし、これらの手法も完璧ではありません。多数決は計算コストが高く、MECは多数決から大きく逸脱する可能性があるとされています。現状では、多肢選択問題におけるLLMの評価フレームワークを確立するためには、より効率的な調整戦略の開発が必要であると結論づけられています。

### 今後の研究方向

この研究は、選択肢の順序に対する敏感性が、モデルの推論と評価設定の信頼性に重大な課題をもたらす可能性があると指摘しています。この問題に対する更なる深い調査が必要であるとされています。

## 今後の対策案

### 選択肢の順序をランダム化

研究者たちは、選択肢の順序によるバイアスを減らす一つの方法として、選択肢の順序をランダム化することを提案しています。これにより、モデルが特定の選択肢にバイアスを持つ可能性が低くなります。

ランダム化は簡単に実装できる利点がありますが、一方で、全ての選択肢が平等に評価されるわけではないという課題も存在します。例えば、選択肢がランダムに並べられた場合でも、モデルが最初に見た選択肢に影響を受ける可能性があります。

### モデルの出力を複数回サンプリング

もう一つの対策として、モデルの出力を複数回サンプリングして平均を取る方法があります。これにより、一回の出力に偏りがあった場合でも、その影響を減らすことができます。

この方法は、モデルの出力が一定でない場合に特に有効です。しかし、複数回のサンプリングには計算コストがかかるため、リアルタイムでの応用が難しい場合もあります。

## まとめ

この研究は、大規模言語モデルが多肢選択問題において選択肢の順序に敏感であるという重要な発見を提供しています。この敏感性は、教育、医療、ビジネスなど、多くの分野での応用に影響を与える可能性があります。

選択肢の順序によるバイアスは、モデルの公平性や信頼性に疑問を投げかけます。この研究によって、その問題点が明らかにされ、今後の研究や応用に生かされるでしょう。

研究者たちは、選択肢の順序をランダム化することや、モデルの出力を複数回サンプリングすることなど、いくつかの対策を提案しています。しかし、これらの対策も完全な解決策ではなく、今後の研究が待たれます。

また、この現象は、「複数の選択肢がある”正解のない問題”」を大規模言語モデルにサポートしてもらう際にも考慮すべきです。特に、モデルが社会的、倫理的な判断を下す場合、この研究の結果は非常に重要な意味を持ちます。

![[GPT-4に選択肢を与えるとき、順序を入れ替えるだけで性能に大きな変化があることが明らかに - AIDB/AIDB_54690_3.png]]

GPT-4とInstructGPTにおける、敏感さ（選択肢の順序に受ける影響の度合い）とエラー率の相関性
