---
created: 2026-01-01T09:37:29 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/63003
author: AIDB Research
---

# GPT-4のコード生成能力を飛躍的に向上させるプロンプトフレームワーク『AlphaCodium』 - AIDB

> ## Excerpt
> 研究者らは、LLM（大規模言語モデル）を使ってより良いコードを生成するための「AlphaCodium」という新しい方法を提案しています。 実験によると、AlphaCodiumを使うと、コード生成の精度が顕著に向上するとのことです。たとえば、GPT-4が生成するコードの正確さが19%から44%まで向上するケースもありました。 参照論文情報 本記事の関連研究： 研究背景 最近ではLLMの台頭により「コ…

---
研究者らは、LLM（大規模言語モデル）を使ってより良いコードを生成するための「AlphaCodium」という新しい方法を提案しています。

実験によると、AlphaCodiumを使うと、コード生成の精度が顕著に向上するとのことです。たとえば、GPT-4が生成するコードの正確さが19%から44%まで向上するケースもありました。

![[GPT-4のコード生成能力を飛躍的に向上させるプロンプトフレームワーク『AlphaCodium』 - AIDB/AIDB_63003-1024x576.jpg]]

**参照論文情報**

-   タイトル：Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering
-   著者：Tal Ridnik, Dedy Kredo, Itamar Friedman
-   所属：CodiumAI
-   URL：[https://doi.org/10.48550/arXiv.2401.08500](https://doi.org/10.48550/arXiv.2401.08500)
-   GitHub：[https://github.com/Codium-ai/AlphaCodium](https://github.com/Codium-ai/AlphaCodium)

**本記事の関連研究**：

-   [Geminiの高い推論能力を活かして、過去最高水準のプログラミングAI『AlphaCode 2』も誕生したとの報告](https://ai-data-base.com/archives/60201)
-   [GPT-4などLLMのコード生成能力にデバッグ機能を追加する『SELF-DEBUGGING（セルフデバッギング）』と実行プロンプト](https://ai-data-base.com/archives/57709)
-   [LLMがソフトウェアエンジニアリングでどのように適用可能か、網羅的な調査＆分析結果](https://ai-data-base.com/archives/57065)
-   [多様な役割のAIエージェント達に協力してソフトウェアを開発してもらう『ChatDev』登場。論文内容＆使い方を解説](https://ai-data-base.com/archives/54863)

## 研究背景

最近ではLLMの台頭により「コード生成」に注目が集まっています。コード生成とは、プログラム（コンピュータに指示を出す言語）を自動で作ることです。

LLMによるコード生成のレベルを上げるためには、標準的なプロンプトテクニックは（例えばCoTなども）十分でないと考えられています。

プログラムは、英語や日本語のように「ちょっとした間違い」が許されず、「普通にうまくいく場合」や「ちょっと変わったケース」を見分けなければいけません。また、仕様（プログラムがどう動くべきかのルール）の細かい部分にも気を付ける必要があります。

そこで研究者らは、コード生成の性能を向上させることに特化したプロンプト手法「AlphaCodium」を考案しました。コードを生成するための段階的な流れや手順を作ってLLMを導くアプローチです。

下記は方法論、実験結果などを紹介します。

ここから限定コンテンツ

### 基本

生成されたコードを繰り返し実行して、既知の例に対して検証するのがAlphaCodiumの基本とされます。コードを生成してから、入出力テストに対して繰り返し実行し、修正していきます。

### フロー

![[GPT-4のコード生成能力を飛躍的に向上させるプロンプトフレームワーク『AlphaCodium』 - AIDB/AIDB_63003_1-1024x877.png]]

AlphaCodiumの手法でコードを生成する際にはステップがあります。大きく分けると以下の2段階です。

1.  **事前処理フェーズ**：問題について理解しやすくするために自然言語で考えます。
2.  **コード反復フェーズ**：コードを生成し、実行し、特定のテストに対して反復的に修正します。

より詳細なステップを見てみましょう。以下の10段階に分けられます。

1.  問題を要点で説明する。
    -   目標、入力、出力、ルール、制約、その他の問題記述に現れる関連する詳細について触れる。
2.  なぜ各テスト入力がその出力につながるのかを説明する。
3.  問題に対する2〜3の可能な解決策を自然言語でリストアップする。
4.  確さ、簡潔さ、堅牢性の点で「最適な解決策」を選ぶ。
    -   必ずしも「最も効率的な」解決策を取るわけではない。
5.  問題に対して6〜8の多様な入出力テストを追加で生成する。
    -   元の公開テストにカバーされていないケースや側面をカバーしようとする。
6.  潜在的な解決策を選び、対応するコードを生成して、選択した公開テストとAIテストで実行する。
7.  テストに合格するまで、または試行回数の限界に達するまでこのプロセスを繰り返す。
8.  テストに合格した最初のコード、または最も近い出力を持つコードが、次のステップのためのベースコードとして使われる。
9.  ベースコードを出発点として、公開テストで反復的に実行する。
    -   特定のテストでコードが失敗した場合は、エラーメッセージを考慮して修正を試みる。
10.  AI生成テストで「実行-修正」の反復を続ける。

![[GPT-4のコード生成能力を飛躍的に向上させるプロンプトフレームワーク『AlphaCodium』 - AIDB/AIDB_63003_2-1024x724.png]]

## 実験結果

主な実験結果は以下のとおりです。

### 性能検証に使用するデータセット

今回考案されたプロンプト手法「AlphaCodium」の性能は、競技プログラミングで最も力を発揮すると考えられています。そのため、研究者らは本手法の性能を検証する際に競技プログラミング問題データセット「CodeContests」を使用しました。LLMの能力がどれだけ柔軟で効果的かを確かめるのに十分の網羅性があると考えました。

### 普通のプロンプトとの比較

研究者らはAlphaCodiumの結果を、単一のよく設計された普通のプロンプトで得られた結果と比較しました。性能の測定には「pass@k」という基準を使用しました。問題ごとに生成されたk個の解決策を使って解決された問題の割合を意味します。

結果、AlphaCodiumフローは、CodeContestsの問題に対するLLMの性能を一貫してかつ大幅に改善しています。オープンソース（DeepSeek）とクローズソース（GPT）モデルの両方、検証セットとテストセットの両方で当てはまり、例えば、GPT-4の検証セットでは、pass@5のスコアが19％から44％に改善しています。

![[GPT-4のコード生成能力を飛躍的に向上させるプロンプトフレームワーク『AlphaCodium』 - AIDB/AIDB_63003_3.png]]

なおAlphaCodiumフローでは、解答ごとに約15-20回のLLM呼び出しを行っています。つまり、pass@5（5つから選ばれた解答）には、合計約100回のLLM呼び出しが含まれています。

それに対して、AlphaCode（Googleが開発した競技プログラミングツール）は仮に1回の実行につき1回の呼び出しだとすると（実際はもっとあるかもしれない）、pass@10@100K（10の提出、10万の生成された解決策から選ばれたもの）では、100万回のLLM呼び出しが必要になります。これはAlphaCodiumよりも4桁多いことになります。

![[GPT-4のコード生成能力を飛躍的に向上させるプロンプトフレームワーク『AlphaCodium』 - AIDB/AIDB_63003_4.png]]

なお、最近、AlphaCode2という新しい研究も発表されました。Gemini-Proモデルがコードプログラミングの問題に特化して微調整され、評価されたものです。AlphaCode2は、100万のサンプルでAlphaCodeと同じレベルの性能を達成するために、約100サンプルが必要だと報告されています。これはAlphaCodeよりも10000倍以上効率的です。これは驚異的ですが、本手法AlphaCodiumは一般目的のモデルをそのまま使っており、追加データや高価な訓練フェーズなしにその性能を向上させている点が魅力となります。

**関連研究**：[Geminiの高い推論能力を活かして、過去最高水準のプログラミングAI『AlphaCode 2』も誕生したとの報告](https://ai-data-base.com/archives/60201)

## まとめ

本記事では、LLMに対してコード生成のためのフローを導入する手法AlphaCodiumについての論文を紹介しました。

AlphaCodiumは、コードを反復的に生成し、入出力テストに対して実行して修正するプロセスが基本となります。主に二つのフェーズ、事前処理フェーズとコード反復フェーズに分かれており、公開テストとAI生成テストを用いて効果的なコードを作成する仕組みになっています。

実験では、このフローがCodeContestsというデータセットでテストされ、クローズドソースおよびオープンソースの両方のモデルにおいて一貫して大幅な性能向上を実現しました。他の方法よりも優れた結果を示し、計算予算も少ないことが示唆されています。

LLMはコード生成に強いことは以前から示されていますが、プロンプトの工夫でさらにレベルが上がるという心強い研究結果ですね。

Copyright © Parks, Inc. All rights reserved.
