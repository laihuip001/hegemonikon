---
created: 2026-01-01T09:37:16 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/62111
author: AIDB Research
---

# Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB

> ## Excerpt
> Googleなどの研究者により、表形式（.csvなど）のデータを通してLLMが「連鎖的な推論」を行うためのフレームワークが考案されました。ユーザーがプロンプトによってLLMに表データを段階的に更新させ、表データの正しい理解に基づいた回答を引き出します。 複数のベンチマークで最高スコアを達成したと報告されています。 本記事では手法の概要や実験結果などを紹介します。 本記事の関連研究：LLMのRAG（…

---
Googleなどの研究者により、表形式（.csvなど）のデータを通してLLMが「連鎖的な推論」を行うためのフレームワークが考案されました。ユーザーがプロンプトによってLLMに表データを段階的に更新させ、表データの正しい理解に基づいた回答を引き出します。

複数のベンチマークで最高スコアを達成したと報告されています。

本記事では手法の概要や実験結果などを紹介します。

**本記事の関連研究：**[LLMのRAG（外部知識検索による強化）をまとめた調査報告](https://ai-data-base.com/archives/61367)

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111-1024x576.jpg]]

**参照論文情報**

-   タイトル：Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding
-   著者：Zilong Wang, Hao Zhang, Chun-Liang Li, Julian Martin Eisenschlos, Vincent Perot, Zifeng Wang, Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu Lee, Tomas Pfister
-   所属：University of California San Diego, Google Cloud AI Research, Google Research
-   URL：[https://doi.org/10.48550/arXiv.2401.04398](https://doi.org/10.48550/arXiv.2401.04398)

## 背景

多くの日常的な仕事で表データを使用する場面は多く、作業の効率化は常に求められています。表データに関わる作業の中で、事実検証などはこれまでの一般的な技術ではできないと考えられてきました。そんな中、言語モデルの性能が著しく進化したことで、表データの処理もさらに発展することが期待されるようになっています。

LLMに表データを深く理解させるアプローチは2通りあります。  
一つは表データを理解できるように特化したトレーニングを行う方法です。たとえば、先行研究ではSQLクエリと応答のペアに関するデータでの事前学習などが試されています。

**関連記事：**[LLMベースの新しい言語『SUQL』が示唆する「非構造化データのクエリ」を処理するパラダイム](https://ai-data-base.com/archives/59144)

もう一つは、プロンプトエンジニアリングを工夫し、基盤モデルの能力を引き出して表データをうまく扱わせる方法です。これまでに提案されてきた有力なプロンプトエンジニアリング手法としては、CoT（Chain of Thought）や最小最大プロンプト、Tree of Thoughtなどが挙げられます（※こちらの記事で詳しく取り上げています：[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介](https://ai-data-base.com/archives/58361)）。しかし、表データを介した複雑な推論を行うことは既存のプロンプトエンジニアリング手法では実現されていないといいます。

そこで研究者らは、表データの操作を通してLLMにステップバイステップの推論を行わせデータに対する深い理解を促すChain of Tableを考案しました。手法の詳細は後述しますが、コンセプトの核心はCoTと類似しています。Chain of Tableでは、表データの編集を繰り返す中で思考の連鎖が紡がれていくといいます。

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111_1-1024x764.jpg]]

上の図は、本論文で提案される手法によってLLMが複雑な表を正しく解釈し、正確な答えを得るまでの流れを示しています。

**本記事の関連研究：**[LLMの情報抽出（文章から必要な事柄を読み取る）タスクについての網羅的な調査結果](https://ai-data-base.com/archives/61703)

### 全体の流れ

Chain of Tableにおいて、

ここから限定コンテンツ

問題解決における大事な要素は次の三つで定義されています。

-   T：表データ
-   Q：関連する質問や指示
-   A：期待される答え

通常のQAタスクに対して、情報源となる表データTが加わった形です。  
質問Qと表データTをもとに答えAを予想するのがタスクになります。

なお、LLMは質問Qに対応して表データTを連鎖的に操作します。操作のアクション例は以下になります。

-   列の追加
-   行や列の選択
-   グループ化
-   並べ替え　など

なお、本フレームワークは操作内容を中心に拡張可能だと述べられています。

Chain of Tableをアルゴリズムで表現すると以下のようになります。

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111_2-1024x970.jpg]]

fは操作を示し、LLMが質問Qに対応して表データTに行う操作を意味します。

クエリをもとにLLMが表Tを変換していき、その操作fを追跡したものがchainで定義されています。終了タグが生成された時点でプロセスは終了し、最新の表がLLMにフィードされ、答えが導かれるという流れです。

一連の操作が、LLMが表データを理解し、最終的な答えを正しく導くためのステップとして機能します。

**本記事の関連研究：**[「入力プロンプト」を最新情報で自動アップデート＆最適化する手法『FRESHPROMPT』がLLMの出力精度を飛躍的に上げる](https://ai-data-base.com/archives/58986)

### Dynamic Planと引数生成

このChain of Tableフレームワークのプロセスの一環として、表に対する連鎖的な操作を動的に計画するコンポーネントがDynamic Planと引数生成（GenerateArgs）です。

下の図で示されるように、Dynamic Planと引数生成は、それぞれ大きく3つの要素から成り立っています。

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111_3-1024x506.jpg]]

Dynamic Plan：

（１）最新の表データT  
（２）操作の履歴chain  
（３）そして質問Q

引数生成：

（１）最新の表データT  
（２）操作fとその引数args  
（３）そして質問Q

この2つのコンポーネントを通して、LLMが操作を動的に計画し、表データから連鎖的な推論を行なっていきます

#### プロンプトテンプレート

下記に具体的なプロンプトテンプレートと例が示されています。最新の中間表Tとそれに対応する質問Q、および表に対して行われた操作のリストであるchainを利用して、LLMに現在のサンプルに対する操作連鎖の残りを生成させる方法を示しています。

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111_4-1024x548.jpg]]

プロンプトの構成は以下になります。

1.  **原子操作**：操作指示、直列化された表、質問、操作とその引数、操作に対する導入の説明。
2.  **操作連鎖**：操作連鎖指示、直列化された表、質問、操作の連鎖。
3.  **入力サンプル**：最新の直列化された表T、質問Q、次の操作の候補、不完全な操作連鎖chain、残りの操作連鎖の生成。

新しく生成された操作は以前の操作を基に生成されるため信頼性が高くなり、LLMの推論が連鎖的に進むことになります。

以下はプロンプトの使用例です。行や列の選択、グループ化、ソートなどを行う中で、LLMは表データをステップバイステップで解析し、最終的に質問に対する正確な答えを導き出すことに成功しています。

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111_5-776x1024.jpg]]

下の図は、Chain of Tableを用いた表推論のプロセスを視覚的に示しています。複数の操作（列の選択、グループ化、ソート）を経て、答えを導き出しています。

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111_E5-1024x354.jpg]]

**本記事の関連研究：**[LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』](https://ai-data-base.com/archives/57018)

## 実験結果

### 他の手法との比較

研究者らはPaLM-2、GPT-3.5、LLaMA2といった複数のモデルを用いて、Chain of Tableを含む異なる推論手法の影響を測定しました。

評価には以下のベンチマークが使用されています。

-   WikiTQ：Wikipediaから収集されたHTMLテーブル上で質問応答（QA）を行うためのデータセット
-   TabFact：表データに関するテキストの真偽を判定するためのデータセット

結果、Chain of Tableの手法が、両方のデータセットにおいて最良の結果を達成していることがわかります。

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111_E1-1024x408.png]]

### 表のサイズ別での比較

異なるサイズの表に対する手法のパフォーマンスを比較した結果もまとめられています。

結果、Chain of Tableは、小〜大すべての規模の表に対して優位性を見せました。

小規模の表において5.63%ポイント、中規模の表において9.91%ポイント、大規模の表において10.25%ポイントの改善を見せています。

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111_E2-1024x290.png]]

### 操作数とサンプル数

WikiTQとTabFactのデータセットにおいて、Chain of Tableを用いて最終的な出力を生成するのに必要な操作連鎖の長さとそのサンプル数が測定されました。

多くのサンプルが最終的な結果を出力するために2〜4回の操作で完了しています。パフォーマンスの観点から優良な結果だと言えます。

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111_E3-1024x568.png]]

### 正確性

異なる長さの操作連鎖を必要とする質問における各手法の正確性（パーセンテージ）も測定されました。

結果、Chain of Tableが各操作連鎖の長さにおいて他の手法よりも一貫して高い正確性を示しました。なお操作連鎖の長さが2のときのパフォーマンスが突出しています。

![[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』 - AIDB/AIDB_62111_E4-854x1024.png]]

## まとめ

本記事では表データを通して連鎖的推論を行う手法Chain of Tableについて紹介しました。

Chain of Tableは、言い換えれば中間思考を表の構造を使って表現することで、言語モデルの推論能力を向上させるアプローチです。入力された表とそれに関連する質問に応じて、LLMに操作の連鎖を動的に計画させ、一連のプロセスを通して表をより理解させることができると考えられています。

実験でも優れた数値が出ており、プロンプティング手法の側面からも興味深い研究成果です。
