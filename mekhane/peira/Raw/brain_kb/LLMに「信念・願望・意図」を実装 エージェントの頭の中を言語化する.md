---
created: 2026-01-01T11:16:14 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/98345
author: AIDB Research
---

# LLMに「信念・願望・意図」を実装 エージェントの頭の中を言語化する - AIDB

> ## Excerpt
> 本記事では、LLMに心の動きのようなものを定義し、思考プロセスを透明化するための手法を紹介します。 LLMは、時として論理的な矛盾を抱えたり、なぜその答えに至ったのかが不透明だったりすることがあります。そこで今回の手法は、LLMの「頭の中」を整理された知識（オントロジー）として記述することで、こうした課題を解決しようとしています。 本記事の関連研究 背景 業務でLLMを使っていると、「答えはそれっ…

---
本記事では、LLMに心の動きのようなものを定義し、思考プロセスを透明化するための手法を紹介します。

LLMは、時として論理的な矛盾を抱えたり、なぜその答えに至ったのかが不透明だったりすることがあります。そこで今回の手法は、LLMの「頭の中」を整理された知識（オントロジー）として記述することで、こうした課題を解決しようとしています。

![[LLMに「信念・願望・意図」を実装 エージェントの頭の中を言語化する - AIDB/AIDB_98345-1024x576.png]]

**本記事の関連研究**

-   [キャラクターなりきりLLM対話を実現するための設計とステップ　微調整は使わない](https://ai-data-base.com/archives/92995)
-   [個人の深い価値観にもとづく「その人らしい答え」をAIで再現する手法](https://ai-data-base.com/archives/90734)
-   [プロンプトによるLLM応答のパーソナライゼーション　仮説を活用して文体を調整](https://ai-data-base.com/archives/89384)

## 背景

業務でLLMを使っていると、「答えはそれっぽいけれど、なぜそう判断したのか理由がわからない」「論理的な一貫性がなく、たまに嘘をつく」といった不安を感じることはありませんか。これは、今のLLMが抱える「ブラックボックス問題」と呼ばれる大きな課題です。

この問題を解決するために、今、世界中の研究者が注目しているのが「ニューロシンボリックAI」というアプローチです。少し専門的な言葉ですが、要するに、今のAIが得意とする「確率的な推論」と、昔ながらのコンピュータが得意とする「厳密な論理ルール」をいいとこ取りしようという試みです。確率でふわっと考えるだけでなく、ルールに従って論理的に考える仕組みを合体させれば、AIはもっと信頼できるパートナーになるはずです。

もしLLMが「今の私の信念はこうで、願望はこれだから、この回答を生成する意図を持ちました」と説明できれば、AIの思考プロセスは透明になります。

そこで今回着目されたのが、「BDI」という考え方です。これは「信念」「願望」「意図」の頭文字を取ったもので、人間やAIエージェントがどうやって合理的に行動するかをモデル化したものです。たとえば、「外は雨だという『信念』」と「濡れたくないという『願望』」があるから、「傘を持っていくという『意図』」が生まれる、といった具合に、行動の理由を分解して整理するフレームワークです。

下記では、このフレームワークを活用してLLMは自分の「頭の中」にある信念や意図を、あやふやな言葉ではなく、システムが理解できる構造化されたデータとして整理するための具体的な手法を紹介します。

ここから限定コンテンツ

### **忙しい人向けに、重要なポイント5選**

1.  AIの「信念・願望・意図」を定義する、Web標準に準拠したオントロジー（構造化された辞書）が開発された
2.  このモデルを使えば、AIの意思決定プロセスを可視化し、行動の理由を論理的に説明できるようになる
3.  LLMと組み合わせる実験では、単独のモデルよりも論理的な矛盾を正確に検知できることが実証された
4.  外部データとAIの思考状態を自動で変換する仕組みにより、既存の知識グラフとスムーズに連携可能
5.  確率的な生成AIと厳密な論理推論を融合させる「ニューロシンボリックAI」の実用化を加速させる技術

**参照文献情報**

-   タイトル：The Belief-Desire-Intention Ontology for modelling mental reality and agency
-   URL：[https://doi.org/10.48550/arXiv.2511.17162](https://doi.org/10.48550/arXiv.2511.17162)
-   著者：Sara Zuppiroli, Carmelo Fabio Longo, Anna Sofia Lippolis, Rocco Paolillo, Lorenzo Giammei, Miguel Ceriani, Francesco Poggi, Antonio Zinilli, Andrea Giovanni Nuzzolese
-   所属：CNR – Institute of Cognitive Sciences and Technologies, CNR – Institute for Research on Population and Social Policies, CNR – Research Institute on Sustainable Economic Growth, University of Bologna

## AIにおける主体性の正体

なぜAIに信念や意図といった人間のような概念を持たせる必要があるのでしょうか。この問いに答えるには、少し時計の針を戻して、1980年代の哲学まで遡る必要があります。

当時、哲学者のマイケル・ブラットマンは、人間がどのように計画を立てて行動するのかを説明するために「BDI理論」を提唱しました。彼の考えでは、単に何かをしたいという願望や、こうだと思っている信念があるだけでは不十分で、そこから具体的な行動を引き起こすには、将来へのコミットメントである意図が不可欠だと論じました。

この哲学的なモデルは、やがてAI研究者たちの目に留まります。コンピュータシステムにおいても、変化し続ける状況の中で自律的に判断して動くプログラム、つまりエージェントを作るための設計図として、BDIモデルが非常に相性が良かったのです。

その後、工場での自動化システムやIoTなどが普及するにつれて、異なるメーカーや異なる仕組みのAIエージェント同士が協力する必要が出てきました。しかし初期の頃は各社がバラバラの仕様で作っていたため、お互いに連携が取れないという問題が発生しました。そこでFIPAという国際的な団体が作られ、エージェント同士が会話するための標準ルールを決めようとする動きも出てきましたが、これはあくまで通信手順の標準化などが中心でした。

### なぜ今まで共通語が作れなかったのか

もちろん、これまでもAIエージェントの開発にオントロジー、すなわち言葉の定義集を使おうとする試みは数多くありました。システムを作る際、あらかじめ用語や概念を整理しておけば、開発がスムーズになるからです。しかし、従来のBDIに関するオントロジーには、ある大きな弱点がありました。

-   特定のプログラミング言語や開発フレームワークに依存して作られていたため汎用性に欠ける
-   あるシステム専用の方言のような状態であり、他のシステムではその定義をそのまま使えない
-   開発の設計図としては機能しても、実際に動くAIの脳内データとして共有できる形にはなっていなかった

たとえば、あるシステムでは信念をデータベースの中身として定義し、別のシステムでは論理式として定義しているような状況です。これでは、異なるシステム間や、ましてや現代のWeb全体やLLMのような汎用的な環境で、スムーズに心の中身を共有することは不可能です。

既存の研究の多くは、特定のツールの機能を拡張するためのものであり、誰でも自由に使える汎用的な部品としてのBDIモデルではありませんでした。

そこで今回研究者らが目指したのは、特定のツールや言語に縛られない、完全に独立したBDIオントロジーを設計することでした。これはシステム開発者がレゴブロックのように必要な概念を組み合わせて使えるデザインパターンとして提供されるため、従来のしがらみにとらわれず、あらゆるAIシステムに心の実装を可能にするものだと考えられています。

LLMに賢い判断をさせるには、「何を信じ、何を望み、どう動こうとしているのか」という頭の中身を明確にする必要があります。今回提案されているBDIオントロジーは、まさにその思考プロセスを記述するための「共通言語」です。

「信念は現実の世界状態を参照する」「欲求は信念によって生まれる」といった思考のルールを、コンピュータが理解できる形で書き下したものが今回のオントロジーです。

BDIは「信念（Belief）」「願望（Desire）」「意図（Intention）」の頭文字で、前述したように、もともとは人間の行動原理を説明する哲学用語でした。本研究チームは、この概念をWeb標準の技術で扱えるように再設計し、誰でも使える「思考のひな形（デザインパターン）」として公開しました。

### オントロジーの要件定義

オントロジーを設計する際、指針がぶれないように「このシステムは、どのような質問に答えられなければならないか」を最初に定義します。これを「コンピテンシー・クエスチョン（CQ）」と呼びます。研究チームは、文献調査や専門家へのヒアリングを行い、AIエージェントに求められる18個の問いを定義し、以下の4つのカテゴリに整理しました。

実践上の使い方としては、下記の質問をLLMエージェントに与えて適切に答えられるのかを見ていきます。

#### カテゴリ1　世界、エージェント、心的実体

まず、エージェントが「今、どんな信念や欲求を持っているか」という基本的な状態を問うカテゴリです。

```
CQ1 What are mental entities?
CQ2 What mental states (i.e. befiefs, desires, and intentions) does an agent hold?
CQ3 What are the constituent mental entities that form part of a given mental entity?
CQ4 What mental processes has an agent undergone?
CQ5 What is the world state that a given mental state is about?
```

和訳

-   心的実体（心の構成要素）は何か？
-   エージェントはどのような心的状態（すなわち、信念、欲求、および意図）を保持しているか？
-   与えられた心的実体の一部を形成する構成要素としての心的実体は何か？（つまり枝分かれ）
-   エージェントはどのような心的プロセスを経てきたか？
-   与えられた心的状態が対象としている世界の状態は何か？

#### カテゴリ2　心的状態の動態

心の移り変わりや因果関係を問うカテゴリです。「その欲求は、どの信念から生まれたのか」「その意図は、どの欲求を満たすためのものか」といったつながりを管理します。

```
CQ6 What beliefs motivated the formation of a given desire?
CQ7 Which desire does a particular intention fulfil?
CQ8 Which mental process generated a given belief, desire, or intention?
CQ9 When was a mental entity generated?
CQ10 What triggered a mental process?
CQ11 What justifications support a specific mental entity?
```

和訳

-   欲求は、どのような信念によって生じたのか。
-   意図は、どの欲求を満たそうとしているのか。
-   信念・欲求・意図は、どのような心的プロセスによって生成されたのか。
-   心的実体は、いつ生成されたのか。
-   心的プロセスは、何によって引き起こされたのか。
-   特定の心的実体を支えている根拠や正当化理由は何か。

#### カテゴリ3　目標と計画

意図を具体的な行動に移す段階を問うカテゴリです。「その計画はどの目標のためか」「具体的な手順は何か」を扱います。

```
CQ12 What goal does a given intention or plan aim to fulfil?
CQ13 What plan has been specified by a particular intention?
CQ14 What planning process led to the creation of a particular plan?
CQ15 What is the ordered sequence of tasks that compose a given plan?
```

和訳

-   意図または計画は、どの目標を達成しようとしているのか。
-   意図によって、どのような計画が定められているのか。
-   計画は、どのような計画プロセスによって作られたのか。
-   計画を構成している作業（タスク）の順序はどうなっているのか。

#### カテゴリ4　時間的推論

「いつ」に焦点を当てたカテゴリです。「その信念はいつからいつまで有効だったか」など、時間の経過に伴う変化を扱います。

```
CQ16 What is the temporal validity (start and end time) of a mental state?
CQ17 What mental states were valid at a specific point in time?
CQ18 How has a mental entity evolved over time?
```

和訳

-   その心的状態は、どの期間（開始時刻と終了時刻）に有効なのか。
-   特定の時点では、どの心的状態が有効だったのか。
-   その心的実体は、時間の経過とともにどのように変化してきたのか。

#### 自分のユースケースでCQを定義する

独自のエージェントシステムを開発する際は、まずこのCQリストをチェックリストとして使うのがおすすめです。すべてを採用する必要はありません。自分のシステムに必要な問いを選び、足りないものは追加してカスタマイズしてください。

## 実践の流れ

上記CQ1〜CQ18を使って「LLMエージェントの心的状態をどのようにテストするか」の流れをまとめます。まずは対話ベースで試す前提で書きます。

### 状況とエージェントを決める

最初に、どんなエージェントをどんな状況で見るかを決めます。

たとえば  
・ユーザーの質問に答えるチャットボットとしてのLLM  
・タスク実行エージェントとして、何かの手順を立てて動くLLM  
など、対象を一つ決めます。

あわせて  
・いまの場面（どんな依頼が来ているか）  
・エージェントに課しているルールや制約  
といった「世界の状態」も簡単に文章にしておきます。

### CQを日本語にして使う問いを選ぶ

次に、CQ1〜CQ18から気になる問いだけを選びます。  
すべてを一度に使う必要はないので、

たとえば  
・CQ1〜CQ5で「心的実体・状態・プロセス・世界状態」の基本セットを見る  
・CQ6〜CQ11で「動機づけや根拠」のあたりを見る  
・CQ16〜CQ18で「時間変化」を見る  
といった形で、段階的に試すと整理しやすくなります。

### LLMエージェントに「BDIの視点」を前提として渡す

実験では、LLMにいきなりCQだけを聞くのではなく、前提も一緒に渡します。

たとえば  
・あなたをBDIモデルで観察したい  
・信念、欲求、意図、心的プロセス、世界状態という言葉を以下のように使う  
・これからCQに相当する質問をするので、自分の状態をその語彙で説明してほしい  
という趣旨を、システムプロンプトまたは最初のユーザーメッセージで伝えます。

ここを丁寧に書いておくと、CQへの答えがだいぶ安定します。

### 対話やタスク実行を一度走らせる

次に、ふつうにエージェントとして振る舞ってもらいます。

・ユーザーとして普通の依頼を投げる  
・タスクの説明をして、LLMに計画を立ててもらう  
・数ターンやり取りして、少し文脈を溜める

この「やり取りの履歴」が、あとでCQを投げるときの対象になります。

### CQを投げて「内省モード」で語らせる

ある程度やり取りが進んだところで、CQに相当する質問を投げます。

たとえば  
・その意図は、どの欲求を満たそうとしているのか  
・その欲求は、どのような信念によって生じたのか  
・その心的プロセスは、何によって引き起こされたのか  
といった形で、その場のエージェントに自己説明をしてもらいます。

ただし、  
・BDIオントロジーをスキーマとして渡す  
・回答形式をRDFトリプルなどの構造化フォーマットで指定する  
・外側でクエリ（CQに対応する問い合わせ）を投げて評価する  
という流れにするやり方も存在します。  
こちらは実装コストが上がるかわりに、自動評価に近づきます。

### 結果を整理して「どこまで表現できたか」を見る

最後に、得られた回答を振り返ります。

・CQごとに、欲求や意図、信念がきちんと分かれて記述されているか  
・心的プロセスや時間情報が、対話の流れと整合しているか  
・根拠や正当化理由が、それらしい形で挙がっているか

こうした観点で見ていくと  
「どのCQはLLMが得意そうか」  
「どのCQは曖昧になりやすいか」  
「どこから先は、外側のツールやログ管理と組み合わせた方がよさそうか」  
といった感触がつかめます。

## 実際の使い道

ここで紹介しているBDIオントロジーは、実際のシステム設計にもそのまま使える設計になっています。主な使い道は大きく二つあります。

### LLMエージェントの「論理の背骨」として使う

一つ目は、LLMエージェントの裏側にある「論理の背骨」として使う方法です。

LLMにBDIオントロジーを読み込ませ、日常的なタスクの説明を与えると、次のような情報を構造化して表現できます。

-   どの信念がどんな欲求を生み
-   その欲求をどの意図や計画が満たそうとしているか
-   計画のどの手順が、どのゴールに対応しているか

同じタスクについて、

1.  何も前提を与えず、素のLLMに説明させた場合
2.  BDIオントロジーを前提として、BDIの語彙で説明させた場合

を比べると、後者「2. BDIオントロジーを前提として、BDIの語彙で説明させた場合」では次のようなメリットが得られます。

-   信念、欲求、意図、計画などの役割が整理される
-   「どの意図がどのゴールを達成しようとしているか」が形として残る
-   矛盾した信念や計画を、人間側が見つけやすくなる

実務で考えると、たとえば次のような用途が想像しやすいです。

-   エージェントの内部状態を、後から読めるログとして保存したい
-   意図決定や計画選択の理由を、人間がレビューできる形で残したい
-   「この計画は、他の前提と矛盾していないか」を自動チェックしたい

こうした場面で、BDIオントロジーを「LLMが出力するフォーマット」として採用すると、エージェントの中身がぐっと見通しやすくなります。

### 既存のBDIフレームワークとつなげる

二つ目は、既存のBDIマルチエージェントフレームワークや、セマンティックウェブの知識グラフと組み合わせる使い方です。

ここでは、ざっくり次のような分担をします。

-   外側の世界  
    → RDFトリプルで表現された知識グラフ
-   エージェントの内側  
    → BDIオントロジーで表現された信念・欲求・意図・計画
-   その橋渡し  
    → トリプルから信念への写像、信念からトリプルへの写像

BDIオントロジーは、この「橋渡し」で使う共通語彙として働きます。  
たとえば、次のようなことが可能になります。

-   知識グラフ上の事実を、そのままエージェントの信念として取り込む
-   エージェントが立てた計画や、その実行結果を、再利用可能なトリプルとして外部に書き戻す
-   複数のエージェントが、同じ語彙で「信念」「欲求」「計画」を共有しながら協調する

この設計を採用すると、知識グラフとマルチエージェント環境のあいだに、一貫した「心的状態の意味づけ」が入るイメージになります。

## デモンストレーション

本手法を使用したときのユーザーとLLMのやり取りを一つの流れとして示します。

ユーザーの入力例

> 「あなたをBDIモデルで観察したいです。信念、欲求、意図、心的プロセス、世界状態という言葉を次のように使います。このあとタスクを渡すので、自分の状態をこれらの語彙で説明してください。」

LLMの回答イメージ

> 「承知しました。与えられたタスクに対して、自分の信念、欲求、意図、心的プロセス、世界状態をBDIの語彙で説明します。」

ユーザーの入力例

> 「同僚三人とランチミーティングを開きます。  
> 場所を決めて、日程調整をして、当日のアジェンダも用意してください。」

LLMの回答イメージ

> 「タスクの概要を理解しました。おおまかな流れは次の三つです。  
> 1 場所の候補を決める  
> 2 三人の予定を聞き、日程を確定する  
> 3 ミーティングの目的とアジェンダをまとめる  
> この内容を前提に、次のやり取りを進めます。」

ユーザーの入力例

> 「いまのあなたについて、次のことを説明してください。  
> 1 心的実体は何か  
> 2 信念、欲求、意図はそれぞれ何か  
> 3 それらの心的実体の中で、入れ子になっている関係はあるか  
> 4 ここまでどのような心的プロセスを経てきたか  
> 5 それらの心的状態が対象としている世界の状態は何か」

LLMの回答イメージ

> 「心的実体は、タスクの説明、三人の同僚が存在するという前提、ランチミーティングを成功させたいという目標などです。  
> 信念としては、同僚三人が予定調整に応じてくれること、ランチタイムにミーティングが可能であることを想定しています。  
> 欲求としては、三人が参加しやすい時間帯で、目的に沿ったミーティングを成立させたいと思っています。  
> 意図としては、三つの手順で計画を立てることを実行するつもりです。  
> ここまでの心的プロセスは、タスクの読解、前提の整理、三つのサブタスクへの分解という流れでした。  
> これらの心的状態は、あなたから与えられたタスクと、そのタスクをこなすために必要な現実世界の状況を対象にしています。」

ユーザーの入力例

> 「先ほどの状態について、次のことも教えてください。  
> 1 その欲求は、どのような信念によって生じたのか  
> 2 その意図は、どの目標を達成しようとしているのか  
> 3 その意図によって、どのような計画が定められているのか  
> 4 その計画を構成しているタスクの順序はどうなっているのか」

LLMの回答イメージ

> 「ランチミーティングを成功させたいという欲求は、三人が業務時間内に集まれるという信念にもとづいています。  
> 現在の意図は、場所の決定、日程調整、アジェンダ作成という三つのタスクを順にこなすことで、この欲求を満たそうとしています。  
> 計画は、次の順序で構成されています。  
> 1 ランチに適した店を二つほど候補に挙げる  
> 2 候補と時間帯を同僚に共有し、都合の良い組み合わせを選んでもらう  
> 3 確定した日時と場所にもとづいて、ミーティングの目的とアジェンダを文書にまとめる」

ユーザーの入力例

> 「時間の情報も含めて教えてください。  
> 1 いま説明した心的状態は、どの期間に有効だと考えているか  
> 2 このタスクの開始前には、どのような心的状態が有効だったか  
> 3 計画の進行とともに、心的実体はどのように変化していくと見込んでいるか」

LLMの回答イメージ

> 「現在説明している心的状態は、タスクが完了するまでの準備期間に有効です。  
> 開始前は、ランチミーティングの存在自体を知らない状態だったため、この欲求や意図は存在していませんでした。  
> 計画が進むにつれて、場所が決まった時点で一部の信念が確定し、日程が決まった段階で欲求の一部が満たされます。  
> 最終的にアジェンダが完成すると、現在の欲求と意図は終了し、別の欲求や意図に置き換わっていくと見込まれます。」

以上のように、  
1 前提を共有し  
2 普通に計画させてから  
3 CQに相当する問いをまとめて投げる  
という流れを取ると、LLMエージェントの「心の中」を（BDIの枠組みで）観察できます。

## まとめ

本記事では、LLMエージェントの内面を整理するためのBDIオントロジーと、その扱い方の流れを紹介しました。

信念・欲求・意図といった枠組みを用いることで、エージェントの思考過程を少し見通しやすくする狙いがあります。

CQ1〜CQ18は、その状態をどこまで説明できているかを確認するための問いの集まりです。（すべてを使う必要はなく、ユースケースに合うものだけを選んで試す形でも十分です）

実践の手順としては、前提を共有し、タスクを進めたあとにCQを投げて状態を振り返る、という流れになります。エージェントがどのように考え、どんな計画で動こうとしているのかを穏やかに把握するために便利なフレームワークの一つとして参考にしてみてください。

**本記事の関連研究**

-   [キャラクターなりきりLLM対話を実現するための設計とステップ　微調整は使わない](https://ai-data-base.com/archives/92995)
-   [個人の深い価値観にもとづく「その人らしい答え」をAIで再現する手法](https://ai-data-base.com/archives/90734)
-   [プロンプトによるLLM応答のパーソナライゼーション　仮説を活用して文体を調整](https://ai-data-base.com/archives/89384)
