---
created: 2026-01-01T09:30:08 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/56671
author: AIDB Research
---

# LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト - AIDB

> ## Excerpt
> LLMによる複雑な多段階の推論には、なお課題があります。そこで、DeepMindの研究者によって推論の性能を上げる「ステップバック・プロンプティング」が開発されました。本記事ではこの手法の性能に関する実験結果と使用方法を解説します。 ステップバック・プロンプティングは極めてシンプルで具体的なテクニックながら、CoT（Chain-of-Thought prompting）やTake a Deep B…

---
LLMによる複雑な多段階の推論には、なお課題があります。そこで、DeepMindの研究者によって推論の性能を上げる「ステップバック・プロンプティング」が開発されました。本記事ではこの手法の性能に関する実験結果と使用方法を解説します。

![[LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト - AIDB/AIDB_56671_1-edited.png]]

ステップバック・プロンプティングは極めてシンプルで具体的なテクニックながら、CoT（Chain-of-Thought prompting）やTake a Deep Breatheといった既存の手法を凌駕する性能を発揮しています。

**参照論文情報**

・タイトル：Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models  
・著者：Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen, Heng-Tze Cheng, Ed H. Chi, Quoc V Le, Denny Zhou  
・所属：Google DeepMind  
・URL：[https://doi.org/10.48550/arXiv.2310.06117](https://doi.org/10.48550/arXiv.2310.06117)

## 従来の課題

LLMはSTEM（科学、技術、工学、数学）や知識ベースの質問応答（Knowledge QA）、多段階推論（Multi-Hop Reasoning）など、複雑なタスクでの使用が増加しています。しかし、これらの高度なタスクにおいて、LLMは中間の推論ステップでの正確性は必ずしも十分ではない場合があります。

既存のプロンプト技術、例えばChain-of-Thought（CoT）プロンプトなどは、中間の推論ステップでの正確性を確かに向上させるものの、分野によっては精度が足りない場合もあります。

簡単に言えば、現在のLLMは「考える過程」でしばしば間違いを犯し、その結果として誤った結論に至る可能性があります。例えば、科学的な問題解決において、LLMは正確なデータ解釈ができない場合があり、それが誤った結論を導く可能性があります。

**本記事の関連研究：**[LLMが真の推論能力を発揮するには時折「一時停止」させるのが重要との報告](https://ai-data-base.com/archives/56487)

## ステップバック・プロンプティングの仕組み

![[LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト - AIDB/AIDB_56671_3.jpg]]

そこで今回、DeepMindの研究者らはLLMの推論能力を向上させるための手法としてステップバック・プロンプティングを考案しました。方法論は主に二つのステップで構成されています。

### ステップ1: 抽象化

まずは高次の概念や原則（要するに前提）に関する質問を最初に提示することで、特定の詳細から高レベルの概念や原則を導き出します。

**問題の詳細を分析**: 問題に含まれる具体的な要素や条件を明確にします。

**高次の質問を設計**: これらの要素や条件から一歩引いて、より高次の概念や原則に関する質問を設計します。

**前提の確認**: 高次の質問に対する答えを用いて、推論の前提を確立します。

### ステップ2: 推論

次に、確認した前提に基づいて、本来の質問における解決策を推論します。

**前提の適用**: ステップ1で確立した前提を、本来の問題解決に適用します。

**論理的推論**: 前提に基づき、可能な解決策を論理的に導き出します。

**最適な解決策の選定**: 複数の解決策が存在する場合、最も効率的かつ効果的なものを選定します。

****本記事の**関連研究：**[LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト](https://ai-data-base.com/archives/55711)

## 従来のプロンプト技術について

### Chain of Thought（連鎖的思考）

Chain of Thought（連鎖的思考）とは、問題解決の過程を段階的に進めるように指示するプロンプト技術です。「ステップバイステップで取り組んでください」といった指示プロンプトを与えることによって実行でき、推論の各ステップが明確になります。この方法は、複雑な問題や多段階の推論が必要な場合に有用です。しかし、この技術は中間の推論ステップでエラーが発生する可能性もあります。

### Take a Deep Breathe（深呼吸）

Take a Deep Breathe（深呼吸）とは、推論の精度を向上させるためのプロンプト技術です。例えば「深呼吸してから取り組んでください」といった指示プロンプトによって実行できます。モデルがより慎重に問題解決に取り組めるようにするテクニックです。

なお、下記の記事で紹介している論文で初めて明らかにされ、その人間らしさからかなり大きな話題になりました。

[LLMが巡回セールスマン問題などの最適化問題を解く〜自分自身で優れたプロンプトを作成＆活用〜](https://ai-data-base.com/archives/55087)

これら従来のプロンプト技術は、それぞれ一定の効果を発揮していますが、中間の推論ステップでの正確性が必ずしも高いわけではありません。

## 性能の検証

### 対象タスク

この研究では、以下の3つのタスクに焦点を当てています。

-   **STEM（科学、技術、工学、数学）**: 高校の物理と化学に関する問題を中心に、モデルの言語理解能力を評価します。
-   **Knowledge QA（知識ベースの質問応答）**: TimeQAとSituatedQAという2つのデータセットを使用しています。TimeQAは時間に関連する複雑なクエリを含み、SituatedQAは地理的または時間的な文脈に基づいてモデルが質問に答える必要があります。
-   **Multi-Hop Reasoning（多段階推論）**: MuSiQueとStrategyQAというデータセットを使用しています。MuSiQueは単一の質問の組み合わせから作成された多段階の推論を必要とするデータセットであり、StrategyQAは解決に一定の戦略を必要とするオープンドメインの質問を含んでいます。

### 使用モデル

研究では、次の2つの最先端の大規模言語モデルを使用しています。

-   **PaLM-2L**: 基本モデルと調整済みモデルの2種類がテストされています。
-   **GPT-4**: OpenAIによって開発されたこのモデルも実験に使用されています。

### 評価指標

-   **精度**: モデルがどれだけ正確にタスクを遂行できるかを測定します。
-   **F1スコア**: 精度と再現率の調和平均を取ることで、モデルの全体的な性能を評価します。

****本記事の**関連研究：**[LLMが巡回セールスマン問題などの最適化問題を解く〜自分自身で優れたプロンプトを作成＆活用〜](https://ai-data-base.com/archives/55087)

## 実験の結果

### 性能向上の範囲

論文によれば、ステップバック・プロンプティングは各ベンチマークで7%から27%の性能向上を達成しました。

### 従来のプロンプト技術との比較

![[LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト - AIDB/AIDB_56671_2.png]]

ステップバック・プロンプティングは、従来のプロンプト技術であるChain of Thought（CoT）とTake a Deep Breathe（TDB）と比較しても、最も高い性能を発揮しました。CoTやTDBのゼロショットプロンプティングは、ベースラインモデルの性能を大幅に向上させることはありませんでした。一方で、ステップバック・プロンプティングは、PaLM-2LとGPT-4といった先進的なLLMに対しても高い性能を発揮しました。

### タスクの難易度と性能

![[LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト - AIDB/AIDB_56671_4.png]]

論文では、難易度の高いタスクにおいてもステップバック・プロンプティングが有効であることが示されました。例えば、TimeQAというタスクにおいて、ステップバック・プロンプティングは、高レベルの概念に基づいて最終的な推論を行うことで、精度を大幅に向上させました。

ただし、ステップバック・プロンプティングも完璧ではありません。論文内でのエラー分析によれば、一部のエラーは依然として存在します。しかし、その数は従来の方法よりも少なく、特に高レベルの抽象概念に基づいた推論においては、その有用性が確認されました。

****本記事の**関連研究：**[推論能力をさらに強める戦略『AoT』で、LLMが「直感」に似た能力を示すようになった](https://ai-data-base.com/archives/54750)

## プロンプト例

このセクションでは、ステップバック・プロンプティングを使用した際の具体的なプロンプト例を示します。

ここから限定コンテンツ

```
ユーザー：〇〇において、××に影響を与える基本的な要素は何ですか？ 
（LLM：*****）
 ユーザー：それを考慮に入れて、××を高める/改善する/強めるetc最も効果的な方法は何ですか？
```

以下の例は、ユーザーが特定の問題に対する解決策を求める一連の対話を表しています。

### 例1：企業経営における利益向上

**ユーザー**: 企業経営において、利益に影響を与える基本的な要素は何ですか？  
**LLM**: 利益に影響を与える基本的な要素は、売上、コスト、市場環境、競合他社の状況などがあります。

**ユーザー**: それを考慮に入れて、利益を高める最も効果的な方法は何ですか？  
**LLM**: 売上を増加させる戦略を採る一方で、コスト削減も重要です。市場環境と競合他社の動きに応じて、製品やサービスの価格設定を最適化することも考慮に入れるべきです。

### 例2：健康促進における運動量

**ユーザー**: 健康促進において、運動量に影響を与える基本的な要素は何ですか？  
**LLM**: 運動量に影響を与える基本的な要素は、個々の体力レベル、時間、目的、そしてモチベーションなどがあります。

**ユーザー**: それを考慮に入れて、運動量を高める最も効果的な方法は何ですか？  
**LLM**: 個々の体力レベルに合わせた運動プランを作成し、時間を効率的に使うことが重要です。目的に応じて運動の種類を選び、モチベーションを維持するための手段も考慮すると良いでしょう。

**関連研究：**[メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」](https://ai-data-base.com/archives/54435)

## 追加の考察

本研究で提案された『ステップバック・プロンプティング』は、従来のプロンプト技術である「Chain of Thought（CoT）」や「Take a Deep Breathe（深呼吸）」よりも優れた性能を示しました。しかし、これらの手法を組み合わせた場合の効果については、まだ未検証の領域です。

例えば、ステップバック・プロンプティングの各フェーズにおいて、「深呼吸して、ステップバイステップで取り組んでください」という指示を加えることで、推論プロセスがさらに洗練される可能性があります。このような組み合わせによって、既存のプロンプト技術の長所を活かしつつ、新たな手法の効果を最大化できるかもしれません。

**関連研究：**[LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト](https://ai-data-base.com/archives/55711)

## まとめ

本記事では、DeepMindの研究者らによって開発された新しいプロンプト技術『ステップバック・プロンプティング』について詳細に解説しました。この手法は、従来のプロンプト技術である「Chain of Thought（CoT）」や「Take a Deep Breathe（深呼吸）」よりも優れた性能を示し、多段階の推論が必要なタスクで有用であることが確認されました。

このプロンプト手法が完璧なわけではありませんが、今後役に立つ可能性がある一つの技として覚えておくとよいかもしれません。

****本記事の**関連研究：**[GPT-4に選択肢を与えるとき、順序を入れ替えるだけで性能に大きな変化があることが明らかに](https://ai-data-base.com/archives/54690)
