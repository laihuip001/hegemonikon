---
created: 2026-01-01T09:38:11 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/66942
author: AIDB Research
---

# LLMによりクエリを生成するアプローチで情報検索の精度を上げる方法 - AIDB

> ## Excerpt
> LLMを用いて対話型の情報検索システムにおける精度を高めるための工夫が研究されています。対話型情報検索システムは、従来型の検索エンジンに対して、ユーザーの意図を汲み取る力に長けている特徴を持つ技術です。 研究者らは今回、対話型情報検索システムの仕組みを検証する実験において、「検索してから生成」するアプローチと「生成してから検索」するアプローチを比較しています。 参照論文情報 本記事の関連研究： 背…

---
LLMを用いて対話型の情報検索システムにおける精度を高めるための工夫が研究されています。  
対話型情報検索システムは、従来型の検索エンジンに対して、ユーザーの意図を汲み取る力に長けている特徴を持つ技術です。

研究者らは今回、対話型情報検索システムの仕組みを検証する実験において、「検索してから生成」するアプローチと「生成してから検索」するアプローチを比較しています。

![[LLMによりクエリを生成するアプローチで情報検索の精度を上げる方法 - AIDB/AIDB_66942-1024x576.jpg]]

**参照論文情報**

-   タイトル：Generate then Retrieve: Conversational Response Retrieval Using LLMs as Answer and Query Generators
-   著者：Zahra Abbasiantaeb, Mohammad Aliannejadi
-   所属：University of Amsterdam

**本記事の関連研究**：

-   [RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』](https://ai-data-base.com/archives/66427)
-   [RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成](https://ai-data-base.com/archives/66269)
-   [RAGにおいて取得された情報と事前知識が矛盾しても、情報に説得力があるときLLMは受け入れる](https://ai-data-base.com/archives/64979)
-   [LLMのRAG（外部知識検索による強化）をまとめた調査報告](https://ai-data-base.com/archives/61367)

## 背景

最近、対話型の情報検索が注目を集めています。ユーザーとの対話を通して情報ニーズを理解し、適切な情報を見つけ出す技術です。

従来の検索エンジンは、ユーザーが入力したキーワードに基づいて関連する文書を検索します。複雑な情報ニーズを短いキーワードで表現するのは難しく、必要な情報を見つけられないケースも多くありました。

一方で対話型情報検索は、ユーザーが知りたい情報をより深く理解し、より精度の高い検索結果を出します。情報収集の負担軽減にも繋がり、さらにユーザー自身が気づいていなかった新しい関連情報も探し出せる可能性があります。

なおここでの情報検索とは、ウェブ検索だけでなく企業内データの検索も含まれます。

![[LLMによりクエリを生成するアプローチで情報検索の精度を上げる方法 - AIDB/AIDB_66942_1.png]]

ユーザーの複雑な要求に対する会話例

そして、対話型情報検索においてはLLMを活用することが期待されています。以下のようなメリットが見込まれます。

-   文脈や感情も含めてユーザーの発話内容をより深く理解する
-   ユーザーの意図に沿った自然な文章を生成する
-   複数の文書を組み合わせたり、推論を行うことで、より深い洞察を提供することができる

今回研究者らは、LLMによる対話型情報検索をどのようなパイプラインで開発するのがよいのかを検証しました。

以下で詳しく解説します。

ここから限定コンテンツ

## 方法論

### タスクの定義

対話型情報検におけるタスクは以下のように定義されました。

会話はユーザーの発言から始まり、特定のトピックを中心に進められます。会話は複数の「ターン」と呼ばれる部分で構成されており、各ターンではユーザーの発言とシステムの応答がペアになっています。

なおユーザーの「ペルソナ」も重要になります。ペルソナとは、ユーザーの個人的な背景、好み、過去の経験などを表す設定のことです。

対話型アシスタントの役割は、以下の2つです。

1.  ユーザーの現在の発言に関連する文章を、大量の文章の集まり（コレクション）から検索すること。
2.  ユーザーの現在の発言と過去のやり取りを考慮して、検索された文章を基に適切な応答を生成すること。

ここで、「検索してから生成」するアプローチと、「生成してから検索」するアプローチが比較対象となります。

### Retrieve then generate（検索してから生成）

ユーザーの発言をそのままクエリ（検索に使う言葉）として使うことはありません。  
一般的には、ユーザーの現在の発言をクエリに変換します。この書き換えたクエリを、BM25などの検索モデルで使います。検索モデルが返した上位の文章は、再ランキングモデルに渡されます。最終的に、再ランキングの上位にある文章を応答生成モデルに渡して、応答を生成します。  
これは通常のRAGシステムの流れとほとんど同様です。

### Generate then retrieve（生成してから検索）

研究者たちは、LLMが生成した応答を利用する方法を提案しています。その目的は、LLMの持つ知識と推論能力を使って、文章検索の性能を上げることです。

まず、ユーザーの現在の発言と会話の流れを考慮して、LLMが最大で5個のクエリを生成します。具体的には、以下のような方法が提案されています。一連のプロセスではなく、それぞれが異なるアプローチです。

**回答生成アプローチ**

LLMの応答を1つの長いクエリとして扱い、検索と再ランキングのモデルに渡します。

**質問生成アプローチ**

LLMに直接、応答を検索するための最大5つのクエリを生成させます。

**回答生成質問アプローチ**

まずLLMに初期応答を生成させ、次にLLMに最大5つのクエリを生成させて、自分が生成した応答を改善します。

なお回答生成質問アプローチの改良版も考案されました。生成された応答との関連性を予測し、最終的な順位付けを調整するアプローチです。

### プロンプト

GPT-4モデルが、回答生成質問アプローチと質問生成アプローチではゼロショット学習器として使用されます。またLLaMAモデルに対して、回答生成質問アプローチと質問生成アプローチでクエリ生成のためのfew-shotプロンプトが与えられます。

## 実験の設定

### パラメータの設定

-   BM25モデル：Pyseriniというライブラリのデフォルト値を使用しました。
-   再ランキング：sentence-transformersというライブラリのms-marco-MiniLM-L-6-v2という事前学習済みモデルを使用しました。最大長は512に設定しました。
-   LLaMA-chat 13Bモデル：特定のパラメータ設定を使用しました。
    -   回答生成質問アプローチ：LLaMAモデルに2つの例を示すプロンプトを使用しました。
    -   回答生成アプローチと質問書き換えアプローチ：事前知識なしの学習器を使用しました。
    -   質問生成アプローチ：1つの例を示すプロンプトを使用しました。
-   GPT-4モデル：すべてのアプローチで、事前知識なしの学習器を使用しました。デフォルトのパラメータ値を使用しました。
-   予測：GPT-3.5をデフォルトのパラメータで使用しました。

### 使用したデータセット

TREC iKATというデータセットを使って実験されました。13のトピックについての25の会話と、合計133のやり取りで構成されています。iKATの会話の平均の長さは13.04で、会話の流れを理解するのがより難しくなっています。iKATが使用されたのは、複雑な会話を含む、数少ないデータセットの1つであるためです。

### 評価指標

iKATの公式の評価指標である以下の指標を使って、文章検索タスクの性能が評価されました。

-   nDCG@5
-   P@20
-   Recall@20
-   Recall
-   mAP

nDCG@5は、検索結果の上位の文章をユーザーに直接提示することを目的とした場合の性能を評価します。P@10とRecall@20は、検索結果の上位20件の文章を読んで、それを基に回答を生成することを想定した場合の性能を測定します。

### GPT-3.5を使った評価

iKATの元の評価データには、回答生成質問アプローチのモデルがほとんど含まれていなかったため、提案手法の検索結果の上位には、まだ評価されていない文章が多く含まれていました。そこで、GPT-3.5を使って新しい文章のデータセットを作成し、文章の関連性を判断するようにお願いしました。公平な比較のために、以下の2点に気をつけました。

1.  元のデータですでに評価されている場合でも、すべてのクエリと文章のペアを判定すること。
2.  提案モデルとベースラインのすべての検索結果の上位10件を含めること。

全部で19,413のクエリと文章のペアの関連性を判定しました。

### ベースラインモデル

TREC（iKATデータセットの作成元）によって提供されたベースラインモデルと、本研究で実装したベースラインモデルについては以下の通りです。

-   Human：正解データセットで提供された、書き換え済みの発話を使用して検索と再ランキングを行います。
-   InfoSense：回答生成+検索パイプラインに基づくTREC iKATに提出されたモデルです。
-   LLaMA10：LLaMA 7Bモデルを使ってクエリを書き換える検索+回答生成モデルです。
-   ConvGQR：QReCCデータセットでクエリの書き換えと拡張の事前学習済みモデルを使用するTRECのベースラインです。
-   monoT5：クエリの書き換えにBARTモデル、再ランキングにT5ベースのモデルを使用します。

## 結果と考察

### 文章ランキングの結果

下記の表に、提案モデルとベースラインモデルの性能が示されています。（結果は、GPT-3.5モデルによって生成されたデータセットに基づいています。）

![[LLMによりクエリを生成するアプローチで情報検索の精度を上げる方法 - AIDB/AIDB_66942_2-1024x555.png]]

iKATデータセットにおける、GPT-3.5ベンチマークを用いた各手法のパッセージ検索結果。QD：質問生成アプローチ、AQD：回答生成質問アプローチ、AD：回答生成アプローチ、QR：質問書き換えアプローチ

回答生成質問アプローチと回答生成質問アプローチ改良版は、LLaMAモデルを使用した質問書き換えベースラインを上回っていることがわかります。  
さらに、回答生成質問アプローチ改良版は、nDCG、Recall、mAPの点で、人間のクエリ書き換えと回答生成アプローチを使用した質問書き換えアプローチを上回っています。

LLaMAモデルは、回答生成質問アプローチにおいて、GPT-4モデルの回答を与えられた場合、質問生成でより良い性能を達成しました。誤った回答が与えられると、エラーが質問生成ステップに伝播し、生成された質問の質に悪影響を及ぼします。

またGPT-4モデルをLLMとし、回答生成質問アプローチ改良版を用いることで、回答生成+検索パイプラインに基づくベストなベースラインモデルであるGPT-4を用いた回答生成アプローチを上回る最高の性能を達成しました。

![[LLMによりクエリを生成するアプローチで情報検索の精度を上げる方法 - AIDB/AIDB_66942_4.png]]

各モデルが返す上位10件の文章における、TREC iKAT公式の関連性評価で判定された文章の割合

回答生成質問アプローチは、平均平均適合率（mAP）、Recall@20、P@20の点で、回答生成アプローチよりも優れた性能を発揮しています。  
検索に複数の質問を使用することで、初期に生成された回答として使用する場合と比較して、より多くの関連文書を検索できることを示唆しています。

また回答生成質問アプローチは、質問書き換えアプローチと比較して優れた性能を示しています。この結果は、複雑なユーザーの質問に対しては、1つの質問ではなく複数の質問を持つことの重要性を示しています。

以上は、回答生成+検索パイプラインを持つモデルが、検索+回答生成パイプラインを持つモデルよりも優れた性能を示していると読み取れます。検索タスクにおけるLLMの知識と能力の活用の有効性を示唆しています。

また、回答生成質問アプローチが直接的な質問生成アプローチよりも優れた性能を示したことは、質問生成のために会話の文脈よりもLLMの回答に依存することの有用性を示しています。

### 分析

提案モデルの会話の深さとトピックごとの性能が2つの図に示されています。

![[LLMによりクエリを生成するアプローチで情報検索の精度を上げる方法 - AIDB/AIDB_66942_5.png]]

提案モデルの会話ごとの性能 ((G): GPT-4)。

![[LLMによりクエリを生成するアプローチで情報検索の精度を上げる方法 - AIDB/AIDB_66942_6.png]]

提案モデルの会話の深さごとの性能 (おなじく(G): GPT-4)

会話が続き、文脈のモデル化がより困難になると（ターン数が14を超える場合）、回答生成質問アプローチと回答生成質問アプローチ改良版は、回答生成アプローチと比較して、より優れた検索性能を示すことがわかります。

## まとめ

本記事では、LLMを活用した対話型情報検索の新手法を提案した研究を紹介しました。

研究者らは、LLMの内部知識と推論能力を活用することで、ユーザーの複雑な質問に対してより適切な回答を生成できると考えました。提案手法は、まずLLMを用いて対話に対する回答を生成し、生成された回答を複数の検索可能なクエリに分割する新しいアプローチです。

実験の結果、提案手法は従来の手法と比較して大幅に性能を向上させることが示されました。

ただし、いくつかの限界もあります。例えば、LLMが特定のトピックについて知識がない場合、正しく完全な回答を生成することができません。また、本アプローチを用いて生成する最終的な回答の品質までは十分な検証がなされていません。（言うなれば、Generate then Retrieve then Generate）

本研究で提案された手法は、LLMの能力を活用した新しい対話型情報検索の可能性を示しています。今後、さらなる改良が期待されます。

参照論文URL：[https://doi.org/10.48550/arXiv.2403.19302](https://doi.org/10.48550/arXiv.2403.19302)
