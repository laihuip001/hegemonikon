---
created: 2026-01-01T09:36:53 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/64136
author: AIDB Research
---

# LLMにタスクに応じた推論プロセスを自ら考えるようにさせるプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発 - AIDB

> ## Excerpt
> Google DeepMindなどの研究者たちは、GPT-4をはじめとする大規模言語モデル（LLM）がタスクごとに適切な推論プロセスを自ら考えることができるようにするプロンプト手法を開発しました。 実験では従来の方法と比較して最大42%の性能向上が確認され、計算コストも10〜40倍削減されることが示されました。 参照論文情報 本記事の関連研究： 背景 LLMで複雑な問題解決を行うことがますます期待…

---
Google DeepMindなどの研究者たちは、GPT-4をはじめとする大規模言語モデル（LLM）がタスクごとに適切な推論プロセスを自ら考えることができるようにするプロンプト手法を開発しました。

実験では従来の方法と比較して最大42%の性能向上が確認され、計算コストも10〜40倍削減されることが示されました。

![[LLMにタスクに応じた推論プロセスを自ら考えるようにさせるプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発 - AIDB/AIDB_64136-1024x576.jpg]]

**参照論文情報**

-   タイトル：Self-Discover: Large Language Models Self-Compose Reasoning Structures
-   著者：Pei Zhou, Jay Pujara, Xiang Ren, Xinyun Chen, Heng-Tze Cheng, Quoc V. Le, Ed H. Chi, Denny Zhou, Swaroop Mishra, Huaixiu Steven Zheng
-   所属：University of Southern California, Google DeepMind

**本記事の関連研究**：

-   [プロンプトの小さな違いがLLMにもたらすバタフライ効果を調査した結果](https://ai-data-base.com/archives/62566)
-   [プロンプトの原則26ヶ条をまとめた報告](https://ai-data-base.com/archives/61417)
-   [ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』](https://ai-data-base.com/archives/51160)
-   [ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介](https://ai-data-base.com/archives/58361)

## 背景

LLMで複雑な問題解決を行うことがますます期待されており、推論能力を高めるアプローチが求められています。

そこで、様々なプロンプト手法が提案されてきました。これまでの研究では、人間が問題を解決する際のステップバイステップのアプローチや、複雑な問題をサブ問題に分解して解決するプロセスなどに注目が集まってきました。しかし各タスクにおける前提に細かく対応しているわけではありません。つまり、タスク固有の推論構造を見落とす傾向がありました。

このような背景から、各タスクに特有の推論構造を自己発見して効率的に問題を解決する新たなアプローチが必要とされていました。  
そこでGoogle DeepMindなどの研究者らは、ニーズに応えるためにSELF-DISCOVERという手法を考案しました。本手法は、LLMが自ら推論プログラムを内部で構築し、問題を解決するプロセスを辿るものです。人間が新しい問題に直面したときに過去の知識や経験を活用して解決策を導き出すプロセスに触発されて考案しています。

実験ではその性能が多角的に確かめられています。

下記では方法論と実験結果を見ていきます。

## 方法論

SELF-DISCOVERの具体的な手順は以下のように2つの段階に分けられます。

ここから限定コンテンツ

![[LLMにタスクに応じた推論プロセスを自ら考えるようにさせるプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発 - AIDB/AIDB_64136_2-1024x413.png]]

各段階ごとに説明します。

### ステージ1：タスク固有の構造を自己発見する

**SELECT（選択）**

まずはモデルが、与えられたタスクの例から、問題解決に役立つ推論モジュールを選び出します。

推論モジュールとは、問題解決のための思考プロセスやアプローチ（例:「批判的思考」や「問題をサブプロブレムに分割する」）を指す単位です。

**ADAPT（適応）**

選択された推論モジュールの説明をタスクに具体的に適合させることで、タスク解決のためのアクションに変換します。

**IMPLEMENT（実装）**

適応させた推論モジュールの説明を、具体的なステップと指示を含む構造に組み立てます。

### ステージ2：発見された構造を使用してタスクに取り組む

ステージ1で発見された推論構造をタスクに適用し、解答を生成させます。

![[LLMにタスクに応じた推論プロセスを自ら考えるようにさせるプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発 - AIDB/AIDB_64136_3-1024x459.png]]

このアプローチでは、LLMが単に与えられたデータを元に回答を生成するだけでなく、その問題解決過程において「どのように考えるか」を自己発見することを目指しています。より人間に近い思考プロセスを模倣することで、複雑な問題に対処できるようになる可能性があるという仮説に基づいています。

なお論文では入力プロンプトテンプレートは直接提供されていませんが、上記の理論から当編集部が入力プロンプトを具体化することを試みました。以下にテンプレートの例を示します。

```
「この問題は、〜〜に関連しています。解決するには、深い推論と分析が必要です。」
「推論プロセスを開始するために、まずは問題を理解し、解決に向けて必要なステップを特定してください。」
「考えられる推論モジュールを複数挙げ、それぞれがこのタスクにどのように貢献するかを検討してください。」
「自己発見した推論構造に基づいて、複数のステップで問題を解決してください。ステップごとに、具体的なアクションや考え方を明示してください。」
「先ほど定義したステップを具体的に実行して問題の解決に必要な計算や分析を行った結果得られた、最終的な推論と解答を生成してください。」
```

## 実験

本手法は以下のような実験で性能が評価されました。

### タスク

以下のベンチマークで多様な推論タスクが試されました。

**BIG-Bench Hard (BBH)**

23の厳選された難しいタスクが含まれます。以下の4つのカテゴリーにまたがる推論問題をカバーしています。

-   アルゴリズムと多段階算数推論
-   自然言語理解
-   世界知識の使用
-   多言語知識と推論

**Thinking for Doing (T4D)**

精神的な論理を推論して行動を決定する社会的タスクが含まれます。

**MATH**

数学問題のデータセットです。今回は12,500問のうち、今回200問が使用されました。

### モデル

1.  GPT-4
2.  GPT-3.5
3.  Instruction-tuned PaLM 2-L
4.  Llama2-70B

### ベースライン

-   直接回答（多段階推論を行わせることなく直接問題を解かせる）
-   CoT（Chain of Thought、ステップバイステップで考えさせる手法）
-   Plan-and-Solve（最初に計画を生成し、その後問題を解決する手法）

### 追加のベースライン

-   CoT-Self-Consistency（CoTを用いて複数の出力をサンプリングし、回答を集約して最終回答を得る手法）
-   各推論モジュールの多数決（各推論モジュールを追加してタスクを解決し、全回答の多数決を使って最終回答を得る場合の精度）
-   各推論モジュールの最良（各推論モジュールを適用した際の最高の精度を使用する場合の精度）

## 実験結果

### 推論の改善

SELF-DISCOVERは、PaLM 2-LとGPT-4の両方で、様々な推論タスクにおいて全体的な推論能力を向上させました。以下でタスクごとの詳細を説明します。

![[LLMにタスクに応じた推論プロセスを自ら考えるようにさせるプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発 - AIDB/AIDB_64136_4.png]]

**BBHタスクにおけるパフォーマンス**

PaLM 2-Lで、Chain-of-ThoughtとPlan-and-Solveに対してそれぞれ7%、6%の絶対改善を達成しました。またGPT-4では、6%および8%の改善が観察されました。

PaLM 2-Lでの直接回答およびCoTと比較した各タスクの改善結果では、SELF-DISCOVERが20/24のタスクでこれらを上回りました。

**T4Dタスクにおけるパフォーマンス**

PaLM 2-LとGPT-4でそれぞれ69%、85%の精度を達成し、すべてのベースラインに対して27%（32%）以上の絶対改善を達成しました。

**MATHタスクにおけるパフォーマンス**

PaLM 2-L（GPT-4）で、ベースラインと比較して1%-7%（2%-3%）の適度な改善が観察されました。

エラー分析では、PaLM 2-LによってSELF-DISCOVERから生成された推論構造が87.5%で正確であり、専門家がこれらの構造に従ってタスクを完璧に解決できることがわかりました。

また失敗の大部分（74.7%）は計算の実行ミスに起因しており、これは以前の研究結果と一致しています。

### SELF-DISCOVERが最も効果的な問題のタイプ

**世界知識が必要なタスクで最も効果を発揮**

スポーツ理解、映画推薦、遺跡名など、広範囲の世界知識を要求するタスクで優れたパフォーマンスを達成しました。事実や一般的な常識に基づく推論が求められるタスクです。

**多角的な推論モジュールの統合が強み**

さまざまな視点からの複数の推論モジュールを統合することで、CoTのみを適用した場合に見落とされがちな重要な知識を補完することがわかりました。

**アルゴリズムカテゴリーにおける改善は穏やか**

数学タスク性能に関する傾向と同じです。

### SELF-DISCOVERの効率性について

**計算効率が高く、優れたパフォーマンスを達成**

自己一貫性や多数決法と比較して、推論計算が10-40倍少ないことがわかりました。GPT-4を使用した比較では、他のベースラインを上回り、特に繰り返し推論呼び出しが必要な手法よりも効率的であると示されました。

![[LLMにタスクに応じた推論プロセスを自ら考えるようにさせるプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発 - AIDB/AIDB_64136_5-1024x470.png]]

**推論呼び出しの数**

SELF-DISCOVERはインスタンス（問題）あたり1回の呼び出しで済み、タスクレベルでさらに3回の呼び出しを要するのみとわかりました。

なおCoT-Consistencyはインスタンスごとに10回のサンプルが必要、推論モジュールの最良を使用する手法は40倍の推論呼び出しが必要でした。

### 質的な例

#### **推論プロセスの比較**

CoTとPlan-and-Solveは初期に誤った主張をし、誤った答えに至ります。

![[LLMにタスクに応じた推論プロセスを自ら考えるようにさせるプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発 - AIDB/AIDB_64136_6.png]]

一方でSELF-DISCOVERの構造に従うと、論理的な結論（例:「始点と終点の座標が同じため、パスは閉じている」）を導き出し、正しい答えに到達します。

![[LLMにタスクに応じた推論プロセスを自ら考えるようにさせるプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発 - AIDB/AIDB_64136_7-1024x638.jpg]]

## SELFDISCOVERにおける推論構造を深掘り

#### アクションの重要性

研究者らはSELECT、ADAPT、IMPLEMENTの3つのアクションに関する削減実験を実施しました。つまり、プロセスの一部を省略してどうなるかの実験を行いました。

GPT-4を使用した4つの推論タスクで、SELECTのみ(-S)、SELECTとADAPTの両方(-SA)、または3つのアクションすべてを適用した場合の結果を示します。

![[LLMにタスクに応じた推論プロセスを自ら考えるようにさせるプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発 - AIDB/AIDB_64136_8.png]]

各ステージでモデルのゼロショット推論能力がタスクごとに一貫して向上し、3つのアクションすべてが有益であることがわかりました。そして3つのアクション全てを実行完了した後に最も精度が高くなることも明らかになりました。

#### 推論構造の普遍性

**PaLM 2-Lで発見された構造をGPT-4に適用**

PaLM 2-Lモデルを使用して4つの推論タスクの推論構造を発見し、その結果得られた推論構造をGPT-4のデコーディングに適用する結果も行われました。OPROと比較したとき、SELFDISCOVERは4つのタスク中3つでOPROを上回りました。

なおOPRO（Optimized Prompting）とは、特定の問題を解決するために最適化されたプロンプトを発見し生成する手法です。

![[LLMにタスクに応じた推論プロセスを自ら考えるようにさせるプロンプト手法『SELF-DISCOVER』Google DeepMindなどが開発 - AIDB/AIDB_64136_9.png]]

**GPT-4で発見された構造をLlama2とChatGPTに適用**

GPT-4を使用してタスク固有の推論構造を発見し、その構造をオープンソースのLlama2-70BおよびGPT-3.5のデコーディングに適用しました。Llama2（52%）がCoT（42%）をQAタスクのゼロショットで、GPT-3.5-turbo（56%）がCoT（51%）を幾何学タスクの3ショットのデモンストレーションで上回りました。

## まとめ

本記事では、任意のタスクに対してモデルが推論構造を自己発見するための効率的なフレームワークであるSELF-DISCOVERについての研究を紹介しました。

実験の結果、複数のLLMで難易度の高い推論ベンチマークにおいて最大30%の顕著な改善が観察されました。また、あるLLMによって作成された推論モジュールは他のLLMに転用可能であることも示されました。

本手法は追加の開発を特に行うことなくプロンプトで実践可能なテクニックです。ぜひ試してみてはいかがでしょうか。

参照論文URL：[https://doi.org/10.48550/arXiv.2402.03620](https://doi.org/10.48550/arXiv.2402.03620)
