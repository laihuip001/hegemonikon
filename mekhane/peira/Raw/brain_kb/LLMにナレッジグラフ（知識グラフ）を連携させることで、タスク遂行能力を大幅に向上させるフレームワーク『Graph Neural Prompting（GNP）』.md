---
created: 2026-01-01T09:30:11 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/57018
author: AIDB Research
---

# LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』 - AIDB

> ## Excerpt
> 大規模言語モデル（LLM）は、質問応答、翻訳、テキスト要約など、さまざまなNLPタスクで優れた性能を発揮しています。しかし、モデルはしばしば正確な事実知識を捉えるのが難しく、根拠のない回答を生成することあります。この問題を解決するために、Amazonなどの研究者らが『Graph Neural Prompting（GNP）』という新しいフレームワークを考案しました。このフレームワークは、LLMにナレ…

---
大規模言語モデル（LLM）は、質問応答、翻訳、テキスト要約など、さまざまなNLPタスクで優れた性能を発揮しています。しかし、モデルはしばしば正確な事実知識を捉えるのが難しく、根拠のない回答を生成することあります。この問題を解決するために、Amazonなどの研究者らが『Graph Neural Prompting（GNP）』という新しいフレームワークを考案しました。このフレームワークは、LLMにナレッジグラフ（知識グラフ）を連携させ、タスク遂行能力を大幅に向上させるものです。

![[LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』 - AIDB/AIDB_57018_20231025-1-1024x576.jpg]]

従来の方法では、モデルに学習データを追加するためには高いコストがかかりました。しかし、GNPを用いることで、より低いコストで高い成果を得ることができます。さらに、この方法はカスタマイズが非常に柔軟であり、特定のドメインや業界に合わせて調整することが可能です。

この記事では、この興味深い研究について詳しく解説していきます。

**参照論文情報**

・タイトル：Graph Neural Prompting with Large Language Models  
・著者：Yijun Tian, Huan Song, Zichen Wang, Haozhu Wang, Ziqing Hu, Fang Wang, Nitesh V. Chawla, Panpan Xu  
・所属：University of Notre Dame, Amazon  
・URL：[https://doi.org/10.48550/arXiv.2309.15427](https://doi.org/10.48550/arXiv.2309.15427)

## 従来の課題と背景

### LLMの限界と課題

LLMは、質問応答などの多くのタスクで優れた性能を発揮しています。しかし、事実に基づいた正確な知識を正確に捉える能力には限界があります。LLMは基本的には訓練データに基づいて予測を行うため、訓練データに応じて誤った情報や偏見を出力するリスクはゼロではありません。

### コストの問題

LLMを知識グラフ（KG）で強化するというアイデアは以前から存在していますが、その実装には大きくコストがかかります。LLMには多数のパラメータがあり、調整するためには膨大な計算リソースが必要です。知識グラフとテキストデータを共同で訓練する場合には多くの資源が必要となります。

### 既存のアプローチとその限界

既存のアプローチでは、知識グラフから得られるトリプル（主語、述語、目的語の組み合わせ）をLLMに直接供給する方法があります。しかし、知識グラフがさまざまな外部コンテキストを含む可能性があり、その結果として大量のノイズを導入する可能性があります。

以上のような背景から、本研究では、知識グラフを事前学習済みLLMに効果的に統合する新しい方法を提案しています。

**本研究の関連研究：**[LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト](https://ai-data-base.com/archives/55711)

![[LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』 - AIDB/AIDB_75018_3-1024x571.jpg]]

Amazonなどの研究者らは、外部の知識グラフとLLMをシームレスに接続するフレームワーク『Graph Neural Prompting（GNP）』を考案しました。以下の主要なコンポーネントで構成されています。

1.  標準的なグラフニューラルネットワークエンコーダ
2.  クロスモダリティプーリングモジュール
3.  ドメインプロジェクタ
4.  自己教師付きリンク予測オブジェクト

### 1\. グラフニューラルネットワークエンコーダ

GNPは、まずグラフニューラルネットワーク（GNN）を用いて、知識グラフ内の複雑な情報をエンティティ/ノードの埋め込みにエンコードします。知識グラフの各エンティティや関係性が数値ベクトルとして表現され、後続の処理で効率的に扱えるようにするための要素です。

### 2\. クロスモダリティプーリングモジュール

次に、クロスモダリティプーリングモジュールがテキスト入力と関連する最も関連性の高いノードの埋め込みを特定します。この要素により、テキストと知識グラフの間で最も重要な情報が統合され、一つのグラフレベルの埋め込みにまとめられます。

### 2\. ドメインプロジェクタ

このグラフレベルの埋め込みは、ドメインプロジェクタを通して、テキストとグラフの間の固有の違いを橋渡しします。この要素により、両者の情報が効果的に統合され、より高度なタスク遂行が可能になります。

### 4\. 自己教師付きリンク予測オブジェクト

最後に、自己教師付きリンク予測オブジェクトがモデルの性能をさらに向上させるために導入されます。このオブジェクトは、知識グラフ内のエンティティ間の関係を予測することで、モデルがより正確な知識を獲得できるようにします。

GNPのこれらのコンポーネントは、連携してLLMのパフォーマンスを大幅に向上させる役割を果たします。特に、このフレームワークは、既存のLLMに対してプラグアンドプレイ可能であり、柔軟なカスタマイズと効率的な実装が可能です。

****本研究の**関連研究：**[LLMに自身のハルシネーション（幻覚）を「自覚」させ、減らす方法](https://ai-data-base.com/archives/55232)

## 性能評価実験

ここから限定コンテンツ

### 実験の設定とデータセット

この研究では、性能評価のために複数の公開ベンチマークデータセットが用いられています。特に注目すべきは、2つの主要なタスクに焦点を当てている点です。

#### タスク1. 常識推論

このタスクでは、一般的な常識や事実に基づいて質問に答える能力を評価します。使用されたデータセットには、OpenBookQA、AI2 Reasoning Challenge、Physical Interaction Question Answering、RiddleSenseなどがあります。人々が日常生活で遭遇するような状況や問題が含まれています。

#### タスク2. バイオメディカル推論

このタスクでは、医学や生物学に関する専門的な知識を用いて質問に答える能力を評価します。PubMedQAやBioASQといった、バイオメディカル分野に特化したデータセットが使用されています。

### 知識グラフの選定

実験では、各タスクに適した知識グラフが選定されています。常識推論タスクでは、一般的な常識知識を含むConceptNetが用いられています。一方で、バイオメディカル推論タスクでは、健康と医学に関する情報を集約したUnified Medical Language System（UMLS）が使用されています。

このように、性能実験は非常に綿密に設計されており、多角的な評価が行われています。

****本研究の**関連研究：**[GPT-4などのLLMに「自らの論理的な整合性をチェック」させるフレームワーク『LogiCoT』と実行プロンプト](https://t.co/1EzfpsxORT)

## 実験の結果

![[LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』 - AIDB/AIDB_75018_4.jpg]]

### パフォーマンスが改善

この研究では、GNPの効果を評価するために、いくつかのベンチマークデータセットを用いて実験が行われました。その結果、ベースラインの性能が+13.5%改善されました。GNPが知識グラフを効果的に活用し、LLM（Language Model）の性能を向上させることができることを示す強い証拠ですね。

### LoRAとの組み合わせ

さらに、パラメータ効率的なアプローチであるLoRA（Low-Rank Approximation）を用いてLLMを微調整すると、性能がさらに+1.8%改善されました。この結果は、GNPが他の最先端の手法とも効果的に組み合わせることができることを示しています。

![[LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』 - AIDB/AIDB_75018_2-1024x817.png]]

なお、LLMの設定（LLM FrozenとLLM Tuned）や使用された知識グラフ（ConceptNetやUMLS）によっても異なることが確認されました。

****本研究の**関連研究：**

## 主な結論

![[LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』 - AIDB/AIDB_75018_5.jpg]]

### GNPの効果性

この研究によると、GNPは、LLMに有益な知識を効果的にエンコードすることができます。GNPは複数の公開ベンチマークデータセットで優れた性能を示しました。

### パフォーマンスの向上

また、GNPは、モデルのパラメータが固定された状態のLLM（Frozen LLM）におけるベースラインを+13.5%改善することができました。さらに、パラメータ効率的なアプローチであるLoRAを用いてLLMを微調整すると、+1.8%の改善が見られました。

GNPはLLMのパフォーマンスを大幅に向上させることができる有望なフレームワークであり、その効果性は複数のデータセットと設定で確認されました。

論文によると、これはKG（知識グラフ）から有益な知識を学び、それをLLMに効果的に統合する初の試みであるとされています。

## 注意点

### LLMのパラメータ数とダウンストリームタスクへの適応

LLMは非常に多くのパラメータを持っています。知識グラフを味方につけたLLMは協力ですが、ダウンストリームタスク（特定のタスクへの適用）において課題となる可能性があります。

### 効果の依存性

GNPの効果は、LLMのサイズや設定に依存する可能性があります。

## メリット

### 信頼性の向上

GNPの一つの大きなメリットは、知識グラフを専門家によって監修されることで、情報ソースを信頼できるということです。すると必然的に、モデルが出力する情報の正確性と信頼性が向上します。

### 特定のドメインへの特化

GNPは特定のドメインや業界に大きく特化する能力があります。正確な情報や詳細な知識が必要な業界や専門分野での問題解決に非常に有用です。

### 説明可能なAIへの一歩

GNPを使用することで、モデルの判断根拠が明確になります。いわゆる説明可能なAIに一歩近づく意味があり、モデルの判断がどのように行われたのかを理解しやすくします。

このように、GNPはコストとカスタマイズ性だけでないメリットを多く提供します。

## まとめ

この記事では、Amazonなどの研究者によって開発されたGraph Neural Prompting（GNP）というフレームワークについて詳しく解説しました。GNPは、LLMに知識グラフを効果的に統合することで、タスク遂行能力を大幅に向上させることができます。本フレームワークは、信頼性、特定のドメインへの特化、説明可能なAIといった多くのメリットを持っています。

従来の課題としては、LLMが持つ情報の正確性とコストが挙げられましたが、GNPはこれらの課題に対する有望な解決策を提供しています。性能実験では、公開ベンチマークデータセットを用いて、常識推論とバイオメディカル推論のタスクで優れた結果を出しています。

注意点としては、ダウンストリームタスクへの適応が困難になる可能性が挙げられています。また、効果はLLMのサイズや設定に依存する可能性があります。
