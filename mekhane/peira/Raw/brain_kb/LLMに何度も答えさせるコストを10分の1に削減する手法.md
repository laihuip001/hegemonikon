---
created: 2026-01-01T11:16:47 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/97310
author: AIDB Research
---

# LLMに何度も答えさせるコストを10分の1に削減する手法 - AIDB

> ## Excerpt
> この記事では、LLMに何回か答えを出させて多数決をとるときの、計算コストを減らす方法を紹介します。 LLMは1回の回答だけでは不安なことがあり、何度か答えを出して多数決をとる方法がよく使われます。ただし、この方法は計算に時間やコストがかかります。 そこで、問題ごとに必要な回数だけ答えを出すことと、複数のLLMをうまく組み合わせること、どちらも計算量を大きく減らせることがわかりました。 どうやってそ…

---
この記事では、LLMに何回か答えを出させて多数決をとるときの、計算コストを減らす方法を紹介します。

LLMは1回の回答だけでは不安なことがあり、何度か答えを出して多数決をとる方法がよく使われます。ただし、この方法は計算に時間やコストがかかります。

そこで、問題ごとに必要な回数だけ答えを出すことと、複数のLLMをうまく組み合わせること、どちらも計算量を大きく減らせることがわかりました。

どうやってそれを実現するのか、見ていきましょう。

![[LLMに何度も答えさせるコストを10分の1に削減する手法 - AIDB/AIDB_97310-1024x576.png]]

**本記事の関連研究**

-   [生成回数を増やすだけでLLMの性能が大幅に向上するシンプルな法則　実用上のポイント](https://ai-data-base.com/archives/75838)
-   [LLMの推論能力は単純に文脈を繰り返し提示するだけでも大幅に向上　最大で30%改善](https://ai-data-base.com/archives/76967)

## 背景

ここ数年、注目されているのは、LLMが持つ複雑な推論の力です。数学の問題を解いたり、論理的に物事を判断したりする能力のことです。この分野でブレイクスルーとなったのが、「Chain-of-Thought（思考の連鎖）」という手法でした。答えをいきなり出すのではなく、人間のように考える過程を言葉で説明しながら答えを導き出す方法です。たとえば「ステップ1では…、ステップ2では…」と順を追って考えを進めることで、モデルの正解率が大きく向上することが分かっています。

そして今は、答えを出すときに多くの計算力を使って、より良い答えを出そうという新しい考え方が注目されています。その中でも代表的な方法が、同じ質問をLLMに何回も（N回）答えさせて、その中で一番いいものを選ぶというものです。答えの選び方にはいろいろありますが、一番かんたんで効果があるのが「多数決」です。つまり、いちばん多く出てきた答えを正解として選ぶ方法です。

多数決には大きなメリットがあります。むずかしい仕組みを実装せず安定して性能が上がっていくという特徴があります。実際、いくつものデータセットで、生成回数Nを増やすほど正解率が上がることが確認されています。

理論的には、無限に答えを出して多数決をとれば、そのモデルが出せるいちばん良い答えが得られると考えられます。でも、実際には無限に答えを出すことはできません。だから、計算コスト（どれだけ計算力がかかるか）とのバランスがとても大事になります。限られた計算リソースの中で、どうすればできるだけ効率よくこの理想に近づけるか。本記事では、そのような現実的な問題を取り上げます。

ここから限定コンテンツ

### **忙しい人向けに、重要なポイント5選**

1.  問題に合わせて生成回数を変え、計算コストを大きく削減できる
2.  十分な確信が得られた時点で自動的に生成を止められる
3.  複数のLLMを組み合わせることで、単体モデルより高い精度が出せる
4.  5〜20問程度の正解データがあれば、実用的な組み合わせの重みを見つけられる
5.  答えの選び方では、多数決がもっともシンプルで安定して高精度だった

**参照文献情報**

-   タイトル：Best-of-∞– Asymptotic Performance of Test-Time Compute
-   URL：[https://doi.org/10.48550/arXiv.2509.21091](https://doi.org/10.48550/arXiv.2509.21091)
-   著者：Junpei Komiyama, Daisuke Oba, Masafumi Oyamada
-   所属：New York University, RIKEN AIP, Institute of Science Tokyo, NEC Corporation

## 計算効率を大幅改善する考え方「適応的サンプリング」

背景で説明したように、理想を言えば、無限に答えをたくさん出して、その中でいちばん多く出たものを選べば、もっとも良い結果が得られます。

![[LLMに何度も答えさせるコストを10分の1に削減する手法 - AIDB/AIDB_97310_1-1024x287.png]]

生成回数Nを増やすとBest-of-Nの正答率が上がり（特にN≈10〜100で顕著）、やがて理想的な上限（Best-of-∞）に近づく

でも実際には、計算にかかるコスト（時間やお金）に限りがあるので、現実には出せる回数は限られています。その中でどうすれば、少ない回数でも理想の答えにできるだけ近づけるのでしょうか。

そこで出てきたアイデアは、「適応的サンプリング」です。どの問題にも同じ回数だけ答えを出すのではなく、問題の内容に合わせて出す回数を変えるという考え方です。たとえば、かんたんな問題であれば少ない回数で終わらせて、むずかしい問題であれば多くの答えを出すようにします。

たとえば、ある言語モデルに数学の問題を解かせたとき、3回答えを出させたら全部同じだったとします。このときは、もうそれ以上答えを出しても同じ結果になる可能性が高いので、そこで止めても大丈夫でしょう。反対に、6回答えを出してもバラバラな場合は、正しい答えを見つけるにはもっと多く出す必要がありそうです。

### 生成停止のタイミングを判定

ここで大事になるのが、「どのタイミングで答えの生成をやめるか」という判断のルールです。

少し専門的な話になりますが、LLMが出す答えの出やすさのパターンを、統計的な方法でモデル化する必要があります。ただし難しいのは、LLMがどんな答えを、どれくらいの確率で出すかが、最初はわからないという点です。たとえば、ある問題では「42」と「105」という2つの答えだけが出るかもしれませんし、別の問題では「111」「1」「2」「702」のように4つの答えが出てくるかもしれません。このように、どんな種類の答え（これを専門的には「サポート」と呼びます）が出てくるかは、事前にはわからないのです。

こうした問題に対応するために、「ディリクレ過程」という統計モデルを使います。まだはっきり分かっていない答えの出やすさを、柔軟に表現できる便利な考え方です。

答えをどんどん生成していくと、少しずつデータがたまっていきます。たとえば、10回生成して「答えA」が6回、「答えB」が3回、「答えC」が1回出たとします。このとき、「答えAが本当にいちばん多い答えだ」とどれくらい信じてよいのでしょうか。

この「どれくらい信じられるか」を数で表すために、「ベイズ因子」という指標を使います。ベイズ因子とは、2つの考え（仮説）を比べるための統計の道具です。

ここでは、次の2つの仮説を比べています。

1つ目の仮説は「今いちばん多く出ている答えAは、本当はいちばん多い答えではない」というもの。  
2つ目の仮説は「答えAが本当にいちばん多い答えである」というものです。

観測されたデータ（ここでは生成された答えの回数）をもとに、どちらの仮説がより信頼できるかを数値で表したのがベイズ因子です。この値が大きければ大きいほど、「答えAが本当にいちばん多い答えだ」と信じられる度合いが高いという意味になります。

### 数学的に正解への到達を保証

この「適応的サンプリング」の方法には、理論的な裏付けもあります。簡単に言えば、「最大で何回まで生成するか」と「どのくらいの確信が持てたら生成を止めるか（閾値）」を十分に大きく設定すれば、ほぼ間違いなく正しい多数派の答えにたどり着ける、ということが保証されています。

つまり、もし無限に答えを生成できるなら、確実に正解が得られるという理想がありますが、この方法では、限られた回数の中でも、それと同じような結果を統計的に得られるのです。

![[LLMに何度も答えさせるコストを10分の1に削減する手法 - AIDB/AIDB_97310_2-1024x558.png]]

適応的サンプリング（ベイズ因子による生成停止）を用いると、より少ない生成回数・トークン数で高精度を達成できる

実際の仕事の現場では、1つのLLMだけでなく、いくつかの違うLLMを使える場合も多いでしょう。そうなると、「いくつかのモデルをうまく組み合わせた方が、1つのモデルだけを使うよりも良い結果が出るのではないか」という考えが自然に出てきます。

### Best-of-1では単体の最強モデルに勝てない

まずは、いちばん基本的なケースとして、「1回だけ答えを出す」場合を考えてみましょう（この方法は「Best-of-1」と呼ばれます）。このときに、複数のモデルを組み合わせて使う意味があるのでしょうか。

答えは「いいえ」です。1回しか答えを出さないなら、いちばん性能の良いモデル1つだけを使うのがいちばん効率的です。たとえば、モデルAの正解率が80%、モデルBの正解率が60%だったとします。このときに、モデルAを70%、モデルBを30%の確率で使うようにすると、全体としての正解率はモデルAの80%よりも低くなってしまいます。ですから、1回きりで答えを出す場合は、迷わずいちばん良いモデルだけを使うのが正しい選択になります。

### 弱いモデルも全体精度を向上させる

ところが、何回も答えを出して多数決をとるようなケースを考えると、話は変わってきます。ここでポイントになるのが、「補完性」という考え方です。

たとえば、30問のテストがあるとします。モデルAは27問正解できますが、残りの3問はどうしても間違えてしまいます。一方、モデルBは全体としての正解数は少なく、22問しか正解できません。でも、実はモデルAが苦手な3問のうち1問はモデルBが正解できるとします。この場合、モデルAだけを使うと正解できるのは最大で27問ですが、モデルAとモデルBをうまく組み合わせて使えば、28問正解できるかもしれない、というわけです。

例えば、「AIME2025」という難しい数学のテストで、GPT-OSS-20Bというモデルは正解率90.0%、Nemotron-Nano-9B-v2というモデルは73.0%でした。でも、この2つを組み合わせて使ったところ、正解率が93.3%まで上がりました。つまり、1つ1つのモデルでは限界があっても、得意なところが違えば、チームとしての力を大きくすることができる、ということです。

### 最適な重みを計算

では、どのモデルをどれくらいの割合で使えばいいのでしょうか。これを手作業で決めるのはとても大変です。モデルが3つあれば組み合わせのパターンは数えきれないほどありますし、10個もあればなおさらです。

しかし、この問題は「混合整数線形計画法」という最適化の方法で解けます。いくつもの条件の中から、最も良い答えを自動で見つけるための数学的なツールです。少し専門的な話になりますが、仕組みを簡単に説明します。

各問題が正解になる条件を「多面体（ためんたい）」という図形の形で表します。たとえば、問題1が正解になるのは「モデルAの重みとモデルBの重みのバランスがこの範囲にあるとき」というふうに、空間の中の一部の領域として条件を表すことができます。そして、できるだけたくさんの問題が正解になるような重みの組み合わせを見つける問題に置き換えます。

![[LLMに何度も答えさせるコストを10分の1に削減する手法 - AIDB/AIDB_97310_3-1024x722.png]]

複数のモデルを重みづけして一緒に使うと、単体モデルより成績が良くなり、生成回数を増やすほどその差がはっきりする

こうした形に直すことで、オープンソースの最適化ソフトを使って、自動で最適な重みを計算できるようになります。実際には、10個くらいのLLMと1,000問くらいの問題であれば、実用的な時間内で解けることが確認されています。

さらに、最適な答えが複数ある場合には、「マックスマージン」という考え方も使えます。これは、もっとも安定した重みの組み合わせを選ぶ工夫です。いくつか正解になりそうな候補があるときに、少し条件が変わっても正解であり続けるような「余裕のある」組み合わせを選ぶという考え方です。

## 手順をまとめると

1.  正解の決め方と入出力の形を決め、最大回数Nと止める基準（例：1位の割合が70％以上）を決める
2.  モデルに1回だけ答えを出させ、正規化して同じ答えごとのカウント表に加える
3.  いちばん多い答えの割合や1位と2位の差を計算し、止める基準を満たすか確認する
4.  基準を満たしたら終了して1位の答えを返し、満たさなければもう1回生成する
5.  2〜4を繰り返し、回数がNに達したらその時点の1位の答えを返す
6.  複数モデルを使う場合は、各回に使うモデルをあらかじめ決めた割合（例：A50％・B30％・C20％）で選ぶ
7.  5〜20問の正解付きミニテストを走らせ、当たりの多いモデルの割合を少し増やすように重みを調整する
8.  似たタスクではその重みをまず流用し、最初の数問の結果を見て微調整する

## 大規模実験で提案手法の有効性を実証

上記手法の有効性を確かめるために大規模な実験が行われました。

実験の対象となったのは、全部で11種類のオープンウェイト（誰でも使える公開された）LLMです。モデルの大きさは、4億パラメータのものから32億パラメータのものまで、さまざまです。

-   Phi-4-reasoning
-   GPT-OSS-20B
-   AM-Thinking-v1
-   EXAONE-Deep-32B
-   NVIDIA-Nemotron-Nano-9B-v2
-   MetaStone-S1-32B
-   Qwen3-4B
-   Qwen3-14B
-   Qwen3-30B-A3B-Thinking-2507
-   LIMO-v2
-   Datarus-R1-14B-preview

テストに使われた問題セットは4つあります。

|    データセット    | 問題数 |         内容／レベル         |   答え形式    |
|--------------|-----|------------------------|-----------|
|   AIME2024   | 30  |    高校生向け数学オリンピック予選     | 整数（1–999） |
|   AIME2025   | 30  |    高校生向け数学オリンピック予選     | 整数（1–999） |
| GPQA-DIAMOND | 198 | 博士課程レベルの生物・物理・化学（選択問題） |    選択式    |
|   MATH500    | 500 |   高度な数学（代数・幾何・確率など）    |  多様（難問）   |

どれもとてもむずかしい問題ばかりです。

注目すべきなのは、生成された答えの数です。LLMと問題の組み合わせごとに、最低でも80回は答えを出しています。

では、なぜこれほど多くの生成が必要だったのでしょうか。それは、理想とされる「無限に答えを出す」場合の性能を、できるだけ正確に予測するためです。80回も答えを出せば、そのモデルが本来持っている力がどれくらいか、おおよそ把握できるようになるからです。

### 適応的サンプリングで計算量を2分の1から10分の1に削減

最初に、提案された適応的サンプリングの効果が検証されました。

結果は明確でした。たとえば、GPT-OSS-20BというモデルがMATH500というテストで使われた場合、従来の方法（すべての問題に対して同じ回数だけ答えを生成する方法）で10回生成されたのと同じ精度が、適応的サンプリングによって平均3回の生成で達成されました。

また、従来の方法で100回生成された場合と同じ精度も、平均10回程度の生成によって達成されています。つまり、計算量が2分の1から10分の1にまで削減されたことになります。

この効果は、生成されたトークン数（文字列の単位）でも確認されました。トークン数は、実際の計算コストに直結する指標として使われていますが、適応的サンプリングを用いることで、同じ精度を得るために必要なトークン数も大きく減りました。

### アンサンブルが単体モデルを上回る

次に、複数のLLMを組み合わせたときに、どれくらい効果があるのかが確かめられました。たとえば、EXAONE-Deep-32B、MetaStone-S1-32B、Phi-4-reasoning、Qwen3-30B-A3B-Thinking、GPT-OSS-20Bの5つのモデルを使い、GPQA-DIAMONDというテストで組み合わせてみたところ、どのモデルを1つだけ使うよりも高い精度が出ました。

モデルごとの使い方の割合（重み）は自動で計算されました。この例では、およそ（0.02, 0.03, 0.27, 0.41, 0.26）という割合になりました。つまり、Qwen3-30B-A3B-Thinkingを一番多く使い、その次にPhi-4-reasoningとGPT-OSS-20Bをよく使う、というバランスが一番良かったということです。生成する回数が5回を超えると、このようなモデルの組み合わせ（アンサンブル）は、どの場合でも単体の最強モデルより良い結果を出しました。

![[LLMに何度も答えさせるコストを10分の1に削減する手法 - AIDB/AIDB_97310_6.png]]

重みを学習するために使う問題数を増やすほど最終的な性能（best-of-∞）が上がり、少数問でもほぼ最適な重みが得られて最終的にアンサンブルが単体モデル（90.0%）を上回り93.3%に達する

### わずか5問で実用的な重みを学習

さらに、モデルの重み（使う割合）を最適に決めるために、どれくらいの数の問題が必要かが調べられました。AIME2025というテストを使った実験では、たった5問ほどの正解データがあれば、最強の1つのモデルと同じくらいの性能を出せる重みが得られることがわかりました。10問から20問ほど使えば、ほぼ最適に近い重みを見つけることができます。

![[LLMに何度も答えさせるコストを10分の1に削減する手法 - AIDB/AIDB_97310_5-1024x358.png]]

5つのモデルを重み付けして組み合わせると、生成回数が5回以上でどの単体モデルより成績が良くなり、理想（無限回）の精度に近づく

この結果は、実際の仕事でもとても大事な意味を持っています。というのも、新しいタスクに取りかかるときに、たくさんのデータを集める必要はなく、数問だけ正解を確認すれば、効果的なモデルの組み合わせを見つけられるということだからです。

### 異なるタスク間でも重みが転用可能

また、あるタスクで決めたモデルの重み（使い方の割合）を、別のタスクにも使えるかどうかが調べられました。AIME2024で学習した重みを、AIME2025という別のテストに使ってみるという実験です。3つのモデルの組み合わせで、全部で165通りのパターンを試したところ、そのうち106通り（全体の64.2%）で、アンサンブルが単体の最強モデルと同じかそれ以上の性能を出しました。

![[LLMに何度も答えさせるコストを10分の1に削減する手法 - AIDB/AIDB_97310_4-1024x345.png]]

あるタスクで学習したモデルの重みを別の似たタスクに使い回しても、多くの場合で性能が保たれる（実験では約64%の組み合わせで単体最強モデルと同等かそれ以上の成績が出た）

この結果も、実際の現場にとってはうれしい発見です。なぜなら、似たようなタスクであれば、一度決めた重みをそのまま再利用できる可能性があるからです。

### 多数決が他の選択方法より優れている

最後に、そもそも「多数決」という方法が、ほかの答えの選び方と比べてどれだけ効果があるのかが調べられました。比較の対象になったのは、報酬モデル（答えの良さに点数をつけるモデル）を使う方法や、LLM自身にどれが良い答えかを選ばせる方法、またモデル自身の「自信の強さ（自己確信度）」をもとに選ぶ方法などです。

AIME2025というテストで、GPT-OSS-20Bというモデルを使って、5つの答えの中から1つを選ぶ実験をしたところ、多数決による正解率は85.4%でした。一方、報酬モデルを使った方法では約80%、LLM自身に選ばせる方法は約82%、自己確信度を使う方法では約76%の正解率でした。つまり、多数決の方法がいちばん良い結果を出したのです。

この傾向は、他のLLMや別のデータセットでも同じように見られました。

つまり、多数決は、複雑な仕組みを使わなくても、シンプルでありながら非常に効果的な方法だということが確かめられました。

## まとめ

LLMに何度も答えを出させて多数決をとる「Best-of-N」という方法を、統計の視点から見直した事例を紹介しました。

少ない計算で理想的な性能に近づけるために、2つの工夫が有効だと示されました。

1つ目は、問題に応じて生成回数を調整する「適応的サンプリング」。計算量を大きく減らせます。

2つ目は、複数のLLMを組み合わせて使う「アンサンブル」。わずか数問の正解データがあれば、有効な使い方が見つかります。

実験では、11種類のモデルと4つの難問データセットで数百万回の生成を行い、方法の効果が確認されました。

**本記事の関連研究**

-   [生成回数を増やすだけでLLMの性能が大幅に向上するシンプルな法則　実用上のポイント](https://ai-data-base.com/archives/75838)
-   [LLMの推論能力は単純に文脈を繰り返し提示するだけでも大幅に向上　最大で30%改善](https://ai-data-base.com/archives/76967)
