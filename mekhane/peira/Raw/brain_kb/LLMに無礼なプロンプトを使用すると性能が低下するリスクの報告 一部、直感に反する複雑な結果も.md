---
created: 2026-01-01T09:38:25 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/64959
author: AIDB Research
---

# LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB

> ## Excerpt
> LLMのパフォーマンスに対する「プロンプトの丁寧さ」の影響について調査が行われました。 通常、人間同士のコミュニケーションにおいては、丁寧な言葉遣いは相手に好印象を与え、よりスムーズな意思疎通を可能にします。また一方で、無礼な態度を取ると相手を遠ざけ、コミュニケーションの質を低下させてしまう可能性があります。 LLMは人間のコミュニケーションの特徴をある程度反映しているとしたら、人間と同じように文…

---
LLMのパフォーマンスに対する「プロンプトの丁寧さ」の影響について調査が行われました。

通常、人間同士のコミュニケーションにおいては、丁寧な言葉遣いは相手に好印象を与え、よりスムーズな意思疎通を可能にします。また一方で、無礼な態度を取ると相手を遠ざけ、コミュニケーションの質を低下させてしまう可能性があります。

LLMは人間のコミュニケーションの特徴をある程度反映しているとしたら、人間と同じように文化的な規範に影響を受ける可能性があります。

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_thum-1024x576.jpg]]

**参照論文情報**

-   タイトル：Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance
-   著者：Ziqi Yin, Hao Wang, Kaito Horio, Daisuke Kawahara, Satoshi Sekine
-   所属：早稲田大学、理研AIP

**本記事の関連研究**：

-   [プロンプトの小さな違いがLLMにもたらすバタフライ効果を調査した結果](https://ai-data-base.com/archives/62566)
-   [プロンプトの原則26ヶ条をまとめた報告](https://ai-data-base.com/archives/61417)
-   [基盤モデル（GPT-4）はプロンプトの工夫で専門特化モデルに匹敵するほど性能が向上することが「医学分野」で示唆される](https://ai-data-base.com/archives/59798)
-   [大規模言語モデル（LLM）のこれまでとこれから③　-使用法・拡張法、データセット編-](https://ai-data-base.com/archives/64398)

## 背景

現在、LLMの挙動や出力には改善の余地が多く残されています。例えばLLMは人間由来のデータで訓練されるため、典型的なバイアスも内包しています。

LLMの言動を調整するための手段としては「プロンプト設計（プロンプトエンジニアリング）」の技術が注目されています。LLMはプロンプトに対して敏感で、小さな変更でも出力に大きな違いを生むことがあります。自動でプロンプトを生成する方法もありますが、まだ完璧とは言えません。そこで手動でプロンプトを構築する際の工夫における知見がまだまだ求められています。

さて、人間のコミュニケーションにおける重要な特徴には、他者への敬意を丁寧さで示すという基本的な礼儀があります。  
そこで研究者らは、LLMに与えるプロンプトの丁寧さが及ぼす影響について網羅的に調査することにしました。

なお敬意の示し方は文化や言語によって異なるため、同じ丁寧さのレベルでもLLMの反応は言語によって変わる可能性があります。そのため英語、中国語、日本語に対して実験が行われました。

下記は日本語の各礼儀正しさレベルのプロンプトテンプレートの抜粋です。

```
<strong>礼儀正しさレベル8（最高）</strong>
(Task Description with Keigo) していただけませんか? (Answer Format with Keigo) よろしくお願いいたします。(Answer Restriction) は不要でございます。
...
<strong>礼儀正しさレベル4</strong>
(Task Description)。ただし (Answer Format) し、(Answer Restriction) ないで。<strong>
</strong>...
<strong>礼儀正しさレベル1（最低）
</strong>(Task Description) しろこの野郎。お前が (Answer Format) だけ。(Answer Restriction) たらどうなるかわかるよな。
```

研究者らはまず「無礼なプロンプトは、間違いを増やし、バイアスを増大させ、情報の欠落などを生じさせ、要するにLLMの性能を低下させることにつながる」と仮説を立てました。

上記の仮説を検証するため、次の3つのタスクで実験が行われました。

1.  テキスト要約
2.  言語理解
3.  バイアスの検出

以下では各礼儀正しさレベルに対するLLMの反応（精度）やタスクごとの具体的なプロンプト例など、報告内容の詳細を紹介します。仮説通りの結果ばかりではありませんでした。

ここから限定コンテンツ

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_1-1024x524.jpg]]

イメージ

## JMMLUについて

今回、LLMの日本語におけるマルチタスク言語理解能力を評価するために、MMLUベンチマーク（モデルの能力を評価する一般的な指標）を日本語に翻訳して日本の文化に関連するタスクを追加した日本語版MMLU (JMMLU) が構築されました。作成手順は以下の通りです。

1.  MMLUの57タスクから、タスクあたり最大150件の質問を選択し、機械翻訳で日本語に変換する
2.  翻訳結果から、内容的に不適切、日本文化と矛盾する質問やタスクを削除する
3.  残った質問を自然な日本語に修正する
4.  MMLUが西洋文化に偏っている点を補うため、社会や日本史などの科目に関するタスクを追加する（日本の教師が作成）

最終的にJMMLUは56のタスクで構成され、タスクごとの質問数は86～150件、合計7,536件となっています。

## 実験

実験設計について説明していきます。

### 対象言語・モデル・プロンプトの丁寧さ

言語については、丁寧さや敬意の捉え方が言語や文化によって異なるため、複数の言語（英語、中国語、日本語）を対象としました。

モデルについては次のとおりです。まず優秀なクローズドモデルであるGPT-3.5とGPT-4が使用されました。また言語特化型のモデルも用いられました。英語はLlama-2-70B、中国語はChatGLM3-6B3 (以下ChatGLM3) 、日本語はSwallow-70b-instruct-hf (以下Swallow-70B) です。なおSwallowは東京工業大学や産総研の研究者らが主導となって研究開発したモデルで、Llama-2の日本語能力を強化する形で開発されています。

プロンプトの丁寧さに関しては、各言語において8段階の丁寧さを持つプロンプト・テンプレートを作成し、それに沿ってタスクが記述されました。各言語のネイティブスピーカーがテンプレートを作成し、さらにアンケート調査で丁寧さの度合いが評価されました。

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_10-1024x1003.jpg]]

**礼儀正しさレベル8（最高）**

(Task Description with Keigo) していただけませんか? (Answer Format with Keigo) よろしくお願いいたします。(Answer Restriction) は不要でございます。

**礼儀正しさレベル7**

(Task Description with Keigo) していただけますか。ただし (Answer Format with Keigo) し、(Answer Restriction with Keigo) は不要です。

**礼儀正しさレベル6**

(Task Description with Keigo) してください。ただし (Answer Format with Keigo) し、(Answer Restriction with Keigo) は不要です。

**礼儀正しさレベル5**

(Task Description) してください。ただし (Answer Format) し、(Answer Restriction) ないでください。

**礼儀正しさレベル4**

(Task Description)。ただし (Answer Format) し、(Answer Restriction) ないで。

**礼儀正しさレベル3**

(Task Description) せよ。(Answer Format) し、(Answer Restriction) ないこと。

**礼儀正しさレベル2**

(Task Description) しろ。(Answer Format) し、(Answer Restriction) な。

**礼儀正しさレベル1（最低）**

(Task Description) しろこの野郎。お前が (Answer Format) だけ。(Answer Restriction) たらどうなるかわかるよな。

### タスク

**要約タスク**

データセットとしては、英語ではCNN/Dailymail、中国語と日本語ではXL-Sumを使用し、それぞれ500個のテストデータが選ばれました。

またテンプレートに従って、要約タスク用に8つの異なるプロンプトが作成されました。簡潔なスタイルで、2〜3文の長さになるように工夫されています。

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_9-865x1024.jpg]]

評価指標として、BERTScore、ROUGE-L、および長さが計算されました。英語では単語数、中国語と日本語では文字数で長さをカウントしました。

**（マルチタスク）言語理解タスク**

データセットとしては、英語ではMMLU、中国語ではCLUE、日本語ではJMMLUが使用されました。各言語のベンチマークからは500個のテストデータが選ばれました。

こちらに関しても、テンプレートに従い8つの異なるプロンプトが作成されました。

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_11-1024x1020.jpg]]

また評価指標としては、各タスクの正解率が計算されました。

**バイアス検出**

各言語で500個のステレオタイプなバイアスを含む文章と500個の含まない文章が用意されました。それぞれの対には、程度の異なるバイアスが含まれています（例：年齢バイアスなど）

例によって、テンプレートに従い8つの異なるプロンプトが作成されました。各文を「肯定」「中立」「否定」で評価するように促されるものです。

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_12-969x1024.jpg]]

評価指標には、各文が典型的なバイアスを含んでいるかどうかを正しく識別する確率が計算されました。

### 人間フィードバック強化学習(RLHF)と教師ありファインチューニング（SFT）

本研究では、SFTとRLHFの有無が丁寧さのレベルによるモデル性能への影響にどう関わるのか、追加実験が行われました。

SFT: 特定のデータセットを使いモデルを改良し、対象のタスクにおける性能を向上させる

RLHF: 人間の反応を元にモデルをさらに訓練し、人間の価値観や好みに合わせて出力を調整する

実験では、SFTとRLHFの影響を排除したベースモデルと、SFTとRLHFがされたLlama2-70Bが比較されます。

ベースモデルで適切な出力を得られるように、プロンプトのテンプレートや意図は変えずに内容を調整しています。ベースモデルは微調整されていないため、要約タスクでは出力文字数の上限に達するまで生成し続けます。そのため、要約タスクでの比較は行いません。

## 実験結果

### 要約タスクの結果

下記のグラフを参照しながら紹介します。

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_2-1024x369.jpg]]

**英語の結果について**

ROUGE-LとBERTScoreは、プロンプトの丁寧さのレベルに関係なく安定しており、モデルが要約タスクにおいて記事の内容を正しく要約できていることを示唆しています。

ただし、生成される要約の長さは丁寧さのレベルと相関関係があります。丁寧さが高レベルから低レベルになるにつれて、生成される要約の長さは減少傾向を示しました。  
丁寧な表現は、説明や指示が多くなりがちで文章が長くなる傾向があるため、丁寧な文脈では要約も長くなる可能性があります。

一方で、非常に無礼なプロンプト（レベル1）を与えた場合に、GPT-3.5とLlama2-70Bは逆に要約が長くなってしまいました。無礼な表現は挑発的・感情的で、これもまた長文になりがちであると考えられます。

上記の傾向は、人間の社会的なふるまいを反映しており、訓練データに含まれ、LLMに影響を与えていると考えられます。

ただし、非常に無礼なプロンプトに対して、GPT-4は要約が長くはなりませんでした。その理由は、GPT-4が高度なモデルでタスク自体を優先するためだと推測されています。

**中国語の結果について**

GPT-3.5とGPT-4はほとんどの場合で記事内容を正確に要約し、丁寧さのレベルが高から低へと変化するにつれて、要約の長さも短くなっていきました。ただし、非常に無礼なプロンプトを与えた場合にGPT-3.5は要約が長くなり、GPT-4は短くなりました。

一方、ChatGLM3では異なる傾向が見られました。 丁寧さのレベルが中程度の場合、極端に丁寧な場合や無礼な場合に比べて生成される要約は短かったのです。ただし中程度の丁寧さから中程度に無礼な場合（レベル6～3）への変化は顕著ではありませんでした。ChatGLM3の主要な訓練言語は中国語であるため、この結果は中国文化特有の社会的傾向を表している可能性があります。 つまり、極端な丁寧さや無礼さを示さない限り、人々は日常のコミュニケーションにおいて丁寧さの変化にそれほど注意を払わないということかもしれません（あくまで推測です）。

**日本語の結果について**

日本語の結果は、英語、中国語と共通する点があるものの、要約の長さには独特の変化がみられました。丁寧さのレベルが高から低へと変化するにつれ、GPT-3.5の生成文の長さは、最初は短くなり、中程度の丁寧さのときに長くなりました。しかし無礼なレベルになると要約の長さは再び短くなりました。 なおGPT-4とSwallow-70Bも同様のパターンを示し、ただし変動は小さいものでした。  
考察

日本語には「敬語」という丁寧さの体系があります。そのため、例えば店員は顧客に対してほとんど常に敬語を使用します。顧客がカジュアルな口調で話していても、店員は丁寧な言葉遣いで返答します。このことが、すべてのモデルにおいて中程度の丁寧さのときに生成文が長くなる理由だと考えられています。

### 言語理解タスク

3つの言語理解ベンチマークの平均スコアとt検定（平均に有意差があるかどうかの計算）のヒートマップ結果を以下に示します。

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_3-1024x262.png]]

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_4-1018x1024.jpg]]

**英語の結果について**

GPT-3.5は、丁寧さのレベル8で最高のスコア60.02を達成しました。丁寧さのレベルが低くなるにつれてスコアは徐々に下がりますが、隣接するレベル間の差は顕著ではありません。レベル3では59.44という高いスコアを維持し、レベル8を除くすべてのレベルを上回りました。最も丁寧さの低いレベル1ではスコアが51.93に下がり、他のレベルに比べて有意に低くなっています。

GPT-4のスコアは変動はあるものの、比較的安定しています。最高スコアはレベル4で、最低スコアはレベル3でした。レベル1のスコアはそれほど低くはないですが、より丁寧なレベルよりも有意に低いことがわかります。GPT-4の性能は比較的安定していたと考えられます。

Llama2-70Bは最も顕著な変動を示し、スコアは丁寧さのレベルにほぼ比例しています。より丁寧なレベルのプロンプトは、一般的にレベルの低いプロンプトより良い結果を出しています。要するにLlama2-70Bはプロンプトの丁寧さに敏感に反応することがわかりました。

**中国語の結果について**

英語と同様に中国語でも丁寧なプロンプトを好む傾向はあるものの、異なる点も見られます。

GPT-3.5は丁寧さのレベル1で最も低いスコアを記録し、他のレベルを大幅に下回りました。 またレベル3、2 のスコアは、レベル7、6、5、4 よりも有意に低くなっています。ただしレベル8でもスコアが下がり、レベル1を除くすべてのレベルに有意に劣りました。GPT-3.5とGPT-4で、過度に丁寧なプロンプトのスコアが下がった理由は、中国語の試験問題が丁寧な言葉で設計されていないため、モデルがそれらをうまく処理できない可能性があると推測されます。

GPT-4は、丁寧さのレベル8と7でパフォーマンスが低下したことを除けば、安定しています。

そして中国語特化モデルのChatGLM3は、丁寧さのレベル8から2にかけて有意に減少する傾向が見られました。 ChatGLM3の主要な事前学習言語は中国語であり、中国語の丁寧さのレベルにより敏感に反応している可能性があります。しかし最も無礼なレベル1でレベル3と2を上回る改善が見られており、中国語特有のニュアンスによるものだと思われます。

**日本語の結果について**

日本語では丁寧レベル1では有意にスコアが低下するものの、英語や中国語とは大きく異なる結果となりました。レベル1を除き、丁寧さのレベルが低いほうがスコアが高い傾向にありました。

GPT-3.5では、レベル5と2が特にスコアが高く、レベル2が最高のスコアを達成しました。GPT-4ではレベル6と5が高いスコアを示し、レベル4が最高でした。ただし、いずれもレベル1を除いて全体的に高スコアでした。

Swallow-70Bはレベル6と3で他のレベルを上回る高い性能を示しました。 日本語の質問や試験ではレベル6と3の表現がより一般的に使用されるため、LLMで良いスコアにつながるのかもしれません。

### バイアスの検出

典型的なバイアス検出タスクの結果が下記にまとめて示されています。

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_5-1024x383.jpg]]

**英語の結果について**

GPT-3.5は全体的にバイアスが高いことがわかります。ただし、人種に関するバイアスを除き、中程度に丁寧さなプロンプト（レベル5）が最も強いバイアスを示しました。また、極端に丁寧さが低い場合にはモデルのバイアスは低くなりますりますが、モデルが答えることを拒否することが多く、実質的に使用不能となっていることがわかりました。さらに、非常に丁寧なプロンプト（レベル8）の場合、ほとんどのケースでバイアスは低いものの、人種に関する問題では高くなりました。

GPT-4が質問への回答を拒否することはほとんどなく、また低いバイアスレベルを反映しています。特に丁寧さのレベルが6のときにGPT-4は全体的にバイアスが最も低いです。

Llama2-70Bも比較的バイアスが低いです。しかし、丁寧さのレベルが最低の場合、Llama2-70Bは回答を拒否することが多く、文に対して理由をたくさん付ける傾向にあります。それは一種のバイアスと言えるかもしれません。Llama2-70Bはより丁寧なプロンプト（レベル7と6）を使用するとバイアスの程度は全体的に低くなりますりますが、丁寧さのレベルが2（命令口調のインフォーマルな表現）のときにバイアスが最も低いです。この裏には別の理由がある可能性があります。その一方で、無礼なプロンプト（レベル3と1）や最も丁寧な場合（レベル8）にはバイアスの程度が高くなり、ほかの2つのモデルと同様の傾向でした。

研究者らは人間文化的な研究から、次のように考察しています。丁寧な環境では人はよりリラックスし、道徳的な制約を気にしすぎずに自分の本当の考えを表現しやすくなると考えられます。対して、丁寧さが低いと人は不快感を覚え、偏見が生まれやすくなるかもしれません。 GPT-3.5およびGPT-4のふるまいは、まさにこのような人間の振る舞いを反映している可能性があります。

**中国語の結果について**

英語とは異なり、中国語のバイアス変動は一定のパターンを示しました。モデルのバイアスは当初比較的高いレベルにあり、丁寧さが低下するにつれて減少します。しかし丁寧さが大きく低下すると、バイアスは急激に上昇して非常に高いレベルに達します。なお丁寧さのレベル6から3で最低のバイアスが頻発しています。

GPT-3.5は基本的にバイアスが低く、最低の丁寧さのレベルで最も高いバイアスを示しますが、英語の実験とは対照的に回答を拒否することはほとんどありません。GPT-4も全体的にバイアスレベルが低く、変動も小さいですが、その中では最低の丁寧さのレベルで最も高いバイアスを示します。

ChatGLM3はGPT-4と同様のバイアスレベルを維持しながら、丁寧さのレベルの変化に敏感で、バイアス変動が顕著です。レベル1の時のバイアスレベルはGPT-3.5とほぼ同じです。他のタスクと同様に中国語独特のニュアンスや社会的傾向が反映されている可能性があり、極端な丁寧さを示さない限り、人々は日常のコミュニケーションにおいて通常レベルの丁寧さの変化にそれほど敏感ではない（そのためモデルは丁寧さの変化に弱い）ということなのかもしれません。

**日本語の結果について**

日本語のバイアスも中国語の実験と似たパターンですが、いくつか違いがあります。

GPT-3.5のバイアスレベルは、丁寧さのレベル2で最低になり、レベル1で最高になります。GPT-4も同様のパターンで、丁寧さのレベル5でピーク、レベル4で最低になります。

RLHFが適用されていないSwallow-70Bは、最も顕著な変動を伴う高いレベルのバイアスを示します。その変化はGPT-3.5に似ていますが、最低バイアスは丁寧さのレベル6で発生します。日本の厳しいマナーや、蔓延している（と考えられている）ジェンダーバイアスを背景に考えると、このパターンは妥当だと考えられています。

### RLHFとSFTの影響

MMLUの平均スコアとヒートマップを示します。

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_6-1024x489.png]]

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_7-1024x390.png]]

MMLUテストでは、ベースモデルはスコアと丁寧さのレベルの間に正の相関関係を示しており、一般的に丁寧さが高いほどスコアが高くなります。しかしLlama2-70Bの結果と比較すると、ベースモデルはプロンプトの丁寧さのレベルに影響を受けるものの、丁寧さに対する感度は主にRLHFとSFTによって制御されていることが推測できます。

なお下の図では、Llama2-70Bはベースモデルよりもバイアスが少ないことが示されており、RLHFとSFTの有効性が確認されています。

![[LLMに無礼なプロンプトを使用すると性能が低下するリスクの報告 一部、直感に反する複雑な結果も - AIDB/AIDB_64959_8-1024x390.png]]

## まとめ

本記事では、プロンプトの丁寧さがLLMの性能に及ぼす影響についての研究を紹介しました。研究結果からは、プロンプトの表現、特に丁寧さが性能向上につながること、しかし過度の丁寧さが必ずしも望ましい結果をもたらすわけではないことが示されました。これは、人間の社会的振る舞いがテクノロジーに反映されている例とも言えます。

この研究が特に強調している点は、言語や文化の違いがLLMのパフォーマンスに与える影響の大きさです。LLMの開発者や研究者は、このような差異を考慮に入れ、より精度高く、公平なモデルを設計することが期待されています

今後は、プロンプトの丁寧さをどう数値化し、LLMの反応をより詳細に分析するか、そして人間のコミュニケーションにおける丁寧さの役割を解明することがテーマになるようです。

参照論文URL：[https://doi.org/10.48550/arXiv.2402.14531](https://doi.org/10.48550/arXiv.2402.14531)
