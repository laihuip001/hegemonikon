---
created: 2026-01-01T09:38:04 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/61651
author: AIDB Research
---

# LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』 - AIDB

> ## Excerpt
> 大規模言語モデル（LLM）は「ハルシネーション」と呼ばれる、事実とは異なる出力を生成することが問題視されています。 関連研究：LLMの誤り（ハルシネーション）発生原因と、「創造性と事実性のバランス」などの対策ロードマップ ハルシネーションへの対策は、出力を外部データと照合するなどが一般的ですが、対処療法と言えなくもありません。 今回研究者らは、LLMが出力を生成する際に「事実と非事実で異なる内部状…

---
大規模言語モデル（LLM）は「ハルシネーション」と呼ばれる、事実とは異なる出力を生成することが問題視されています。

**関連研究**：[LLMの誤り（ハルシネーション）発生原因と、「創造性と事実性のバランス」などの対策ロードマップ](https://ai-data-base.com/archives/58767)

ハルシネーションへの対策は、出力を外部データと照合するなどが一般的ですが、対処療法と言えなくもありません。

今回研究者らは、LLMが出力を生成する際に「事実と非事実で異なる内部状態を示す」という仮説に基づき、新しい検証アプローチ『LLMファクトスコープ』を開発しました。実験では、96%以上の精度で事実が判別できたと示されています。

本記事では、課題、アプローチの概要、実験結果を紹介します。

![[LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』 - AIDB/AIDB_61651_thum-1024x576.jpg]]

**参照論文情報**

-   タイトル：LLM Factoscope: Uncovering LLMs’ Factual Discernment through Inner States Analysis
-   著者：Jinwen He, Yujia Gong, Kai Chen, Zijin Lin, Chengan Wei, Yue Zhao
-   所属：SKLOIS Institute of Information Engineering, Chinese Academy of Sciences / School of Cyber Security, University of Chinese Academy of Sciences
-   URL：[https://doi.org/10.48550/arXiv.2312.16374](https://doi.org/10.48550/arXiv.2312.16374)

## 事実検証の課題

LLMは、複雑な言語パターンを駆使して、さまざまな分野で顕著な能力を発揮しています。

しかし、LLMはしばしば事実とは異なる出力を生成することがあり、この現象は「ハルシネーション」と呼ばれています。「ハルシネーション」は例えば医療や法律などの重要な分野では特に問題となってきます。LLMの信頼性を高める上では、出力が事実に基づくものかを検証する手段が必須です。

そこで今回研究者らは、人間のウソ検出器が行うように、LLMの内部状態を分析することで事実と非事実の出力を区別する手法を提案しています。

下のグラフは、事実データと非事実データにおける平均活性化レベルを層ごとに比較したグラフを示しています。

![[LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』 - AIDB/AIDB_61651_1-1024x855.jpg]]

研究者らは、この活性化レベルを”Siamese Network（シャムネットワーク）”で分析し、LLMが出力する内容が事実に基づいているかどうかを効果的に識別するアプローチを試しています。

なお本アプローチの名称は「LLMファクトスコープ（Factoscope）」と付けられました。

**本記事の関連研究**：

-   [「入力プロンプト」を最新情報で自動アップデート＆最適化する手法『FRESHPROMPT』がLLMの出力精度を飛躍的に上げる](https://ai-data-base.com/archives/58986)
-   [LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』](https://ai-data-base.com/archives/57018)

### パイプライン

LLMファクトスコープの基本は、

ここから限定コンテンツ

LLMの中間情報を活用している点にあります。データベースから特定の関係性を持つエンティティとターゲットを抽出し、それらを使ってLLMの反応が事実と一致するかを検証するものです。

**関連研究**：[LLMのRAG（外部知識検索による強化）をまとめた調査報告](https://ai-data-base.com/archives/61367)

下は、LLMファクトスコープの開発プロセスを示したフローチャートです。事実データ収集、内部状態収集、内部状態の前処理、そしてモデル設計の4つのステップを示しています。

![[LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』 - AIDB/AIDB_61651_2-1024x480.jpg]]

### 事実データ収集

本研究では、Kaggleから収集したCSV形式の事実関連データセットを用いています。データセットはアート、スポーツ、文学、地理、歴史、科学、経済など、様々なカテゴリを含んでおり、多岐にわたる事実を網羅しています。

そしてGPT-4の能力を活かし、LLMが問いに正確に答えられるように、明確で曖昧さのないプロンプトを慎重に作成しました。そうして、質問と答え（事実）のペアデータセットが作られました。

下の表は、研究で使用される事実データセットのカテゴリと例をまとめたものです。

![[LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』 - AIDB/AIDB_61651_3-1024x608.jpg]]

### 内部状態の収集と前処理

#### 収集する内部状態

LLMにプロンプトを提示し、応答と同時に下記の内部状態を収集します。

**活性化マップ**: プロンプトの最終トークンに対する活性化値を表し、LLMのプロンプトに関連する知識の内部表現を捉えるものです。

**最終出力ランク**: 各レイヤーでの最終出力トークンの確率分布における位置を示し、LLMの出力嗜好の進化を反映するものです。

**top-k出力インデックスと確率**: 各レイヤーで最も高いロジットを持トークンです。モデルの処理に関するさまざまな認知的側面を明らかにすると考えられています。

上記の内部状態データはシャムネットワークモデル作成のために以下のように前処理されます。

#### 前処理

まずモデルの学習メカニズムの比較可能性と関連性を上げるために、活性化マップの平均値と標準偏差を計算し、データセットを標準化します。

次に最終出力トークンのランクを正規化し、モデルの語彙サイズに合わせて0から1の範囲内に収まるように調整します。

### モデルの作成

LLMファクトスコープモデルは、フューショット学習とシャムネットワークの原則に基づいて開発されました。

上述した内部情報（活性化マップ、top-k出力インデックス、top-k出力確率、最終出力ランク）データを用いて、ResNet18やGRUネットワークなどの4つの異なるサブモデルが訓練されています。

CNN（Convolutional Neural Networks）とGRU（Gated Recurrent Unit）ネットワークを使用し、異なる特徴埋め込みを生成し、統合してLLMの包括的な事実理解を形成したと述べられています。

なおテストフェーズではサポートセットを利用して新しいテストデータの分類を行ったとのことです。

## 実験と結果

LLMファクトスコープの性能は以下のように実証されました。

### 実験設定

**データセット：**前章で述べた通り、芸術、スポーツ、文学、地理、歴史、科学、経済などの様々なドメインを含む事実データセットを用意しました。各ドメインは、特定の芸術作品のアーティストや企業の創始者など複数の関連を含んでいます。

**モデル：**GPT2-XL、LLaMA-2-7B、LLaMA-2-13B、Vicuna-7B-v1.5、Vicuna-13B-v1.5、StableLM 7Bなど、様々なLLMを実験対象としました。

**環境：**32個のIntel Xeon Silver 4314 CPU、386GBのRAM、4つのNVIDIA A100 Tensor Core GPUを搭載したサーバー上で行われ、Ubuntu 20.04 LTSオペレーティングシステム上で実施されました。

### LLMファクトスコープの効果

複数のLLMに対して中間層から後段層の活性化値を用い、実際にニューラルネットワークを訓練しました。

結果完成したLLMファクトスコープモデルは、LLMの出力における事実検証において一貫して高い精度（96.1%～98.3%）を発揮し、基準モデルの精度（78.5%～88.8%）と比較して優位性を示しました（下記表）。

![[LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』 - AIDB/AIDB_61651_4-1024x165.png]]

### 一般化性能

また、LLMファクトスコープの一般化能力も評価されました。ニューラルネットワーク研究では、モデルの有効性は訓練データとテストデータの分布の類似性に依存しているとされています。この原則に基づいて評価が行われ、大多数のケースで基準モデルより優れた一般化能力を示しました。

ただし、一部のLLMに対しては、一般化能力に弱点も見られました。よってモデルの使用時には訓練データとテストデータの分布の類似性を確保することが推奨されています。

下の表は各LLMアーキテクチャでのLLMファクトスコープの一般化性能を異なるデータセットで評価しており、全体的にベースラインより優れていることを示しています。

![[LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』 - AIDB/AIDB_61651_5-1024x261.png]]

### 解釈可能性

LLM出力の事実性を識別する際に、特定の機能がどのように貢献するかが、統合勾配によって分析されました。その結果、LLMの中間層から後期層にかけての特徴が最も影響力を持っていることが示されました。

下の図はLLMの異なる要素の寄与を視覚化した図です。平均活性化、最終出力ランク、top-k出力インデックス、top-k出力確率という異なる特徴の影響を層ごとに示しており、それぞれがLLMの出力にどのように影響を与えているかが分かります。

![[LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』 - AIDB/AIDB_61651_6-899x1024.png]]

### 追加実験

またサブモデルの貢献を評価するために、それぞれを徐々に追加して実験を行いました。ぞの結果、複数のサブモデルを統合することで一般化性能が向上することが示されました。また、サポートセットのサイズを変えた実験では、サポートセットのサイズが増加すると精度がわずかに向上する傾向が見られました。

下の表は、異なるサブモデルの組み合わせが事実検出モデルの有効性と一般化に与える影響を数値的に整理したものです。

![[LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法『LLMファクトスコープ』 - AIDB/AIDB_61651_7-1-1024x461.png]]

## まとめ

この記事では、大規模言語モデルの「内部の働き」を解析して、事実かどうかを見極める新しいモデル、「LLMファクトスコープ」の研究を紹介しました。

「LLMファクトスコープ」モデルは、シャムネットワークとフューショット学習を用いて、少ないデータからでも精度良く学習できるように設計されています。実験の結果、ベースラインよりも、より高い精度と幅広い適用能力を持っていることがわかりました。つまりLLMの出力における事実性を優れたパフォーマンスで識別できることが示唆されました。

今後は、より複雑なデータや多様なシナリオでの応用が期待されます。なお注意点としては、このモデルも（当然ながら）完璧ではなく、分野やデータの種類に制限があるかもしれません。実用においては精度を検証しながら進めることが必要です。

また、この手法はあくまでも学習データに対する出力の事実性を検証するものであり、学習データそのものが誤りである可能性に関しては範囲外であることにも注意が必要です。
