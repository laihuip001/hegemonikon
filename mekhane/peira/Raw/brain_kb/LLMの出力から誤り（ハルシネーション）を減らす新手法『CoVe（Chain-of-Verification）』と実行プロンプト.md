---
created: 2026-01-01T09:30:35 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/55711
author: AIDB Research
---

# LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト - AIDB

> ## Excerpt
> 大規模言語モデルにおけるハルシネーション（事実とは異なる誤った出力）を有意に減少させることができる手法Chain-of-Verification（CoVe）手法が発表されました。 この手法は、Wikidataに基づいたリストベースの質問、長文のテキスト生成といった多様なタスクで効果を発揮しました。 本記事は論文を参照し、『CoVe』の性能や、具体的なプロンプト例などを紹介します。 参照論文情報 「…

---
大規模言語モデルにおけるハルシネーション（事実とは異なる誤った出力）を有意に減少させることができる手法Chain-of-Verification（CoVe）手法が発表されました。

この手法は、Wikidataに基づいたリストベースの質問、長文のテキスト生成といった多様なタスクで効果を発揮しました。

本記事は論文を参照し、『CoVe』の性能や、具体的なプロンプト例などを紹介します。

**参照論文情報**

-   タイトル：Chain-of-Verification Reduces Hallucination in Large Language Models
-   著者：Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu, Roberta Raileanu, Xian Li, Asli Celikyilmaz, Jason Weston
-   機関：Meta AI, ETH Zurich
-   URL：[https://doi.org/10.48550/arXiv.2309.11495](https://doi.org/10.48550/arXiv.2309.11495)

**「LLMの推論能力を向上させる手法」に関連する他の研究**

-   [推論能力をさらに強める戦略『AoT』で、LLMが「直感」に似た能力を示すようになった](https://ai-data-base.com/archives/54750)
-   [タスクに応じてロールプレイさせるとChatGPTなどLLMの推論能力は普遍的に向上する](https://ai-data-base.com/archives/54536)
-   [LLMに自身のハルシネーション（幻覚）を「自覚」させ、減らす方法](https://ai-data-base.com/archives/55232)

## 従来の課題

大規模言語モデルは、しばしば「ハルシネーション」と呼ばれる現象を引き起こします。ハルシネーションとは、モデルが「事実に基づかないが一見妥当に見える情報」を生成することを指します。訓練データに少なく出現する事実に対して、モデルは誤った情報を生成する傾向があります。

ハルシネーションが問題とされるのは、例えば質問応答システムで正確な情報を提供する必要がある場合や、自動要約で信頼性が求められる場合などです。

今回Meta AIが発表した『CoVe』は、大規模な言語モデルが生成する回答の信頼性を高めるためのフレームワークです。モデルは初めに回答のドラフトを生成し、その後でその回答が事実に基づいているかどうかを検証するための質問を計画します。次に、それらの質問に独立して回答し、最終的な検証済みの回答を生成します。

### CoVeの主要なステップ

CoVeの主要なステップは以下の4つです。

1.  基本的な回答を生成
2.  検証のための質問を計画
3.  検証質問に独立して回答
4.  最終的な検証済みの回答を生成

各検証質問に対する回答を元に、初稿の回答に対する修正や補足を行い、最終的な検証済みの回答を生成します。このプロセスで、生成された回答の信頼性と精度が向上します。

![[LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト - AIDB/AIDB_55711_2.png]]

## 方法論の詳細

提案されている方法論は前述の通り4つの主要なステップで構成されています。その詳細を紹介します。

### **1\. 基本的な回答を生成**

まず、与えられたクエリに対して大規模言語モデル（LLM）を使用して基本的な回答を生成します。

### 2\. 検証の計画

検証の計画ステップでは、生成された基本的な回答とクエリを元に、その回答が事実に基づいているかどうかを確認するための質問が（LLM自身によって）生成されます。質問は、基本的な回答の各部分に対する事実検証を目的としています。

### 3\. 検証の実行

検証の実行ステップでは、生成された質問に対して独立して回答が行われます。回答は、基本的な回答の事実性を検証するために使用されます。

### 4\. 最終検証済み回答を生成

最終検証済み回答を生成するプロセスでは、検証の結果を元に、基本的な回答に対する修正や補足が行われます。このステップで最終的な検証済みの回答が生成され、その信頼性と精度が向上します。

## 具体的なプロンプト例

『CoVe（Chain-of-Verification）』フレームワークを使用するには、ユーザーが初期の質問プロンプトで大規模言語モデル（LLM）への指示を追加する方法が有効です。

ChatGPTのようなインタフェースで容易に実行できるほか、システムにあらかじめ組み込むことも可能です。以下がプロンプト例です。

ここから限定コンテンツ

ユーザー：  
_\[質問や指示\]_

1.  _まずは上記の問いに対して、回答の初稿を作成してください。_
2.  _回答を細かく分解して複数の小さな問い（検証質問）を生成してください。_
3.  _それぞれの小さな問いに対して細かく回答してください。_

上記のように自発的な検証を促すプロンプトによって、回答の質が上がります。

## 実験結果の詳細

研究者らが行なった実験の結果は、『CoVe』フレームワークが言語モデルの回答の質を有意に向上させる（ハルシネーションが減る）ことを示しています。論文では以下のような定量的なデータが報告されています。

#### 1\. Wikidataタスク

-   **モデル**: Llama 65B
-   **評価指標**: 精度
-   **結果**: few-shotベースラインが0.17であったのに対し、CoVeを使用することで精度が0.36に達しました。

![[LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト - AIDB/AIDB_55711_3.png]]

#### 2\. MultiSpanQA

-   ****評価指標****: F1スコア
-   **結果**: few-shotベースラインが0.39であったのに対し、CoVeを使用することでF1スコアが23%向上し、0.48になりました。

![[LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト - AIDB/AIDB_55711_4.png]]

#### 3\. ネガティブな回答（ハルシネーション）

-   ****評価指標****: ネガティブな回答の数
-   **結果**: CoVeを使用することで、ネガティブな回答（ハルシネーション）が2.95から0.68に減少しました。

#### 4\. 長文生成

-   ****評価指標****: FACT SCORE
-   **結果**: CoVeを使用することで、FACT SCOREが28%向上しました。

![[LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト - AIDB/AIDB_55711_5.png]]

![[LLMの出力から誤り（ハルシネーション）を減らす新手法『CoVe（Chain-of-Verification）』と実行プロンプト - AIDB/AIDB_55711_6.png]]

Wikidataタスクにおいてのみモデルの情報（Llama 65B）を明示したのは、そのタスクで使用されたモデルの種類が結果に影響を与えた可能性があるためです。

## まとめ

本記事では、大規模言語モデルにおける「ハルシネーション」問題を解決する新手法『Chain-of-Verification（CoVe）』について詳しく解説しました。この手法は、Meta AIとETH Zurichによって開発され、WikidataタスクやMultiSpanQAなどで顕著な効果を示しています。

CoVeはまだ発表されたばかりであり、さまざまな応用例や改良の余地が考えられます。どのようなタスクや業界で最も効果を発揮するのか、今後の研究が待たれます。皆さんもぜひ試して、よければ結果を共有してくださいね。

Copyright © Parks, Inc. All rights reserved.
