---
created: 2026-01-01T09:36:42 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/63672
author: AIDB Research
---

# LLMの検索結果をさらに正確にする手法『CRAG』（Corrective Retrieval Augmented Generation：修正型の検索拡張生成） - AIDB

> ## Excerpt
> LLMは知識が不足しているときに不正確な出力をしてしまうことがあります。そして知識を足すために検索を活用する手法（RAG）では、「検索結果の正確性」が鍵となります。 そこでGoogleなどの研究者らは今回、モデルが検索した結果の信頼性を評価する手法を提案しています。もし不正確だと思われる場合には補完することで、より正確な文章生成を実現する仕組みになっています。 研究者らが行った評価実験により、本手…

---
LLMは知識が不足しているときに不正確な出力をしてしまうことがあります。そして知識を足すために検索を活用する手法（RAG）では、「検索結果の正確性」が鍵となります。

そこでGoogleなどの研究者らは今回、モデルが検索した結果の信頼性を評価する手法を提案しています。もし不正確だと思われる場合には補完することで、より正確な文章生成を実現する仕組みになっています。

研究者らが行った評価実験により、本手法の性能が実証されています。

![[LLMの検索結果をさらに正確にする手法『CRAG』（Corrective Retrieval Augmented Generation：修正型の検索拡張生成） - AIDB/AIDB_63672-1024x576.jpg]]

**参照論文情報**

-   タイトル：Corrective Retrieval Augmented Generation
-   著者：Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, Zhen-Hua Ling
-   所属：University of Science and Technology of China, University of California, Google Research

**本記事の関連研究**：

-   [LLMに対するプロンプトで「無関係な」文書を混ぜたほうが出力精度が上がる可能性がRAGシステムの検証で示唆された  
    ](https://ai-data-base.com/archives/63536)
-   [LLMに外部知識を取り入れる2つの手法、ファインチューニングとRAGを比較した実験結果  
    ](https://ai-data-base.com/archives/63401)
-   [LLMのRAG（外部知識検索による強化）をまとめた調査報告  
    ](https://ai-data-base.com/archives/61367)
-   [RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』](https://ai-data-base.com/archives/66427)

## 背景

LLMは文章生成などを中心に様々なタスクで優れた能力を発揮しますが、誤った情報や知識を出力してしまう「ハルシネーション」という問題を抱えています。

そんな知識不足の問題に対処することを目的の一つとして、モデルが関連する情報を取り込む手法「RAG：Retrieval-Augmented Generation」が出現しました。Metaなどの研究者らによる2020年の考案に端を発するものです。

しかしRAGは有効な手段ではあるものの、取り込んだ文書が間違っていた場合、かえって誤りを助長するという課題があります。

最近の研究では、必要な時に必要な外部知識を取り込むなど、RAGの改善が進められています。これまで、「RAGをより便利に」「そもそも使うべきか」という点を中心に探求されてきました。

そして今回、Googleなどの研究者らは「取り込んだ情報が間違っている場合」に焦点を当て、従来の手法とは異なるアプローチ「修正型検索拡張生成（CRAG：Corrective Retrieval Augmented Generation）」を提案しています。

CRAGの利点は以下にようにまとめられるとのことです。

-   不正確な情報を排除し、信頼できる情報のみを使用する
-   取得された情報から重要な情報のみを抽出し、不要な部分を削除する
-   他のLLM手法と容易に統合することができ、さまざまなタスクに適用することができる

本記事では詳細を紹介します。

ここから限定コンテンツ

![[LLMの検索結果をさらに正確にする手法『CRAG』（Corrective Retrieval Augmented Generation：修正型の検索拡張生成） - AIDB/AIDB_63672_1.png]]

CRAGでは、まず検索された文書の関連度が評価され、信頼レベルが算出されます。信頼レベルは「正確」「不正確」「曖昧」の3段階に分類され、それぞれのレベルに応じてシステムは異なるアクションを実行します（詳細は後述）。

そして最適化された検索結果を使用して、最終的な文章を生成するという流れです。  
CRAGは従来の「検索結果をそのまま使う手法」とは異なり、情報の信頼度を考慮することに特化したフレームワークです。下記の図が全体の概要を示すものです。

![[LLMの検索結果をさらに正確にする手法『CRAG』（Corrective Retrieval Augmented Generation：修正型の検索拡張生成） - AIDB/AIDB_63672_2-1024x813.png]]

### リトリーバの評価器

「CRAG」では、検索された文書の重要度を評価するためのコンポーネント「レトリバル評価器（retrieval evaluator）」が用いられます。

レトリバル評価器は、まず検索された10個の文書それぞれと入力質問を組み合わせ、文書と質問の関連スコアを算出します。スコアは-1から1までの範囲で、高いスコアほど関連性が高いことを示します。

このレトリバル評価器には、従来の手法と比べて2つの特長があります。

1つ目は、軽量モデルであるT5-largeを使用していることです。従来の手法で使われていたモデルと比べると、サイズが小さく効率的です。

2つ目は、追加の人間やLLMによる注釈を必要としないことです。従来の手法は注釈データが必要でしたが、レトリバル評価器は必要としません。

### アクション

CRAGは検索結果の信頼性に基づいて下記3つのアクションを起こします。

-   **正確：**信頼できる文書が見つかった場合。この文書から必要な知識を抽出するため、より詳細な分析を行います。
-   **不正確：**信頼できる文書が見つからない場合。インターネット検索を行い、新しい情報を取り入れます。
-   **曖昧：**判断がつかない場合。信頼できる文書とそうでない文書の両方の情報を活用し、最適な結果を出そうとします。

このように選択肢を複数持つことで柔軟な働きができるようになっています。

なお、下記はアクションの変化をアルゴリズムで表したものです。

![[LLMの検索結果をさらに正確にする手法『CRAG』（Corrective Retrieval Augmented Generation：修正型の検索拡張生成） - AIDB/AIDB_63672_3-1024x610.png]]

### 知識の抽出（正確だった場合のアクション）

信頼できる検索結果に対して行う「知識抽出」については、以下の2段階で行われます。

1.  **分割**：まず、検索された文書を細かい「知識の断片」に分割します。
2.  **重要度評価・抽出**：「レトリバル評価器」を使って、各断片の関連度を評価します。評価結果に基づいて、関連性の低い断片は取り除かれ、関連性の高い断片は順番に並べて連結され、最終的に「内部知識」として利用されます。

つまり検索結果が正確だった場合でも、必要な情報だけを抽出して加工する仕組みになっています。

### 検索（不正確だった場合のアクション）

また、検索された文書がどれも関連がないと判断された場合、インターネットで新しい情報を補充します。

従来の手法では、限られた文書の中から検索するので、必ずしも最適な情報を得られません。そこで、CRAGでは検索エンジンのようにキーワード検索を行い、より幅広い情報を集めてきます。

具体的には、検索エンジンで使うようなキーワードに質問を書き換えて、商用検索APIを利用して複数のURLを取得します。その後、そのURL先のウェブページの内容を抽出し、必要な情報を抽出します。

## 実験

CRAGの性能が様々なタスクとデータセットを用いて評価されました。実験では、CRAGがRAGベースのアプローチにいかに柔軟に適用できるか、そして短文・長文生成タスクの両方で通用するかを検証しています。

### タスクとデータセット

4つのタスクとデータセットが用いられました。

-   **PopQA**: 短い質問に対して事実のみ答えるタスクで、1,399個の質問と回答のペアで構成されています。評価指標は正解率です。
-   **Biography**: 特定のエンティティについて詳細な伝記を生成するタスクです。評価指標は、生成された伝記の正確さと情報量を測るFactScoreが用いられました。
-   **PubHealth**: 医療に関する真偽判断タスクです。健康に関する主張に対して真偽を判定し、その精度が評価されます。
-   **Arc-Challenge**: 日常の科学現象に関する選択肢問題です。与えられた現象の説明として正しいものを4つの選択肢から選び、その精度が評価されます。

タスクは短文生成から長文生成、選択式問題などさまざまであり、CRAGの汎用性を多角的に評価することを目的に選ばれました。

### ベースライン

ベースラインは以下の3種類です。

**1\. 検索機能を持たないベースライン**

-   LLaMA2-7B/13B
-   Alpaca-7B/13BとCoVE65B（生成内容の事実性を向上させるための反復エンジニアリング手法を使用したモデル）

**2\. 標準的なRAGモデル**

-   検索された上位ドキュメントをクエリの前に付加し、それを元にLLMが出力を生成するモデル。
-   LLaMA2-7B/13B、Alpaca-7B/13B、Self-RAGでインストラクション調整されたLLaMA2-7Bなど。

**3\. 発展的なRAGモデル**

-   Alpacaのインストラクション調整データを利用し、上位ドキュメントを挿入した状態でLLMを調整したSAILモデル。
-   LLMにGPT-4でラベル付けされた複数の「リフレクショントークン」を含むインストラクション調整データを用いて調整されたSelf-RAGモデル。
-   上記と同様に上位ドキュメント挿入を行ったRet-ChatGPTとRet-LLaMA-chatモデル、「InstructGPT」を使用した実用検索システムperplexity.aiの結果。

### 結果

CRAGの性能評価結果における主なポイントは以下の通りです。

CRAGは従来のRAGと組み合わせることで、質問回答タスクで2.1%、伝記生成タスクで2.8%の精度向上を達成しました。また最先端のSelf-RAGと組み合わせることで、質問回答タスクで20.0%、伝記生成タスクで36.9%の精度向上を達成したことも明らかになっています。

![[LLMの検索結果をさらに正確にする手法『CRAG』（Corrective Retrieval Augmented Generation：修正型の検索拡張生成） - AIDB/AIDB_63672_4.png]]

また、短文生成、長文生成、選択式問題など、さまざまなタスクで性能を発揮することができることもわかりました。使用する言語モデルを柔軟に置き換えることも示されています。

一貫してCRAGは汎用性が高い結果でした。ただし、医療情報判断タスクでの性能が低かったのは、使用した言語モデルが指示に対して理解が弱かったためであることが報告されています。

### アブレーション研究

CRAGの各要素がどのように性能に貢献しているかの検証も行われています。

検証の方法としては、それぞれの要素（アクション、文書の細分化、検索クエリ書き換え、外部知識選択）を個別に無効にし、性能の変化を測定しました。

検証結果は以下のとおりでした。

-   全ての要素を無効にした場合、性能が低下しました。つまり、全ての要素がCRAGの性能向上に貢献していることが示されました。
-   曖昧な評価結果が出た場合のクションは、性能向上に特に重要であることが分かりました。
-   また、検索結果やウェブページからの情報の抽出・活用方法も、性能向上に貢献していることが確認されました。

![[LLMの検索結果をさらに正確にする手法『CRAG』（Corrective Retrieval Augmented Generation：修正型の検索拡張生成） - AIDB/AIDB_63672_5.png]]

![[LLMの検索結果をさらに正確にする手法『CRAG』（Corrective Retrieval Augmented Generation：修正型の検索拡張生成） - AIDB/AIDB_63672_6.png]]

### リトリーバ評価器の精度について

検索された文書に対して、それらの質を正確に評価できるかどうかがこの手法の肝になります。

軽量なT5ベースの検索結果評価器と商用LLMであるChatGPTの性能比較を行ったところ、なんとT5ベースの評価器が全ての設定でChatGPTを上回ることが示されました。

![[LLMの検索結果をさらに正確にする手法『CRAG』（Corrective Retrieval Augmented Generation：修正型の検索拡張生成） - AIDB/AIDB_63672_7.png]]

### ロバストネスについて

研究者らは、CRAG手法が検索結果の質にどのくらい影響を受けるかを調べる実験を行いました。良い検索結果の一部をランダムに削除し、悪い検索結果に対するCRAGのパフォーマンスを計測しました。結果として、検索結果が悪くなると、（当然ながら）CRAGも性能が下がることが分かりました。

しかし従来の手法と比べると、CRAGは性能の低下が緩やかでした。つまりCRAGは検索結果の影響を受けにくく、より安定した性能を発揮することが示されました。重要なデータの一つです。

![[LLMの検索結果をさらに正確にする手法『CRAG』（Corrective Retrieval Augmented Generation：修正型の検索拡張生成） - AIDB/AIDB_63672_8.png]]

## まとめ

この記事では、LLMが生成するテキストの正確さを保証する手法「修正型検索拡張生成（CRAG：Corrective Retrieval Augmented Generation）」の研究を紹介しました。

CRAGは、検索結果の品質を評価し、必要に応じて異なるアクションをトリガーする軽量の検索評価器を設計することで、生成の精度を向上させます。大規模ウェブ検索を活用し、取得したドキュメントから重要な情報に焦点を当て、無関係な情報をフィルタリングすることで、検索結果を強化します。

実験では、本手法が従来のRAGベースのアプローチとシームレスに統合でき、一貫して精度を向上させることが示されました。

かなりすばらしい実験結果だったと言え、今後アプリケーションレベルで実装した事例に期待が高まります。

参照論文URL：[https://doi.org/10.48550/arXiv.2401.15884](https://doi.org/10.48550/arXiv.2401.15884)
