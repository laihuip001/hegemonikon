---
created: 2026-01-01T09:37:11 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/61831
author: AIDB Research
---

# LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB

> ## Excerpt
> 本記事では、LLMの知識を狙い撃ちして編集する手法（Knowledge Editing：知識編集）について整理します。 知識編集はモデル全体を再学習させることない効率的なアプローチと言われており、信頼性の向上や、パーソナライズされたエージェントの開発に役立つとのことです。なお、有名な手法としてはLoRAなどが含まれます。 背景、知識編集の概要、3つのフェーズ、評価方法、今回行われた実験と結果、そし…

---
本記事では、LLMの知識を狙い撃ちして編集する手法（Knowledge Editing：知識編集）について整理します。

知識編集はモデル全体を再学習させることない効率的なアプローチと言われており、信頼性の向上や、パーソナライズされたエージェントの開発に役立つとのことです。なお、有名な手法としてはLoRAなどが含まれます。

背景、知識編集の概要、3つのフェーズ、評価方法、今回行われた実験と結果、そして応用例について紹介します。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_eye2-1024x576.jpg]]

**本記事の関連研究**：

-   [ハーバード研究者などがLLMを創造的にすべく考案した、大喜利データセットでユーモアラスにチューニングする手法『LCoT』](https://ai-data-base.com/archives/60765)
-   [LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』](https://ai-data-base.com/archives/57018)
-   [LLMにベートーヴェンなど特定の人物の行動や感情を模倣させる、イタコのような技術『Character-LLM（キャラクターLLM）』](https://ai-data-base.com/archives/57223)
-   [「わたしの話」を体系的に覚えてもらいながらLLMと会話する技術MemoChat登場](https://ai-data-base.com/archives/54560)

## 背景

LLMは、さまざまな知識をパラメータ内に蓄えています。下の図は、LLMにおける知識の保存方法を図式化したものです。モデルが情報を処理し、さまざまなレベルで言語の特徴をエンコードする様子を示しています。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_1-1024x527.png]]

LLMには、時として誤りや古い情報を出力するといった問題があります。この問題に対処する最も一般的な方法は、RAG（外部データの参照）やファインチューニングです。

参考：[LLMのRAG（外部知識検索による強化）をまとめた調査報告](https://ai-data-base.com/archives/61367)

しかし、RAGやファインチューニングにも課題があります。まず、外部のデータベースにいちいちアクセスするのも、場合によっては効率的とは言えません。また、ファインチューニングにはコストと時間がかかる上に、新しい知識を学ぶと古い知識を忘却するという問題も存在します。

そのためパラメータ効率の良いチューニング技術が必要とされています。

そこで「知識編集」という戦略に注目が集まっています。LLMの知識を直接編集し、より効率的に最適化する方法です。

以下で詳しく見ていきましょう。

ここから限定コンテンツ

## **知識編集とは**

知識編集は、モデルのパフォーマンス向上を目指して特定の知識をLLM内で変更するものです。事実や常識、感情など、多岐にわたる情報が対象です。

知識編集後のモデルは、指定された知識が上書きまたは追加されますが、他の知識に関しては理論上はそのまま保持されます。

下の表は、知識編集と他の手法（ファインチューニングなど）を比較しています。モデルのパラメータ数、精密さ、広範さを評価したものです。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_2-1024x361.png]]

### 3つのアクション

知識編集には、知識の挿入、変更、および消去という3つのアクションがあります。

**知識の挿入：**LLMに新しい知識を授けることです。

**知識の変更：**既にLLM内に格納されている知識を変更することです。誤った情報を修正する目的と、ユーザーからの誤ったプロンプトへの回答を修正する目的の2つがあります。

**知識の消去：**モデル内の既存の知識を消去することです。事実や関係、属性をリセットするために実施されます。

## フェーズは3つ

知識編集には、3つのプロセスがあります。

それらのプロセスは人間の学習フェーズ（認識、結合、習得）に類似していると言われています。下の図が概念図です。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_3-1024x675.jpg]]

各フェーズを見ていきましょう。

### 認識フェーズ

モデルが新しい情報に出会ったとき、それをどのように理解して処理するかを学ぶ段階です。私たち人間が新しい情報に出会ったときと同じように、モデルも新しい情報をすぐにマスターするわけではなく、適切な文脈や例を通じて、徐々にその情報を理解していきます。

モデルに新しい情報を学ばせる手法には、いくつかの方法があります。一つは、新しい知識を記憶しておき、必要な時にそれを取り出して適切な答えを生成するようにモデルを導く方法です。

しかし、新しい情報を学ぶと、それが他の知識と衝突することもあります。また、モデルが新しい問題に出くわしたとき、記憶した答えを使うべきか、文脈に基づいて生成された答えを使うべきかを選ぶべきシナリオもあり、これら問題を解決するアプローチが研究されています。

#### 認識フェーズに属する知識編集手法の例

-   **デモンストレーションを用いた方法（IKE）**：デモンストレーション（例えば、コピー、更新、保持）を構築して、モデルが信頼できる事実編集を行うのを支援します。
-   **インコンテキスト学習（ICE）**：入力の前に「Imagine that {knowledge}」というプロンプトを追加することで、モデルが特定の知識を考慮して回答を生成します。

### 結合フェーズ

結合フェーズは、モデルが新しい知識を受け入れて、それをもとの知識と「組み合わせる」段階です。

このフェーズで使われる技術の一つに、「ニューロンを追加する」というものがあります。ニューロンはモデルの脳の中の小さな処理ユニットのようなもので、新しい知識をAIの既存の知識に結びつけるために使われます。

しかし、新しい情報をただ追加するだけではなく、それがモデルの全体的な「知識ネットワーク」にどのようにフィットするかを考える必要があります。情報源が異なるために、時には情報が衝突することもあります。そこで、「忘れてから学ぶ」という考え方が重要になります。

また、新しい知識をモデルのどの部分に組み込むか、どのように組み込むかも大切です。しかし、新しい知識を組み込むたびにAIの構造に多くの変更を加えると、モデルの処理能力に負担をかけることがあります。そのため、新しい知識を効率的に組み込む方法を見つけることが、今後の研究で求められています。

#### 結合フェーズに属する知識編集手法の例

-   **パラメータ効率の高い微調整（LoRA）**：モデルの重みを凍結し、微調整プロセス中にトランスフォーマーレイヤーにトレーニング可能なランク分解行列を導入する方法です。
-   **知識パッチ（Knowledge Patch）**：新しい出力ヘッドを導入し、それを元のヘッドと補間する方法です。

### 習得フェーズ

習得フェーズは、モデルが新しい知識を完全に「身につける」段階です。簡単に言うと、学校で勉強してテストで良い点を取るために、勉強した内容を完全に理解して覚える必要があるのと似ています。モデルにとってのテストは、新しい情報をどれだけしっかりと使えるかです。

ただし、通常は計算コストと時間がかかります。また、モデルが新しいことを覚えるときに、以前に学んだことを忘れてしまうことがあるので、そういった問題を解決するために、研究者たちはいくつか方法を考え出しています。

その中の一つが「メタ学習」と呼ばれる方法で、これはモデルに直接重み（＝知識）を更新させるのではなく、モデルが変更点を自分で学べるようにするアプローチです。もう一つの方法は「位置を特定してから編集する」というアプローチで、これはモデルがどの部分に知識を保存しているかを見つけ出してから、その特定の部分だけを編集する方法です。

**「メタ学習」の関連記事：**[従来の小さなニューラルネットワークでも「メタ学習」でChatGPTを凌駕するほど高度な生成AIができるとの報告、Nature誌](https://ai-data-base.com/archives/57838)

#### 習得フェーズに属する知識編集手法の例

-   **ハイパーネットワークを用いた編集（MEND）**：ハイパーネットワークが新しい知識の変更を学習し、それをモデルに適用します。

各フェーズに分類される様々な知識編集手法が下記にまとめられています。編集領域、編集機能、追加トレーニング必要の有無、バッチ編集の有無、そして編集によって更新されるパラメータの数が記載されています。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_4-1024x836.jpg]]

## 知識編集の評価

それぞれの知識編集手法は、下記のような複数の基準で評価されるとのことです。

**（１）編集の成功**：編集後のモデルが意図した知識を出力できるかどうかを指します。成功の基準はさらに「信頼性」と「一般化」の2つに分かれるとされています。なお、編集されたモデルは狙ったプロンプトに対してだけでなく、類似した表現に対しても正しい答えを提供するべきですとのことです。

**（２）移植性**：編集後のモデルが実世界での下流タスクを処理できるかどうかを評価します。変更された事実に対するモデルの推論能力と、関連知識に対するパフォーマンスの評価が含まれます。

**（３）局所性**：編集が意図した知識のみに影響を与え、関連しない知識には不要な変更を及ぼしていないかを測定します。

**（４）生成能力：**生成能力とは、モデルがテキストを作る際の創造性や多様性を指します。簡単に言うと、編集後のモデルが同じ言葉やフレーズを繰り返さないようにする能力のことです。

## 実験と分析

### 実験設計

研究では、複数の知識編集手法を評価する実験が行われました。

まず本実験では、「LLaMA-2」が使用されました。このモデルは、人間からのフィードバックを通じた強化学習（RLHF）によって、一貫性のある応答を生成するようになっています。

8つの知識編集手法で編集されたLLaMA-2モデルのパフォーマンスを「EasyEdit」というツールを使って評価しました。編集の目的は、モデルが望ましい出力を生成することです。そのため、実験では、編集後のモデルが正確な答えを出すかどうかを測定する「正確さ」を重要な指標として使用しました。

なお、EasyEditは今回研究者らによって作成されたツールであり、GitHubで公開されています。

さらに、先ほど紹介した指標「移植性」と「局所性」を使用して、編集後のモデルが編集前の答えを保持しているか、また編集後も関連するトピックに対する正しい感情反応を示すかを評価しました。

### 主な結果

様々な知識編集手法の評価結果は以下の表にまとめられています。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_E1-1024x716.png]]

知識編集手法の一つであるSERACは、知識を追加したり変更するタスクで良い成績を収めました。この方法では、他の方法と比べて、編集が成功する確率が高く、新しい知識を学ぶ能力（移植性）も比較的良好でした。しかし、SERACは言葉を自然に生成する能力（流暢さ）では、他の方法に比べて劣っていることが分かりました。

またMENDは、さまざまなタスクで高い成績を収め、編集の成功率や移植性だけでなく、流暢さや局所性（編集後も元の答えを保持する能力）でも良好でした。

一方で、ROMEやMEMITといった手法は、編集の成功は良いものの、局所性や移植性には問題があることが示されました。

また、局所的な微調整方法であるFT-Lは、編集の成功率はROMEやMEMITほど高くはないものの、局所性や移植性では優れていることが示されました。新しい情報の挿入タスクに関しては、他のタスクよりも成功率が高かったです。

なおモデルの感情を変えるというタスク（Convsent）では、現在の方法では全体的に成功率が65%未満と低い結果になりました。また、知識を消去するタスク（Sanitation）では、現在の方法ではうまく対処できていないことが分かりました。

### 一般タスクにおける知識編集の影響

研究者たちは、一般的な知性や世界知識など、さまざまな分野をカバーする一連のベンチマークでの知識編集の性能を検証しました。選ばれたベンチマークにはCommonsenseQA、PIQA、Xsum、TriviaQAなどが含まれます。

異なる知識編集手法を適用した後のゼロショット性能が下記にまとめられています。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_E2-1024x428.png]]

実験結果より、モデル全体を編集したあとに直接ファインチューニングすると、一般的なタスクにおける編集後のモデルのパフォーマンスが著しく低下することが観察されました。編集後のモデルは、編集されたケースに似た出力を生成する傾向があり、過学習の一種だと考えられます。

しかし、全体として見ると、編集されたモデルは未編集のものと近いパフォーマンスレベルを維持することができました。編集のネガティブな影響は直接変更されたトピックに限られるということです。

ただし、TriviaQAでのFT-Lモデルのパフォーマンスは、編集後に初期スコアの45.39から34.60へと顕著に低下しました。

それでもより広い視点から見ると、現代の知識編集方法は、モデルの認知能力や多様な知識に対して最低限の悪影響しか及ぼさないと言えます。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_E3-829x1024.jpg]]

### エラー評価

さらに本実験では、異なる知識編集手法が起こり得る特定のエラーパターンを分析しました。

知識編集における主なエラータイプは以下の通りです：

**（１）意味のないトークン生成**

編集されたモデルが「\\n」のような意味のないトークンや、意味のない文字の繰り返しを生成すること。

**（２）トークンの欠落**

モデルが目標とする答えの一部分しか生成せず、重要なトークンを省略すること。

**（３）知識に関係のない生成**

モデルが予想された事実知識に関連しないテキストを生成すること。

下のグラフは、それぞれの知識編集手法がどのような種類のエラーを起こしやすいかを示しています。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_E7-1024x389.png]]

例えば、SERACという方法は、使用された小さなモデルの生成能力が限られているため、意味のないトークンを生成する傾向があります。また、AdaLoRAは、目標とする知識に関連する一部のトークンを見逃す可能性があります。

なお下記は、一つの編集ケースの結果を示しています。入力文、元の出力、編集目標、そして各手法による編集後の文が示され、正しい振る舞いを示すキーワードは緑色、誤った振る舞いを示すキーワードは赤色、繰り返しまたは意味のない文はシアン色で表現されています。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_E6-1024x416.png]]

### モデルに対する影響

知識編集がモデルの重みに与える影響のヒートマップ分析から、知識編集はモデルの重みに対して大きく変更を加えることができ、特にMENDのような手法は局所的な変更に特化していることがわかりました。

下記は異なる手法別のヒートマップです。各手法によるモデルの重みの変化を色の濃さで視覚化しており、より暗い色はより多くの変化を示しています。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_A1-1024x759.jpg]]

また、知識編集前後のモデルのパフォーマンスが編集前に比べてどの程度改善または悪化するのかが定量的に調査されました。編集後のスコアは基本的に上昇しています。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_A2.png]]

### ナレッジグラフ編集との違いに関する分析

知識グラフの編集と回復に関しては元の構造を完全に復元できる一方で、LLMでは元のモデルを復元できないと考えられています。下記はナレッジグラフとLLMの編集効果の比較を示す図です。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_A5-1024x751.jpg]]

## 知識編集はどう応用できるのか

### LLMの効率化

質問応答、事実確認、自然言語生成といったタスクは知識編集によって改善される可能性があるといいます。例えば以下のような形で効果が出るだろうと考えられています

-   複雑な質問を分解し、多段階の推論によって徐々に知識を編集しながら答えに辿り着く
-   LLMのパラメータによる知識を更新して推論能力を向上させる
-   医療などのの質問応答の正確性を向上させる
-   事実確認の性能を向上する
-   誤情報の問題を軽減する

### AI生成コンテンツをよりよくする

LLMが、画像やオーディオなどを含む様々なモダリティでコンテンツを作成します。知識編集は、情報や知識を適宜更新するため、LLMの正確性と機能性を改善し、結果としてコンテンツの品質が上がるのではないかと述べられています。

![[LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」 - AIDB/AIDB_61831_AP1-1024x570.jpg]]

### 信頼できるAIにつながる

社会的に受け入れられ信頼できるAIシステムは、正確な知識だけでなく、適切な社会規範や価値観を示すべきだとされています。一部の研究では、知識編集技術を適用してより信頼できるAIを構築することが探求されています。

知識編集はLLM内の有害性を操作するための手段としてコストパフォーマンスがいいのではないかと期待されています。

なおネットワーク層のリバースエンジニアリングを使用してニューロンの有害な単語を取り除く研究なども出てきています。

**関連研究：**[LLMのLlama-2を分解したところ、1057個のパーツから「抑制」に影響する部品が明らかに](https://ai-data-base.com/archives/61767)

さらにLLMにおけるバイアスを削減する用途でも、知識編集が役立つことが示唆されています。

### エージェントのパーソナライズ

ユーザーの好みや興味に合わせたLLMエージェントを開発するのにも役立つと述べられています。ユーザーに合わせた情報を加えたり編集することで、独自の感覚やニーズなどを理解し、それに合った提案を行うエージェントに育つ可能性があります。あるいはより人間らしく、個性を持ったチャットボットに育つかもしれません。

## まとめ

本記事ではLLM内の情報を更新するための「知識編集」技術に関するサーベイ研究の報告内容を紹介しました。  
知識編集とは何か、3段階の編集フロー、そして手法による違いについてまとめ、最後にどのような応用が見込めるのかについて触れました。

モデルを全体を再学習することなく知識を一部だけ変更することができるのは開発者にとって非常にリーズナブルなアプローチであり、今後も本技術が発展していくことが予想されます。

**参照論文情報**

-   タイトル：A Comprehensive Study of Knowledge Editing for Large Language Models
-   著者：Ningyu Zhang et al.（多数）
-   所属：浙江大学, シンガポール国立大学, カリフォルニア大学ロサンゼルス校, Ant Group, Alibaba Group
-   URL：[https://doi.org/10.48550/arXiv.2401.01286](https://doi.org/10.48550/arXiv.2401.01286)
-   GitHub：[https://github.com/zjunlp/KnowledgeEditingPapers](https://github.com/zjunlp/KnowledgeEditingPapers)
-   EasyEdit：[https://github.com/zjunlp/EasyEdit](https://github.com/zjunlp/EasyEdit)
-   KnowEdit：[https://huggingface.co/datasets/zjunlp/KnowEdit](https://huggingface.co/datasets/zjunlp/KnowEdit)
