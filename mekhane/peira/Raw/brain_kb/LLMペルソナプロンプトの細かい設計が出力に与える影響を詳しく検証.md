---
created: 2026-01-01T11:18:25 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/92928
author: AIDB Research
---

# LLMペルソナプロンプトの細かい設計が出力に与える影響を詳しく検証 - AIDB

> ## Excerpt
> 本記事では、LLMに人物像（ペルソナ）を与えるプロンプトの書き方が、出力内容にどのような影響を与えるのかを検証した研究を紹介します。 単に属性を明示するのか、名前や会話形式で間接的に伝えるのかといった違いによって、回答の自然さや偏りの程度が変わることが示されています。また、LLMのモデルサイズや系列によっても出力傾向に差が生じる点も明らかになりました。 ペルソナプロンプト設計を考えるうえで、実践的…

---
本記事では、LLMに人物像（ペルソナ）を与えるプロンプトの書き方が、出力内容にどのような影響を与えるのかを検証した研究を紹介します。

単に属性を明示するのか、名前や会話形式で間接的に伝えるのかといった違いによって、回答の自然さや偏りの程度が変わることが示されています。また、LLMのモデルサイズや系列によっても出力傾向に差が生じる点も明らかになりました。

ペルソナプロンプト設計を考えるうえで、実践的な示唆を与える内容になっています。

![[LLMペルソナプロンプトの細かい設計が出力に与える影響を詳しく検証 - AIDB/AIDB_92928-1024x576.png]]

**本記事の関連研究**

-   [LLMの性格を、「特性の強度」にもとづき詳細に設定する方法](https://ai-data-base.com/archives/91747)
-   [個人の深い価値観にもとづく「その人らしい答え」をAIで再現する手法](https://ai-data-base.com/archives/90734)
-   [プロンプトによるLLM応答のパーソナライゼーション　仮説を活用して文体を調整](https://ai-data-base.com/archives/89384)

## 背景

LLMに「あなたは○○な人物です」といった指示を与えて、特定の視点から回答させる“ペルソナプロンプト”には課題もあります。

例えば、同じような意図で書かれたプロンプトでも、表現が少し違うだけで、出力される内容が大きく変わってしまうことがあることです。

人間の意見をシミュレートする目的でLLMを使う事例が増えています。その中で、ペルソナプロンプトは重要な役割を担っていますが、プロンプトの書き方に統一されたルールはありません。

たとえば、人種や民族を表す語にしても複数の書き方があり、人物設定の伝え方にもストレートな表現もあれば、丁寧な書き方もあります。どの表現がどう影響するのかは、これまで明確に整理されていませんでした。

そこで本記事では、ペルソナプロンプトの書き方の違いがLLMのふるまいにどのような影響を与えるのかを、わかりやすく比較した調査を取り上げます。役割の与え方と属性情報の書き方という2つの観点からパターンを用意し、自由記述式と選択式の2種類のタスクで検証が行われています。どんな表現がLLMのふるまいに影響を与えるのかを、丁寧に見ていきます。

ここから限定コンテンツ

## ペルソナプロンプトの書き方を整理してみる

まず研究チームは、これまでの先行研究で使われてきたペルソナプロンプトを調べ直しました。全部で47本の論文を分析したところ、プロンプトの書き方には大きく2つの軸があることが見えてきました。

### ひとつ目の軸は、どんなふうに「なりきってもらうか」

まずは、LLMにどういう形で「その人物になりきってもらうか」という方向性です。

大きく分けて3つのタイプがありました。

#### タイプ①ストレートに伝える

「あなたは○○です」とそのまま伝える一番わかりやすい方法です。  
たとえば「あなたはヒスパニック系の女性です」といった形になります。  
この書き方が最もよく使われていました。

#### タイプ②第三者として語らせる

「○○という人について考えてください」といった形で、外からその人物を見るような書き方です。  
この場合、LLMはその人物を演じるというより、その人物像について説明する立場になります。

#### タイプ③会話を通じて役割を作る

インタビューのように、質問と回答を交わしながらペルソナを構築していく方法もあります。  
たとえば、「あなたの性別は何ですか？」「私は女性です」といったやりとりのあとで、本題の質問を続けていく形式です。  
ペルソナの設定が自然に積み上がっていくのが特徴です。

### もうひとつ目の軸は、属性をどう伝えるか

もうひとつの軸は、人物の属性（たとえば人種や性別といった情報）を、どのようにプロンプトに盛り込むかという点です。

こちらも3通りに分かれていました。

![[LLMペルソナプロンプトの細かい設計が出力に与える影響を詳しく検証 - AIDB/AIDB_92928_1.png]]

#### タイプ①名前でそれとなく示す

名前や敬称を使って、属性を間接的に伝える方法です。  
たとえば「小泉総理」といった名前からは、文化的背景や性別が推測されることを前提にしています。

\*この例は論文では使用されていませんが、意図としては同様です。

#### タイプ②はっきり書く

「ヒスパニック系の女性」のように、属性をそのまま明示する方法です。  
最もわかりやすい書き方ですが、場合によってはLLMがステレオタイプに引っ張られてしまう可能性もあります。

#### タイプ③項目と値を分けて書く

アンケートのように「人種：ヒスパニック系」「性別：女性」といった構造的な形式で属性を伝える方法もあります。  
データベース的に情報を整理する場面でよく使われます。

### 組み合わせると全部で9通り

これら2つの軸（役割の与え方 × 属性の伝え方）の各3通りを組み合わせると、全部で9通りのプロンプトパターンが作れます（3×3）。研究チームはそれぞれの組み合わせについて、LLMの応答がどう変わるのかを詳しく比較しました。

たとえば、「ストレートに役割を伝えつつ、名前で属性を暗示する」といった場合は、「あなたは小泉総理という首相です」という書き方になります。一方、「会話形式で、属性を明示的に伝える」パターンでは、冒頭のやりとりの中で性別や人種が自然に出てくる形になります。

こうして、これまで直感や慣れに頼っていた書き方の違いを、体系的に比較します。LLMに何を伝えるかだけでなく、どう伝えるかが大きく影響することを、あらためて検証するというわけです。

## 実際にプロンプトの違いはどう効くのか検証した方法

では、9通りのプロンプトの違いが、LLMの出力にどんな影響を与えるのか。研究チームはそれを丁寧に調べるために、3種類のタスクを用意して実験を行いました。

### 検証タスク

使われたのは、自由記述タスクと選択式タスクです。

#### 自由記述タスク「自己紹介とSNSプロフィールの自由記述」

まずは自由に文章を書かせるタスクです。設定されたペルソナになりきったうえで、「あなた自身について説明してください」「SNS用のプロフィールを書いてください」といった課題を出しました。

人種や性別が違っても、自己紹介の中身が極端に変わることは本来あまりないはずです。たいていは趣味や性格、仕事や価値観など、個人の経験に根ざした内容になるからです。

もしLLMが属性情報だけを根拠にした、いかにもなテンプレート的自己紹介を返してくるようなら、ペルソナの設定がステレオタイプを助長しているおそれがあります。

#### 選択式タスク「世論調査に答える選択式タスク」

次は、実際の世論調査の質問に対してLLMに選択肢を選ばせるタスクです。

つまり、誰かになりきってもらってアンケートを答えさせるということです。

世論調査の質問に使われたのは、アメリカの調査データセット「OpinionsQA」から選んだ100問で、それぞれを指定したペルソナの立場で答えてもらいました。

理想的には、属性によって答えに傾向が出てくる方が自然です。実際の人間の回答にも、年齢や出身地による違いが現れるからです。

そこで、LLMの答えが人間の統計とどれくらい近づいているかを見ることで、プロンプトによる影響を測定しました。

### どんな人物を想定したのか

タスクには、全部で15種類の人物像が用意されました。人種・民族は白人、黒人、アジア系、中東系、ヒスパニック系。性別は男性、女性、ノンバイナリー。この組み合わせから成る設定です。

ただし選択式タスクでは、実在の世論調査データが得られる４つの人種（白人、黒人、アジア系、ヒスパニック系）×男性／女性の計８パターンに絞りました。

### どんなLLMを使ったのか

実験には、Llama、OLMo、Gemmaなど、異なる系列のLLMが使われました。モデルのサイズもさまざまで、比較的小さなモデルから大きなものまで含まれています。

具体名

-   Llama-3.3-70B-Instruct
-   Llama-3.1-8B-Instruct
-   OLMo-2-0325-32B-Instruct
-   OLMo-2-1124-7B-Instruct
-   gemma-3-27b-it

### どう評価したのか

#### 自由記述タスクの評価

自由記述については、複数の観点から分析されました。

**観点①ステレオタイプの検出**  
特定の属性グループで頻出する単語をリストアップし、その単語がどの程度使われているかを測定。  
たとえば、もしアジア系の設定で「伝統」や「家族」といった語が不自然に多いと、属性に引きずられた表現になっている可能性があります。

**観点**②**回答の多様性**  
文章の意味的なばらつきを数値化し、似たような内容ばかりになっていないかを調べました。同じグループでも、出力される文章にバリエーションがあれば自然です。

****観点****③**言語の使い分け**  
プロンプトは英語で与えられた場合、「プロンプトが英語で与えられている以上、LLMの応答も英語であるべき」という前提で評価しています。「特定の文化圏の人は母語を使う」という偏見の表れとして現れるケースがあるため、言語の使い分けもチェック対象になりました。

#### 選択式タスクの評価

選択式タスクでは、LLMの出した回答の分布と、実際の世論調査データとの距離を数値で計測しています。使われたのは「ワッサースタイン距離」という指標で、人間に近いほど値が小さくなります。

### 実験の規模感

この検証では、すべてのプロンプトパターンについて何度も繰り返しテストを行い、プロンプトとモデルの組み合わせごとに大量の出力を収集し、合計で数万件にのぼる出力を分析しています。偶然ではなく傾向として信頼できる結果を得るよう設計されたのです。

## プロンプト設計の影響を確かめる実験の結果

プロンプトの書き方を9通りに変えて行った大規模な実験から、ペルソナの設定が与える影響や、特定の書き方が持つ効果が明らかになっています。

### 属性ごとの出力傾向に差がある

#### ステレオタイプが強く出る属性もある

人物像を人種や性別などで設定したとき、どのグループでも均等に自然な応答が得られるわけではありませんでした。なかでも、ノンバイナリー、ヒスパニック系、中東系の設定では、文章が画一的になったり、ある種の言葉が過剰に使われたりする傾向が目立っています。

![[LLMペルソナプロンプトの細かい設計が出力に与える影響を詳しく検証 - AIDB/AIDB_92928_2-1024x274.png]]

こうした偏りが見られた出力には、「伝統」や「家族」といった語が目立つケースがあり、属性に対する固定観念が投影されている可能性があるとされます。一方で、白人男性の設定では多様性が保たれた自然な出力が得られることが多く、バランスの偏りが浮き彫りになりました。

|      グループ      |                           上位10語（出現頻度順）                           |
|----------------|------------------------------------------------------------------|
|    アジア系の女性     |               伝統／暗い／小柄／長い／現代的／アーモンド形／文化的／お団子／金色／繊細               |
|    アジア系の男性     |             中国人／韓国人／尊敬／スタイリング／伝統／武術／ベトナム人／細い／日本人／伝統的             |
|  アジア系ノンバイナリー   |             アイデンティティ／性別／伝統的／二元／芸術／文化的／伝統／受け入れ／融合／代名詞             |
|     黒人の女性      |             アフリカ系／姉妹／強さ／娘／レジリエンス／回復力／豊か／正義／ゆるぎない／先祖              |
|     黒人の男性      |            アフリカ系／息子／レジリエンス／兄弟／コミュニティ／豊か／強さ／誇り／正義／前向き             |
|   黒人ノンバイナリー    |          アイデンティティ／性別／アフリカ系／流動性／レジリエンス／二元／世界／芸術／黒人性／ユニーク          |
|   ヒスパニック系の女性   |     ラティーナ／活気／誇り／スペイン語／伝統／温かさ／アメリカ人／ラテン／mujer（「女性」）／mi（「私の」）      |
|   ヒスパニック系の男性   | ラテン／誇り／アメリカ人／スペイン語／家族／la（冠詞）／サルサ／mi（「私の」）／hombre（「男性」）／que（「〜な」） |
| ヒスパニック系ノンバイナリー |               ラティンクス／伝統／性別／ラテン／活気／正義／二元／社会／プエルト／リコ               |
|     中東系の女性     |            豊か／伝統／信念／伝統（複数形）／女性／温かみ／現代性／深く／自立／伝統（単数形）             |
|     中東系の男性     |              おもてなし／信念／アラビア語／地域／古代／豊か／伝統／強い／ムスリム／中東               |
|   中東系ノンバイナリー   |            アイデンティティ／伝統／伝統的／性別／中東／タペストリー／文化的／東部／豊か／二元             |
|     白人の女性      |           ブロンド／長い／波状／ヨガ／ほっそり／カール／親しみやすい／肌の色白い／オリーブ色／青            |
|     白人の男性      |            短い／アウトドア／フィート／率直／青／始まり／無精ひげ／コンピュータ／ビール／正直             |
|   白人ノンバイナリー    |            性別／二元／アイデンティティ／代名詞／伝統的／使用／中性／カテゴリ／流動的／創造的             |

#### 言語の混在にも注意が必要

プロンプトは英語で与えられているにもかかわらず、ヒスパニック系の設定では10%を超える回答にスペイン語が混ざる現象が確認されました。特定の文化背景を持つ人は自動的にその母語を話すと想定するような、永続的外国人ステレオタイプに近いものと考えられます。

![[LLMペルソナプロンプトの細かい設計が出力に与える影響を詳しく検証 - AIDB/AIDB_92928_5-1024x542.png]]

### プロンプトの工夫で結果は大きく変わる

プロンプトの細かな工夫がLLMの公平性や自然さに大きな影響を与えることが実証されました。

![[LLMペルソナプロンプトの細かい設計が出力に与える影響を詳しく検証 - AIDB/AIDB_92928_4-1024x283.png]]

単なる出力制御の手段にとどまらず、社会的な観点からも重要な設計要素として捉える必要がありそうです。

#### 属性を間接的に伝えると偏りが抑えられる

プロンプトの書き方を比較した結果、良い影響を与えたのは、属性を直接書かずに名前で暗示する方法と、会話形式で段階的に設定していく方法でした。

たとえば「ヒスパニック系の女性です」と明示する代わりに「あなたはMs. Garciaです」と伝えたり、インタビュースタイルで質問を重ねながら人物像を浮かび上がらせたりすると、以下のような変化が見られました。

-   出力される語彙がより自然になり、特定の属性に偏った表現が減る
-   自己紹介文の内容に多様性が生まれる
-   英語以外の言語が混ざる率が低下する
-   世論調査への回答が人間の統計に近づく

![[LLMペルソナプロンプトの細かい設計が出力に与える影響を詳しく検証 - AIDB/AIDB_92928_6-1024x274.png]]

#### 明示的な属性記述は逆効果になることも

属性を構造化して記述する方法、たとえば「人種：ヒスパニック系、性別：女性」のようなプロンプトは、内容が定型化しやすくなる傾向がありました。特に自由記述のタスクでは、画一的で個性の乏しい出力につながりやすく、LLMが属性に引きずられた回答を返す一因と考えられます。

### モデルサイズと出力の関係

#### 大きければ良いとは限らない

5種類のLLMを比較したところ、最も人間に近い応答を出したのはOLMo-2-7Bという中規模モデルでした。逆に、パラメータ数が多いLlama-3.3-70BやGemma-3-27Bでは期待したほどの精度が出ませんでした。

とくに大規模モデルでは、ひとつの選択肢に極端に高い確率（99.9%以上）を割り当てるケースが多く、あいまいな回答や意見のばらつきといった「人間らしさ」が出にくい傾向がありました。

### 世論調査を使った評価でも差が出る

#### グループによって人間との一致度にばらつき

選択式タスクでは、属性ごとに回答の傾向が異なりました。

![[LLMペルソナプロンプトの細かい設計が出力に与える影響を詳しく検証 - AIDB/AIDB_92928_3-1024x496.png]]

もっとも人間の統計に近い応答を示したのは黒人の設定で、逆にズレが大きかったのは白人の設定でした。

この差は、LLMが学習したデータ内の意見分布が、現実の人口構成と一致していない可能性を示唆します。

#### インタビュースタイルはここでも有効

自由記述だけでなく、選択式タスクでもインタビュー形式でペルソナを立ち上げていく方法が有効でした。質問を通じて人物像を構築することで、回答がより人間に近づく傾向が確認されています。

### 出力のばらつきを抑える効果もある

名前の使用やインタビュー形式を用いたプロンプトでは、グループごとの出力の差も縮まりました。特定の属性だけが極端に不利になるような状況を避けるためにも、プロンプト設計が果たす役割は大きいと考えられます。

## 実務に役立つ視点と知見

### 設計の選び方が社会性にもつながる

今回の研究から見えてきたのは、プロンプト設計が単なる技術上の工夫ではなく、社会的なふるまいにも深く関係するという点です。どのような表現を使うかによって、LLMが描き出す人物像や価値観の幅が変わってしまいます。

LLMを活用したサービスやアプリケーションが社会に広がるにつれ、出力の自然さや精度だけでなく、公平性や多様性の観点も無視できない設計要素として浮上しています。

### 現場で活かせる実践的なヒント

本実験で有効だったプロンプト設計の工夫は、実際のLLM活用にも応用できそうです。少し振り返ります。

たとえば、属性を明示するのではなく、名前や語調などの文脈から暗に伝える方法に切り替えると、固定観念に引きずられた表現が減り、応答がより自然になります。インタビュー形式で人物像を少しずつ構築していく手法も、効果が高いことが確認されました。

一方で、「人種：アジア系、性別：女性」といった構造的な属性指定は、出力を画一的にしてしまう傾向があります。LLMが属性情報に過剰に反応してしまうリスクがあるため、避けた方がよいと考えられます。

プロンプトを一種類だけで使うのではなく、いくつかの書き方を並行して試し、結果を比較する姿勢も有用です。想定外の出力に気づく手がかりになります。

### 出力の評価にも工夫が必要

どのようなプロンプトが適切かを判断するには、出力を評価する手段も工夫が求められます。

今回は「ステレオタイプの検出」「内容の多様性」「人間の回答との一致度」など、複数の視点からの評価が行われました。数値だけで判断するのではなく、言葉の使われ方や全体の傾向も丁寧に読み解くことが、偏見の発見や公平性の確認につながります。

### モデル更新にあわせた再設計の視点

LLMは日々進化しており、出力傾向も少しずつ変わっていきます。一度は自然で公平と判断されたプロンプトも、モデルが変われば期待通りの挙動にならないことがあります。

そのため、プロンプト設計は一度きりの最適化ではなく、モデルの変化にあわせて何度も見直す対象として考えておくのがよさそうです。継続的に検証と改善を繰り返すことで、長期的な信頼性を保つことができます。

### LLMにとどまらない広がりも

本実験結果はLLMを使う際の設計の工夫や注意点にとどまらず、AI全般に共通する設計上の課題を改めて浮かび上がらせています。性能や精度だけでは測れない、社会的な影響のコントロールがこれからの技術開発でますます重要になっていきます。

とくに、多様なユーザーが関わるサービスやツールでは、プロンプト設計の段階から「どんな視点が欠けていないか」「誰の立場が見落とされていないか」を丁寧に検討し、実験や分析を通じて確認していくことが求められます。

## まとめ

本記事では、LLMのペルソナプロンプトにおける表現の違いがモデルの出力にどのような影響を与えるかを検証した研究を紹介しました。

プロンプトの書き方によって、出力内容に含まれる語彙や言語の使い分け、回答の多様性に明確な差が現れることが確認されています。とくに属性を明示する方法と、名前や対話を通じて間接的に伝える方法とでは、応答の自然さや公平性に差が出る傾向が示されました。また、モデルのサイズが大きければ性能が高いとは限らず、中規模モデルが最も人間らしい応答を示すケースも見られました。

LLMを活用した対話システムや社会調査、ユーザーモデリングなどを検討する際に、プロンプト設計の選び方を見直すきっかけとしていただければと思います。

**参照文献情報**

-   タイトル：The Prompt Makes the Person(a): A Systematic Evaluation of Sociodemographic Persona Prompting for Large Language Models
-   URL：[https://doi.org/10.48550/arXiv.2507.16076](https://doi.org/10.48550/arXiv.2507.16076)
-   著者：Marlene Lutz, Indira Sen, Georg Ahnert, Elisa Rogers, Markus Strohmaier
-   所属：University of Mannheim, GESIS – Leibniz Institute for the Social Sciences, Complexity Science Hub Vienna
