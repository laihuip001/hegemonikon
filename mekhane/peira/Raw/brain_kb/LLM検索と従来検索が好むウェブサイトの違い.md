---
created: 2026-01-01T11:15:32 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/99037
author: AIDB Research
---

# LLM検索と従来検索が好むウェブサイトの違い - AIDB

> ## Excerpt
> 現在、ChatGPTやGeminiといった生成AIが検索結果をまとめて提示する「LLM検索エンジン」の利用が急速に広がっています。こうしたAIがどのような情報源を選び、どこから情報を引用しているのかについては、これまで詳しく調べられていません。 本記事では、この疑問に答えるために行われた大規模な比較研究を紹介します。研究では、6つの主要なLLM検索エンジン（ChatGPT、Gemini、Perpl…

---
現在、ChatGPTやGeminiといった生成AIが検索結果をまとめて提示する「LLM検索エンジン」の利用が急速に広がっています。こうしたAIがどのような情報源を選び、どこから情報を引用しているのかについては、これまで詳しく調べられていません。

本記事では、この疑問に答えるために行われた大規模な比較研究を紹介します。研究では、6つの主要なLLM検索エンジン（ChatGPT、Gemini、Perplexity、Grok、Google AI Mode、Copilot）と、従来型の検索エンジン（GoogleとBing）の合計8種類を対象とし、55,000件以上の検索クエリを分析しました。

![[LLM検索と従来検索が好むウェブサイトの違い - AIDB/AIDB_99037-1-1024x576.png]]

## 背景

これまで検索エンジンは、インターネット上の情報にアクセスするための主な手段として使われてきました。GoogleやBingなどの従来型検索エンジンは、ウェブ上の情報を集め、関連性や信頼性をもとに順位をつけてリンクの一覧として表示します。ユーザーはこのランキングを参考に、自分で情報を探してきたわけです。

しかし、近年のLLMの進化によって、情報検索のあり方が大きく変わり始めています。実際、アメリカでは2027年までに約9,000万人の成人がAIを使った検索を利用するようになると予測されています。

こうした新しい検索のかたちが「LLM検索エンジン」です。これは、ChatGPTやGeminiのように、AIが検索結果を自動でまとめて読みやすい文章として提示してくれるものです。これまでのように、いくつものリンクをクリックして情報を集める必要はなく、ひとつのまとまった回答が返ってくるのが特徴です。

ただし、この便利な仕組みには課題もあります。AIが複雑な処理を行うことで、「どの情報源が使われたのか」がわかりにくくなり、透明性が損なわれやすいのです。また、RAGによって思わぬバイアス（偏り）が生じたり、LLMが誤った情報をあたかも正確であるかのように生成してしまう「ハルシネーション（幻覚）」の問題も指摘されています。

こうした問題への対応として、近年では多くのLLM検索エンジンが回答に引用元を明記するようになっています。つまり、どのウェブサイトから情報を得たのかをリンク付きで示すことで、ユーザーが元の情報を確認できるようにしているのです。

とはいえ、「LLM検索エンジンはどうやって引用元を選んでいるのか？」また「従来型検索と比べて、使われている情報源はどれくらい違うのか？」といった点については、これまで体系的な調査が行われていませんでした。

このような背景から、本記事ではそれらの疑問を明らかにするために行われた大規模な実証分析を紹介します。

ここから限定コンテンツ

### **忙しい人向けに、重要なポイント5選**

1.  6つのLLM検索エンジンと2つの従来型検索エンジンを対象に、55,936件のクエリと140万件超の引用リンクを分析した大規模研究
2.  LLM検索は従来検索の半分以下の情報源（平均4.3件 vs 10.3件）しか提示しないが、ドメインの分布はより均等
3.  LLM検索が引用するドメインの37%は従来検索には登場せず、両者で共通するのは38%のみ
4.  Geminiは極左寄りの情報源を6.4%引用し、Grokは政治的中立性が最も低く、情報源の少なさが信頼性を損なう要因
5.  LLM検索は、構造化されたHTML、読みやすいテキスト、人気度の低いドメイン、外部リンクの多い情報源を好む傾向がある

**参照文献情報**

-   タイトル：Source Coverage and Citation Bias in LLM-based vs. Traditional Search Engines
-   URL：[https://arxiv.org/abs/2512.09483](https://arxiv.org/abs/2512.09483)
-   著者：Peixian Zhang, Qiming Ye, Zifan Peng, Kiran Garimella, Gareth Tyson
-   所属：The Hong Kong University of Science and Technology, Rutgers University

まず従来型検索エンジンと、LLM検索エンジンの基本的な動作の仕組み、そしてこれまでの研究で明らかになってきた特徴について整理します。

### 従来型検索エンジンの仕組み

GoogleやBingなどの従来型検索エンジンは、主に3つのステップを経て動作しています。

最初のステップは「クローリング」です。「クローラー」と呼ばれるプログラムがウェブ上を巡回し、リンクやサイトマップをたどって新しいページを見つけてくる作業です。

次に「インデクシング」が行われます。収集したページに含まれる単語やその出現場所を記録し、「転置インデックス」と呼ばれるデータベースを作成する工程です。本の巻末にある索引のようなもので、どの単語がどのページにあるのかをすぐに検索できるようにする仕組みです。

最後に「ランキング」の段階では、さまざまな要素を組み合わせて検索結果の表示順が決まります。代表的なのが「PageRank」というアルゴリズムで、他の多くのページからリンクされているページほど信頼性が高いと評価されます。さらにGoogleでは、「E-E-A-T（経験・専門性・権威性・信頼性）」という品質基準も導入されており、情報の質を多面的に評価するようになっています。

こうして表示された検索結果は、ユーザーの行動にも大きな影響を与えます。たとえば、検索結果で上位に表示されたリンクほどクリックされやすく、該当サイトへの訪問数（トラフィック）も大きく増えることが知られています。実際、従来型検索エンジンは今でも全世界のウェブトラフィックの半数以上を占めています。

ただし、こうした従来型の検索にも課題があります。たとえば、ユーザーが検索結果の上位に表示されたものや、有名なドメインばかりを過剰に信頼してしまう「ランクバイアス」や「権威ドメインバイアス」が起きやすいと指摘されています。また、似たような情報ばかりが表示されることで「エコーチェンバー（同じ考え方が繰り返し強化される現象）」が生まれ、政治的な偏りや意見の分極化が進む可能性も懸念されています。

### LLM検索エンジンの特徴

LLM検索エンジンは、従来型とは根本的に異なる方法で情報を処理しています。その中心にあるのが、「RAG」という考え方です。

まず、LLMはユーザーの意図を読み取り、その質問（クエリ）を複数の小さなサブクエリに分解します。

こうして作られたサブクエリは、ローカルの知識ベース（内部情報）やオンライン上の情報源から、関連するコンテンツを収集するために使われます。

集められた情報は関連性にもとづいてランク付けされ、重要なテキストが選別されます。そして最後に、LLMがこれらの文書を読み取り、統合して、わかりやすく自然な文章として要約を生成します。この際、情報の出典を明示するために、文中には「インライン引用」が付けられます。

しかし、こうした仕組みにもいくつか課題があります。まず、LLMそのものがバイアス（偏り）を持つ可能性があるという点です。たとえば、取得した文書に誤った情報が含まれていた場合、その誤りがそのままLLMの回答にも反映されてしまう恐れがあります。また、ニュースソースを評価する際に、LLMが特定の政治的立場に偏った判断を下すことや、悪意あるリンクをうっかり生成してしまうケースも報告されています。

### これまでの比較研究

行われた研究によると、LLM検索は複雑な判断が必要なタスクでは従来型よりも優れている一方で、誤った回答にユーザーが頼りすぎる傾向も見られます。反対に、画像の位置を探すようなタスクでは従来型のほうが高精度です。

LLM検索に引用があると信頼感が増すこともわかっており、意味の深いテーマではLLM検索が好まれる傾向があります。ただし、安全でないリンクを生成してしまうリスクも指摘されています。

## 調査手法とデータ収集

![[LLM検索と従来検索が好むウェブサイトの違い - AIDB/AIDB_99037_1.png]]

調査の全体フロー（クエリ収集→検索→引用抽出→アノテーション）

### 対象とした検索エンジン

まず研究チームは、どのようなものをLLM検索エンジンと呼ぶかをはっきりと定義しました。ここでは「ウェブ上の情報を取得し、引用を含む要約を生成できる大規模言語モデルを使ったシステム」をLLM検索エンジンとしています。

この定義に当てはまるものとして、次の6つの主要なLLM検索エンジンが調査対象となりました。ChatGPT、Gemini、Perplexity、Grok、Google AI Mode（以下AI Mode）、そしてBingのCopilot Search（以下Copilot）です。

|   サービス名    |    参照したモデルや版     | ログイン必要 | 検索ボタン |  収集した引用数  |
|------------|------------------|--------|-------|-----------|
|  AI Mode   |  Gemini系（詳細不明）   |   なし   |  なし   |  414,524  |
|  ChatGPT   | gpt-5.0-instant  |   あり   |  あり   |  206,590  |
|  Copilot   |    GPT系（詳細不明）    |   なし   |  なし   | 1,029,015 |
|   Gemini   | Gemini-2.5-flash |   なし   |  なし   |  182,541  |
|    Grok    |     Grok 3.0     |   なし   |  なし   |  62,420   |
| Perplexity |      Sonar       |   なし   |  あり   |  280,699  |

あわせて比較対象として、従来型検索エンジンの代表であるGoogleとBingも調査に含まれています。

### 検索クエリの準備

次に重要なのは、どのような検索クエリ（質問や検索語）を使うかという点です。

#### キーワードクエリの収集

まず土台となるのは、実際のユーザーが検索している内容を反映したキーワードです。研究チームは、2025年7月16日から8月10日までの期間にアメリカで話題となったトピックを調べるため、Google TrendsとX（旧Twitter）のトレンドデータを活用しました。Google Trendsから7,519件、Xから5,593件のユニークなキーワードが収集されました。

#### 関連質問の生成

ただし、単なるキーワードだけでは不十分です。キーワードは意味があいまいだったり、文脈によって解釈が変わったりするためです。また、LLM検索では、単語よりも自然文での問いかけの方が好まれることも分かっています。

そこでチームは、集めたキーワードを使ってGoogle検索とGoogle AI Modeで実際に検索を行い、そこに表示される「関連する検索クエリ」を収集しました。

Google検索から37,931件、AI Modeから2,612件の文章形式のクエリが得られました。

#### 「意見が分かれる話題」の追加

さらに、検索エンジンが社会的に敏感なテーマをどのように扱うかを調べるために「意見が分かれる話題」もデータに加えられました。質問サイトQuoraに投稿された人気の質問の中から、LLMが社会的に敏感と判断した内容をまとめた公開データセットを使っています。中には2,281件のクエリが含まれており、政治や社会問題など、扱いの難しいトピックが多く含まれています。

### 検索の実行とデータ処理

クエリの準備が終わったら、次はそれらのキーワードや質問文を実際に各検索エンジンへ入力していきます。

#### 従来型検索エンジンの処理

従来型検索では、個人の検索履歴などによる影響を避けるため、ブラウザはシークレットモードで操作しました。また、ほとんどのユーザーが1ページ目の結果しか見ないことが分かっているため、分析対象は1ページ目のリンクに限定しています。

さらに、「広告」や「スポンサー」といったタグが付いているURLは、広告として明示的に記録しました。ただし、それらのリンクの順位は、表示された順番のまま残しています。

この方法で、Googleからは48万件以上、Bingからは約21万件のURLが集まりました。

#### LLM検索エンジンの処理

LLM検索エンジンでも、ブラウザを使って同様の手順でデータを集めました。こちらも個人化の影響を避けるため、シークレットモードを使用しています。

ただし、LLM検索にはサービスごとの違いがあります。たとえばChatGPTは、今回の調査対象の中で唯一ログインが必要なサービスだったため、過去のやりとりが影響しないようにメモリ機能をオフにして、毎回新しいセッションとして検索が行われました。

集めたデータは、それぞれの回答の中から引用された情報とあわせて記録されました。具体的には、AI Modeから約41万件、ChatGPTから約20万件、Copilotは約103万件、Geminiは約18万件、Grokは約6万件、Perplexityからは約28万件の引用が得られています。

### データのアノテーション

収集したデータを分析できるように、研究チームはラベル付け（アノテーション）を行いました。

#### 検索クエリの分類

まず、各検索クエリをGoogle Trendsのカテゴリ分類に基づいて分類しました。この作業には大規模言語モデルを使って自動で行われ、クエリは最終的に26のカテゴリに分かれました。中でも多かったのは「アート＆エンターテインメント（27%）」、「人々＆社会（19%）」、「スポーツ（17%）」で、幅広い話題が含まれていたことがわかります。

#### ドメインの分類と評価

引用されたウェブサイトを分類するために、Forcepointの自動分類ツール「ACE」が使われました。また、各サイトの人気度は「Tranco Ranking」で評価され、どれくらいアクセスがあるかを推定しました。

さらに、情報の信頼性や安全性を調べるために、2つの外部データも利用しました。一つは「Media Bias/Fact Check（MBFC）」で、政治的な偏りや信頼性を評価します。もう一つは「VirusTotal」で、悪意あるサイトを検出するためのものです。

最終的に、5万5千件以上の検索クエリ、12万以上のドメイン、140万件超の引用リンクからなる大規模データセットが構築されました。

## 情報源の引用パターンを分析（研究課題1）

従来型は順位付きのリンクを返す一方で、LLM検索は少数の情報源を使って要約を提示します。ただし、その情報源が本当に質の高いものかどうかは、これまでよく分かっていませんでした。

### 引用パターンの比較

#### 情報源の数

まず、1回の検索で何件の情報源が引用されるのかを比較しました。その結果、すべてのLLM検索は、従来型よりも引用数が少ないことが明らかになりました。LLM検索は平均4.3件のURL、3.4件のドメインを返したのに対し、従来型はそれぞれ10.3件と7.3件でした。

![[LLM検索と従来検索が好むウェブサイトの違い - AIDB/AIDB_99037_2.png]]

1回答あたりの引用数（LLM検索は少数の情報源に集約）

Grokでは82%、Geminiでは38%の回答に、引用元のURLがまったく含まれていませんでした。これらのモデルが内部の知識ベースに強く依存していたり、引用の基準が厳しいことが影響していると考えられます。ただし、情報源が少なすぎるとユーザーの信頼を損なうおそれもあります（先行研究で指摘）。

#### ドメインの集中度

次に、特定のサイトに偏って情報が集まっていないかを調べます。

結果として、すべてのLLM検索エンジンは従来型より、情報源の偏りが少ない傾向がありました。特にGemini、Grok、ChatGPTは、従来型との間に統計的な差が見られました。

ChatGPTはGoogleとの間にのみ差があり、Bingとはあまり差が見られませんでした。ChatGPTがBingの情報を活用しているためだと考えられます。一方、GrokとGeminiは両方の従来型検索と明確に異なっていました。

とはいえ、引用が分散しているとはいえ、そもそもの情報源の数が少ないという点は注意が必要です。この多様性がユーザー体験にどう影響するかは、次の「情報源の質」に関する分析へと続きます。

### ドメイン選択の違い

#### 全体的な違い

まず、各検索エンジンがどれだけ独自の情報源（ドメイン）を返しているかを調べました。これは、使う検索エンジンによってユーザーが得る情報がどれほど違うかを示します。

![[LLM検索と従来検索が好むウェブサイトの違い - AIDB/AIDB_99037_3.png]]

参照ドメインの重なり（共通は約38%、LLM検索のみも多い）

結果は興味深く、従来型とLLM検索の両方で使われている共通ドメインは全体の38%しかなく、37%はLLM検索でしか見られないものでした。どの組み合わせでも、ドメインの重なりは平均40%未満です。

たとえ同じ企業のサービス間でも違いが見られました。たとえば、Google、AI Mode、Geminiは同じ会社の提供ですが、30%以上のドメインが一致しませんでした。

この差の背景には、LLM検索がクエリを細かく分けて処理していることがあると考えられます。結果的に、LLM検索だけを使うユーザーと従来型検索だけを使うユーザーとでは、接する情報源が大きく異なる可能性があります。

#### ニュースソースにおける違い

LLM検索と従来型検索で情報源が異なる傾向は、ニュースサイトにも表れていました。特定のサイトに偏っていないかを確かめるため、まずニュースサイトに該当する2,675件のドメインを抽出しました。

結果を見ると全体の差はそれほど大きくないものの、一部のドメインに偏りが見られました。たとえばChatGPTは、ロイターやAP Newsといった通信社を、GoogleやBingよりもよく引用していました（GoogleとのRTDは−0.48、Bingとは−0.41）。

一方、従来型検索ではCNNやUSA TODAY、Townhallなどの放送局や意見色の強いメディアが多く見られました。こうした差は、検索結果にバイアスが入りやすいことを示唆しており、この点については次のセクションでさらに詳しく分析されています。

### 情報源の人気度

最後に、引用されているドメインの人気度を調べました。どの情報源がよく使われているかは、検索エンジンがどれだけ「権威のある情報」と判断しているかに関わるためです。研究では二つの指標が使われました。一つはGoogleとBingでの検索順位で、もう一つはサイト全体のアクセス量を推定するTrancoランキングです。

#### 検索による露出

まず、LLM検索と従来型検索の両方に登場するドメインについて、従来型検索での順位を調べました。ただし、両者に共通して現れるドメインは全体の37%にとどまります。

従来型検索では、同じドメインが複数の順位に表示される場合もあるため、そのすべてをカウントしました。そのうえで、LLM検索が引用したドメインが、従来型検索では何位に表示されていたかを集計しています。

その結果、LLM検索がよく引用する情報源は、従来型検索でも最上位に表示されているケースが多いことが分かりました。実際、Bingでは約23%、Googleでは約15%が1位の結果でした。重複する情報源に限れば、LLM検索は従来型検索で最も目立つドメインを選ぶ傾向があると言えます。

![[LLM検索と従来検索が好むウェブサイトの違い - AIDB/AIDB_99037_4.png]]

LLM検索の引用先は従来検索の“上位結果”に集中

#### トラフィックベースの人気度

次に、、引用されたドメインのアクセス量ベースの人気度を調べました。

分析の結果、検索エンジンごとに引用されるドメインの人気度には明確な差がありました。統計的な検定でも、すべてのLLM検索は従来型検索と異なる傾向を示しています。

全体として、ChatGPTを除くLLM検索は、従来型検索よりもアクセスの少ないドメインを引用しやすい傾向がありました。特にCopilotとGeminiでは、平均して2万以上ランクが高く、トラフィックの少ないサイトが多く使われていました。

こうした傾向は、ユーザーの信頼に影響する可能性があります。一般に、人はアクセスの多いサイトを信頼しやすいためです。また、トラフィックの少ない情報源は信頼性が低い場合もあります。

## 情報源の品質評価

LLM検索では提示される情報源が少数に限られるため、それぞれの情報源の「質」がより重要になります。そこで、情報源の信頼性とセキュリティリスクの観点から品質を評価しました。

### 信頼性の評価

調査は主にニュースやメディアの情報源を対象に行いました。

#### スコアの割り当て方法

信頼性の評価には、MBFC（Media Bias/Fact Check）のデータを使用しました。MBFCは、各メディアの政治的傾向と事実性（信頼度）をスコア化しています。

![[LLM検索と従来検索が好むウェブサイトの違い - AIDB/AIDB_99037_5-1024x317.png]]

引用ドメインの信頼性・政治的傾向（MBFC）の分布

統計的検定の結果、信頼性・政治的傾向のどちらでも検索エンジン間に有意差が見られました。

#### 信頼性スコアの分析

引用頻度が最も高かったのはWikipedia（スコア −0.9）で、全体の32%を占めていました。従来型検索ではBingが最も高い信頼性を示しましたが、これはbing.comやcambridge.orgなど信頼性の高いドメインに偏っていたためです。

LLM検索では、GeminiとChatGPT以外はBingとGoogleの中間レベルでした。ただし、GeminiはWikipediaへの依存が非常に高く、引用の41%を占めており、引用されたドメインが1つだけという回答も62%にのぼりました。こうした偏りは、全体のスコアの低さにもつながっています。

#### 政治的傾向の分析

MBFCによる政治的傾向のスコアは−10（左派）〜+10（右派）の範囲で評価されました。全体として、すべての検索エンジンが左寄りの傾向を示し、特にGrokを除くエンジンでは極端に左寄りのドメインも含まれていました。

Geminiは6.4%のドメインが極左（スコア −5以下）に該当しており、引用数が少ないことがバイアスをさらに強めていました。

また、回答全体の中立性を評価したところ、Grokの中立スコア（0点）はわずか16%にとどまり、公式には中立をうたっているものの、実際には偏りが強いことが分かりました。

GeminiとGrokはいずれも引用ドメインの数が少なく、多様性に欠けており、そのことが政治的バイアスの強さに影響していると考えられます。情報源の数が少ないと、特定の視点に偏った内容にユーザーがさらされやすくなるのです。

### サイバー脅威の評価

情報源の信頼性だけでなく、ユーザーの安全を守るために、引用元がサイバー脅威を含んでいないかも評価されました。研究チームは、2つ以上のベンダーから「危険」と判定された場合に、そのドメインを「安全でない」とみなす基準を採用しました。

#### 露出リスク

125,555件のドメインのうち、439件（0.36%）が悪意のあるものと判定されました。特定の少数のドメインが繰り返し登場しており、上位10%のドメインが全体の59%の出現を占めていました。

悪意あるドメインが最も多く含まれていたのは、Google（19%）とCopilot（18%）でした。全体的なリスクを見ると、従来型検索ではBingが0.42%、Googleが0.23%の割合で悪意あるドメインを含んでいました。

|        指標         | AI Mode | ChatGPT | Copilot | Gemini | Grok  | Perplexity | Bing（従来型） | Google（従来型） |
|-------------------|---------|---------|---------|--------|-------|------------|-----------|-------------|
|     脅威ドメインの割合     |  0.25%  |  0.32%  |  0.34%  | 0.26%  | 0.34% |   0.23%    |   0.42%   |    0.23%    |
| 回答1件あたりの脅威ドメイン平均数 |  1.07   |  1.01   |  1.03   |  1.56  | 1.11  |    1.02    |   1.33    |    1.05     |

LLM検索は、引用数が少ないにもかかわらず、これらの中間程度のリスクを示しました。中でもGeminiだけは、従来型よりもやや高い平均リスクを示し、Googleよりも1.5倍高い数値でした。

引用数が少ないLLM検索でも、必ずしもリスクの軽減にはつながっていないことが明らかになりました。また、同じ企業のサービスであっても、脅威への対応にばらつきがあることも示されています。

#### ドメインの重複

次に、異なる検索エンジンが同じ悪意あるドメインを返しているかどうかを調べました。Jaccard類似度という指標を使ったところ、エンジン同士の85%がスコア0.5を超えており、14%は0.8超という高い重複度でした。

複数の検索エンジンが同じような危険な情報源を共有している可能性を示しており、共通の対策が有効であることを意味します。

#### 検索クエリのカテゴリ

どんなタイプの検索が悪意あるドメインを引き起こしやすいかも調査されました。クエリごとの類似度は低く（すべて0.4未満）、異なる質問がそれぞれ異なるリスクを生んでいることが分かりました。

ただし、全体の中で悪意あるドメインが返されたクエリの多くは、「アート＆エンターテインメント」「人々＆社会」「金融」「スポーツ」といった一見無害に見える4カテゴリに集中していました。

![[LLM検索と従来検索が好むウェブサイトの違い - AIDB/AIDB_99037_6.png]]

悪意ドメインが出やすいクエリカテゴリ（上位）

日常的なトピックの検索でも、安全性に注意が必要であることを示しています。

## LLM検索と従来検索が好むウェブサイトの特徴

どのようなウェブページがLLM検索に選ばれやすいのかを詳しく調べるため、サイトの構造や内容の特徴に着目した分析を行いました。

### HTML構造の特徴

はじめに、ウェブページを構成する基本であるHTMLの使われ方に注目しました。先行研究によると、HTMLの構造は、検索エンジンがどの情報を拾って引用するかに大きく関係していることが分かっています。

調査には、ランダムに選んだ1万件のURLを使いました。対象は、robots.txtでクローリングが許可されているウェブサイトに限定しています。

テキストの面では、文章の読みやすさを数値化する2つの指標を用いました。一つ目は「フレッシュ読みやすさスコア」で、スコアが高いほど読みやすいとされます。二つ目は「フレッシュ・キンケイド学年レベル」で、内容を理解するのに必要な学力レベルを示しています。

HTMLの構造に関しては、以下の4つの要素を分析しました。

-   意味をもったHTMLタグの数。たとえば、ヘッダーやナビゲーション、記事など、ページの構造や情報の役割を明確にするタグの使用がどれだけあるかを見ました。
-   ページ内のHTMLの階層の深さ。タグがどの程度入れ子になっているかを調べ、ページ構造の複雑さを測りました。
-   アクセシビリティ対応の属性の数。代替テキストや支援技術用のラベルなど、使いやすさへの配慮がどの程度されているかを確認しました。
-   古い書き方のタグの使用数。たとえば、すでに推奨されていないタグを使っているかどうかが、技術的な質の判断材料になりました。

これらの項目について、LLM検索と従来型検索でどれだけ違いがあるかを統計的に検証した結果、すべてにおいて有意な差が見られました。

読みやすさに関しては、従来型検索が引用するページは内容がかなり難しく、大学院レベルの読解力が必要な平均18.24という結果でした。対してLLM検索は、大学1〜2年程度にあたる14.57とやややさしい傾向がありました。読みやすさスコアも、LLM検索の方が高く、内容に対する理解の負担が軽いページが選ばれやすいことが分かりました。

HTMLの構造面では、LLM検索が引用するページの方が、意味のあるタグの数や階層の深さでわずかに高い数値を示していました。つまり、LLM検索は読みやすく、かつ構造がしっかりした情報源を優先して選ぶ傾向があると考えられます。

### ドメインの独自選択の予測

研究チームは予測モデルを使って、LLM検索が好んで引用するドメインの特徴を明らかにしようとしました。

#### 分類器の設計

まず、LLM検索にしか出てこないドメインと、従来型検索にしか出てこないドメインを分類できるモデルを作りました。その目的は、両者の選ぶ情報源の違いを特徴づける要素を明らかにすることです。

モデルに与える情報は三つの種類に分けられました。

-   数値的な情報には、Trancoランキング、VirusTotalが提供する外部リンクの数、MBFCのバイアススコアと信頼性スコアが含まれました
-   分類項目としては、ドメイン名やVirusTotalによるメディアカテゴリが使われました
-   テキスト情報には、検索クエリの内容とVirusTotalによる説明文が使われました

モデルの評価には、全体のデータを8対2に分けて訓練とテストに使用し、さらに訓練データは5分割の交差検証で性能を確認しました。使われた手法はロジスティック回帰、ランダムフォレスト、XGBoost、K近傍法、ニューラルネットワークの5種類で、どれもパラメータの調整はグリッドサーチで最適化されています。

分類の精度はF1スコアで評価しました。F1スコアは、予測が正確だった割合と、実際に正解をどれだけ見つけられたかのバランスを見る指標です。

最も良い成績を出したのはXGBoostで、全体のF1スコアは0.758でした。LLM検索にしか登場しないドメインの検出では、精度が0.668、再現率が0.879と高い数値を示しました。

#### 特徴の重要度

次に、XGBoostがどの情報を重視して判断していたのかを調べました。ここではSHAPという手法を使って、どの特徴が予測に強く影響しているかを分析しています。

平均的に影響が大きかったのは以下の6項目です。

-   Trancoランキング
-   外部リンクの数
-   ドメインが.comで終わっているかどうか
-   サブドメインの数
-   .nl（オランダの国別ドメイン）であるかどうか
-   メディアのカテゴリがビジネス・経済に属するかどうか

Trancoランキングはウェブサイトの人気度を表す指標で、数値が高いほど訪問者が少ないサイトになります。LLM検索では、従来型よりもこうした人気の低いサイトを選ぶ傾向があることが、ここでも確認されました。

外部リンクの数が多いサイトは、他の情報源とのつながりが豊富で、文脈が深くなる可能性があります。つまり、LLM検索は他の信頼できる情報とよく結びついているサイトを高く評価している可能性があります。

以上をまとめると、LLM検索が好んで引用するサイトには次のような特徴があるといえます。

-   HTML構造が複雑で、階層的に整理されている
-   内容が比較的読みやすい
-   人気はそれほど高くないが、特徴ある情報を持っている
-   外部リンクが多く、他の情報源とつながっている

このような特徴が、LLM検索の情報選びにおいて大きな役割を果たしていると考えられます。

## まとめ

本記事では、6つのLLM検索と2つの従来型検索を比べて、情報源の選び方にどんな違いがあるのかを大規模に調べた初めての取り組みを紹介しました。

LLM検索は、従来よりも少ない情報源を使いますが、その中には従来型では見られない独自のドメインも多く含まれていました。また、特定のサイトに偏らず、引用が分散していることも分かりました。

一方で、引用する数が少ないことで、政治的な偏りが目立ったり、安全性の面でも必ずしも安心とは言えない結果も見られました。

LLM検索が選ぶ情報源には、読みやすく構造が整理されていて、あまり知られていないけれど外部リンクが多いといった特徴があります。これは質の高い情報を選ぼうとする姿勢の表れでもありますが、情報の幅を狭めてしまう可能性もあります。
