---
created: 2026-01-01T09:36:31 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/66170
author: AIDB Research
---

# Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB

> ## Excerpt
> LLMにおける「タスクに依存しないプロンプト圧縮」についての研究が行われています。 既存の手法はプロンプト圧縮に必要な全ての重要な情報を捉えられない可能性があるため、最適な方法とは考えられていません。そこで今回Microsoftなどの研究者らは、プロンプト圧縮技術を新たに考案しました。 参照論文情報 本記事の関連研究： 背景 LLMにおける様々なプロンプティング技術が登場しています。例えばChai…

---
LLMにおける「タスクに依存しないプロンプト圧縮」についての研究が行われています。

既存の手法はプロンプト圧縮に必要な全ての重要な情報を捉えられない可能性があるため、最適な方法とは考えられていません。そこで今回Microsoftなどの研究者らは、プロンプト圧縮技術を新たに考案しました。

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170-1024x576.jpg]]

**参照論文情報**

-   タイトル：LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression
-   機関：清華大学、マイクロソフト
-   著者：Zhuoshi Pan, Qianhui Wu, Huiqiang Jiang, Menglin Xia, Xufang Luo, Jue Zhang, Qingwei Lin, Victor Rühle, Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu, Dongmei Zhang

**本記事の関連研究**：

-   [ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』](https://ai-data-base.com/archives/51160)
-   [LLMへの入力プロンプトを「意味を保持したまま」高度に圧縮する技術『LLMLingua』](https://ai-data-base.com/archives/60431)
-   [LLMの記号推論タスク（化学式や絵文字の理解など）で記号を自然言語に変換することの有効性を確認](https://ai-data-base.com/archives/65784)
-   [「人間の自然言語を超えて」LLMにタスク実行時の思考を非自然言語フォーマットで行わせるプロンプト手法『AutoForm（オートフォーム）』](https://ai-data-base.com/archives/65090)

## 背景

LLMにおける様々なプロンプティング技術が登場しています。例えばChain-of-Thought（CoT）などが代表的な例です。課題に対して適切なプロンプティング技術を使用することで、LLMは複雑なタスクを処理できることが分かってきました。

しかし工夫を凝らせば凝らすほど基本的にプロンプトの長さは増してきます。すると計算コストと金銭的コストの増加、およびLLMの情報認識能力の低下という問題が出てくることとなります。

そこで役立つ可能性があるのが、プロンプトの情報を失わずに短くすることを目指すプロンプト圧縮技術です。

これまでにもプロンプト圧縮手法はいくつか提案されてきました。主に特定のタスクやクエリに合わせて圧縮されたプロンプトを生成することを目的としたタスク依存型の手法によって、特に質問応答における下流のタスクでパフォーマンスが向上する結果が得られてきました。

しかし、タスク依存型の手法は、効率性や汎用性の面で理想的とは言えません。例えば、RAGのアプリケーションでは、タスク依存型のプロンプト圧縮を使用すると、関連するクエリに応じて同じ文書を複数回圧縮する必要が生じる問題があると報告されています。

今回研究者らは、汎用性と効率性を高めるために「自然言語には冗長性があり、LLMには冗長性が必ずしも必要ではない」という仮説からスタートすることにしました。その結果として、優秀な技術が開発されました。

以下で方法論や実験結果などを詳しく紹介します。

ここから限定コンテンツ

研究者らは今回、プロンプト圧縮のためのモデルを開発するために、独自のデータセットも作成しています。そのために作成したものは次の通りです。

-   LLM（GPT-4）から知識を蒸留する方法論
-   LLMから蒸留された知識を活用して、圧縮後に各単語を保持すべきかどうかを示すラベルを元のテキストの各単語に割り当てるデータアノテーションアルゴリズム
-   データセットの品質を確保するために、低品質のサンプルをフィルタリングする2つの品質管理指標

それぞれのプロセスを以下に説明します。

### データ蒸留する方法論

研究者らはGPT-4から知識データを蒸留するためのプロセスを考案しました。GPT-4は指示に一貫して従い続けるわけではないため、GPT-4から蒸留することは容易ではありません。また、「元のテキストの情報を保持する」というタスク自体が難易度の高いものです。

そこで、生成されたテキストが元のテキストに忠実であることを保証するために、元のテキストの重要でない単語のみを破棄することでテキストを圧縮し、生成中に新しい単語を追加しないようGPT-4に明示的に指示することにしました。

そして、以下の基準を満たす圧縮テキストを元のテキストから生成するようプロンプトを与えました。

1.  圧縮されたプロンプトは、コストを削減し推論を高速化するために、長さが短くなければいけない
2.  重要な情報は保持されなければいけない
3.  圧縮されたプロンプトは、下流のタスクでLLMにプロンプトを与える際の精度を確保するために、忠実であり、幻覚的なコンテンツを導入しないようにする必要がある

実際に設計されたプロンプトは以下の通りです。

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_2.png]]

```
与えられたテキストを短い表現に圧縮し、それをあなた（GPT-4）が可能な限り元のテキストに近づけて再構築できるようにしてください。通常のテキスト圧縮とは異なり、以下の5つの条件を守る必要があります。

1. 重要でない単語のみを削除することができます。
2. 元の単語の順序を変えてはいけません。
3. 元の単語を変更してはいけません。
4. 略語や絵文字を使用してはいけません。
5. 新しい単語や記号を追加してはいけません。 

単語を削除することのみによって元のテキストを積極的に圧縮してください。可能な限り情報を保ちながら、できるだけ短く圧縮してください。
理解できたら、以下のテキストを圧縮してください：{圧縮するテキスト}
圧縮されたテキストは：
```

なお、テキストの情報密度は、そのジャンル、スタイルなどによって大きく異なる可能性があります。例えば、ニュース記事は通常、会議の文字起こしと比較して情報密度が高くなります。さらに、会議の文字起こしでも、話者によって情報密度が異なります。

そのため、圧縮率を固定にすることは最適ではない可能性があります。そこで研究者らは、指示から圧縮率の制限を取り除き、代わりにGPT-4に可能な限り多くの情報を保持しながら、元のテキストをできるだけ短く圧縮するよう指示することにしました。

その結果、GPT-4は異なる文に様々な圧縮率を割り当て、一部の文を完全に破棄することがわかりました。

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_3.png]]

また経験的に、元のテキストの長さが圧縮性能に大きな影響を与えることがわかりました。GPT-4は非常に長いコンテキストを処理する際に高い圧縮率を適用する傾向があり、これはGPT-4の長いコンテキストを扱う能力が限られていることが原因である可能性があります。（もし他のLLMを活用するアプローチを取るとしても出てくる問題かもしれません）

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_4.png]]

なお圧縮率が高すぎると、下流のタスクのパフォーマンスに大きな影響を与える恐れがあります。この問題を軽減するため、研究者らは最初に長いコンテキストを複数のチャンクに分割し、各チャンクが512トークン以下で、ピリオドで終わるようにしました。そしてGPT-4に各チャンクを個別に圧縮するよう指示しました。

### データアノテーション

データ蒸留から元のテキストとその圧縮版のペアを得た後、圧縮後に保持すべきかどうかを決定するために、元のテキストの各トークンにバイナリラベルを割り当てる作業が必要でした。

研究者らは、今回の研究の過程で発見した3つの主な問題を以下のように整理しています。

問題は、GPT-4が指示に正確に従うことができないことから生じています。実際の例をもとに問題を色付けして説明します。

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_5.png]]

(i) 曖昧さ（赤色）：圧縮テキストにおける単語が元の内容の中で複数回出現する場合がある。  
(ii) 変化（黄色）：GPT-4は圧縮中に元の単語を時制や複数形などに変更することがある。  
(iii) 単語の順序変更（青色）：圧縮後に単語の順序が変わることがある。

そして、上記の問題に対応するアノテーションアルゴリズムを以下のように示しています。

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_6.png]]

### 品質管理

研究者らは、GPT-4の蒸留によって生成された圧縮テキストの品質と、自動的にアノテーションされたラベルの品質を評価するための2つの品質管理指標を導入しました。

Variation Rate（変化率）：GPT-4が指示に従わない可能性があるため、変化率という指標を導入し、データ蒸留から生成された圧縮テキストの品質を評価しました。変化率は、元のテキストに存在しない圧縮テキスト中の単語の割合を測定します。変化率が高いほど、幻覚的なコンテンツが含まれている可能性が高くなります。そのため、今回変化率が上位5％の例は除外しました。

Alignment Gap（アライメントギャップ）：アライメントギャップは、自動的にアノテーションされたラベルの品質を評価するために提案されました。AGの定義には、圧縮テキストの単語が元のテキストに見つかる割合を測定するヒット率が含まれています。

完全なアノテーションのアライメントギャップは0でなければなりません。AGが大きいということは、マッチング率が低いのにヒット率が高いということであり、その例のアノテーションの質が低いことを意味します。そのため、研究者らはアライメントギャップが最も高い10％の例を破棄し、データセットの品質管理を確保しました。

## LLMLingua-2フレームワーク

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_1-1024x389.png]]

### トークン分類モデルで圧縮を実現

研究者らは今回、プロンプト圧縮をバイナリトークン分類問題（つまり、「保持」するか「破棄」するかの問題）として定式化しました。こうすることで、圧縮されたプロンプトが元のコンテンツに忠実であることを保証しつつ、圧縮モデル自体の低レイテンシーを確保しています。

なおトークン分類モデルには、各トークンの双方向コンテキストからの情報を活用するために、特徴抽出器としてTransformerエンコーダを採用しました。また、MeetingBank（Hu et al.、2023）から構築されたデータセットでモデルを訓練しました。

このモデルにN個の単語からなる元のプロンプトが与えられると、特徴ベクトルが計算され、各単語のラベル（保持または破棄）の確率分布が出力されます。

### 圧縮戦略

元のプロンプトを目標圧縮率で圧縮するアプローチは、以下の3段階プロセスで説明できます。

1.  圧縮されたプロンプトで保持すべきトークン数の目標を導出する
2.  トークン分類モデルを使用して、各単語が保持ラベルとしてラベル付けされる確率を予測する
3.  元のプロンプトで最も高い確率を持つ単語を保持し、元の順序を維持して圧縮プロンプトを形成する

なお今回のアプローチは、[LLMLingua](https://ai-data-base.com/archives/60431)で提案された「粗から細へのフレームワーク」に統合できるとのことです（今回はLLMLingua-2）。LLMLinguaの際には複雑度ベースの反復トークン圧縮モジュールが採用されていましたが、それを今回のトークン分類ベースのコンプレッサに置き換えることができます。

## 実験

### モデルの準備

今回研究者らは評価実験において、Huggingface’s TransformersとPyTorch 2.0.1、CUDA-11.7を用いて提案手法を実装しました。また特徴エンコーダとしてはxlm-roberta-largeとmultilingual-BERTを使用し、それぞれLLMLingua-2とLLMLingua-2-smallと呼んでいます。

両方のモデルを10エポックでファインチューニングし、学習率1e-5とバッチサイズ10でAdamオプティマイザを使用しました。特に明記されていない限り、すべての報告された指標は、安定性を高めるために温度0でグリーディデコーディングを行ったGPT-3.5-Turbo-0613をターゲットLLMとして使用しています。

### データセットと評価指標

なお、MeetingBankの訓練例を用いて構築したデータセットでコンプレッサを訓練しているため、MeetingBankのテスト例をドメイン内評価とし、それ以外をドメイン外評価としました。

1.  ドメイン内：要約タスクに加えて、コンテキスト全体に分布する各例について3つの質問-答えのペアを生成するQAタスクも導入しました。要約タスクでは、LLMLinguaと同じ評価指標を使用しました。QAタスクでは、LongBenchで提供されているメトリクスとスクリプトを使用して評価しました。  
    
2.  ドメイン外：長いコンテキストのシナリオについては、LongBenchとZeroSCROLLSを使用し、LongLLMLinguaと同じ評価指標を採用しました。推論とin-context学習については、GSM8KとBig Bench Hard（BBH）を使用し、LLMLinguaと一致する評価指標を用いました。

なおGSM8Kは数学のベンチマークデータセットで、Big Bench Hard（BBH）は広範で難解な問題のベンチマークデータセットです。

### ベースラインとの比較

研究者らは、比較のために2つの最先端のプロンプト圧縮手法「Selective-Context」と「LLMLingua」をベースラインとして採用しました。どちらもLLaMA-2-7Bをベースとしています。

さらに、retrieval-basedな手法やLongLLMLinguaなどのタスク依存型プロンプト圧縮手法とも比較しました。

### ドメイン内ベンチマークでの結果

MeetingBankにおけるベースラインとの比較結果が以下です。

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_7-1024x264.png]]

提案モデルがベースラインで使用されているLLaMa-2-7Bよりもかなり小さいにもかかわらず、QAタスクと要約タスクの両方で大幅に優れたパフォーマンスを達成し、元のプロンプトのパフォーマンスに匹敵する結果となりました。

### ドメイン外ベンチマークでの結果

今回のモデルは、会議の文字起こしデータのみを使用して訓練されているため、長いコンテキストのシナリオ、推論、in-context学習のさまざまなベンチマークにおける汎化能力を探りました。

LongBench、ZeroSCROLLS、GSM8K、BBHでの結果は、提案モデルが他のタスク非依存型ベースラインと比較して優れたパフォーマンスを示しました。BERT-baseサイズのより小さなモデルでさえ、元のプロンプトに匹敵する、場合によってはわずかに上回るパフォーマンスを達成できました。

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_8-1024x734.jpg]]

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_9-1024x298.png]]

全体的に有望な結果を示しましたが、Longbenchにおいては、LongLLMlinguaなどの他のタスク依存型圧縮手法と比較すると及ばない結果となりました。この性能差は、質問から活用される追加情報によるものだと考えられています。

### ターゲットLLMとしてのMistral-7Bでの結果

Mistral-7B-v0.1をターゲットLLMとして使用した場合の各手法の結果は以下の通りです。

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_10-1024x237.png]]

提案手法は、他のベースラインと比較して大幅な性能向上を示し、ターゲットLLMにわたる良好な汎化能力を示しました。特筆すべきは、LLMLingua-2が元のプロンプトよりも優れたパフォーマンスを示したことです。プロンプトを圧縮した結果、さらにタスク性能まで向上しているのは直感的にはすぐに飲み込めない現象です。

この結果を受けて、研究者らは、Mistral-7BがGPT-3.5-Turboと比較して長いコンテキストの管理が苦手である可能性があると推測しています。提案手法は、情報密度の高い短いプロンプトを提供することで、Mistral-7Bの最終的な推論性能を効果的に向上させています。

### レイテンシー評価

異なる圧縮率でのシステムのレイテンシーは以下の通りです。

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_12-1024x255.png]]

LLMLingua-2は、軽量であるため、他の圧縮手法よりもはるかに小さい計算オーバーヘッドを持っており、2倍から5倍の圧縮率で1.6倍から2.9倍のエンドツーエンドの高速化を達成できることがわかりました。さらに、提案手法はGPUメモリコストを8分の1に削減し、ハードウェアリソースの需要を低減します。

### プロンプトの再構成

さらに研究者らは、LLMLingua-2の圧縮プロンプトから元のプロンプトを再構成するようにGPT-4にプロンプトを与える実験を行いました。つまり圧縮ファイルを展開するようなプロセスです。

その結果、GPT-4は（驚くべきことに）元のプロンプトを効果的に再構成できることが示され、LLMLingua-2の圧縮プロセスでは重要な情報が失われていないことが示唆されました。

![[Microsoftなどのプロンプト圧縮技術『LLMLingua-“2″』タスクの精度を維持したまま圧縮率2-5倍 - AIDB/AIDB_66170_13.png]]

## まとめ

本記事では、LLMにおけるタスク非依存型プロンプト圧縮に関する研究者らの取り組みを紹介しました。彼らは、汎用性と効率性を併せ持つプロンプト圧縮手法の確立における従来の課題を特定し、それらに対処する新たなアプローチを提案しました。

今回、圧縮されたプロンプトが元のコンテンツに忠実であることを保証するために、プロンプト圧縮をトークン分類問題として定式化し、双方向のコンテキスト情報を活用するTransformerエンコーダを採用されました。

提案手法の有効性を検証した結果、提案モデルが強力なベースラインと比較して優れたパフォーマンスを示し、GPT-3.5-TurboからMistral-7Bまで、様々なLLMに対して良好な汎化能力を有することが明らかになりました。さらに、提案手法は圧縮速度の面でも既存手法を上回り、エンドツーエンドのレイテンシーを大幅に改善することができました。

一方で、研究者らは手法の限界についても議論しています。提案手法のコンプレッサは、会議の文字起こしデータのみを用いて訓練されたため、その汎化能力には懸念が残ります。ただし、ドメイン外のデータセットを用いた評価により、提案モデルが異なるドメインのデータに対しても良好な汎化能力を有することが示されています。

LLMの実用シーンが増えていくにつれ、トークンの増大に伴うコストの問題と、レイテンシーの問題は顕著になる可能性があります。今回のようなプロンプト圧縮技術は必須のモジュールとして使用されていくかもしれません。

-   参照論文URL：[https://arxiv.org/abs/2403.12968](https://arxiv.org/abs/2403.12968)
-   PJページ：[https://llmlingua.com/llmlingua2.html](https://llmlingua.com/llmlingua2.html)
