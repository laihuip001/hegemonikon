---
created: 2026-01-01T09:36:34 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/66269
author: AIDB Research
---

# RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成 - AIDB

> ## Excerpt
> 新しい知識をLLMに効果的に学習させる上でRAGやファインチューニングなどが提案されてきましたが、最適な汎用的方法はまだ明らかになっていません。そんな中今回新しく提案されたのが、Retrieval Augmented Fine Tuning (RAFT)という学習手法です。質問と関連する文書群が与えられた際に、質問に答えるのに役立たない文書を無視するようモデルを学習させるフレームワークです。 参照…

---
新しい知識をLLMに効果的に学習させる上でRAGやファインチューニングなどが提案されてきましたが、最適な汎用的方法はまだ明らかになっていません。そんな中今回新しく提案されたのが、Retrieval Augmented Fine Tuning (RAFT)という学習手法です。質問と関連する文書群が与えられた際に、質問に答えるのに役立たない文書を無視するようモデルを学習させるフレームワークです。

![[RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成 - AIDB/AIDB_-66269-1024x576.jpg]]

**参照論文情報**

-   タイトル：RAFT: Adapting Language Model to Domain Specific RAG
-   機関：UC Berkeley
-   著者：Tianjun Zhang, Shishir G. Patil, Naman Jain, Sheng Shen, Matei Zaharia, Ion Stoica, Joseph E. Gonzalez

**本記事の関連研究**：

-   [検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上](https://ai-data-base.com/archives/65359)
-   [LLMの検索結果をさらに正確にする手法『CRAG（修正型検索拡張生成：Corrective Retrieval Augmented Generation）』](https://ai-data-base.com/archives/63672)
-   [LLMに外部知識を取り入れる2つの手法としてのファインチューニングとRAGを比較実験した結果](https://ai-data-base.com/archives/63401)
-   [RAGにおいて取得された情報と事前知識が矛盾しても、情報に説得力があるときLLMは受け入れる](https://ai-data-base.com/archives/64979)

## 背景

LLMは、膨大な量の公開データで学習することにより、幅広い一般知識推論タスクで著しい進歩を遂げてきました。一方で、LLMが特定の分野のタスクに用いられる場合、一般的な知識推論よりも、与えられた文書に対して正確であることが強く求められています。例えば最新のニュースや企業の非公開文書などに適応させることは課題になっています。

LLMを特定分野に適応させる際、検索拡張生成（RAG）を用いたコンテキスト学習と、教師あり微調整（supervised fine-tuning）の2つの手法が主に考えられます。

RAGベースの手法は、LLMが質問に答える際に文書を参照するものです。この手法では、モデルが事前に学習しているわけではありません。外部のナレッジベースから関連情報を取得することで問題解決能力を向上する（比較的リーズナブルな）アプローチです。

教師あり微調整は、文書からより一般的なパターンを学習し、エンドタスクやユーザーの好みにモデルが適応します。この手法に関しては、学習に使用された文書を活用できないことがあるにもかかわらず、検索プロセスの不完全性を考慮できていません。要するにRAGと組み合わせることが前提となっていません。

筆者らは、この問題を、参考書を見ながら受ける試験（オープンブック試験）に例えて解決しようと考えています。既存のRAG手法は、勉強せずにオープンブック試験を受けるようなものです。一方、既存の微調整アプローチは、入力文書を直接「暗記」したり、文書を参照せずに練習問題に答えたりするようなものと言えます。どちらも、ベストなパフォーマンスが出るアプローチとは言えません。

そこで今回研究者らは、教師あり微調整（SFT）と検索拡張生成（RAG）を効果的に組み合わせた方法「検索拡張微調整（RAFT）」を開発しました。

![[RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成 - AIDB/AIDB_-66269_1-1024x194.jpg]]

RAFTは、LLMが分野の知識を組み込むための微調整と、分野内RAGのパフォーマンス向上の両方の課題に取り組んでいます。問題に対して役立つ知識とそうでない知識を判別できる状態で、参考書を開いてテストに臨めるようなコンセプトだと言います。

ここから限定コンテンツ

## 参考書を見ながら受ける試験（オープンブック試験）について

研究者らは、試験の形式とLLMの学習方法の関係を、以下のように説明しました。

### クローズドブック試験とLLM

クローズドブック試験は、追加の文書や参考資料を一切参照せずに質問に答えるものです。LLMはチャットボットとして事前学習や教師あり微調整の過程で獲得した知識のみを用いて、プロンプトに応答します。その結果出るパフォーマンスはゼロショット性能と呼ばれます。

### オープンブック試験とLLM

一方、オープンブック試験は、外部情報源（ウェブサイトや書籍の章など）を参照するものです。このケースでは、通常、LLMはリトリーバーと組み合わせて使用されます。リトリーバーは、関連性の高い文書（またはその一部）を取得し、プロンプトに追加します。LLMは、取得された文書を通じてのみ「新しい知識」を得ることができます。その性能は主にリトリーバーの品質と、最も関連性の高い情報を特定する精度に依存してしまいます。

### ドメイン特化型オープンブック試験

本研究では、一般的なオープンブック試験よりも範囲を狭めた、ドメイン特化型オープンブック試験に焦点が当てられています。LLMは、答えるべき特定分野（推論に用いられる分野）に微調整され専門知識をもってプロンプトに応答します。例としては、企業の文書、最新のニュース、組織のコードリポジトリなどがあります。

本論文は、主にこのドメイン特化型オープンブック設定において、LLMをこの特定の分野にどのように適応させるかが探究されています。

![[RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成 - AIDB/AIDB_-66269_2-1024x375.jpg]]

RAFTの全体像

研究者らが今回提案しているRAFT（Retrieval Aware Fine-Tuning）について紹介します。RAFTは一般的な教師あり微調整（SFT）の改良版です。

一般的なSFTは、質問（Q）と対応する回答（A）のペアが既に用意されています。モデルは事前学習中またはSFTの学習フェーズで獲得した知識に基づいて、質問に答えます。なお、性能のテスト時においてはRAGを使用することもあります。

### RAFTの概要

RAFTは、LLMをRAGに適合させるための微調整データを準備する手法です。本手法を一言でいうと、LLMを不要な文書を含めて学習することにより、RAGにおいて「役立たない情報を無視」する能力を身につけさせる手法です。

まず学習データとしては、各データポイントが質問、文書セット、および1つの文書から生成された思考の連鎖スタイルの回答を含むように準備します。  
ここで研究者らは、質問の答えが導出できる「オラクル」文書と、答えに関連しない情報を含む「ディストラクター」文書の両方を準備しました。この部分が本手法のポイントにあたります。

その後、標準的な教師あり学習（SFT）手法を用いて言語モデルを微調整し、提供された文書と質問から答えを生成するように学習させます。

なお学習の質を向上させる重要な要因は、提供された答えを説明するための思考の連鎖（Chain-of-Thought）などの推論プロセスを組み込むことです。学習データをこのように生成するには、モデルに質問、文脈、検証済みの回答を提示し、元の文脈を適切に参照する推論の連鎖を形成するように要求します。

実験に使用したすべてのデータセットについて、上記の手法を用いて回答を生成しました。なおGorilla APIBenchデータセットには、既に回答に推論が含まれています。

![[RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成 - AIDB/AIDB_-66269_3-1024x485.png]]

RAFTの学習データ生成ステップの例

## 実験

研究者らは、RAFTの性能を様々なベースラインと比較するための実験を行いました。また、モデルが思考の連鎖（Chain-of-Thought）による応答を学習することがいかに重要であるかを検証する実験も行いました。

### データセット

実験では、以下のデータセットを使用して、一般的かつ多様な分野が検証されました。

1.  Natural Questions（NQ）、Trivia QA、HotpotQA：主に一般的な知識（映画、スポーツなど）に関するWikipediaベースの質問応答データセット
2.  HuggingFace、Torch Hub、TensorFlow Hub：文書に基づいて正しく機能する実行可能なAPIコールを生成する能力を測定する（APIBench（Gorilla論文で提案）からの）データセット
3.  PubMed QA：生物医学研究の質問応答に特化したデータセット

NQ、Trivia QA、HotpotQAは比較的一般的な分野ですが、後者の2つの分野は非常にドメイン特化型の文書を対象としています。

### ベースライン

研究者らは、以下のベースラインを実験で比較しました：

1.  LlaMA2-7B-chatモデルの0ショット
2.  RAGを用いたLlaMA2-7B-chatモデル（Llama2 + RAG）
3.  ドメイン特化型微調整（DSF）モデルの0ショット
4.  RAGを用いたドメイン特化型微調整（DSF + RAG）

### 結果

RAFTは一貫してベースラインを大幅に上回ることが示されました。特に通常のLLaMA-7Bモデルは、RAGの有無にかかわらず、情報を抽出する能力やディストラクターに対する頑健性においてRAFTに大きく劣ることが明らかになりました。

![[RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成 - AIDB/AIDB_-66269_4-1024x243.png]]

![[RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成 - AIDB/AIDB_-66269_6-1024x403.png]]

また、思考の連鎖（Chain-of-Thought）がモデルの性能向上にどの程度効果があるかを分析した結果、質問に対して単に答えを提供するだけでは不十分な場合があることが示唆されました。モデルを答えに導くだけでなく、理解を深めるような推論の連鎖を組み込むことで、全体的な精度が向上する可能性があります。

![[RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成 - AIDB/AIDB_-66269_5-1024x123.png]]

## 学習データにおける「役立たない文書」の役割

研究者らはディストラクター文書（問題に対して役に立たない文書）の数が、性能にどれほど影響を与えるのかを実験で確かめることにしました。前提として、オラクル（高関連）文書のみで学習すると、モデルが無関連な情報を見分けて無視する能力が低い（低下する）ことがわかっています。

RAFTアルゴリズムでは、高関連文書と無関連文書が混ざっています。研究者らは、LLMの無関連テキストに対する頑健性を高めるため、ゴールデン（高関連）文書とディストラクター（無関連）文書の両方を組み込んだ微調整アプローチを採用しました。モデルはディストラクター文書の数を変えて学習しましたが、常にリトリーバーから得られたtop-k文書を使用して評価されました。

実験の結果、オラクル文書のみで微調整した場合、ディストラクター文書の数が多い設定よりも性能が低下することが明らかになりました。

また研究者らは、テスト時の文書数の変動がモデルの性能に与える影響についても調査を行いました。具体的には、ディストラクター文書の数を変えて学習したモデルが、テスト時に遭遇する文書数の変化にどのように対応するかを評価しました。

実験の結果、学習中にディストラクター文書を含めることで、テスト時の文書数の変動に対するモデルの耐性が実際に高まることが確認されました。

![[RAGにおいてLLMが「役立たない情報を無視」できるようにする『RAFT』QAタスクで従来の手法を大幅に上回る結果を達成 - AIDB/AIDB_-66269_8-1024x353.jpg]]

## まとめ

本記事では、ドメイン特化型オープンブック設定でモデルの性能を向上させるための学習戦略であるRAFT（Retrieval Augmented Fine Tuning）に関する研究を紹介しました。

RAFTは、特定の分野の文書に基づいて質問に答えるタスクにおけるLLMの微調整レシピのようなものです。ディストラクター文書とともにモデルを学習させること、オラクル文書を含まないコンテキストを持つデータセットの一部を整理すること、関連するテキストから直接引用して思考の連鎖方式で回答を定式化することなど、いくつかの重要なポイントが整理されています。

実験ではPubMed、HotpotQA、Gorilla API Benchでの評価により、RAFTの有効性が明らかになりました。

本研究は、LLMがドメイン固有の知識を用いて質問に答えるという実用的なシーンを想定するものです。覚えておいて損はない知見と言えるかもしれません。

-   参照論文URL：https://arxiv.org/abs/2403.10131
