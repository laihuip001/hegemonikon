---
created: 2026-01-01T11:17:16 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/96111
author: AIDB Research
---

# RAGの実用性レベルを上げるために「データソースを構造化する」という考え方 - AIDB

> ## Excerpt
> ChatGPTやGemini、Claudeなどが広く使われるようになった今、LLMを社内システムに組み込もうとする動きが活発化しています。しかし、単純にLLMを導入するだけでは、情報の正確性や信頼性の面で課題が残ります。そこで注目されているのがRAGという技術です。しかし実用的なレベルにするにはどうしたらいいでしょうか。 本記事では、まずRAGの基本的な仕組みをおさらいした上で、データソースの「構…

---
ChatGPTやGemini、Claudeなどが広く使われるようになった今、LLMを社内システムに組み込もうとする動きが活発化しています。しかし、単純にLLMを導入するだけでは、情報の正確性や信頼性の面で課題が残ります。そこで注目されているのがRAGという技術です。しかし実用的なレベルにするにはどうしたらいいでしょうか。

本記事では、まずRAGの基本的な仕組みをおさらいした上で、データソースの「構造化」がどのように実務の課題を解決し得るのかを、深堀りしていきます。

![[RAGの実用性レベルを上げるために「データソースを構造化する」という考え方 - AIDB/AIDB_96111-1024x576.png]]

**本記事の関連研究**

-   [5つの業界における現場導入から学ぶRAGシステム実践の教訓12個](https://ai-data-base.com/archives/91808)
-   [「RAGOps」RAGシステムを安定運用するための実践的な考え方の整理](https://ai-data-base.com/archives/90875)
-   [RAGシステムへのユーザークエリは4つのレベルに分類できる　最も複雑なのは「隠れた根拠からの推論が必要なクエリ」](https://ai-data-base.com/archives/76241)

## 背景

例えば、自社の製品についての質問をLLMに投げかける場合を考えてみましょう。RAGを使わないLLMは、訓練データの中にあった一般的な知識しか使えません。しかしRAGを使うと、まず社内の製品マニュアルや最新の仕様書を検索し、その内容をLLMに渡してから答えを生成させることができます。

ChatGPTやClaudeなどに文書ファイルを添付して回答を生成させる場面を思い出していただけると良いかと思います。ChatGPTやClaudeがそれらのファイルに書かれてある情報を抽出して答えることができますが、あの機能はRAGの一種です。

実際、RAGは現在多くの企業で使われている実用的な技術です。しかし、RAGは完ぺきではありません。

その限界とは何でしょうか。RAGは、基本的に「文章の塊」を検索して持ってきます。例えば、あなたが「この製品の保証期間と修理手続きについて教えて」と質問したとします。RAGシステムは関連しそうな文書の断片をいくつか持ってきますが、それらは構造化されていないバラバラな情報です。保証に関する情報と修理手続きの情報が別々の文書にあったり、情報同士の関係性が明確でなかったりします。また、複雑な質問、例えば「A部門とB部門の過去三年間の業績を比較して、その背景にある市場要因を分析して」といった複数のステップを踏む必要がある質問には対応しづらいのです。

そこで、RAGをもう一段階進化させて使い勝手を良くする工夫が必要になります。

本記事では、最近登場した「新しい方法論」を深堀りし、RAGが企業の実務レベルに耐えられるようになるためのヒントを見出していきます。

まずはRAGの全体的な仕組みとRAGにおける情報検索の理論を振り返っていきます。

ここから限定コンテンツ

**参照文献情報**

-   タイトル：A Survey on Retrieval And Structuring Augmented Generation with Large Language Models
-   URL：[https://doi.org/10.48550/arXiv.2509.10697](https://doi.org/10.48550/arXiv.2509.10697)
-   著者：Pengcheng Jiang, Siru Ouyang, Yizhu Jiao, Ming Zhong, Runchu Tian, Jiawei Han
-   所属：University of Illinois

## 前提のおさらい

### RAGの仕組み

RAGシステムを実際に構築する時には、いくつかポイントがあります。

まず、どこから情報を取得するかです。

最も一般的なのは非構造化テキストデータですが、データベースのような構造化データ、ナレッジグラフのような半構造化データ、さらにはLLM自身が生成した情報を使うこともあります。企業で使う場合、社内の様々な形式のデータを統合する必要があるでしょう。

次に、検索の粒度、つまり情報をどのくらいの大きさの単位で扱うかという問題があります。

トークンや文という細かい単位から、段落やドキュメント全体という大きな単位まで様々です。細かすぎると文脈が失われ、粗すぎると不要な情報が混入します。適切なバランスを見つけることが重要です。

また、検索した情報をどう処理するかも重要です。

複数の検索結果を関連度順に並べ替えるリランキングというプロセスがよく知られています。また、冗長性を削減しながら重要な情報は保持するコンテキスト圧縮も有効です。これらの技術は、LLMが長い文脈の中で重要な情報を見落とす現象への対処としても役立ちます。

興味深いのは、LLMのコンテキストウィンドウ、つまり一度に処理できる文章の長さが大幅に伸びても、RAGの重要性は変わらないという点です。長い文脈を扱えるようになっても、効率性、透明性、ドメイン適応性の面でRAGは依然として価値があります。

### RAGにおける重要な要素「情報検索」

情報検索には、大きく分けて二つの基本的なアプローチがあります。一つは「スパース検索」、もう一つは「デンス検索」です。また、その二つを組み合わせるハイブリッド検索が登場しています。

**スパース検索（キーワードで探す古典的手法）**

スパース検索は、最も伝統的で直感的な検索方法です。これは、文書と検索クエリを「単語の出現回数」で表現します。例えば、「製品保証」というクエリに対して、「製品」という単語が何回出てくるか、「保証」という単語が何回出てくるかを数えて、それに基づいてスコアを計算します。

スパース検索の最大の利点は、効率性と解釈可能性です。どの単語がマッチしたから検索結果が出てきたのか明確に分かりますし、計算も比較的高速です。データが限られている場合や、ドメイン固有の専門用語が重要な場合には、今でも非常に効果的です。

しかし、重大な欠点もあります。それは、完全に同じ単語が使われていないと検索できないということです。例えば、ユーザーが「携帯電話の修理方法」と検索しても、文書に「スマートフォンのメンテナンス手順」としか書かれていなければ、意味的には同じ内容でも検索に引っかからない可能性があります。

**デンス検索（意味で探す現代的手法）**

デンス検索は、この問題を解決するために登場した新しいアプローチです。この方法では、テキストを「ベクトル」という数値の列に変換します。ベクトルというのは、文章の意味を数百から数千の数字で表現したものです。重要なのは、意味が似ている文章は、似たようなベクトルになるという点です。

例えば、「犬」「猫」「ペット」という単語のベクトルは互いに近くなりますが、「自動車」のベクトルは遠くなります。これにより、完全に同じ単語を使っていなくても、意味が似ていれば検索できるようになります。

なお、文章の意味に基づいて検索する手法を総合的にセマンティック検索と呼ぶことがありますが、その中でも「ベクトルに変換する」プロセスを使用する手法がデンス検索です。

デンス検索の大きな利点は、意味的な類似性を捉えられることです。言葉遣いが違っても、同じ概念について話していれば検索できます。これは、ユーザーが必ずしも適切な専門用語を知らない場合に特に有効です。

一方で、デンス検索にも欠点があります。計算コストが高いこと、そして何より、なぜその結果が返ってきたのか説明しにくいという問題があります。ブラックボックス的な側面があるため、医療や法律など説明責任が重要な分野では慎重に使う必要があります。

**良いとこ取りのハイブリッド検索戦略**

スパース検索とデンス検索のそれぞれに長所と短所があることが分かりました。では、両方を組み合わせたらどうでしょうか。これがハイブリッド検索の基本的なアイデアです。

ハイブリッド検索の利点は、頑健性です。どちらか一方の手法が失敗しても、もう一方が補うことができます。企業のシステムで、様々なタイプの検索クエリに対応する必要がある場合、ハイブリッドアプローチは安全で効果的な選択肢と言えます。

### ユーザーの「入力」を支える仕組み

ユーザーが入力する検索クエリは、必ずしも検索に最適な形とは限りません。曖昧だったり、情報が不足していたり、表現が不適切だったりします。そこで、クエリを自動的に改善する技術が開発されています。

そこで、元のクエリに関連する単語を追加する「クエリ拡張」が使われつつあります。例えば、「新製品」というクエリに、具体的な製品名やカテゴリを追加します。

また、より根本的にクエリを変換する「クエリ書き換え」も行われることがあります。例えば、最初の検索結果を見て、それを参考にクエリを改善する、といったアプローチです。

### 多段階検索

最後に、効率性と精度を両立させる多段階検索について見てみましょう。これは、まず高速だが粗い検索で候補を絞り込み、次により精密だが遅い方法で順位を付け直すというアプローチです。

典型的には、第一段階でBM25のような軽量な手法で数千の候補を高速に取得し、第二段階でBERTベースのリランカーで上位数十件を精密に評価します。最近では、LLMをリランカーとして使うことで、さらに大きな性能向上が得られることが分かっています。

この多段階アプローチは、実務的に意義があることがあります。全ての文書に対して重い計算を行うのは現実的ではありませんが、候補を絞り込んでから精密評価することで、実用的な速度で高精度を実現できます。

それでは、RAGのレベルを上げるための「構造化」という考え方について見ていきましょう。「検索した情報がバラバラで関係性が不明確」という問題を、どう解決するのか。

### なぜ「構造化」が必要なのか

企業が持つ文書の多くは、マニュアル、レポート、メール、議事録など、非構造化テキストです。これらをそのまま検索して持ってくるだけでは不十分です。

例えば、カスタマーサポートのシステムで「製品Aが動かない」という問い合わせがあったとします。従来のRAGで関連文書を検索すると、過去のトラブル事例、製品Aの仕様書、一般的なトラブルシューティング手順など、様々な情報が返ってきます。しかし、どの情報が最も重要か、どの順番で確認すべきか、製品Aは製品カテゴリのどこに位置するのか、といった関係性が見えません。

テキストを構造化することで、これらの情報を整理し、関係性を明確にし、LLMがより的確な回答を生成できるようになります。

つまり、データソースの段階で「検索フレンドリー」な状態にしておくという、前処理の必要性に目を向ける話です。

### 構造化の主要な手法

データソースの構造化には以下のアプローチがあります。

#### タクソノミー（分類体系を作る）

タクソノミーとは、概念を階層的に整理した木構造のことです。生物学での「界・門・綱・目・科・属・種」という分類がイメージしやすいでしょう。企業の文脈では、製品カテゴリ、顧客の問い合わせタイプ、業務プロセスなど、様々なものをタクソノミーで整理できます。

例えば、「電子機器」という大カテゴリの下に「スマートフォン」「ノートPC」「タブレット」があり、「スマートフォン」はさらに「Android端末」「iOS端末」に分かれる、といった階層構造です。

タクソノミーがあると、文書を適切なカテゴリに分類できます。また、検索の際に「このカテゴリとその下位カテゴリを全て対象にする」といった柔軟な検索が可能になります。

LLMを活用して、少数の例から半自動的にタクソノミーを構築したり、既存のタクソノミーを拡張したりもできるため、このプロセスにおいてもLLMを活用するのは一つのアイデアです。

タクソノミーがあると、検索が格段に賢くなります。

ユーザーが「機械学習の最新動向」と検索したとき、従来の検索では「機械学習」という単語が含まれる文書を探すだけでした。しかし、タクソノミーがあれば「機械学習」が人工知能の下位分野であることが分かり、関連トピックとして「深層学習」「強化学習」があることも分かります。これらの情報を使って、検索を自動的に拡張したり、絞り込んだりできます。

自社の製品カタログや業務プロセスのタクソノミーを一度整備すれば、そのドメインに特化した高精度な検索システムを比較的簡単に構築できます。

### ナレッジグラフ（知識をネットワークで表現する）

ナレッジグラフがあれば、「製品Aの競合製品でよく発生する問題は？」といった、複数のステップを経る複雑な質問にも答えられます。ナレッジグラフは情報を点と線のネットワークとして表現したものです。グラフをたどっていくことで、直接的には結びついていない情報同士の関係も見えてくるのです。

ナレッジグラフを構築するにはまずエンティティと関係を組み合わせる作業が必要になります。「Apple」「iPhone」「製造」という情報から、「Apple→製造→iPhone」というグラフの一部を作るイメージです。

テキストから「誰が」「何を」「いつ」といった具体的な情報を抽出するエンティティ抽出作業はLLMの登場で大幅に効率化されました。少数の例を示すだけで、LLMは新しいドメインでも適切にエンティティと関係を抽出できます。また、抽出した情報が正しいか自己検証する機能もあり、精度が向上しています。

ナレッジグラフの強みは、複雑な関係を表現できることです。「製品Aと製品Bは競合関係にある」「顧客Xは製品Yを購入した」「問題Zは製品Yでよく発生する」といった情報がネットワークとして蓄積されていきます。

例えば、顧客サポートで「製品Xの不具合について以前どんな対応をしたか？」という質問があったとします。ナレッジグラフには、製品、類似製品、過去のトラブル事例、解決策などがノードとして登録されています。

システムは、製品Xから「類似」関係をたどって類似製品を見つけ、そこから「トラブル事例」への関係をたどり、さらに「解決策」への関係をたどります。直接製品Xの事例がなくても、類似ケースから有用な情報を見つけ出せるのです。

#### タクソノミーとナレッジグラフを組み合わせることも可能

まず、タクソノミーを使って関連文書を検索します。次に、その文書群からナレッジグラフの一部を抽出し、LLMに渡します。LLMは暫定的な回答を生成しますが、情報が不足していれば、より具体的な追加質問を生成します。その質問で再び検索を行い、ナレッジグラフを更新します。

この循環を繰り返すことで、徐々に完全な回答に近づいていきます。最初から全ての情報を取得しようとするのではなく、必要に応じて段階的に情報を集めていく、人間の調べ方に近いプロセスです。

こうした実装は簡単ではありませんが、理論的にはシステムの実用レベルがかなり向上することが想定されます。

![[RAGの実用性レベルを上げるために「データソースを構造化する」という考え方 - AIDB/AIDB_96111_1-1024x654.png]]

システム全体像

## まとめ

企業が抱える「LLMを実務で使いたいが実用性が不安」という課題に対する一つの解決策を提示しているのがRAGですが、求められる品質に近づけるには工夫すべきことが幾つかあります。

ChatGPTやClaudeなどのチャットサービスだけでなくAWSなどのクラウドサービスも、データソースを検索フレンドリーに加工する機能はまだ十分にありません。そのため、今回示されたようなデータソースを構造化させる方法論を実践するのは一つの手です。

ただし実務で導入する際には、ドメインの専門知識と時間が求められます。また、全ての用途で高度な構造化が必要とは限りません。シンプルなRAGで十分な場面も多いでしょう。自社の課題とデータの性質を見極め、一般的な質問応答や簡単な情報検索では物足りないかを十分に検討してからでもよいかと思います。
