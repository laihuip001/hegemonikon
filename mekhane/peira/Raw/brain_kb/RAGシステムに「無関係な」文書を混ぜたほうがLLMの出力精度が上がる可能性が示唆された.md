---
created: 2026-01-01T09:36:40 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/63536
author: AIDB Research
---

# RAGシステムに「無関係な」文書を混ぜたほうがLLMの出力精度が上がる可能性が示唆された - AIDB

> ## Excerpt
> 「無関係な」文書を混ぜたほうが出力精度が上がる可能性がRAGシステムの検証で示唆されました。 これまでになかった視点だと述べられています。 通常RAGシステムではRetrieverによってタスクに関係する文書を取り出してLLMにコンテキストとして与えるのが一般的です。しかし今回の実験では、あえて無関係な文書も「ノイズ」として乗せる実験を行なっています。 参照論文情報 本記事の関連研究： LLMとR…

---
「無関係な」文書を混ぜたほうが出力精度が上がる可能性がRAGシステムの検証で示唆されました。

これまでになかった視点だと述べられています。

通常RAGシステムではRetrieverによってタスクに関係する文書を取り出してLLMにコンテキストとして与えるのが一般的です。しかし今回の実験では、あえて無関係な文書も「ノイズ」として乗せる実験を行なっています。

![[RAGシステムに「無関係な」文書を混ぜたほうがLLMの出力精度が上がる可能性が示唆された - AIDB/AIDB_63536-1024x576.jpg]]

**参照論文情報**

-   タイトル：The Power of Noise: Redefining Retrieval for RAG Systems
-   著者：Florin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone Filice, Cesare Campagnano, Yoelle Maarek, Nicola Tonellotto, Fabrizio Silvestri
-   所属：Sapienza University of Rom, Technology Innovation Institute, University of Pisa

**本記事の関連研究**：

-   [RAG（外部知識検索による強化）をまとめた調査報告](https://ai-data-base.com/archives/61367)
-   [外部知識を取り入れる2つの手法、ファインチューニングとRAGを比較した実験結果](https://ai-data-base.com/archives/63401)
-   [知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」](https://ai-data-base.com/archives/61831)
-   [情報抽出（文章から必要な事柄を読み取る）タスクについての調査  
    ](https://ai-data-base.com/archives/61703)

LLMは、長い文章や複雑な質問への対応にはまだ課題があると言われています。そこで注目されているのが、LLMと情報検索技術を融合したRAGシステムです。  
RAGシステムは、LLMに情報を提供することで、より正確で文脈に沿ったテキスト生成を実現するものです。主に以下2つのコンポーネントから構成されます。

・Retriever：外部情報源からクエリに関連する情報を検索します。

・Generator：Retrieverから得られた情報に基づいて、文脈に沿ったテキストを生成します。今回はLLMのことを指します。

今回紹介する論文では、研究者らがLLMにおけるRAGシステムの新しい知見を得たことが報告されています。  
結論から紹介すると、以下のことが分かりました。

1\. 検索フェーズにおいて関連文書の追加は必ずしも有益とは限らない  
2\. コンテキストにノイズを含めることが精度向上に貢献する

この結論は、RAGシステム特有の情報処理メカニズムが従来の情報検索とは異なることを示唆するものです。  
実験内容に詳しく触れる前に、LLMの発展の経緯やRAGの登場について少しおさらいします。

ここから限定コンテンツ

### LLMの歴史

2017年にGoogleの研究者らにより発表された「Attention Is All You Need」という論文から、LLM研究のトレンドが始まりました。いまや当たり前になったアーキテクチャのトランスフォーマーは、従来のモデルで使用されていた再帰層ではなく、アテンションメカニズムと呼ばれる新しい手法を用いて、データ内の長距離依存関係を学習することができるものです。

Googleはその後トランスフォーマーによって構築された言語モデルとしてBERTを発表しました。その後、OpenAIからGPT、GPT-2、GPT-3といったモデルが次々と発表されました。トランスフォーマーベースの言語モデルは規模や構造の進化に伴って、様々なタスクで驚異的なパフォーマンスを発揮するようになり、ついにGPT-3.5やGPT-4などのモデルが圧倒的な性能を達成しました。

そして最近では、LlamaなどのオープンソースLLMも次々とリリースされ、研究者や開発者によって追加の学習ができる高性能なモデルの環境が整いつつあります。

### RAGの登場

RAGシステムは、そんなLLMに対して情報検索を融合する新しい技術です。検索モジュールによって関連する情報を取得し、生成モジュールで文章を生成します。

従来の情報検索システムよりも高い精度で、文脈に沿った出力を実現します。そのため大変注目を集めており、様々な研究が行われています。例えば以下のような研究が行われています。

-   異なるタイプの文書の影響分析
-   RAGシステムにおけるアテンションメカニズムの動作分析

そんな中行わなれた本研究では、RAGシステムにおけるリトリバーモジュールの役割に関する以下が試されています。

1.  リトリバーモジュールのパラメータ（文書の位置やタイプ、数など）がLLMの生成結果に与える影響を分析する
2.  RAGシステムにおけるリトリバーモジュールの重要性全体を検証する

以下では、LLMにおけるRAGシステムを質問応答タスクで使用するアーキテクチャと、Retrieverの仕組みに関する実験内容、そして実験の結果を紹介します。

### RAGの構成

RAGは、様々な問題や下流タスクに適用できる強力なフレームワークです。今回はRAGを質問応答（QA）にいかに効果的に適用することについて探求されています。

特定のドメインや事前定義されたデータセットに制限されることなく、自然言語で提起された幅広い質問に対して正確な回答を提供するシステムをオープンドメイン質問応答（OpenQA）と言います。

流れとしては、クエリに対する回答を見つけるために、通常は大きなサイズの文書コーパスから情報を引き出します。

このタスクを効果的に解決するために効果的だと考えられているのがRAG（とLLMの組み合わせ）です。

RetrieverとGenerator（しばしばReasnerとも呼ばれる）によるアーキテクチャで、タスクを情報検索（正しい文書セットの発見）と回答の合成（実際の応答の提供）という異なるフェーズにプロセスを分けるのが肝だと言われています。

#### Retriever

RetrieverはOpenQAにおいて重要な役割を果たします。Retrieverの役割は、LLMがクエリに正確に答えるのを助けるために、小さな文書のサブセットを見つけることです。

様々な検索方法が模索されていますが、複雑で多様なクエリを扱うときのために「密集型Retriever」の使用が注目されています。

密集型の基本的な原則は、テキストデータを高次元のベクトル表現に変換することにあります。密集型Retrieverは、クエリと潜在的なソース文書の両方を処理して埋め込みを生成します。

埋め込みが生成されると、検索プロセスに移ります。検索プロセスの初期においては、クエリの埋め込みと、各文書の埋め込み間の類似性も計算されます。

類似性スコアに基づいて文書が順序付けされたら、トップランクの文書がGeneratorコンポーネントでのさらなる処理のために使用されます。

#### Generator

次のステップとして、Generatorが回答を生成します。今回はLLMにおけるRAGの話をしているので、GeneratorはLLMを指します。

LLMは、与えられたクエリ（プロンプトとも呼ばれる）に基づいて、正確なテキストを生成するように設計されています。

RAGでは、LLMはユーザークエリとRetriever取得文書を入力として受け取り、次トークンを逐次的に予測して回答を生成します。クエリという与えられたテキストと、取得された文書という動的なテキストに依存するという状態です。

今回研究者らが探究したかったのは、取得する文書を変更することがLLMの生成にどのように影響を与え、結果としてエンドツーエンドシステム全体にどのように影響を与えるかということでした。

その先には、Retrieverを最適化してシステムのパフォーマンスを最大化することを目指しています。

では次にいよいよ実験内容を見ていきましょう。

## 実験

### 実験の方法論

#### データセット

今回は以下のデータセットを加工したものが準備されました。

**Natural Question Dataset**

-   Googleの検索データをもとにした現実世界クエリの大規模コレクション
-   ユーザークエリと、回答を含む対応するウィキペディアページで構成される
-   自然言語理解とオープンドメイン質問応答の研究を促進するために設計されたもの

上記に対して、以下の加工が施され、「NQオープンデータセット」が作成されました。

-   特定のウィキペディアの文章に回答をリンクするという制限を取り除く
-   ウェブ検索に似た、より一般的な情報検索シナリオを模倣

なおデータセットのその他の情報は以下のとおりです。

-   2018年12月20日時点の英語版ウィキペディア
-   各記事は100語の非重複文章に分割
-   トレーニングセット：72,209のクエリ
-   テストセット：2,889のクエリ
-   文書数：21,035,236

#### 文書のタイプについて

データセットに含まれた文書は以下の4タイプに分類されます。

-   ゴールド文書 ：NQデータセットの元の文脈
-   関連文書：ゴールド文書と同様に、正しい回答を含み、クエリに答えるために文脈的に有用
-   関連するが不正確な文書：クエリと意味的に似ているが、正しい回答を含んでいない
-   無関係な文書：クエリに関連していないし、回答も含んでいない

### **文書の検索**

研究者らは今回ContrieverというBERTベースの密集型Retrieverを使って（Retrieverにも言語モデルを使用しています）クエリに似た文書（とそうでない文書）をコーパスから上位k個選び出します。このとき、文書とクエリは、モデルの最終層の隠れ状態を平均化して埋め込みに変換します。

### **LLMへの入力**

選び出された文書とクエリは、LLMが応答を生成するための入力となります。

LLMへの入力は、基本的にはタスクの指示、文書、そして最後にクエリの順に並びます。文書の中身における構成は実験によって異なりますが、指示は常にプロンプトの最初に、クエリは常に最後に配置されます。

![[RAGシステムに「無関係な」文書を混ぜたほうがLLMの出力精度が上がる可能性が示唆された - AIDB/AIDB_63536_1.png]]

### 実験で使用されたモデルについて

以下のLLMが使用されました。

-   Llama2：70億パラメーター、4096トークンのコンテキストウィンドウ、マルチクエリアテンション
-   Falcon：70億パラメーター、2048トークンのコンテキスト長、マルチクエリアテンション
-   Phi-2：27億パラメーター、2048トークンのコンテキストウィンドウ
-   MPT：70億パラメーター、2048トークンのコンテキスト長、ALiBiアテンション

すべてのモデルで、最大15トークンの応答長で貪欲生成アプローチが採用されてます。また、全モデルざ4ビット表現に量子化されたとのことです。

### **精度**について

今回はLLMによって生成された応答の精度が評価軸になっています。具体的な評価方法としては、LLMによって生成された応答の中に、予め定義された正しい回答が少なくとも1つ含まれているかどうかが確認されます。LLMの応答を、正確または不正確として二値的に測定したようです。なお、正確さを測定するのは常に難しく、評価基準を見直すのは今後の課題とされています。

## 実験結果

今回LLMに与えられる入力はタスク指示、クエリ、および”さまざまな文書”で構成されています。コンテキストとしての文書は前述のとおり、ゴールド、関連、関連するが不正確、および無関係のものが使用されます。また、文書数も変数になります。

### 関連文書の影響

研究者らは、NQオープンデータセットのトレーニングセットから10,000のクエリを選択して、関連文書（Retrieverによって高スコアが付けられた文書）の影響を調査しました。

下の図は、LLMへの入力例です。

![[RAGシステムに「無関係な」文書を混ぜたほうがLLMの出力精度が上がる可能性が示唆された - AIDB/AIDB_63536_2.png]]

調査の結果、コンテキストに含まれる関連文書の数が”増える”につれて、テストされた全てのLLMで精度が徐々に”劣化する”ことが明確に分かりました。場合によっては精度が67%以上悪化しています。さらに、関連文書をたった1つ加えるだけで精度が急激に低下してしまいます。

以下の表で確認できます。

![[RAGシステムに「無関係な」文書を混ぜたほうがLLMの出力精度が上がる可能性が示唆された - AIDB/AIDB_63536_3-1024x473.png]]

![[RAGシステムに「無関係な」文書を混ぜたほうがLLMの出力精度が上がる可能性が示唆された - AIDB/AIDB_63536_4-1024x472.png]]

このパフォーマンスの低下は、Retrieverの訓練フェーズ中に遭遇する「ネガティブ」な文書の性質と密接に関連しているのではないかと考えられています。

この仮説を探る、「ネガティブ」な文書で訓練されたRetrieverを使って実験を行いました。するとパフォーマンスの低下が起こりました。

このことから、関連情報と関連情報を区別することにモデルが苦労してしまうという現象が考えられています。

なお、ゴールド文書がクエリの近くにあるときは精度が高く、ゴールド文書が最も遠いときは低く、ゴールド文書がコンテキストの中央に置かれているときは最も低くなることも検証されました。入力されるテキスト内におけるコンテキスト文書の位置も敏感に影響してしまうということです。

### ノイズの影響

RAGシステムにおけるノイズ、つまり無関係な文書の影響を調べる実験も行いました。ランダムな無関係文書がコンテキストに導入されたときに、パフォーマンスがどう変化するかという内容です。

予想に反して、ノイズによって精度が悪化することはなく、むしろ良くなってしまう現象が確認されました。

![[RAGシステムに「無関係な」文書を混ぜたほうがLLMの出力精度が上がる可能性が示唆された - AIDB/AIDB_63536_7-1024x455.png]]

モデルによって挙動は細かく異なります。Llama2とPhi-2は、ノイズがクエリから最も遠い位置に導入されたときにパフォーマンス向上を示しました。しかし、ノイズが中間地点にあるとき、パフォーマンスは低下しました。

つまり、Llama2とPhi-2がクエリから遠いノイズを効果的に処理できるものの、ノイズが近づくにつれて無関係な情報をふるいにかける能力が減少することを示唆しています。

なおMPTモデルは独特の反応を示し、ノイズの位置によらずパフォーマンスが向上しました。

Falconモデルは特殊で、ノイズの位置がクエリよりも遠いよりむしろ近い（中間地点にある）ほうが精度が良いという結果が出ました。

### Retrieverの最適化について

LLMのコンテキストサイズは限られていますが、Retrieverがどんな文書をLLMに供給すべきでしょうか？

一般的な（従来の）考え方としては、クエリに意味的に近い文書が良いのだと考えられてきました。しかし、今回の実験結果は、関連文書と無関係文書との間のバランスが重要だと示唆しています。

LLMが正確な回答を生成するためには、コンテキスト内に、ある程度の関連情報が存在する必要があります。しかし関連情報が多すぎると処理しきれないのではないかと思われます。

普遍的な理論を導き出すことは困難ですが、最小限の文書セットが最初に取得され、その後、コンテキストの限界に達するまでは無関係な文書で補完するのがひとつのアプローチです。

しかし、まだ明確に答えることができません。LLMがこのような振る舞いを示す理由を理解することは今後の課題です。今はこの現象を報告し、強調するに留めると述べられています。将来的には、より正確な理解が求められます。そしてRAGシステムの設計と最適化に役立てることも重要です。

## 結論

この研究では、Retrieverによって取得された文書がRAGフレームワークにどのように影響するかが調べられました。Retrieverがプロンプト構築においてどんな役割を負うべきかという問題です。

主な発見は以下の通りでした。

-   関連情報は、クエリの近くに配置されるべきです。
-   ただし関連文書を無闇に追加していくことはRAGシステムにとっては有害になってしまいます。
-   無関係でノイズの多い文書は、適切に配置された場合、システムの精度を向上させるのに役立ちます。

ただし無関係でノイズの多い文書をプロンプトのどこに配置するのがいいのかは、モデルの種類によって異なります。そのあたりの普遍的なルールは今後調査されるべきだと考えられています。

同時に、内部メカニズムを明らかにするためにさらなる研究が必要です。

## まとめ

本記事では、RAGシステムにおけるRetrieverの役割と、無関係な文書がLLMによる回答生成の精度にどのように影響を与えるかについて調査した研究を紹介しました。

意外にも、関連性の低い文書がシステムの精度を向上させることが見出され、RAGシステムの理解と改善に新たな視点を提供しています。これまでの直感に反する結果と言えます。

実際のアプリケーションに役立てる際には、モデルの種類によってコンテキストのどこにどれくらい無関係な文書を含めるのかは変わってくることに注意した上で、すこし試してみてはいかがでしょうか。

なおこの論文ではコンテキストに一定のノイズを含ませるという戦略が提案されていますが、これは特にRetrieverを使用しなくても、「タスクの指示＋無関係な文書＋クエリ」といった構造を、ユーザーがLLMにダイレクトにプロンプトを打ち込む際に手打ちで入力して模倣してもいいかもしれません。

論文URL：[https://doi.org/10.48550/arXiv.2401.14887](https://doi.org/10.48550/arXiv.2401.14887)
