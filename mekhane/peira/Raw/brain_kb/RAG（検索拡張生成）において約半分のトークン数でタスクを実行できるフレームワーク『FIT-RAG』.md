---
created: 2026-01-01T09:38:08 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/66427
author: AIDB Research
---

# RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB

> ## Excerpt
> RAGを効率化する新しいフレームワーク「FIT-RAG」が提案されました。FIT-RAGでは、不必要な拡張を避け、トークン数をできる限り削減します。 実験により、様々な分野で幅広く応用できる可能性が示されました。 参照論文情報 本記事の関連研究： 背景 最近のLLMは、GPT-4に代表されるように、人間に近い洗練された文章生成能力を持っています。しかし、LLMのパラメータに保存されている知識が古く…

---
RAGを効率化する新しいフレームワーク「FIT-RAG」が提案されました。FIT-RAGでは、不必要な拡張を避け、トークン数をできる限り削減します。

実験により、様々な分野で幅広く応用できる可能性が示されました。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_-66427-1024x576.jpg]]

**参照論文情報**

-   タイトル：FIT-RAG: Black-Box RAG with Factual Information and Token Reduction
-   機関：Zhejiang University, Zhejiang Gongshang University
-   著者：Yuren Mao, Xuemei Dong, Wenyi Xu, Yunjun Gao, Bin Wei, Ying Zhang

**本記事の関連研究**：

-   [検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上](https://ai-data-base.com/archives/65359)
-   [LLMに対するプロンプトで「無関係な」文書を混ぜたほうが出力精度が上がる可能性がRAGシステムの検証で示唆された](https://ai-data-base.com/archives/63536)
-   [RAGにおいて取得された情報と事前知識が矛盾しても、情報に説得力があるときLLMは受け入れる](https://ai-data-base.com/archives/64979)
-   [GPT-4にRAG（検索拡張生成）を適用するケーススタディ　臨床問題で人間の医師よりも高い精度を達成](https://ai-data-base.com/archives/63952)
-   [LLMの検索結果をさらに正確にする手法『CRAG（修正型検索拡張生成：Corrective Retrieval Augmented Generation）』](https://ai-data-base.com/archives/63672)

## 背景

最近のLLMは、GPT-4に代表されるように、人間に近い洗練された文章生成能力を持っています。しかし、LLMのパラメータに保存されている知識が古くなったり、そもそも不完全だったりする可能性もあります。知識を更新する手段としてファインチューニングもありますが、頻繁に実行するのは現実的ではありません。

この問題に対処する有望なアプローチが、検索データを付加する「RAG」です。RAGは、LLMの事前知識だけに頼るのではなく、大規模コーパスやデータベースを活用します。（参考：[LLMのRAG（外部知識検索による強化）をまとめた調査報告](https://ai-data-base.com/archives/61367)）

従来のRAGシステムの理論は、検索器と生成モデルの両方を調整し、下流のタスクに適応させるのが一般的です。しかし、多くの高性能LLMはAPIを通じてのみアクセス可能で、ファインチューニングができません。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_1-1024x554.jpg]]

LLMが好むドキュメントが関連事実を含まない例

そこで、ブラックボックスLLMをRAGで拡張する「ブラックボックスRAG」が注目されています。LLMの好みに基づいて検索器をファインチューニングし、検索したドキュメントを入力に連結するものです。

しかし、まだ問題があります。検索でLLMの好みのみを考慮すると、事実情報が無視され、RAGの効果が低下します。例えば検索されたドキュメント自体、実際には役立つ事実情報を含んでいない場合があります。不必要なドキュメントで検索器を報酬付けすると、検索器を誤った方向に導いてしまいます。

また、検索したすべてのドキュメントを入力すると、大量の不必要なトークンが生成され、RAGの効率が損なわれることになります。

今回研究者らが解決したいと考えたのは上記の問題です。

ここから限定コンテンツ

研究者らは、効果と効率を同時に実現する新しいブラックボックスRAGフレームワーク「FIT-RAG」を提案しました。FIT-RAGは、5つのコンポーネントで構成されています。名称と機能を下記にまとめます。

1.  類似度ベースの検索器：コーパスから候補ドキュメントを選択
2.  バイラベルドキュメントスコアラー：事実情報とLLMの好みに基づいて候補ドキュメントを評価
3.  二面的自己知識認識器：外部知識が必要かどうかを判定
4.  サブドキュメントレベルのトークン削減器：トップ10の候補ドキュメントを選択し、サブドキュメントに分割してトークン数を削減
5.  プロンプト構築モジュール：質問、自己知識認識器の結果、トークン削減器の出力に基づいてプロンプトを構築

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_2-1024x538.jpg]]

FIT-RAGの概要

なおFIT-RAGの推論プロセスは下記のアルゴリズムで示されています。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_3-1024x610.png]]

### コンポーネント1：類似度ベースの検索器

論文では類似度ベースの検索器についての詳細な説明が省略されており、「Contrieverをベースに構築した」と簡単に言及されているだけで、その詳細な仕組みや実装について深く掘り下げられていません。おそらく、類似度ベースの検索器自体は既存の手法を利用しているため、著者らは詳細な説明を省略し、FIT-RAGの新規性により重点を置いたのだと考えられます。

### コンポーネント2：バイラベルドキュメントスコアラー

検索されたドキュメントの事実情報とLLMの好みを評価するために、バイラベル（2つのラベルでの）学習を用いてバイラベルドキュメントスコアラーを学習することが提案されています。

2つのラベルは、Has\_Answer（ドキュメントが質問の答えを含む可能性）とLLM\_Prefer（ドキュメントがLLMの正確な応答に役立つかどうか）です。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_4-1024x534.png]]

バイラベルドキュメントスコアラーの訓練プロセス

スコアラーの学習では、深刻なデータの不均衡が発生し、バイラベルドキュメントスコアラーの性能が低下します。そこで、研究者らはデータ不均衡を考慮したバイラベル学習アルゴリズムを提案しています。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_5-1024x323.png]]

このアルゴリズムは、異なるデータに異なる重みを与え、ハイパーグラディエント降下法（モデルのハイパーパラメータを自動的に最適化する手法。）を用いて重みを自動的に学習します。

### コンポーネント2：二面的自己知識認識器

与えられた質問に対してLLMが自己知識を持っているかどうか、つまりLLMが外部ドキュメントを検索せずに質問に答えられるかどうかを判定するコンポーネントです。

判定は、下記2つの側面に基づいて行われます。

1.  質問が長期的な知識や古くなった知識に関連しているかどうか
2.  質問の近傍に自己知識があるかどうか

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_6-1024x516.jpg]]

二面的自己知識認識器の推論プロセス

### コンポーネント3：サブドキュメントレベルのトークン削減器

検索されたドキュメントを分割し、LLMを拡張するのに必要な最小限のサブドキュメントを選択するコンポーネントです。

削減器は3つのコンポーネントで構成されています。

1.  サブドキュメント生成器：検索されたドキュメントをサブドキュメントに分割
2.  適格拡張検出器：サブドキュメントの組み合わせがLLMを拡張して正しい答えを導き出すのに適しているかを判定する分類器
3.  サブドキュメントフィルター：LLMを拡張して正しい答えを導き出すのに適したサブドキュメントの組み合わせを選択

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_7-1024x453.jpg]]

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_8-1024x350.jpg]]

サブドキュメントレベルのトークン削減器の推論プロセス

なお、サブドキュメントフィルターは下記のアルゴリズムで説明されています。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_9-1024x909.png]]

再ランク付けされたドキュメントセットからサブドキュメントを生成し、スコアに基づいてソートした後、貪欲法を使用して最適なサブドキュメントの組み合わせを選択することで、トークン数を削減しつつ、LLMを効果的に拡張できるサブドキュメントの組み合わせを見つける。といった流れが記述されています。

### コンポーネント4：プロンプト構築

研究者らは、検索されたドキュメントをプロンプトに追加してLLMを拡張する際のプロンプトテンプレートも設計しました。プロンプトの構成はRAGの性能に大きな影響を与えます。

以下3つの指示が含まれるテンプレートを提案しました。

1.  以下の文章を参照して次の質問に答えること
2.  質問を注意深く読んで理解し、質問の意味を完全に理解すること
3.  質問に答え、なぜその答えを選んだのかを説明すること

なお、検索が不要な場合、研究者らは内部知識を引き出すアイデアを用いました。LLMに質問に関する背景を生成させ、自己生成したコンテキストに基づいて質問に答えるよう指示する方法です。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_10-1024x312.png]]

検索の要不要に応じたプロンプトテンプレート

## 実験

### データセットとベースライン

研究者らは、TriviaQA、Natural Questions、PopQAの3つのデータセットを使用して、FIT-RAGの有効性を検証しました。それぞれの説明を簡単に記載します。

-   TriviaQA (TQA): トリビア愛好家が作成した95,000以上の質問と回答のペアを含む、読解力向上のために特別に設計されたデータセットです。
-   Natural Questions (NQ): オープンドメインの質問応答システムの訓練と評価のための大規模なデータセットで、約300,000の質問と回答のペアで構成されています。
-   PopQA: 大規模言語モデルの事実知識の記憶を評価することを目的としたオープンドメインの質問応答データセットです。

ベースラインとしては、Llama2-13B-Chat、ChatGPT、GenRead+Llama2-13B-Chat、REFEED+Llama2-13B-Chat、AAR+Llama2-13B-Chatが比較対象とされました。GenRead、REFEED、AARについての説明を下記に加えます。

-   GenRead：まず質問に基づいてコンテキスト文書を生成し、次にそれらの文書を読んで最終的な回答を生成する手法
-   REFEED：まず初期回答を生成し、次に質問と初期回答に基づいて関連情報を検索し、最後にその情報を使って初期回答を洗練させる手法
-   AAR：ソース言語モデルを使用して優先シグナルを提供し、エンコーダ-デコーダのアテンション機構を利用して、検索器をLLMの好みに合わせてファインチューニングする手法

実装では、Wikipedia 2018をコーパスとし、Llama2-13B-Chatをブラックボックス言語モデルとして使用しました。

なお評価指標には、回答の正確性と、検索性能Recall@Kが用いられました。

### 性能評価結果

FIT-RAGは、3つのデータセットのすべてにおいて、ベースライン手法を上回る性能を示しました。

特に、Llama2-13B-Chatと比較して、TriviaQAで14.3%、NQで19.9%、PopQAで27.5%の精度向上が見られました。さらに、他のブラックボックスRAG手法と比較して最も少ないトークン数で済みました。3つのデータセットで平均して、約半分のトークンを節約できました。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_11-1024x230.png]]

ベースラインと提案手法の回答精度比較

**バイラベルドキュメントスコアラーの効果**

バイラベルドキュメントスコアラーの効果を調べるために、研究者らは2つのラベル（事実情報ラベルとLMの好みラベル）の影響を分析しました。その結果、事実情報ラベルが最も高いRecall@Kを示し、事実情報の重要性が実証されました。また、データ不均衡を考慮したバイラベル学習アルゴリズムの有効性も確認されました。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_12-1024x294.png]]

TriviaQAの再ランク付けされたトップ100ドキュメントのRecall@K

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_13-1024x294.png]]

Natural Questions (NQ)の再ランク付けされたトップ100ドキュメントのRecall@K

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_14-1024x294.png]]

PopQAの再ランク付けされたトップ100ドキュメントのRecall@K

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_15-1024x294.png]]

各手法の回答精度比較

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_16-1024x321.png]]

データ不均衡を考慮したバイラベル学習の効果

**二面的自己知識認識器の効果**

アブレーション実験により、提案手法が回答精度を低下させずにトークン数を大幅に削減できることが示されました。ただし、NQやPopQAのようにLLMの自己知識が少ないデータセットでは、トークン削減の効果は限定的でした。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_17-1024x341.png]]

二面的自己知識認識器とサブドキュメントレベルのトークン削減器の効果

**サブドキュメントレベルのトークン削減器の効果**

さらにアブレーション実験により、提案手法が回答精度を低下させずにトークン数を大幅に削減できることが示されました。具体的には、TriviaQAで49%、NQで37%、PopQAで49%のトークン数削減が達成されました。また、トークン削減器に入力するドキュメント数の影響も調査され、10個のドキュメントを使用することが、回答精度とトークン削減効果のバランスに優れていることが明らかになりました。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_18-1024x324.png]]

トークン削減器の入力ドキュメント数と回答精度・トークン数の関係

**プロンプト構築の効果**

異なるプロンプトテンプレートの性能を比較した結果、提案手法のプロンプトが、シンプルなプロンプトやCoTプロンプトと比較して、それぞれ2.7%、1.5%の精度向上を達成しました。

![[RAG（検索拡張生成）において約半分のトークン数でタスクを実行できるフレームワーク『FIT-RAG』 - AIDB/AIDB_66427_19-1024x597.png]]

プロンプトテンプレート間の比較

## まとめ

本記事では、ブラックボックスLLMの拡張に特化した新しいRAGフレームワーク「FIT-RAG」を紹介しました。FIT-RAGは、事実情報とLMの好みの両方を考慮した検索、自己知識の活用、サブドキュメントレベルのトークン削減により、優れた有効性とトークン効率を同時に実現する手法です。

実験では、手法をLlama2-13B-Chatモデルに適用し、TriviaQA、NQ、PopQAの3つのオープンドメイン質問応答データセットで評価したところ、Llama2-13B-Chatのみと比較して、回答精度が大幅に向上しました。また、他のブラックボックスRAG手法と比較して、最も少ないトークン数で済むことが示されました。

膨大なコーパスを扱う必要がある実世界のアプリケーションにおいて、トークン効率の高さはメリットです。今後、FIT-RAGのような手法を実用シーンで使用することが多くなる可能性も考えられます。

-   URL：[https://doi.org/10.48550/arXiv.2403.14374](https://doi.org/10.48550/arXiv.2403.14374)
