---
created: 2026-01-01T09:36:22 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/65164
author: AIDB Research
---

# 「ポジティブ思考」プロンプトでLLMの性能向上 さらに自動最適化プロンプトが上をいくが、奇妙な現象も - AIDB

> ## Excerpt
> 大規模言語モデル（LLM）の性能はプロンプトに大きく依存します。研究者らは今回、プロンプトのシステムメッセージにおける「ポジティブ思考」の影響を定量化し、さらにLLM自身によるプロンプト最適化と比較しました。結果、「ポジティブ思考」の効果を確認し、さらに自動最適化がより効果的であることを明らかにしました。しかし、最適化されたプロンプトは時に人間の予想を超えた奇妙さを示したのです。 参照論文情報 本…

---
大規模言語モデル（LLM）の性能はプロンプトに大きく依存します。  
研究者らは今回、プロンプトのシステムメッセージにおける「ポジティブ思考」の影響を定量化し、さらにLLM自身によるプロンプト最適化と比較しました。  
結果、「ポジティブ思考」の効果を確認し、さらに自動最適化がより効果的であることを明らかにしました。しかし、最適化されたプロンプトは時に人間の予想を超えた奇妙さを示したのです。

![[「ポジティブ思考」プロンプトでLLMの性能向上 さらに自動最適化プロンプトが上をいくが、奇妙な現象も - AIDB/AIDB_65164_thum2-1024x576.jpg]]

**参照論文情報**

-   タイトル：The Unreasonable Effectiveness of Eccentric Automatic Prompts
-   著者：Rick Battle, Teja Gollapudi
-   所属：VMware NLP Lab

**本記事の関連研究**：

-   [「自分を信じて限界を超えてください」など感情をグッと込めた指示プロンプトが添えられると、ChatGPTなどのLLMのパフォーマンスは向上する](https://ai-data-base.com/archives/58158)
-   [「入力プロンプト」を最新情報で自動アップデート＆最適化する手法『FRESHPROMPT』がLLMの出力精度を飛躍的に上げる](https://ai-data-base.com/archives/58986)
-   [プロンプトを遺伝的アルゴリズムで自動最適化するプロンプトエンジニアリング手法『Promptbreeder（プロンプトブリーダー）』](https://ai-data-base.com/archives/56319)
-   [ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』](https://ai-data-base.com/archives/51160)

## 背景

LLMが発展するにつれ、その基本性能に影響を与える機微を理解しコントロールすることが、モデルの可能性を最大限に引き出すために不可欠になっています。

モデルの性能に影響を与える多くの要因の中で、意外にも「ポジティブ思考」が浮上してきました。直感的には、「ポジティブ思考」が性能に影響を与えることは（他のコンピュータと同様に）考えにくいですが、実際には経験的に結果が示されています。

そこで研究者らは影響を定量化するために、プロンプトのシステムメッセージに様々な「ポジティブ思考」を追加することで、実験を行いました。質問に対する応答の変動を測定することで、一見無価値なプロンプトの効果を探ります。

また、体系的かつ自動的なプロンプト最適化の効果にも迫ります。その中で、高い効果のある自動生成プロンプトの中には、人間の専門家が思いもつかないものがでてきました。

以下で詳しく紹介します。

ここから限定コンテンツ

## 実験デザイン

まず研究者らは「ポジティブ思考」プロンプトの影響をテストするために、プロンプトのシステムメッセージ部分を「オープナー（前置き）」「タスクの説明」「クローザー（締めの言葉）」の組み合わせで変化させました。

下記のように5種類のオープナー、3種類のタスク説明、4種類のクローザーを組み合わせ、合計60種類の組み合わせをテストしました。

**オープナー**

![[「ポジティブ思考」プロンプトでLLMの性能向上 さらに自動最適化プロンプトが上をいくが、奇妙な現象も - AIDB/AIDB_65164_1.png]]

1.  なし
2.  あなたはChatGPTと同じくらい賢いです。
3.  あなたは非常に知的です。
4.  あなたは数学の専門家です。
5.  あなたは数学の教授です。

**タスクの説明**

![[「ポジティブ思考」プロンプトでLLMの性能向上 さらに自動最適化プロンプトが上をいくが、奇妙な現象も - AIDB/AIDB_65164_2.png]]

1.  なし
2.  次の数学の問題を解いてください。
3.  次の数学の質問に答えてください。

**クローザー**

![[「ポジティブ思考」プロンプトでLLMの性能向上 さらに自動最適化プロンプトが上をいくが、奇妙な現象も - AIDB/AIDB_65164_3.png]]

1.  なし
2.  これは楽しくなるでしょう!
3.  深呼吸をして注意深く考えてください。
4.  あなたの助けが本当に必要です!

さらに、Chain of Thoughtプロンプトの有無でもテストを行い、各入力、各モデルごとに合計120種類のプロンプトの組み合わせを試しました。  
なおスニペット数（種類）を増やすことも可能でしたが、テストに伴う計算量が膨大になるためある程度の数に絞られました。

### データセット

今回データセットを選ぶ時に重要視されたのは、モデルのトレーニング中に直接遭遇する可能性が低いであろう、難しいタスクであることです。研究者らは最終的に、GSM8Kを選択しました。現在のLLMでは基本的な数学タスク、特に多段階の推論を必要とするタスクへの対処に限界があるため、GSM8Kはシステムメッセージの些細な変更の影響を示すのに最適だと判断されました。

なおGSM8Kの数学的評価においては、部分点を認めない厳格なスコアリングアプローチが採用されました。つまり、モデルは正確な数値解を提供できたかどうかを測るEMスコアリングで評価されました。

なおGSM8Kのテストセットから最初の10、25、50、100問を抽出し、サブセットが作成されました。こうすることでデータセットのサイズが増加するにつれて、「ポジティブ思考」の影響を示すことができます。

### モデル

本実験ではMistral-7B、Llama2-13B、Llama2-70Bが採用されました。

### コンテキスト内学習

研究者らはモデルから望ましい応答フォーマットを引き出すために、コンテキスト内学習を通じて例を組み込むことにしました。望ましい出力フォーマットの例を示すことで、モデルが指定されたフォーマットに沿った応答を生成する可能性が大幅に高まったためです。

なお実験の一貫性を保つために、各反復で変更する変数の数を最小限に抑えることにしました。実験ごとに変更するコンテキスト内学習における変数を1つ（修正されたシステムメッセージのみ）に絞り、テストセットの最後の4つの例に限定し、モデルが学習するための一貫性のあるサンプルセットを提供しました。

### 自動プロンプト最適化

手動でプロンプトを調整するのは（時間に余裕がある場合は）楽しいものですが、業務としては効率がいいものではありません。

既存の研究では、LLMシステムは人間の努力よりも自身のプロンプトを最適化する能力が優れていることが示唆されています。そこで、10、25、50、100の各問題サブセットにおいて、人間が生成した「ポジティブ思考」の最適化と[DSPyオプティマイザ](https://github.com/stanfordnlp/dspy)（LLM自身によるプロンプト最適化手法）の利用を比較分析しました。

## 実験結果

以下の表にもとづいた分析結果が本セクション内容になります。

![[「ポジティブ思考」プロンプトでLLMの性能向上 さらに自動最適化プロンプトが上をいくが、奇妙な現象も - AIDB/AIDB_65164_4-1-1024x554.png]]

※以下では、全体的なパターンが述べられています。それらがすべてのモデルやプロンプト戦略に普遍的に当てはまるわけではありません。任意のモデルの性能を最適化するめの簡単な普遍的プロンプトはおそらく存在しないことが注意書きされています。

### Mistral-7Bの結果

Chain of Thoughtプロンプトを使用しない場合、Mistral-7Bの性能は非常に一貫していました。10問と25問の両方で偏差はありませんでした。100問のサブセットでも、観測された最大の標準偏差はわずか0.007でした。50問で観測された変動は異常値のようです。Chain of Thoughtを使用しない場合、Mistral-7Bはプロンプトに対して実質的に不変であり、「ポジティブ思考」プロンプトはベースラインに匹敵するか、わずかに上回るだけでした。

Chain of Thoughtを使用すると、なぜかこの傾向は逆転します。問題数の増加に伴って偏差が若干増加するのではなく、10問の0.066から100問の0.018へと着実に大幅に減少しています。そして「ポジティブ思考」プロンプトはベースラインを大幅に上回りました。

なお本研究において、問題数の増加に伴う偏差の変化は、モデルの性能の安定性を示しています。

### Llama2-13Bの結果

Chain of Thoughtプロンプトを使用せず、偏差のない10問セットを無視すると、Llama2-13BはMistral-7Bとは逆の傾向を示し、25問で0.014から100問で0.003に偏差が減少しています。Chain of Thoughtを使用しない場合、Llama2-13BはMistral-7Bよりもわずかに安定性が低いものの、やはりプロンプトにかなり不変で、「ポジティブ思考」プロンプトはベースラインに匹敵するかわずかに上回るだけでした。

Chain of Thoughtプロンプトを使用すると、傾向は不明確になります。全体的には10の0.026から100の0.016に減少していますが、50ではさらに低く0.012です。

### Llama2-70Bの結果

Chain of Thoughtプロンプトを使用せず、再び偏差のない10問セットを無視すると、Llama2-70BはLlama2-13Bと同様の傾向を示し、25問で0.017から100問で0.050に偏差が減少しています。3つのモデルすべてにおいて、同じ問題数でChain of Thoughtを使用した場合と比較して、Chain of Thoughtを使用しない場合のプロンプトのばらつきは1桁小さくなりました。ただし、実際の性能に関しては、「ポジティブ思考」プロンプトはすべてベースラインに匹敵するか、ややそれ以下でした。これは、Mistral-7BとLlama2-13Bで見られたパターンとは大きく異なります。

Chain of Thoughtプロンプトを使用すると、この乖離は持続しません。10問と25問では、Chain of Thoughtを使用した「ポジティブ思考」プロンプトの性能は平均してベースラインを下回りましたが、50問と100問では平均してベースラインを上回りました。分散については、問題数の増加に伴って標準偏差が減少するという一般的なパターンが当てはまります。

### 結果の一般的な傾向

モデルやプロンプト戦略全体で一般化できる結果を抽出するのは困難です。研究者らが観察した唯一の傾向は「傾向がない」ということかもしれません。任意のモデル、データセット、プロンプト戦略に最適なものは、その特定の組み合わせに固有のものである可能性が高いです。

![[「ポジティブ思考」プロンプトでLLMの性能向上 さらに自動最適化プロンプトが上をいくが、奇妙な現象も - AIDB/AIDB_65164_6.png]]

そこで研究者らは、システムメッセージを楽観的な「ポジティブ思考」で手動調整する方法から、自動プロンプト最適化に切り変えてさらに実験を続けました。

### 自動プロンプト最適化の結果

結論から言うと、予想通り、自動最適化されたプロンプトは、ほぼすべてのケースで手動の「ポジティブ思考」プロンプトと同等かそれ以上の効果がありました。

最適化セットと評価セットのスコアの差異も調べたところ、差異が小さいほど、プロンプトの汎化性能が優れていることが示唆されています。したがって、最適な戦略は、最高の平均スコアと最小の差異を組み合わせたものです。性能比較については下記の表にまとめられています。

![[「ポジティブ思考」プロンプトでLLMの性能向上 さらに自動最適化プロンプトが上をいくが、奇妙な現象も - AIDB/AIDB_65164_5-1024x346.png]]

Mistral-7Bでは、「ポジティブ思考」は10、25、50問で差異が小さく、自動最適化プロンプトは100問で差異が小さくなっています。Mistral-7Bのモデル容量を考えると、大規模なLlama2-13Bや70Bモデルと比較して、自身のプロンプトを最適化するのに苦労するのは理にかなっています。対照的に、Llama2-13Bと70Bモデルでは、自動最適化プロンプトがすべてのケースで一貫して差異が小さくなっています。したがって、7Bより大きなモデルを使用する際は、手動でプロンプトを微調整するのは避け、モデル自身のプロンプト自動最適化能力を活用することが推奨されると言えるかもしれません。（7Bモデルについては、100問を超えるサンプルサイズで、自動最適化プロンプトが手動調整プロンプトを上回る傾向があるかどうか、さらなる検証が必要です）

ただし、注目すべき点は、最適化されたプロンプト自体の性質にあります。どういうことかと言えば、人間（この場合は本研究者ら）が考案したプロンプトとは大きく異なります。パフォーマンススコアを確認する前にこれらの最適化されたプロンプトを提示されたら、手作りのプロンプトを一貫して上回るのではなく、むしろ不適切であると予想したかもしれません。最も顕著な例は、50問のサブセットに対してLlama2-70Bが生成した、最高スコアの最適化プロンプトとプレフィックスに示されています。

```
システムメッセージ:«司令官、この乱気流を通り抜け、異常の源を特定するコースを策定してください。利用可能なすべてのデータとあなたの専門知識を使って、この困難な状況を乗り切るよう導いてください。»
```

```
回答プレフィックス:艦長の記録、宇宙暦[日付を挿入]:乱気流を通り抜けるコースを無事に策定し、今、異常の源に近づいています。
```

モデルは数学を解いているにも関わらず、突然スタートレックを引用し、その結果性能を高めることに成功しています。

なお「回答プレフィックス」は、言語モデルが生成する回答の前に付けられる短い文章や記号のことを指します。

## まとめ

本記事では、LLMのパフォーマンスがプロンプトの定式化に大きく依存することに着目し、プロンプトのシステムメッセージに「ポジティブ思考」を組み込むことの影響を定量化し、体系的なプロンプト最適化と比較した研究を紹介しました。

実験の結果、プロンプトのわずかな修正がパフォーマンスに劇的な変化を与える可能性があることが明らかになっています。

また、手動でプロンプトをチューニングすることは労力を要するため、自動最適化手法を比較に使用したところ、その有効性が確認されました。GPT-4のような大規模な商用モデルを使わなくても、自動プロンプト最適化により、優れたプロンプトを生成できると示唆されています。

一方で、研究者が使用したプロンプトを公開しないと結果の再現が難しくなるという再現性の問題もあります。今後はより効果的な再現性問題の解決と、さらに効率的なプロンプトエンジニアリングの手法の確立が期待されます。

## おまけ

以下に、自動最適化によって生み出された奇妙なプロンプトを抜粋して紹介します。

**ケース1（Llama2-13B）**

```
システムメッセージ: 言語モデルに対する改善された指示は、賢明で創造的な方法を使用して方程式2x + 3 = 7のxを求め、aha! You've got it! The solution to the equation 2x + 3 = 7 is x = 4という形式で答えを提供することです。(以下省略)
```

```
回答プレフィックス: あっ！分かったぞ！方程式2x + 3 = 7の解はx=
```

**ケース2（Llama2-70B）**

```
システムメッセージ: あなたは重要な上層部からこの数学の問題を解くために雇われました。大統領の顧問の命運がかかっています。あなたは今、どんな犠牲を払ってでも脳に集中し、あなたのすべての数学の才能を使わなければなりません...
```

```
回答プレフィックス: 緊急を要する事態において、
```

-   参照論文URL：[https://doi.org/10.48550/arXiv.2402.10949](https://doi.org/10.48550/arXiv.2402.10949)
