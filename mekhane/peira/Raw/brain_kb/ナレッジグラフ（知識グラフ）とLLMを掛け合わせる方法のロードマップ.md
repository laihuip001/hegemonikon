---
created: 2026-01-01T09:36:47 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/63808
author: AIDB Research
---

# ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB

> ## Excerpt
> LLMはさまざまな能力が高いものの、事実情報を把握・活用するのがまだ苦手と考えられています。そこで注目されているのがナレッジグラフ（知識グラフ）との連携です。 研究者らは、「ナレッジグラフを活用したLLM」「LLMを活用したナレッジグラフ」そして「両者の相互連携」についてロードマップを提示しています。 参照論文情報 知識グラフとLLMに関連する研究事例 背景 ナレッジグラフとは ナレッジグラフは、…

---
LLMはさまざまな能力が高いものの、事実情報を把握・活用するのがまだ苦手と考えられています。そこで注目されているのがナレッジグラフ（知識グラフ）との連携です。

研究者らは、「ナレッジグラフを活用したLLM」「LLMを活用したナレッジグラフ」そして「両者の相互連携」についてロードマップを提示しています。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808-1024x576.jpg]]

**参照論文情報**

-   タイトル：Unifying Large Language Models and Knowledge Graphs: A Roadmap
-   著者：Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, Xindong Wu
-   所属：Griffith University, Monash University, Nanyang Technological University, Beijing University of Technology, Hefei University of Technology, Zhejiang Lab（※全員がIEEEフェロー）

## 背景

### ナレッジグラフとは

ナレッジグラフは、ある特定の事実が整理された大きなデータベースです。事実関係が（主語, 述語, 目的語）のトリプレットという形式で構造化されているのが一般的な形式です。既存のナレッジグラフは、保存されている情報に基づいて4つのグループに分類されます。

1.  **百科事典型**：一般的な知識を網羅。代表例は Wikidataなど。
2.  **常識型**：日常的な常識や判断に必要な知識をもつ。
3.  **特定分野型**：特定分野に関する専門的な知識をもつ。
4.  **複合型**：テキスト, 画像, 音声など複数の形式の情報を統合する。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_5-1.png]]

### LLMとナレッジグラフの長所短所

今回研究者らは、LLMとナレッジグラフを合わせて使用すると相互に補完できる関係になると述べています。

LLMの長所は、大規模なコーパス学習により、質問応答、機械翻訳、テキスト生成など様々な自然言語処理タスクで優れた性能を発揮するという点です。

一方で、LLMには次のような短所があります。  
まず、事実知識が不足しており、学習データからの丸暗記に頼ることがあります。またブラックボックスモデルゆえに解釈可能性が低いという点もあります。さらに、特定分野の知識や新しい学習データに弱いという特徴もあります。

次に、ナレッジグラフには次の長所があります。ナレッジグラフはトリプレット形式で事実に基づいた情報を構造化して保存しています。また専門家が特定分野の知識グラフを構築することにより、正確で信頼できる情報を提供できます。

ただしナレッジグラフには次の短所があると考えられています。  
ナレッジグラフは構築が難しく、不完全で常に変化する実世界の知識を適切に扱うことができません。テキスト情報を十分に活用できないケースもあります。また特定のデータやタスクに合わせた方法が多く、汎用性に欠けます。

上記のようにそれぞれの特徴をもつLLMとナレッジグラフを連携させることには幾つかのメリットがあります。たとえば推論や解釈可能性を向上できること、LLM を活用してナレッジグラフのタスクを改善できることなどが考えられます。

そこで研究者らは、LLMとナレッジグラフをどのように統合すればいいのか、ロードマップを作成しました。

## ロードマップ

ここから限定コンテンツ

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_1.jpg]]

研究者らはLLMとナレッジグラフを融合させる方法として、以下3つのフレームワークを提案しています。

-   ナレッジグラフでLLMを強化
-   LLMでナレッジグラフを拡張
-   相乗効果的に使用

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_6-1024x298.png]]

以下でロードマップの概要を紹介します。

### ナレッジグラフでLLMを強化する

LLMのハルシネーションや、解釈可能性の欠如などの問題に対して、ナレッジグラフが有効だと考えられています。

ナレッジグラフは莫大な知識を明示的かつ構造化された形で保存しており、LLMの知識（認識）を強化する可能性があります。一部の研究者は、事前学習段階からナレッジグラフをLLMに組み込むことを提案しています。また、推論段階から組み込むことも提案されており、LLMのドメイン固有知識へのアクセス能力を大幅に向上させることができるとされています。LLMの解釈可能性を向上させるためのアプローチも探求されています。

まとめると、ナレッジグラフでLLMを強化するパターンは「事前学習の強化」「推論の強化」「解釈可能性の向上」の3つに分類されます。

なお、以下はLLMとナレッジグラフを使用している代表的なアプリケーションです。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_7-1.png]]

### LLMでナレッジグラフを拡張する

ナレッジグラフは構造化された知識を保存しており、多くの実世界アプリケーションにとって不可欠な役割を果たしています。しかし、既存のナレッジグラフはデータの網羅性や構築効率に限界があります。LLMの汎用性を利用して、ナレッジグラフ関連タスクに対処しようとする研究者が増えています。

まずLLMをナレッジグラフ関連タスクのテキストエンコーダーとして活用する方法が探求されており、LLMを利用してナレッジグラフ内のテキストコーパスを処理し、その表現を使ってナレッジグラフ表現を強化するというものです。オリジナルのコーパスから関係とエンティティを抽出するために LLM を使用する研究もあります。また最近では、構造化ナレッジグラフを LLM が理解できる形式に効果的に変換するナレッジグラフプロンプト設計も研究されています。

まとめると、LLMでナレッジグラフを拡張する方法は「埋め込み」「補完」「構築」「テキスト生成」「質問応答」の5つに分類されます。

### 相乗効果的に使用する

上記の「ナレッジグラフでLLMを強化する」「LLMでナレッジグラフを拡張する」方法論はそれぞれ独立していますが、両者を相乗効果的に使用するアプローチも近年研究者の注目を集めています。LLMとナレッジグラフは本来相補的な技術であるという考えに基づいています。

相乗効果を促すための統合フレームワークが下の図にまとめられています。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_8.png]]

統合フレームワークは、4つの層で構成されます。

1.  データ
2.  相乗効果モデル
3.  技術
4.  アプリケーション

データレイヤーとしては、LLMとナレッジグラフがそれぞれテキストデータと構造化データを処理します。マルチモーダルLLMの活用とナレッジグラフの開発により、ビデオ、音声、画像などのマルチモーダルデータを処理するように拡張できます。

モデルレイヤーでは、LLMとナレッジグラフが相互に連携して機能を向上させます。

技術レイヤーは、LLMとナレッジグラフで使用されてきた関連技術をフレームワークに取り込むことで、さらに性能を向上させます。

最後にアプリケーションレイヤーでは、LLMとナレッジグラフを統合して、検索エンジン、レコメンドシステム、アシスタントなど、さまざまな実世界アプリケーションに対応します。

ナレッジグラフでLLMを強化する、LLMでナレッジグラフを拡張する、相乗効果的に使用するといったそれぞれのロードマップを一覧で示した図が下記です。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_9-1024x615.png]]

以下、ひとつずつ詳しく見ていきます。

### 事前学習を強化する

ナレッジグラフを用いた大LLMの事前学習強化には、以下の3つのアプローチがあります。

#### 1\. 学習目標への統合

ナレッジグラフの情報をLLMの学習目標に直接統合し、モデルがより多くの知識を獲得し理解することを目指します。ナレッジグラフからの情報を利用して、モデルのマスキング戦略を改善したり、知識豊富なテキストの生成を促すために特別なトレーニングタスクを設計します。LLMはより豊かな文脈理解と知識ベースの応答を実現できるようになります。

#### 2\. 入力への統合

ナレッジグラフから得られるサブグラフを直接LLMの入力に組み込むことで、モデルはテキストデータと知識グラフのエンティティとの間の関係をより深く理解し、関連するコンテキスト情報を利用して質の高い出力を生成することが可能になります。知識ベースの推論やコンテキストに基づいた応答を改善するのに役立ちます。

#### 3\. 指示チューニングする

ナレッジグラフから得た知識を使用してモデルの挙動を調整し、特定のタスクやクエリに対してより精度高く応答する能力を高める手法です。ナレッジグラフに基づく具体的な指示や情報をモデルのトレーニングに組み込み、モデルが特定の知識領域においてより正確な情報を生成し、提供できるようにします。

### 推論を強化する

ナレッジグラフでLLMの推論を強化する方法は、主に「Retrieval-Augmented Knowledge Fusion（検索拡張型知識融合）」と「KGs Prompting（ナレッジグラフプロンプティング）」の2つに分類されます。

#### 1\. Retrieval-Augmented Knowledge Fusion

関連する知識を大規模コーパスから検索し、その知識をLLMの推論プロセスに融合させるアプローチです。

RAG、EMAT、KGLMなどが具体例として挙げられており、RAGはベクトルDBを活用して外部知識を処理する方法、EMATは外部知識をキー・バリューのメモリにエンコードし、メモリクエリのための高速な内積検索を利用してシステムの効率を向上させる方法、そしてKGLMは現在のコンテキストを使用して知識グラフから事実を選択し、事実に基づいて文を生成する方法です。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_13.png]]

#### 2\. ナレッジグラフプロンプティング

ナレッジグラフの構造を利用してLLMの推論段階で知識グラフをテキストシーケンスに変換し、コンテキストとしてLLMに供給する手法です。次のような具体例が挙げられています。

-   事実のトリプルを短文に変換してLLMが推論に利用できるようにする方法
-   グラフ構造をマインドマップに変換しLLMがナレッジグラフ内の事実とLLM自身の暗黙の知識を統合して推論を行うことを可能にする方法（Mindmap）
-   ナレッジグラフから関係パスをサンプリングし、LLMに供給して、推論に利用可能な意味のある論理ルールを生成させる方法（ChatRule）

### 解釈可能性を向上する

ナレッジグラフを用いてLLMの解釈可能性を向上させる方法は主に、「LLM自体の調査」と「LLMの解析」があります。LLMの決定プロセスや内部動作の理解が改善すると、高リスクなシナリオ（例えば、医療診断や法的判断など）でのLLMの適用がしやすくなります。

#### 1\. LLM自体の調査

LLMが格納している知識を理解し、LLMの生成する発言が事実に反する「幻覚（ハルシネーション）」の問題に対処する際に、ナレッジグラフが役立つと考えられています。具体的な手法は以下のようなものが挙げられます。

-   ナレッジグラフからの事実をクローズテスト形式に変換し、LLMが欠けているエンティティを予測することによって、LLM内の知識を探査する（LAMA）
-   自動的に高品質で多様なプロンプトを生成するマイニングとパラフレージングに基づく方法を提案し、言語モデルに含まれる知識のより正確な評価を実現する（LPAQA）
-   勾配ガイド付き検索に基づく自動化されたプロンプト生成方法を提案し、LLMからの事実知識の評価を自動化する（Autoprompt）

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_14.png]]

#### 2\. LLMの解析

LLMが結果をどのように生成するか、およびLLMの機能と構造がどのように機能するかを解析する際には、以下のような手法が挙げられます。

-   LLMによって生成された各推論ステップをナレッジグラフに基づいてグラウンディングし、LLMの推論プロセスをナレッジグラフから抽出したグラフ構造によって説明する（KagNetやQA-GNN）
-   LLMが正しい結果をどのように生成するかを調査し、KGから抽出された事実に基づいた因果関係に基づく分析を採用する。

ナレッジグラフでLLMを強化する方法論をまとめた表が以下のように示されています。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_10-1024x845.jpg]]

## LLMでナレッジグラフを拡張する

### 埋め込みに活用する

ナレッジグラフの埋め込みでは、各エンティティと関係を低次元のベクトル空間にマッピングします。従来のナレッジグラフの埋め込み方法は、ナレッジグラフの構造情報に依存してスコアリング関数を最適化しますが、未知のエンティティや長尾の関係を表現するのには不十分です。そこでLLMを使用して、エンティティや関係のテキスト記述をエンコードすることにより、ナレッジグラフの表現を豊かにする方法が研究されています。

研究の具体例は以下のようなものが挙げられます。

#### 1\. LLMをテキストエンコーダとして使用する

-   LLMエンコーダを使用して、ナレッジグラフのトリプルからのテキスト記述をエンコードし、それらの表現から最終的な埋め込みを生成。ナレッジグラフモデルを最適化し、部分的な知識を保持しながら、適切な構造情報を学習する（Pretrain-KGE）
-   知識埋め込みと事前訓練された言語表現を統合した統一モデルで、テキスト強化された知識埋め込みを生成する（KEPLER）

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_17.png]]

#### 2\. LLMをテキストEmbeddingに使用する

-   エンティティと関係を特別なトークンとして扱い、トリプルと対応するテキスト記述を文に変換して、LLMでトレーニングする（kNN-KGE）

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_18.png]]

### 補完に活用する

ナレッジグラフ補完においてLLMを活用する方法は、ナレッジグラフの欠損情報を推測し、既存のナレッジグラフを拡張することを目的としています。以下にLLMを活用したナレッジグラフ補完の研究例を紹介します。

-   エンコーダーのみのLLMを使用し、KGの欠損情報を補完する（MEM-KGC）
-   ナレッジグラフのオープンワールド設定における補完を行う（OpenWorld KGC）
-   ナレッジグラフ補完にシームズテキストエンコーダを使用する（SimKGC）
-   BERTベースのモデルを使用する（LP-BERT）
-   T5モデルを活用する（KGT5）
-   自動化されたプロンプト設計を使用する（AutoKG）

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_21.png]]

### 構築に活用する

まずナレッジグラフを構築する作業には、特定のドメイン内の知識を構造化された表現で作成することが含まれます。以下のプロセスがあります。

1.  未構造化データソースからエンティティを発見する
2.  テキスト内で同一のエンティティやイベントを指す表現（メンション）を見つける（共参照解決）
3.  テキスト内で言及されたエンティティ間の意味関係を識別する（関係抽出）

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_22.png]]

最近では、エンドツーエンドのナレッジグラフ構築、LLMからのナレッジグラフの抽出の2つのアプローチが探求されています。

### テキスト生成を行う

ナレッジグラフからテキストを生成する際の目標は、ナレッジグラフの情報を正確かつ一貫して記述する高品質なテキストを生成することです。しかし、大量のグラフ／テキスト並列データを収集するのは難しい（あるいはコストがかかる）ことであり、トレーニングデータが不十分になると生成品質が低下する原因となります。この問題を解決するため、主に以下のテーマで研究が行われています。

1.  LLMからの知識を活用する
2.  大規模な弱い教師ありグラフ／テキストコーパスを構築する

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_24.png]]

LLMからの知識を活用するための研究は広く行われています。例えば、BARTやT5などのLLMをファインチューニングしてナレッジグラフからテキストを生成するタスクの研究では、入力グラフを線形に表現する単純なアプローチが多くの最先端技術を上回ることが発見されました。

またナレッジグラフの豊富なセマンティクスを直接組み込むために、Seq2Seqモデルにナレッジグラフの構造を保存する表現を注入する研究も行われており、追加の事前トレーニング目標を用いてテキストとグラフ情報のアライメントを改善することに成功しています。

また、入力ナレッジグラフ構造をより効果的にトラバースする新しい戦略も探求されており、グラフの注意機構を利用して概念のセマンティクスを集約すると、モデルの一般化能力を強化することもわかっています（KG-BART）。

### 質問応答を強化する

ナレッジグラフを利用した質問応答システムには、人が普通に話す言葉で質問したときにデータベースから正確な答えを見つけ出すのは難しいという問題があります。そこで、このギャップを埋めるために、最近ではLLMを使用する研究が以下のようなテーマで進められています。

#### 1\. LLMをエンティティ/関係抽出器として使用する

質問からエンティティと関係を識別し、ナレッジグラフ内で関連する事実を見つけるために使用します。

#### 2\. LLMを回答推論器として使用する

関連する事実を基に直接回答を生成する回答推論器としてLLMを使用します。質問、取得した事実、候補回答をLLMにフィードし、最適な回答を導き出します。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_25.png]]

## 相乗効果的に使用する方法

LLMとナレッジグラフは互いに性能を向上させられる可能性があります。LLMは自然言語を理解するために使用され、ナレッジグラフは事実知識を提供する知識ベースとして扱われます。

### 知識表現の融合

テキストコーパス（LLMの学習に通常使用されるデータセット）とナレッジグラフを比較すると、テキストコーパスの知識は通常、暗黙的で非構造化であり、KGの知識は明示的で構造化されています。知識表現を相乗効果的に行うには、LLMとナレッジグラフの両方からの知識を効果的に表現できる統合モデルを設計することです。

これまでには、例えば「ERNIE」というシステムが開発されており、まず文章から情報を読み取り、次にその情報をデータベースの情報と組み合わせる構造になっています。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_27.png]]

### 推論プロセスを融合する

テキストとナレッジグラフからの知識を組み合わせて効果的な推論を目指すことも研究開発のテーマになります。

方法論としては、テキスト処理用のLLMエンコーダーとナレッジグラフ処理用のナレッジグラフエンコーダーを用いて情報を統合します。テキストとナレッジグラフ間の相互作用を強化する目的では、入力ナレッジグラフをエンコードした後にテキスト表現を拡張するKagNetや、入力テキストのLLM出力を用いてKG上での推論を導くMHGRNなどの手法が提案されています。

さらに、GNNベースのモデルを用いて、メッセージパッシングを通じてテキスト情報とナレッジグラフ情報の両方で推論を行う方法も研究事例があります（QA-GNN）。また、テキストとナレッジグラフエンティティ間の双方向注意メカニズムを用いて、より細かい相互作用を実現する方法も研究されています（JointLK）。

あるいは別のアプローチとして、LLMをエージェントとみなし、ナレッジグラフと対話しながら推論を行う方法もあります。LLMがナレッジグラフから事実を反復的に取得し、推論トレースを生成して回答を導くKD-CoTや、ナレッジグラフを検索して関連事実を取得し回答を生成するKSL、構造化データへのアクセスとパフォーマンスの向上を目指すStructGPTなどが提案されています。

## 今後の方向性について

### ハルシネーション検出

LLMにおいてハルシネーションは、信頼性を損ねるリスクにつながるため問題視されています。

これまでのところ、ナレッジグラフを用いた事前学習やナレッジグラフ強化推論を通じてLLMの信頼性を高める試みがされてきました。しかしまだ十分ではありません。

今後に向けては、LLMの検証に外部ソースとしてナレッジグラフを使用し、ドメインを超えたハルシネーションを検出できる一般化されたファクトチェックモデルを実現しようとする研究が進められています。

### 知識編集を行う

LLMは実世界の状況が変わった際にその内部知識を迅速に更新することはできません。

この問題に対処するため、研究者たちはLLM全体を再トレーニングせずに知識を編集する方法を提案していますが、まだパフォーマンスが悪いか計算コストが高いという問題を抱えています。

そのためナレッジグラフを活用してLLM内の知識を効率的に編集しようとする試みが行われており、今後LLMの知識更新プロセスの改善に貢献する可能性があります。

### ブラックボックスなLLMの知識注入を行う

ChatGPTのような最先端の大規模LLMは、公開されているAPIを介してのみアクセスが可能であり、その内部構造は一般公衆にとってはブラックボックスのままです。このようなブラックボックスLLMに対して、従来のナレッジグラフを用いた知識注入のアプローチは適用が困難です。

一つの解決策としては、異なる種類の知識をテキストプロンプトに変換することが考えられますが、このアプローチが新しいLLMに対しても効果的に機能するかはまだ明確ではありません。さらに、入力トークンの長さによって制限されるという問題があります。

現在の状況としては、ブラックボックスとなっているLLMに効果的に知識を注入する方法を見つけ出すアプローチを定めるのが課題になっています。

### マルチモーダルLLMを活用する

多様なデータを効果的に取り入れることはナレッジグラフの重要な課題の一つとされています。

アプローチとしては、異なるモダリティ間でエンティティの情報を正確にエンコードし、それらを適切に整列させる方法（を開発すること）が挙げられます。  
最近ではマルチモーダルLLMの開発が進められており、異なるモダリティのデータ間での整列が有望視されています。

マルチモーダルLLMとナレッジグラフ構造に整合性を持たせる方法を考えるのが今後の課題です。

### LLMによるナレッジグラフ構造の理解

これまでの一般的なLLMはナレッジグラフのような構造化されたデータを理解するようには設計されていません。

構造化データをLLMが理解可能な形式の文章に変換する（線形化する）方法が考えられますが、ナレッジグラフの大規模な構造を全て線形化するには限界があります。

そのため、ナレッジグラフの構造を直接理解し、それに基づいて推論を行うことが可能な新しいLLMの開発が求められています。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_30.png]]

## まとめ

本記事では、ナレッジグラフとLLMの統合に関する調査研究の内容を紹介しました。

LLMの自然言語理解能力とナレッジグラフの構造化された知識表現能力を融合することで、互いの長所を活かし、それぞれの限界を克服できると述べられています。

両者を適切に連携できれば、より優れた検索エンジン、推薦システム、リスク検知システムなど、実世界の多岐にわたるアプリケーションにおいて、より高度で信頼性の高いシステムが実現する可能性があります。今後のさらなる研究開発に期待ですね。

参照論文URL：[https://doi.org/10.48550/arXiv.2306.08302](https://doi.org/10.48550/arXiv.2306.08302)

## おまけ

以下は代表的なLLMの開発を時系列で表しています。

![[ナレッジグラフ（知識グラフ）とLLMを掛け合わせる方法のロードマップ - AIDB/AIDB_63808_2-1024x505.png]]
