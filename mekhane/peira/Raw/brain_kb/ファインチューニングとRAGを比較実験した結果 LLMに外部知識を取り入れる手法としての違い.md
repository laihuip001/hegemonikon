---
created: 2026-01-01T09:37:39 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/63401
author: AIDB Research
---

# ファインチューニングとRAGを比較実験した結果 LLMに外部知識を取り入れる手法としての違い - AIDB

> ## Excerpt
> Microsoftの研究者が、LLMに外部知識を取り入れる2つの手法としてのファインチューニングとRAGを比較した実験結果を報告しています。 大まかな結論としては、ファインチューニングよりもRAGは一貫して効果的と考えられるとのことです。 ただし、選定や実装はデータやアプリケーションに大きく依存します。 参照情報： 関連研究： 研究背景 LLMが持つ情報はモデルの訓練データに依存しています。モデル…

---
Microsoftの研究者が、LLMに外部知識を取り入れる2つの手法としてのファインチューニングとRAGを比較した実験結果を報告しています。

大まかな結論としては、ファインチューニングよりもRAGは一貫して効果的と考えられるとのことです。

ただし、選定や実装はデータやアプリケーションに大きく依存します。

![[ファインチューニングとRAGを比較実験した結果 LLMに外部知識を取り入れる手法としての違い - AIDB/AIDB_63401-1024x576.jpg]]

**参照情報：**

-   論文タイトル：Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs
-   機関：Microsoft Israel
-   著者：Oded Ovadia, Menachem Brief, Moshik Mishaeli, Oren Elisha
-   URL：[https://doi.org/10.48550/arXiv.2312.05934](https://doi.org/10.48550/arXiv.2312.05934)

**関連研究：**

-   [LLMのRAG（外部知識検索による強化）をまとめた調査報告](https://ai-data-base.com/archives/61367)
-   [既存のLLMを融合させて強力なモデルを作る手法「知識融合」](https://ai-data-base.com/archives/63153)
-   [LLMの知識を狙い撃ちして変更・修正する「知識編集（Knowledge Editing）」](https://ai-data-base.com/archives/61831)
-   [LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』](https://ai-data-base.com/archives/57018)

## 研究背景

LLMが持つ情報はモデルの訓練データに依存しています。モデルが最新の情報や、特定の専門知識を必要とする場合に、情報をどのように学ぶかが非常に重要な課題になってきています。

![[ファインチューニングとRAGを比較実験した結果 LLMに外部知識を取り入れる手法としての違い - AIDB/AIDB_63401_0-1024x580.jpg]]

LLMに新しい情報を注入する方法としては、主に「ファインチューニング」と「RAG」の二つがあります。ファインチューニングは、モデルを特定のタスクやデータセットに対して再訓練する手法です。一方、RAGは、モデルが回答を生成する際に外部のデータベースや情報源を参照する手法です。

実用的にLLMを使用するには、内部の情報が必然的に古くなっていくこと、特定の専門分野の知識が不足すること、そしてそれらに対処するための新しい情報の学習が困難であるという問題があります。現実世界にモデルで対応するためには、定期的な更新や適応のためのノウハウが求められています。

そこでMicrosoftの研究者らは、LLMに最新の情報を効率的に注入する方法としてファインチューニングとRAGの効果を比較し、どちらがLLMに新知識を学ばせるのにより効果的かを調査しました。

以下で詳しく紹介します。

ここから限定コンテンツ

前段で述べたファインチューニングとRAGについて、もう少し詳しく説明します。

### ファインチューニング

ファインチューニングは、主にLLMを特定のタスクに特化させるための技術として知られています。

新しいデータセットでモデルを再訓練し、特定の領域における知識を強化します。モデルの柔軟性を高めると同時に、特化した情報の処理能力を向上させることができます。

しかし新しい情報を取り入れる過程で既存の知識を忘れてしまう「Catastrophic Forgetting（壊滅的な忘却）」という問題に直面することがあります。ファインチューニングを用いる際にはこのリスクを考慮して、モデルの知識を長期間維持するために、継続的な再訓練が必要になることもあります。

### RAG（Retrieval-Augmented Generation）

RAGは、情報の取得と統合を行うための手法です。外部のデータベースから関連情報を検索し、その情報をベースに回答を生成します。LLMが訓練データには含まれていない最新の情報を活用して、質問に対してより豊かで正確な応答を生成するようになります。

時系列が重要なタスクや、継続的な知識更新が求められる応用分野において有効だと考えられています。既存の情報を忘れるリスクを軽減することにも役立つ可能性があります。

## ナレッジベースの作成方法

ナレッジベースとは、LLMが参照する整理された情報やデータの集合体で、つまりは知識のデータベースです。中身には事実、概念、理論などが含まれます。本論文ではファインチューニングやRAGで使用するためにナレッジベースの大まかな作成方法にも言及されています。

#### 1\. データの収集

ナレッジベースを作成するには、まず関連するデータを収集します。例えば、書籍、論文、ウェブサイト、データベースなど、さまざまな情報源から得ることになります。

#### 2\. データの処理

収集したデータは、モデルが理解できる形に加工されます。データのクリーニング、整形、標準化が含まれます。それぞれ以下のように説明されます。

-   クリーニング：不要または誤った情報を取り除き、品質を確保する作業
-   整形：データを一定のフォーマットや構造に整理し、モデルが効率的に処理できるように整頓する作業
-   標準化：異なるソースからのデータを共通の形式に統一し、モデルが一貫して情報を解釈できるようにする作業

#### 3\. データの統合

次に、処理されたデータを統合して、モデルがアクセスしやすいナレッジベースを構築します。

#### 4\. モデルへの統合

作成されたナレッジベースを、ファインチューニングやRAGによってLLMに組み込みます。

#### 5\. 更新と維持

ナレッジベースは定期的に更新され、最新の情報に保つ必要があります。また、古い情報の削除や誤った情報の訂正も重要です。

## 実験の枠組み

#### モデル選択

今回の実験では、3つの異なる7B（70億パラメータ）モデル、Llama2・Mistral・Orca2を選択しました。人気のある代表的なオープンソースのモデルです。

Orca 2についてはこちらで紹介しています：[Microsoftの研究者ら、比較的小さなサイズでもタスクによってはOpenAIのGPT-4を凌駕する言語モデル『Orca2』を開発](https://ai-data-base.com/archives/59349)

なおMistralについては、最新モデルのMixtral 8×7Bが大きく性能向上しており、そちらについては右記の記事で紹介しています：[最高水準のオープンソースLLM『Mixtral 8x7B』は内部で専門家が切り替わる高効率モデル](https://ai-data-base.com/archives/62480)  
※本実験で使用されたのはMixtral 8×7Bではありません。

なお、RAGコンポーネント用には、業界標準の埋め込みモデルとして、bge-large-enとFAISSベクトルストア（Langchain）が使用されました。

#### 設定の変更

実験では、様々な設定を試すためにグリッドサーチ（パラメータの組み合わせをすべて試す方法）が行われました。ベースモデルとファインチューニングされたモデルの性能をRAGコンポーネントと比較し、RAGにおける最適なテキストチャンクの数を調査しました。また、0ショットと5ショットのパフォーマンスを調べました。

RAGにおけるチャンクとは、外部データを取得する際の断片を指します。つまり、チャンクの数（チャンクサイズ）とは、取り出す情報の量を意味します。

#### トレーニング

すべてのモデルは、教師なしトレーニング手法を用いてトレーニングされました。NVIDIA A-100 GPUを4つ使用し、5エポック、バッチサイズ64でトレーニングしました。

エポックとは、モデルが全てのトレーニングデータセットを繰り返して学習する回数を意味します。各エポックでは、モデルがデータセットの各サンプルから学習を試み、その過程で重みを調整していきます。

一方、バッチサイズとは、モデルが一度に学習するデータのサンプル数を示しており、これはメモリ使用量と学習速度のバランスをとるためのパラメータです。

どちらも、トレーニングの効率と最終的なモデルの性能に影響を与える重要な要素です。

#### 評価方法

各選択肢を質問に追加してモデルに渡し、選択肢ごとにログ確率スコア（log-likelihood accuracy）を得ました。最もスコアが高いものがモデルの選択として解釈され、精度計算に使用されました。

ログ確率スコア（log-likelihood accuracy）とは、モデルが与えられた入力に対してどれだけ確信を持っているかを示し、高いスコアはモデルがその選択肢をより正確だと判断していることを意味します。

## 実験結果

#### MMLUの結果

次の4つのアプローチを比較しました。

1.  ベースモデルのみ
2.  RAG
3.  ファインチューニング（FT）
4.  FTとRAGを組み合わせ

RAGはベースモデルに比べて顕著に良い結果を示しました。またファインチューニングとRAGの組み合わせに関しても、いくつかのタスクで最も良い結果を示しています。

なお5ショットアプローチは、わずかに結果を向上させました。

![[ファインチューニングとRAGを比較実験した結果 LLMに外部知識を取り入れる手法としての違い - AIDB/AIDB_63401_1-1-1024x973.jpg]]

#### 新しい出来事に対する性能

本実験ではMMLUの他に、「Current event」についての各種法の性能が比較されました。

「Current event」とは、モデルがトレーニングデータに含まれていない最新の出来事や情報についてのクエリに対応する能力を評価するために行われた実験を指します。定期的に知識ベースを更新しない静的なモデルにとって、新しい情報に適応する能力が定量的に示されるのは重要です。

細かく見ると、RAGは特に有効であることが示されました。ファインチューニングはRAGに対して競合する性能は発揮しませんでしたが、複数の言い換えを用いたファインチューニングはベースラインよりも大幅な改善をもたらしました。なお、RAGとファインチューニングを組み合わせたものは、RAG単独と比較しても劣る性能を示しました。

![[ファインチューニングとRAGを比較実験した結果 LLMに外部知識を取り入れる手法としての違い - AIDB/AIDB_63401_2-1024x211.png]]

#### ファインチューニング対RAGをまとめると

MMLUと「Current event」タスクの結果では、RAGがファインチューニングよりも顕著に優れていることが明らかになりました。ファインチューニングはベースモデルに比べてほとんどの場合で改善に貢献はするものの、RAGの性能と競合するには至りませんでした。

![[ファインチューニングとRAGを比較実験した結果 LLMに外部知識を取り入れる手法としての違い - AIDB/AIDB_63401_3-1024x780.png]]

## 反復の重要性について

新しい情報に関するタスクでは、モデルは予め訓練されていないため、標準的なファインチューニングだけではパフォーマンスが向上せず、時には悪化させることがあります。そのため、やるべきこととしてはまずデータ拡張が挙げられます。

データ拡張は、言語モデルのパフォーマンス向上のための定番的な方法です。パラフレーズを使うことで、ファインチューニングの結果が向上することが確認されています。

ファインチューニングにおけるパラフレーズとは、トレーニングデータにバリエーションを加えるために、元のデータセットの文章を異なる言い回しや表現で再記述することです。すると、モデルが同じ意味の情報を様々な形で理解し、より一般化する能力を向上させることができます。

今回、パラフレーズを用いた反復的な学習は、限られたデータから新しい知識を理解し、一般化するモデルの能力に肯定的な影響を与えることがわかりました。

![[ファインチューニングとRAGを比較実験した結果 LLMに外部知識を取り入れる手法としての違い - AIDB/AIDB_63401_5-1024x844.png]]

データを反復することは、モデルが単に文を記憶するのではなく、内容を理解し、一般化するのを助けます。

ただし、パラフレーズによる反復とモデルの性能における関連性は、さらなる研究が必要と述べられています。

なおMistral-7Bを対象に、トレーニングの繰り返しに伴う損失の推移も記録されています。下記のグラフからは、Mistral-7Bモデルがトレーニングを重ねることで損失が時間とともに減少していること、すなわちモデルがデータを適切に学習し、予測精度が向上していることを示唆しています。

![[ファインチューニングとRAGを比較実験した結果 LLMに外部知識を取り入れる手法としての違い - AIDB/AIDB_63401_4-1024x780.png]]

## 結論と展望

ファインチューニングは多くの用途に役立つものの、知識の注入に関してはRAGがより信頼性の高い方法であることが示唆されました。

なお、今回は教師なし学習に焦点を当てましたが、指示チューニングや強化学習ベースの方法との組み合わせが、さらに良い結果をもたらす可能性はあるので今後の研究テーマだとされています。

なおLLMにおける知識表現については、理論的観点からさらなる研究が必要と考えられています。知識表現とは、LLMがどのようにして知識を内部的にエンコードし、保持するかということです。これは、モデルが事実、概念、関連性をどのように理解し、それらを使用してタスクを処理するかに関係しています。

次の記事が関連研究を紹介しています：[LLMは世界モデルを持ち「物事がどのように位置づけられ、時間がどのように進行するか」を理解する可能性](https://ai-data-base.com/archives/56365)

また、知識を測定する方法については、他の定義や視点の見直し（または拡張）も大事だと述べられています。モデルがどれだけの知識を持っているか、またその知識がどれだけ正確であるかを、どのように評価するかという話です。出力の正確さや、特定のクエリに対する回答の質を評価する指標などが含まれます。

## まとめ

本記事では、LLMが新しい専門知識や見たことのない情報にどのように適応するか、特定の手法で実験した研究を紹介しました。

現時点での主要な二つのアプローチであるファインチューニングとRAGを比較したところ、新しい知識を注入する手法としてRAGの方が信頼性が高いことが示唆されています。

なお今後の研究では、様々な技術の組み合わせや理論的な知識表現についてより深めることが提案されています。

本研究は特定の実験条件下での結果のみを示しているため、より広範な視点で継続的な情報収集が必要であることに留意していただければと思います。
