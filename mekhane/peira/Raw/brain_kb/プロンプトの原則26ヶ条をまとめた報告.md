---
created: 2026-01-01T09:37:55 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/61417
author: AIDB Research
---

# プロンプトの原則26ヶ条をまとめた報告 - AIDB

> ## Excerpt
> プロンプトの原則26ヶ条をまとめた論文が公開されています。 LLaMA-1/2, GPT-3.5/4を使用してスケール評価をした結果、これらの原則が応答品質を向上させると確認できているとのことです。 本記事では、詳細を見ていきます。 参照論文情報 本記事の関連研究：ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介 研究背景 現代のAI技術は多岐にわたる分野で…

---
プロンプトの原則26ヶ条をまとめた論文が公開されています。

LLaMA-1/2, GPT-3.5/4を使用してスケール評価をした結果、これらの原則が応答品質を向上させると確認できているとのことです。

本記事では、詳細を見ていきます。

![[プロンプトの原則26ヶ条をまとめた報告 - AIDB/AIDB_61417-1024x576.jpg]]

**参照論文情報**

-   タイトル：Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4
-   著者：Sondos Mahmoud Bsharat, Aidar Myrzakhan, Zhiqiang Shen
-   所属：VILA Lab, Mohamed bin Zayed University of AI
-   URL：[https://doi.org/10.48550/arXiv.2312.16171](https://doi.org/10.48550/arXiv.2312.16171)
-   GitHub：[https://github.com/VILA-Lab/ATLAS](https://github.com/VILA-Lab/ATLAS)

**本記事の関連研究**：[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介](https://ai-data-base.com/archives/58361)

## 研究背景

現代のAI技術は多岐にわたる分野での応用が進展しています。その中で、LLMを有効に活用するためにはまだ解決すべき課題が残っています。多くのユーザーにとって、LLMにどう質問するか、どのようにプロンプトを設計するかは、まだまだ明確ではありません。

そこで研究者たちはプロンプトの最適化、つまり「プロンプトエンジニアリング」に注目しています。LLMの応答品質を向上させるために、特定のタスクに合わせた適切な指示を設計する技術です。

研究者らは網羅的な調査を通して、LLMとユーザーのやり取りを改善する原則を作成しました。モデルの機能を最大限に引き出すことを目指しています。

**本記事の関連研究**：[「自分を信じて限界を超えてください」など感情をグッと込めた指示プロンプトが添えられると、ChatGPTなどのLLMのパフォーマンスは向上する](https://ai-data-base.com/archives/58158)

## 原則の概要

LLMの応答の品質は、ユーザープロンプトの質と直結しています。LLMに適切に反応させるためには、あらかじめしっかりプロンプトを設計することが重要だと考えられています。

本研究では、効果的なコミュニケーションを促進するための26の原則を提案しています。

簡潔で明確なプロンプト設計、文脈に即した内容、タスクに沿ったアライメント、具体例の提示、バイアスの回避などが、高品質な応答を促すための原則として重視されています。

ただしプロンプトの設計は進化し続ける分野であり、今後も改善され拡張される見込みです。

なお下の図は、原則を適用する前と後のプロンプトの例と、それに対するLLMの応答を示しています。以下で説明する原則5と原則6を適用した例です。

![[プロンプトの原則26ヶ条をまとめた報告 - AIDB/AIDB_61417_3.png]]

## 原則一覧（カテゴリー別）

下の表は本論文で提供された、プロンプト設計における原則26ヶ条です。これらが5つのカテゴリーで分類されますので、記事でははじめからカテゴリー別で紹介します。

![[プロンプトの原則26ヶ条をまとめた報告 - AIDB/AIDB_61417_4.png]]

### 1\. 構造と明確さに関する原則

#### 原則2: オーディエンスを定義する

モデルの出力を受け取る対象が、どんなフィールドの専門家であるかという点をプロンプトに組み込むことが推奨されています。

#### 原則4: 肯定的な表現を使用する

肯定的な行動を促す指示を使用し（do）、否定的な言葉遣い（don’t）を避けましょう。

例えば、「汚い言葉遣いをしないでください」ではなく「綺麗な言葉遣いをしてください」などです。

#### 原則12: 中間ステップを導入する

「ステップバイステップで考える」などの言葉を使って出力の段階を作りましょう。

#### 原則20: 出力プライマーを使用する

出力してほしい内容が自然と出てくるようなテキスト（期待する出力内容の最初の方）を、プロンプトの最後に添えます。

例えば、「〜〜のポイントを日本語で教えてください。 まず最も言いたいことは次のとおりです：」など

#### 原則17: 区切り文字の使用

区切り文字を使用してプロンプト内の情報を整理します。

#### 原則8: プロンプトのフォーマットを作る

プロンプトを構成する際は、「####Instruction####」で始め、必要に応じて「####Example####」や「####Question####」を追加します。

### 2\. 情報に関する原則

#### 原則7: 事例の導入をする

少数の事例を用いたプロンプトを作成すると、モデルがタスクを理解しやすくなります。

![[プロンプトの原則26ヶ条をまとめた報告 - AIDB/AIDB_61417_7.png]]

#### 原則5: シンプルな説明を促す

トピックやアイデアについて明確さや深い理解が求められる場合、まずは易しい説明を求めるプロンプトを活用するのも有用です。

例えば、以下のような形式です。

-   〜〜を簡単な言葉で説明してください。
-   私が11歳の子供のようなら、どう説明しますか？
-   〜〜の初心者になったとして、どう説明しますか？
-   5歳の子供に何かを説明するように、シンプルな言葉で〜〜を書いてください。

#### 原則13: バイアスのない応答を促す

プロンプトに「回答は偏見に基づいていないこと、固定観念に依存しないこと」などを含めます。

下の図は、プロンプトに原則13を適用することで、LLMの応答がより中立的な内容になることを示しています。

![[プロンプトの原則26ヶ条をまとめた報告 - AIDB/AIDB_61417_6.png]]

#### 原則26: 類似テキストでは同じ言語を使用させる

例と似たエッセイやパラグラフなどを書かせる際は、同じ言語を使用するよう指示します。

#### 原則24: 特定の言葉を指定する

出力に使用してほしいテキストを指定することも可能です。

例えば、「”〜〜〜”で開始する形でコンテンツを完成させてください。一貫性は保ってください」

#### 原則25: 従うべき要件を提示する

モデルがコンテンツを生成するために従うべき要件を、キーワードや規則として明確に提示しましょう。

#### 原則15: テストを出させる

特定のトピックについて質問させて、自らの理解度をチェックすることも可能です。

例えば、「〜〜について教えてください。その後、テストを出してください。答えは書かないでください。私が回答するので、正解／不正解を告げてください。」

#### 原則21: 詳細なテキストを作成させる

詳細が必要なエッセイ、テキスト、パラグラフを書く際には、「必要な全ての情報を加えて、詳しく〜〜について書いてください」などと指示します。

### 3\. ユーザーの対話と関与に関する原則

#### 原則14: モデルから質問させる

モデルからユーザーに対して質問を繰り返し行わせ、必要な出力を提供するのに十分な情報をモデルが収集できるようにしてみてください。

#### 原則21: 詳細なテキストを作成させる

（先ほどと同じ内容）

### 4\. 内容と言語スタイルに関する原則

#### 原則22:

ここから限定コンテンツ

#### テキストのスタイルを保持する

テキストを修正させる際に、スタイルを変えずに行いたい場合は、「文法や語彙のみを改善し、自然に読めるようにしてください。書き方のスタイルは変えないでください」などと指示します。

#### 原則9: タスクを定義する

「あなたのタスクは〜〜です」や「必ず〜〜してください」といったフレーズをプロンプトに組み込んでみてください。

#### 原則10: 何かを禁止する時は罰則があるという

「〜〜には罰則が課せられます」といった書き方をすることで、有効に行動を制限できるようです。

#### 原則16: 役割を割り当てる

モデルに特定の役割を割り当てることで、その性能を最大限に活用できるとされています。

#### 原則11: 自然な対話を促す

「人間らしく自然に質問に答えてください」というフレーズを使用するのが有効です。

#### 原則1: 丁寧語は不要

LLMに対するプロンプトでは「もしよかったら」といった丁寧語は省略して、要件をダイレクトに述べてください。

#### 原則18: 特定の言葉やフレーズの繰り返し

プロンプト内で特定の言葉やフレーズを複数回繰り返し使用すると、強調したい点が明確になります。

#### 原則6: より良い解決策にチップを提案する

より良い出力を引き出す際に、「優れた解決策にはxxxドルのチップを払います」などといったテキストを添えるのは有効だと考えられています。

### 5\. 複雑なタスクやコーディングに関する原則

#### 原則3: 複雑なタスクの細分化

複雑なタスクをシンプルなものに分解してください。

#### 原則23: 複数ファイルにまたがるコーディングプロンプト

複数のファイルにまたがるコードを生成する場合、指定されたファイルを自動的に作成するか、既存のファイルを変更して生成したコードを挿入するスクリプトを生成するのが有効とのことです。

#### 原則19: チェーンオブソートとフューショットプロンプトの組み合わせ

複雑なタスクを行わせる際には、チェーンオブソート（CoT）をフューショットプロンプトと組み合わせて、段階的に解決できるようにしてみましょう。

下記は、上記の内容をまとめている表です。

![[プロンプトの原則26ヶ条をまとめた報告 - AIDB/AIDB_61417_5.png]]

**本記事の関連研究**：[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』](https://ai-data-base.com/archives/51160)

## 実験

研究者らは、上記の原則における有効性を実験で検証しています。

ATLASというベンチマークを使用して、原則を使用した時のLLMの応答品質を評価しました。各原則ごとに20個の質問を人間が選定し、原則が適用された場合とそうでない場合を比較したのです。

### モデルと評価基準

実験されたモデルは、微調整されたLLaMA-1/2、LLaMA-2-70B、GPT-3.5、GPT-4です。これらを小規模（7B）、中規模（13B）、大規模（70B、GPT-3.5/4）のスケールに分け、「Boosting」と「Correctness」の2つの設定で評価しました。

「Boosting」と「Correctness」はそれぞれ、応答品質と正確さを測るものです。

### 実験結果

#### 小規模、中規模、大規模モデルにおける結果

-   **Boosting**: 原則を適用することで、すべてのスケールのLLMで著しい改善が見られました。大きなモデルは特段の変化がありました。
-   **Correctness**: 原則の適用により、平均して20％以上の改善が見られ、小規模・中規模モデルでは20〜30％、大規模モデルでは50％以上の改善がありました。

![[プロンプトの原則26ヶ条をまとめた報告 - AIDB/AIDB_61417_8.png]]

![[プロンプトの原則26ヶ条をまとめた報告 - AIDB/AIDB_61417_9.png]]

#### 個々のモデルにおける結果

-   **Boosting**: 原則を適用した後の個々のモデルは平均して50％の改善が見られました。
-   **Correctness**: モデルの大きさに比例して正確さが向上しました。

![[プロンプトの原則26ヶ条をまとめた報告 - AIDB/AIDB_61417_10.png]]

![[プロンプトの原則26ヶ条をまとめた報告 - AIDB/AIDB_61417_11.png]]

**本記事の関連研究**：[基盤モデル（GPT-4）はプロンプトの工夫で専門特化モデルに匹敵するほど性能が向上することが「医学分野」で示唆される](https://ai-data-base.com/archives/59798)

## まとめ

本記事で紹介した研究では、LLMの反応を改善するための26の原則が提示されました。

これらの原則を使ってLLMと対話することで、より簡潔で客観的な応答が得られるという結果が得られました。

プロンプトの影響はモデルの能力や訓練に依存しますが、今回はさまざまな規模のLLMで検証されており、一定の普遍性が確認されています。

ユーザーや開発者の皆様は、このような調査結果を普段のプロンプトにぜひ活用してみてはいかがでしょうか。
