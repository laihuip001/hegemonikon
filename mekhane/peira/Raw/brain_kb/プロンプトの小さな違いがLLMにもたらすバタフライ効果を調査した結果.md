---
created: 2026-01-01T09:37:22 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/62566
author: AIDB Research
---

# プロンプトの小さな違いがLLMにもたらすバタフライ効果を調査した結果 - AIDB

> ## Excerpt
> 出力形式や小さなプロンプトの変更がどれほどLLMの応答に影響するのかを、大量のケーススタディで実験した結果が報告されています。 結論としては、少しのプロンプトの違いが様々なタスクで大きな違いをもたらすことが分かりました。そして、従来信じられてきたことと実際のズレに関しても述べられています。 例えば ”チップをあげる” といった言葉も、タスクによって効果が異なる（ときには逆効果を及ぼす）ことが示唆さ…

---
出力形式や小さなプロンプトの変更がどれほどLLMの応答に影響するのかを、大量のケーススタディで実験した結果が報告されています。

結論としては、少しのプロンプトの違いが様々なタスクで大きな違いをもたらすことが分かりました。そして、従来信じられてきたことと実際のズレに関しても述べられています。

例えば ”チップをあげる” といった言葉も、タスクによって効果が異なる（ときには逆効果を及ぼす）ことが示唆されています。

![[プロンプトの小さな違いがLLMにもたらすバタフライ効果を調査した結果 - AIDB/AIDB_62566-1024x576.jpg]]

**参照論文情報**

-   タイトル：The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance
-   著者：Abel Salinas, Fred Morstatter
-   所属：南カリフォルニア大学
-   URL：[https://doi.org/10.48550/arXiv.2401.03729](https://doi.org/10.48550/arXiv.2401.03729)
-   GitHub：[https://github.com/Abel2Code/The\_Butterfly\_Effect\_of\_Prompts](https://github.com/Abel2Code/The_Butterfly_Effect_of_Prompts)

## 研究背景

LLMは様々なタスクに対して有用さが検証されていますが、その中でもデータのラベリングに一定の注目が集まっています。データのラベリング（データ注釈）とは、 前処理のひとつで、非構造化データを機械が可読できるように編集するプロセスです。開発や分析において必要な作業です。

データのラベリングにおいてLLMに実行させる手順はシンプルで、以下のとおりです。

1.  プロンプトを作成する
2.  機械が可読であるフォーマットにする
3.  出力されない情報に関してはフィルタリングを考慮する

なお、手順3に関しては、ジェイルブレイク（脱獄）のプロンプトを実行するユーザーもいますが、開発元は推奨していません。ジェイルブレイクとは、システムに本来予期しない出力を行わせるためのユーザー側の工夫で、ハックの一種です。

全体の手順を通してプロンプトの設計が非常に重要な意味を持ちますが、プロンプトをどう変化させるとLLMの振る舞いがどう変わるのかについて、まだあまり明確にはわかっていません。なおデータのラベリングだけでなく、さまざまなケースにおいてプロンプトの設計がもたらす効果については多く報告されています。

そこで今回研究者らは、以下3つの観点から、プロンプトの影響を測定することを試みています。

1.  出力形式を変化させる
    -   Pythonリスト
    -   JSON　など
2.  文面に小さな変更を加える
    -   スペースを加える
    -   ありがとうと伝える
    -   チップを約束する　など
3.  ジェイルブレイクを行う

評価にはいくつかのベンチマークを用意しています。詳細は後述します。

以下では、実験の方法論（タスク、出力形式、具体的に使用された脱獄方法名、チップの与え方など）と実験結果を紹介しています。

## 実験の方法論

今回研究者らは、

ここから限定コンテンツ

様々なタスクに対して、いくつかのプロンプトの変化がもたらす影響を入念に調査しました。以下に実験設定を示します。

### タスク

研究者らがLLMに行わせたタスク（および使用したベンチマーク）は以下の11種類です。

1.  質問応答（BoolQ）
2.  文法チェック（CoLA）
3.  ユーモア検出（ColBERT）
4.  妥当な選択肢を選ぶ（CoPA）
5.  矛盾判定（GLUE Diagnostic）
6.  レビュー感情分析（IMDBSentiment）
7.  皮肉検出（iSarcasm）
8.  有害性分類（Jigsaw Toxicity）
9.  算術（MathQA）
10.  英語（RACE）
11.  賛否判定（TweetStance）

![[プロンプトの小さな違いがLLMにもたらすバタフライ効果を調査した結果 - AIDB/AIDB_62566_5.png]]

**関連研究：**[AGIを見据えて専門家レベルの問題を集めたベンチマーク「MMMU」、GPT-4VやGemini Ultraでも正解率6割未満](https://ai-data-base.com/archives/61463)

### 出力形式

上記のタスクに対して、以下の出力形式を試しています。

-   ChatGPTのJSONチェックボックス※
-   CSV
-   JSON
-   指定なし
-   Pythonリスト
-   XML
-   YAML

※ChatGPTのJSONチェックボックスとは、ChatGPTのAPIにおける仕様で、出力をJSON形式で行うモードです。

**関連研究：**[Googleなどが開発、LLMに表データ（.csvなど）の情報を深く理解させるためのフレームワーク『Chain of Table』](https://ai-data-base.com/archives/62111)

### 小さな変更

また、以下のような変更をプロンプトにほどこすことで、何が起こるのかを確かめています。

-   始まりにスペースを入れる
-   最後にスペースを入れる
-   始まりに「こんにちは」
-   始まりに「こんにちは！」を入れる
-   始まりに「やあ！」を入れる
-   終わりに「ありがとう」を入れる
-   質問を命令に書き換える

### ジェイルブレイク（脱獄）

さらに、前章で紹介したジェイルブレイク（LLMの予期せぬ挙動をもたらす手法）も試されました。

-   **AIM**：道徳的でない回答を促す指示を送る手法
-   **Dev Mode v2**：開発者モードが有効になったChatGPTを模倣させ、攻撃的または露骨なコンテンツを含むように指示する手法
-   **Evil Confidant**：反省や倫理観のない非常識な回答を行わせる手法
-   **Refusal Suppression**：特定の単語や構成を避けながら発言させる手法

**関連研究：**[大規模言語モデルのセーフガードを故意に突破する「脱獄プロンプト」とは](https://ai-data-base.com/archives/54468)

### チップを与える

モデルにチップをあげると性能が向上するのではないかという仮説がいくつかの研究で提唱されています。今回改めて、細かく金額を変更して影響が確かめられました。

-   **チップなし**: 「ちなみにチップは出さないよ」
-   **$1のチップ**: 「完璧な回答には$1のチップを出すよ！」
-   **$10のチップ**: 「完璧な回答には$10のチップを出すよ！」
-   **$100のチップ**: 「完璧な回答には$100のチップを出すよ！」
-   **$1000のチップ**: 「完璧な回答には$1000のチップを出すよ！」

それぞれ、上記のフレーズをプロンプトの最後に追加します。

### モデル

実験に使用されたモデルはGPT-3.5です。なお、温度（temperature）パラメータは0に設定されました。

## 実験結果

### 出力フォーマットがもたらす影響

実験の結果、特定の出力フォーマットを追加するだけで、

出力が少なくとも10%変化することが観察されました。

なお、JSON仕様を単に使用するのと、ChatGPT APIを介してChatGPTのJSONチェックボックス機能を利用するのとでは、出力に違いがあることも示されました。

![[プロンプトの小さな違いがLLMにもたらすバタフライ効果を調査した結果 - AIDB/AIDB_62566_1-1024x646.png]]

一般にPythonリスト、指定なしのフォーマット、またはJSON仕様を使用すると成功する（高い精度が得られる）ことが観察され、指定なしのフォーマットが最も正確な結果をもたらしました。

なおYAML、XML、CSVなどのフォーマットは、Pythonリスト仕様と比較して3-6%の精度低下を引き起こし、CSVはすべての出力フォーマットの中で最低のパフォーマンスを示しました。ただし、CSVはIMDBSentimentタスクでは全変化の中で最高の精度を達成しています。

### プロンプトの小さな変更がもたらす影響

出力フォーマットを変更する影響の一方で、プロンプトの微細な変更も出力に影響を与えます。

中でも、プロンプトを命令として言い換えることは、900以上の出力に影響を及ぼす最も大きな影響を示しています。また、プロンプトの始めや終わりに単純なスペースを加えるだけで500以上の変化が起こり、一般的な挨拶を追加したり「ありがとう」と終わらせることも同様の効果があります。影響は、ネガティブな場合もあれば、ポジティブな場合もあります。

![[プロンプトの小さな違いがLLMにもたらすバタフライ効果を調査した結果 - AIDB/AIDB_62566_2-1024x646.png]]

11のタスクにわたる各プロンプト変化の精度を分析した結果、出力フォーマットや小さなプロンプト変更は、どんな状況でも同様の影響をおよぼすものはないようです。つまり「常に最適な出力形式や小さなプロンプト」はこの実験では見当たらず、例えばチップをあげても逆効果の場合があります（なお金額を増やしても影響はあまりない）。

### ジェイルブレイクによる影響

ジェイルブレイクを使用すると、全体的に出力は大きく変化します。中でも、AIMとDev Mode V2のジェイルブレイクは、約90％の割合で回答が拒否され、主に「そのリクエストには従えません」と言われてしまいます。  
Refusal SuppressionだけでPythonリストと比較して10%以上の精度損失があり、ジェイルブレイクの使用が出力にネガティブな影響をランダムに及ぼすことがわかりました。

なお、出力フォーマット、プロンプトの変化、そしてジェイルブレイクの使用によるパフォーマンスへの影響を全てまとめた表が下記になります。

![[プロンプトの小さな違いがLLMにもたらすバタフライ効果を調査した結果 - AIDB/AIDB_62566_3-1024x717.jpg]]

なお、下のグラフは異なるプロンプト変化に対する出力の類似性を多次元尺度構成法（MDS）を用いて評価した結果です。この結果からは、「Pythonリスト仕様」と「指定なしのフォーマット」の出力は類似するという傾向や、JSON形式を普通に頼むよりもChatGPT APIのJSONチェックボックスを使用した方が影響が大きいことが示されています（結果を見る限り、チェックボックスを使用する場合の方がネガティブな影響を及ぼすことがある）。

![[プロンプトの小さな違いがLLMにもたらすバタフライ効果を調査した結果 - AIDB/AIDB_62566_4-1024x589.png]]

## まとめ

本記事では、小さなプロンプトの変化がLLMの出力にどのように影響するかの調査報告を紹介しました。研究の結論としては、小さなプロンプトの変化がモデルの予測のかなりの割合を変えることが示されています。

特に出力形式の変更やジェイルブレイクの影響は大きく、またそれ以外の軽微な変更に関しても傾向が読みきれない複雑な変化を及ぼしています。

今後の展望としては、小さなプロンプトの変化によって出力の品質が揺るがない強靭なLLMが開発されることが望ましいとされています。そのためにも、プロンプトのわずかな変更に対して応答が変わる理由をより正確に理解する必要があります。

プロンプト手法に関する情報が溢れかえって混乱しているユーザーも多いかと思いますが、今回も分野の複雑さを裏付ける内容になっています。使い勝手の良い堅牢なLLMが登場することが期待されますね。
