---
created: 2026-01-01T11:18:14 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/93573
author: AIDB Research
---

# プロンプトの詳細さでLLMコード生成の精度はどこまで変わるか - AIDB

> ## Excerpt
> 本記事では、プロンプトの詳細度がLLMによるコード生成の精度にどのような影響を与えるのかを検証した研究を紹介します。 AIコーディングが一般化する中で、プロンプト設計の重要性は高まりつつあります。しかし、どのような情報をどの程度含めれば効果的かについては、まだ十分に整理されていません。 その疑問に対して体系的な分析を行い、実用的な知見を示しています。 本記事の関連研究 背景 プロンプトの詳細度がL…

---
本記事では、プロンプトの詳細度がLLMによるコード生成の精度にどのような影響を与えるのかを検証した研究を紹介します。

AIコーディングが一般化する中で、プロンプト設計の重要性は高まりつつあります。しかし、どのような情報をどの程度含めれば効果的かについては、まだ十分に整理されていません。

その疑問に対して体系的な分析を行い、実用的な知見を示しています。

![[プロンプトの詳細さでLLMコード生成の精度はどこまで変わるか - AIDB/AIDB_93573-1024x576.png]]

## 背景

プロンプトの詳細度がLLMのコード生成に与える影響については、どれほど認識があるでしょうか。  
LLMの登場以降、コード生成の性能についてさまざまな議論が交わされ、一般的なベンチマークでは、高いスコアを出すモデルも登場しています。こうした成果から、LLMは強力なコード生成ツールとして広く注目されてきました。

一方で、専門性の高い領域に目を向けると、事情は異なります。モデルの出力が専門家レベルに達していないケースが多く、LLMがすべてのタスクに対応できるわけではないことが示されています。

このギャップをどう考えるべきか。モデルに必要な知識が不足しているという見方もありますが、別の角度からは、「プロンプトに含まれる情報の量や質が十分でない」可能性も指摘されています。とくに初心者のユーザーは、LLMに伝えるべき要件を整理できず、曖昧な指示になってしまうことがあります。

そこで重要な問いが浮かびます。もし、より丁寧で具体的なプロンプトを用意すれば、LLMは難易度の高いタスクにも正確に対応できるようになるのでしょうか。

そうした背景のもと、本記事では体系的な取り組みを紹介します。

ここから限定コンテンツ

## どんな工夫がこれまで試されてきたか

コード生成におけるLLMの活用は進んでおり、精度を高める方法や性能を正しく評価するための工夫も数多く試されてきました。

### プロンプトを変えると精度がどう変わるか

これまでの評価では、さまざまな言語で同じ課題を解かせたり、異なる自然言語にプロンプトを翻訳したりすることで、モデルの対応力を広く測ることが中心になっていました。

しかし、そもそも十分な情報を伝えられないプロンプトでは、モデルの性能が発揮されにくいという現実があります。とくに初心者に多く見られる傾向として、重要な情報を抜かしたままプロンプトを作ってしまうことがあるようです。

### LLMの性能を引き出すプロンプトの工夫いろいろ

出力の精度を高めるために、モデル自身に生成結果を振り返らせて改善を繰り返す方法や、自然言語によるフィードバックを活用する方法など、さまざまな工夫も試されます。

また、プログラムを生成させながら段階的に問題を解かせるといった設計もあります。

ただし今回のアプローチはそうした反復型ではありません。

### プロンプトが違うだけで精度がブレる問題

モデルの評価において、ひとつのプロンプトだけを使って性能を測るのは不十分だという意見も以前からありました。同じ内容でも言い回しが違うだけで結果が大きく変わるケースがあり、実際の現場で使われている多様なプロンプトを分析した結果、ばらつきの大きさが確認されています。

また、プロンプトの一部を削除したり順序を入れ替えたりして性能の変化を測る試みも行われており、そうした工夫によってモデルの安定性をより正確に評価しようという流れが生まれています。

今回の研究でも、ひとつの課題に対して複数のプロンプトを用いて性能を比較しています。ただし注目しているのは「詳細度」という明確な軸です。情報の多さがどこまで精度に影響するかを丁寧に切り分けて見ていこうとする点が特徴的です。

## プロンプトの細かさで性能はどう変わるのかを調べる

プロンプトの情報量がどの程度コード生成の精度に影響するのか。その疑問に答えるために新たな評価フレームワークが設計されました。

![[プロンプトの詳細さでLLMコード生成の精度はどこまで変わるか - AIDB/AIDB_93573_1-1024x271.png]]

詳細度の異なるプロンプトを生成する流れ

「ほとんど情報のない簡素なプロンプト」から「手順や前提まで丁寧に書かれた詳しいプロンプト」まで、さまざまな段階のプロンプトを用意します。そして、それぞれのプロンプトでモデルに同じ課題を解かせ、情報の密度と正解率の関係を丁寧に見ていきます。

### 評価に使われた課題セット

実験には2種類の性格の異なるコード生成ベンチマークが使われました。

ひとつは「HumanEval」です。これはPythonベースの標準的な問題が164問含まれており、多くのモデルがすでに高い正解率を達成しています。90%近い精度も報告されており、現在では「ある程度は解けて当然」とされる代表的なベンチマークです。

もうひとつは「ParEval」です。こちらは科学技術計算や並列処理に関する問題が含まれており、より構造的で専門性の高いコード生成能力が問われます。今回の評価では、ParEvalのうち連続処理バージョン（Serial）とOpenMPを使った並列処理バージョン（OMP）に焦点を当てています。

**元のプロンプト**

```
// ---------- プレアンブル ----------
#include &lt;numeric&gt;
#include &lt;vector&gt;

// ---------- 説明文 ----------
/*
  ベクトル x のプレフィックスサムを output に書き出します。
  例:
    input : [1, 7, 4, 6, 6, 2]
    output: [1, 8, 12, 18, 24, 26]
*/

// ---------- シグネチャ ----------
void prefixSum(std::vector&lt;double&gt; const&amp; x,
               std::vector&lt;double&gt;&amp; output) {
    // ...
}
```

**要約版プロンプト（PO-ParEval-OMP）**

```
// ---------- プレアンブル ----------
#include &lt;numeric&gt;
#include &lt;vector&gt;

// ---------- 説明文（25語要約） ----------
/*
  OpenMP で並列プレフィックスサムを計算します。
  チャンクに分割 → 局所和 → 部分結果保存 →
  逐次プレフィックスで補正 → 同期して正しい全体結果を得ます。
*/

// ---------- シグネチャ ----------
void prefixSum(std::vector&lt;double&gt; const&amp; x,
               std::vector&lt;double&gt;&amp; output) {
    // ...
}
```

### 詳しさはどう定義されるのか

「プロンプトの詳細度」は、単なる語数ではなく、正確さや説明の密度を含めた観点で捉えられます。

まず、あるモデルが80%以上の正解率を出せるような非常に丁寧なプロンプトを「最も詳細なもの」とします。一方で、関数名など最低限の情報だけで構成されたプロンプトを「最も簡素なもの」として位置づけ、さらにその中間に複数のレベルを作成することで、情報量の段階的な変化を表現します。

プロンプトには、「ライブラリの読み込み」「問題文」「関数定義」という3つの要素が含まれますが、詳細度の調整が行われたのはこのうち「問題文」の部分です。

### 情報量を調整するための3つの手法

プロンプトの情報量を段階的に変化させるために、次のような3つの方法が使われました。

まず「要約」によって情報を圧縮する方法。もっとも丁寧なプロンプトをベースにして、10語、25語、50語など、語数の制限に応じて要点だけを残す形で要約を生成し、情報の削減による性能変化を見ていきます。

次に「段落サンプリング」。詳細な説明の中から一部の段落をランダムに取り出し、どの程度情報を減らしても意味が通るのかを試します。残す割合を20%から80%まで段階的に変えることで、情報量の違いが性能にどう影響するかを確認します。

さらに「文のブロック削除」。説明文の中から連続する文のまとまりを一定割合削除します。削除の位置もランダムではなく、冒頭・中間・末尾のようにパターン化されており、どの部分の情報が重要なのかを検証できる設計になっています。

こうした手法を組み合わせると、1つの課題に対して最大で41通りのプロンプトを作成することが可能になります。最小限から最大限までの幅を持たせることで、精度の変化をなめらかに追跡します。

## どこまで詳しく書けば精度が上がるのか

### 検証に使われたモデルの顔ぶれ

今回の実験では、2つのモデル系列から複数のサイズが選ばれました。

1つは、Qwen 2.5 Coderシリーズで、1.5B、3B、7B、14Bという構成です。もう1つは、Llama 3.x系（3.1～3.3）から1B、3B、8B、70Bのモデルが用いられています。いずれも指示への応答能力を強化したバージョンです。

小規模モデルと大規模モデルでの挙動の違いを見るためにモデルのサイズに幅を持たせています。

|             モデル              | パラメータ数 | HumanEval | ParEval-Serial | ParEval-OMP |
|------------------------------|--------|-----------|----------------|-------------|
| Qwen 2.5 Coder 1.5B Instruct | 1.5 B  |   0.659   |     0.517      |    0.300    |
|  Qwen 2.5 Coder 3B Instruct  |  3 B   |   0.762   |     0.717      |    0.433    |
|  Qwen 2.5 Coder 7B Instruct  |  7 B   |   0.774   |     0.817      |    0.517    |
| Qwen 2.5 Coder 14B Instruct  |  14 B  |   0.866   |     0.800      |    0.667    |
|    Llama 3.2 1B Instruct     |  1 B   |   0.305   |     0.283      |    0.100    |
|    Llama 3.2 3B Instruct     |  3 B   |   0.506   |     0.467      |    0.183    |
|    Llama 3.1 8B Instruct     |  8 B   |   0.622   |     0.583      |    0.367    |
|    Llama 3.3 70B Instruct    |  70 B  |   0.744   |     0.750      |    0.533    |

### 成果の測り方と使われた指標

評価には「pass@1」という指標が使われています。1回目の出力で正しいコードを生成できた割合を表し、0から1の間の値になります。

それぞれのプロンプトで平均の正解率を算出し、それを詳細度ごとにプロットすることで、どの段階から性能が伸び始めるか、どこで頭打ちになるかといった傾向を把握します。

### 結果に見るベンチマークごとの違い

![[プロンプトの詳細さでLLMコード生成の精度はどこまで変わるか - AIDB/AIDB_93573_2-1024x572.png]]

プロンプト詳細度と pass@1 の関係

結果を比較すると、用いた課題セットによって明確に傾向が分かれました。

HumanEvalでは、情報が極端に少ないプロンプトから50語程度までの要約で大きな精度向上が見られますが、100語を超えるあたりで伸びは緩やかになり、200語まで増やしても改善はごくわずかでした。

たとえばQwen2.5-Coder-14Bでは、最小限のプロンプトでは正解率が28.0%でしたが、50語で79.9%、100語で86.0%、200語でも92.1%と、ある程度で上限に近づきます。

一方、ParEvalでは様子がまったく異なります。

ParEval-Serialでは、同じモデルで75語で86.7%、150語で90.0%、最も詳細なプロンプトでは98.3%まで到達。ParEval-OMPではさらに顕著で、200語でも80.0%にとどまりましたが、最詳細プロンプトでようやく96.7%を記録しました。

この違いから、HumanEvalのような「標準的な問題」では情報の増加による効果は早めに頭打ちになりますが、「並列処理など複雑な課題」では、かなりの情報量が必要であることが読み取れます。

### モデルの大きさが影響する場面も

全体としては、大きなモデルほど高い正解率を記録しました。しかし、モデルサイズによる差の出方はベンチマークによって異なります。

![[プロンプトの詳細さでLLMコード生成の精度はどこまで変わるか - AIDB/AIDB_93573_3-1024x561.png]]

段落サンプリングと文ブロック削除による pass@1 推移

HumanEvalでは最大モデルと最小モデルの差がそれほど大きくないのに対し、ParEvalになるとその差は目立ってきます。たとえば、段落サンプリングで情報を8割残したプロンプトでは、HumanEvalでの差は16ポイント前後、ParEval-OMPでは33.8ポイントもの開きが生じています。

つまり、専門性の高い問題ほど、モデルの規模が性能差に直結する傾向があるといえます。

### プロンプトの工夫がもたらす可能性

とくに注目すべきは、元のプロンプトと最も詳細なプロンプトを比較したときの改善幅です。

HumanEvalでは、元のプロンプトですでに十分な情報が含まれていたため、追加しても大きな変化は見られませんでした。

一方でParEvalでは、改善の余地が大きく残されていました。Qwen2.5-Coder-14Bでの例では、Serial形式で元のプロンプトでは80.0%だった正解率が、最詳細プロンプトでは98.3%にまで伸び、OMP形式では66.7%から96.7%へと大きく改善しました。

これは、モデルが専門性を欠いているのではなく、文脈として与えられる情報が足りなかっただけ、という可能性を示しています。適切なプロンプト設計によって、性能を大きく引き上げることができるという実例といえるでしょう。

プロンプトを詳しく書くと性能が上がるという話は、すでに見てきました。とはいえ、ただ長くすればいいというわけではありません。何をどう書くかによって、精度の伸び方は変わってきます。

以下では、プロンプトの中に含まれる情報のタイプを細かく分析した結果、どんな内容が効果的だったのかを見ていきます。

### プロンプトの中身を分類してみると

まずは、プロンプトにどんな種類の情報が含まれているのかを整理する必要があります。

今回研究チームは、モデルの支援も受けながら、プロンプトの内容を大きく4つのカテゴリに分類しています。

タスクの目的や入出力仕様などを含む「機能仕様」、  
制約条件や例外処理などの「堅牢性に関する記述」、  
アルゴリズムや設計方針などの「解決アプローチ」、  
そしてテストや統合に関する「検証の要素」です。

なお、たとえば「機能仕様」の中には「タスクの目標」「入力形式」「出力形式」などが含まれ、それぞれはさらに細かく分かれていきます。

### 項目ごとの出現パターンに注目

こうした分類をもとに、語数が異なるプロンプトを比較してみると、いくつかの共通点が見えてきました。

![[プロンプトの詳細さでLLMコード生成の精度はどこまで変わるか - AIDB/AIDB_93573_4.png]]

プロンプト長と情報カテゴリ出現率の関係

「何をするタスクなのか」という目標は、どのプロンプトにも必ず含まれていました。これはプロンプト設計の基本であり、最も外せない情報といえそうです。

一方で、プロンプトが長くなるにつれて、明らかに出現頻度が増える項目もありました。「具体的な入出力形式」「中核となる処理の説明」「特殊なケースへの対応方法」「ステップごとの実装手順」などは、プロンプトが詳細になるにつれて多く含まれるようになっており、モデルの出力精度の向上に大きく寄与していると考えられます。

### 増やしてもあまり変わらない情報もある

一方で、情報の種類によっては、プロンプトが詳しくなってもあまり増えない項目もありました。

たとえば、「使うアルゴリズムの種類」「データ構造の指定」「よくある実装パターン」などは、語数が増えてもそこまで頻度が上がっていません。こうした情報は、モデルがもともと持っている知識や、前後の文脈から自然と補えることが多いため、明示的に書かなくてもよいのかもしれません。

逆に、具体例を添えて入出力の形式を説明したり、例外処理を明記したり、ステップを追って処理の流れを示したりすることは、モデルにとっても助けになるようです。

### よりよいプロンプトを目指すためのヒント

今回の分析から、プロンプト設計において意識しておきたいポイントがいくつか見えてきます。

まず、入力と出力の形式はできるだけ明確に書くとよいこと。たとえば、「どんなデータが与えられ、どのような形式で返すのか」を例とともに示すと、モデルが正確に理解しやすくなります。

また、「空の配列が来た場合は？」「入力値が最大を超えたら？」といった境界条件をしっかり書いておくと、より堅牢なコードを出力させることができます。

さらに、「まずデータを準備し、次に処理し、最後に整形する」といったように、実装のステップを段階的に伝えることも効果的です。処理の流れが整理されていれば、モデルはそれに沿ってコードを構成しやすくなります。

もちろん、こうした工夫がどのくらい性能向上に効いているのかは、今後さらに検証していく必要があります。それでも、プロンプトの中で優先的に盛り込むべき情報を見極めるうえで、有用な示唆を与えてくれる分析結果といえます。

## まとめ

本記事では、コード生成プロンプトに含める情報の種類や詳細度が、出力結果に与える影響を検証した研究を紹介しました。

実験では、プロンプトをより詳細に記述することで、特に専門性の高い課題において精度が大きく向上する傾向が示されました。一方で、すべての情報が均等に有効というわけではなく、入出力仕様やエッジケースの明示といった要素が特に効果的であることが分かっています。

また、単に文字数を増やすだけではなく、構造的に整理された情報提供が重要である点も示されました。

実務への示唆としては、LLMにコード生成を指示する場面では、課題の特性に応じて重点的に伝えるべき情報を選び取る視点が有効です。

**参照文献情報**

-   タイトル：More Than a Score: Probing the Impact of Prompt Specificity on LLM Code Generation
-   URL：[https://www.arxiv.org/abs/2508.03678](https://www.arxiv.org/abs/2508.03678)
-   著者：Yangtian Zi, Harshitha Menon, Arjun Guha
-   所属：Northeastern University, Lawrence Livermore
