---
created: 2026-01-01T11:17:51 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/94515
author: AIDB Research
---

# プロンプト作成スキルを育てる研修設計の実践例 - AIDB

> ## Excerpt
> 本記事では、プロンプト作成スキルの習得を目的とした研修プログラムに関する研究を紹介します。 対話型LLMの活用が広がる中で、入力文の工夫が結果に大きく影響する場面が増えています。そうしたスキルをどう教えるか、どのように測るかという視点は、教育だけでなく実務にも関わるテーマです。 今回は、学生を対象に実施された検証結果をもとに、研修設計に活かせる知見を整理します。 本記事の関連研究 背景 ChatG…

---
本記事では、プロンプト作成スキルの習得を目的とした研修プログラムに関する研究を紹介します。

対話型LLMの活用が広がる中で、入力文の工夫が結果に大きく影響する場面が増えています。そうしたスキルをどう教えるか、どのように測るかという視点は、教育だけでなく実務にも関わるテーマです。

今回は、学生を対象に実施された検証結果をもとに、研修設計に活かせる知見を整理します。

![[プロンプト作成スキルを育てる研修設計の実践例 - AIDB/AIDB_94515-1024x576.png]]

## 背景

ChatGPTなどLLMとの対話型ツールは、教育や業務、情報整理の手段として多くの現場に入り始めています。効率的に情報を引き出したり、思考の整理に役立てたりと、使い方次第で生産性に大きく貢献する可能性があります。しかしその一方で、期待する結果が得られなかったり、内容をうまく評価できなかったりする場面も少なくありません。

理由の一つには、意図を正確に伝える力が求められることが挙げられます。入力する文の内容や構成が適切でないと、出力も目的に沿ったものになりにくく、業務上の応用もしにくくなります。そのためツールとやりとりする際の「問いの立て方」や「表現の工夫」は、実践的なスキルとして注目されています。

よって教育・研修での応用を意識した指導法や教材の整備は、依然として必要とされています。

そこで本記事では、対話型ツールの活用を前提とした実践的な学習プログラムを開発・検証した事例を取り上げます。実際の利用シーンを想定した問いの練習と、AIからの即時フィードバックを組み合わせた学習形式で、指示の出し方や情報整理の技術を段階的に習得できる構成です。学生を対象として検証されていますが、実務者向けにも応用可能です。

プロンプトの作り方を授業や研修で扱う際の観点を整理する参考になると思われます。

ここから限定コンテンツ

## 対話型LLMツールを使いこなすには何が必要か

対話型LLMツールの活用にあたっては、学び方や研修設計が重要になります。

### 実は「使い方」を学ぶ機会はあまりない

ツールを適切に使えるかどうかが、新たなスキル格差を生むといわれています。入力の工夫によって結果が大きく変わるLLMでは、目的に応じた使い方を身につけることがとても重要です。たとえば教育現場でも、入力文の書き方を教える教材が求められるようになっていますが、実際にはツールの仕組みや歴史の説明にとどまる授業も多く、活用方法まで踏み込んだ指導はまだ限られています。

### 「試してみる」と「すぐ返ってくる」が学びを深める

#### 手を動かすほうが、理解が進む

今回紹介する学習プログラムでは、学習科学の基本的な知見が活かされています。1つ目のポイントは、「実践を通じた学習」です。文章や動画を見るだけでなく、自分で入力して試してみることが理解の定着につながるという考え方です。ツールの使い方も同様で、説明を聞くより実際に使ってみることで使い方が身につきます。

#### フィードバックが早くて具体的だと、手応えがある

2つ目のポイントは、「即時かつ具体的なフィードバック」です。試してみた内容に対してすぐに反応が返ってくると、自分の取り組みを客観的に見直しやすくなります。もし反応が遅かったり抽象的すぎたりすると、何をどう直せばよいかがわからず、学びが進みにくくなります。

LLMの進化によって、記述式の解答を評価したり、個別にコメントを返したりする機能はすでに一定の性能を示しています。

LLMの使い方を知るためにもLLM技術を活用し、「試してみて」「すぐ反応が返ってくる」を実現するということです。ChatGPTの「あらゆる学びをサポート」という機能も、少し近いコンセプトかもしれません。

## 対話型LLMツールの研修設計

対話型ツールをテーマにした研修では、受講者が自ら試し、改善しながら学べるように全体の流れを設計します。

### 研修で扱うべき学習目標

取り扱うスキルは、次の三つに整理できます。

-   AIの得意な作業や使える領域を理解すること
-   どのような状況で活用するのが適切かを判断できること
-   利用目的に合った入力文を自分で組み立てられること

ツールの操作方法を伝えるだけでなく、判断力や表現力も含めた設計にすることが重要です。

### 学習ステップの設計

理想的には、Webベースの学習環境を想定し、次の流れで研修を構成します。この一連の流れを繰り返します。

#### 1\. 状況を理解する

受講者が取り組む場面や前提条件を明示します。たとえば目的、手元にある情報、達成したいゴールなどを提示します。

#### 2\. 入力文を考える

設定された場面に対して、受講者がツールに入力する文を自分で作成します。

#### 3\. 応答を確認する

AIが返した内容を読み取り、入力文との関係や表現の効果を確認します。

#### 4\. フィードバックを受ける

入力文が適切だったかどうかを評価し、改善点を具体的に把握できるようにします。

![[プロンプト作成スキルを育てる研修設計の実践例 - AIDB/AIDB_94515_1-1024x274.png]]

学習サイクルの画面遷移例（シナリオ提示から自動採点まで）

### 研修で使うシナリオの設計

学習内容に関連したリアルな場面設定を用意します。受講者の日常業務に近いテーマを扱うと、実用性が高まりやすくなります。

たとえば教育向けの事例では、教科をベースにして、学習の目的別に三つのパターンを用意します。知識を広げたい場面、理解を深めたい場面、困りごとを解決したい場面というように使い分けを行います。

研修で応用する場合は、たとえば業界情報を集めたいとき、提案書をまとめたいとき、調査資料の整理に迷っているときなど、実務との接点が感じられるように設計します。

|        採点項目        |           一般的定義           |
|--------------------|---------------------------|
|        関連性         |   問いが提示されたトピックに関連しているか    |
|       目的の明確さ       |     特定の明確な目的が示されているか      |
|        簡潔さ         |        入力文が簡潔であるか         |
|       背景・文脈        |  なぜその問いを立てたかの背景が示されているか   |
|      説明や拡張の要求      | 直接的解答を求める以外の説明や拡張を要求しているか |
| 直接的な解答を明示的に求めていないか |  解答そのものや値を直接求める表現をしていないか  |

### フィードバックの与え方

入力文の評価は、場面や目的に応じて評価基準を調整します。たとえば問題解決が目的の場合は、直接的な回答を求めない工夫が必要になることがあります。一方で知識を広げることが目的の場合は、制約を緩めても問題ありません。

フィードバックは、入力内容ごとに評価結果を示したうえで、その理由を説明します。受講者がどこを修正すればよいかが自然に理解できるように伝え方を工夫します。

## 検証結果から見えること

111名の中高生を対象とした検証では、自動評価の精度、受講者のスキル変化、学習体験の質といった観点から分析が行われました。研修設計に活かせる知見も得られています。

### 検証の進め方

検証は、情報技術の授業を活用して実施されました。  
冒頭でAIの利用経験や基礎知識に関する調査を行ったあと、実際に学習システムを使って練習を行い、最後に振り返りのアンケートに回答する流れです。

自動評価の限界については、開始前に説明されており、評価が必ず正しいとは限らないことを受講者に理解させたうえで実施されています。

### 自動評価は実用レベルだが調整も必要

自動評価の精度は高く、全体で92％の一致率が確認されました。とくに「関連性」「背景情報」「詳細要求」の項目では90％を超える高い精度を示しています。

|       指標        | 関連性  |  目的  | 簡潔さ  |  背景  | 説明・拡張 | 直接解答回避 |  全体  |
|-----------------|------|------|------|------|-------|--------|------|
|   合否判定の精度（合否）   | 0.98 | 0.85 | 0.93 | 0.96 | 0.90  |  0.88  |  －   |
| 説明の精度（詳細説明の一致度） | 0.98 | 0.87 | 0.96 | 0.95 | 0.72  |  0.91  | 0.95 |

一方で、「簡潔さ」「直接的な答えを避ける」「目的の明確さ」の3項目はやや精度が低く、判定のばらつきが見られました。  
たとえば「簡潔さ」では、背景情報を含めた入力文が冗長と判定されるケースがあり、「目的の明確さ」では曖昧な表現でも明確と誤認される傾向がありました。

このような傾向を踏まえると、評価基準の調整やシステムの補足説明を含めた設計が必要だとわかります。

### 演習を通じてスキルが高まる

繰り返しの練習によって、背景情報を含めて書く力が明らかに向上しています。初回では適切に書けた受講者が4％しかいなかったのに対し、3回目では大きく改善が見られました。

その他の項目（関連性、簡潔さ、目的の明確さ）では、初回から一定の水準が保たれており、練習による変化は小さめでした。

また、演習後には「AIを学習に活用できる」と感じる受講者が増え、自信の向上も確認されています。数値で見ると、自己評価は平均で10.4％上昇しており、統計的にも有意な変化です。

加えて、知識テストで高得点だった受講者が実践では苦戦する場面もありました。知識と活用スキルの間には差があることが示唆されます。

![[プロンプト作成スキルを育てる研修設計の実践例 - AIDB/AIDB_94515_3-1024x232.png]]

演習前後の自己評価の変化と問題の識別力・難易度

### 学習体験に対する受講者の反応

振り返りのアンケートでは、87％がAIに関する新しい学びがあったと回答しました。  
「背景や文脈を含めるとAIの回答が良くなる」「直接答えを求めるだけでは学びにならない」といったコメントが多く、研修の狙いに沿った理解が得られている様子がうかがえます。

質問の仕方によってAIの応答が変わることへの関心も高く、実際のやりとりを通じて興味を持った受講者も多く見られました。

また、学習環境そのものに対する評価もあり、「AIが問題作成までできると知って驚いた」「フィードバックが具体的で役に立った」という声が寄せられています。

### どこに難しさを感じたか

受講者が感じた難しさは、大きく二つに分かれます。

ひとつは、学びに必要な建設的な困難です。  
「うまく質問が書けない」「文脈をどう書けばよいかわからない」といった声は、まさに研修を通じて身につけるべきポイントを反映しています。教材の内容に即したコメントが多く、理解が深まったことを示す材料にもなっています。

もうひとつは、学習を妨げる余計な負荷です。  
「AIの応答が遅い」「タイピングが苦手で入力に時間がかかった」といった、技術的・環境的な要因が挙げられました。  
全体で22名が操作面に不安を抱えており、学習環境の整備も設計時の検討項目として重要であることがわかります。

### 多択式では測れない力がある

上記の検証では、多択式テストで高得点を出していたにもかかわらず、実際のプロンプト作成では成果が振るわない事例が多くありました。

このような「天井効果」が起こると、研修によるスキルの伸びを正しく測ることが難しくなります。多択式では、知識の有無は確認できても、実際の場面でどう使うかという力は見えにくくなります。

そこで新たな評価方法として、10問の正誤問題と5問の記述式問題を組み合わせた15問構成が採用されました。正誤問題は細かい理解度を測るのに有効で、記述式では受講者の思考力や表現力といった実践的なスキルを直接評価できます。

また、具体的な状況を扱う問題と、より抽象的な概念を問う問題が組み合されました。受講者の理解の深さと応用力の両方を測定するためです。

その結果、スキルの差を適切にあぶり出せる問題が増えました。

## 個別の研修に活かせるポイント

実践を通じた検証から、対話型LLMツールを研修の設計に役立つ知見が得られました。

### 練習とフィードバックは対で考える

受講者が自ら入力文を考え、LLMの応答とフィードバックを通じて改善していく形式が有効であることが示されました。

背景情報を含めた問いの設計については、こうしたサイクルを通じて確実な習得が見られました。一方で、「簡潔さ」や「詳細な指示」といった観点では、変化が限定的でした。習熟に時間がかかる要素は、繰り返し練習の機会を設けることで対応していく必要があります。

また、演習で使うシナリオは、受講者の関心を引く題材であることが重要です。実際に、提示されたシナリオが興味を高めたという声が多く見られましたが、一部からは「理科系に偏っていて興味が持てなかった」との指摘もありました。職種や背景に応じて、題材の幅を持たせる工夫が求められます。

### 自動評価は活用できるが、補完が必要

自動評価によって、即時かつ具体的なフィードバックを大規模に提供する仕組みが成立することが確認されました。評価項目の多くで高い精度が得られています。

ただし、「目的の明確さ」や「直接的な答えの回避」などの評価では、誤判定が一定数発生しています。たとえば、曖昧な表現を過剰に評価してしまう、意図と異なる判断を下してしまうといった傾向が見られました。実務で使用する際は、人間の確認を要する項目を明確にし、基準の調整やコメント補助を加えると精度を補えそうです。

### 評価手法は目的に合わせて調整する

研修の成果を測る際、多択式だけでは十分な評価が難しいことが確認されました。事前テストの得点が高かった受講者でも、実際の入力文作成では成果が出ない場面が見られました。理解と実践のあいだにギャップがある場合、評価手法を見直す必要があります。

正誤式や記述式を組み合わせることで、知識と応用力の両面をより正確に測れるようになります。記述式では、表現力や判断の根拠といった高次の認知スキルを評価できます。さらに、具体的な場面をもとにした問題と、抽象的な知識を問う問題の両方を含めると、理解の深さと幅を同時に確認できます。

![[プロンプト作成スキルを育てる研修設計の実践例 - AIDB/AIDB_94515_2-1024x555.png]]

評価問題の例（初期案と改訂案の比較）

### ポイントを一文ずつで整理

研修を実務向けに設計する場合でも、今回の検証で得られた知見は有効です。次のような考え方が設計時の参考になります。

-   入力の工夫を体感しながら学べる練習形式にする
-   実務でありがちな場面をもとにシナリオを構成する
-   自動評価と人の判断を組み合わせて現実的な負荷に抑える
-   知識確認とスキル評価の両面から効果を測定する

一度で完璧な設計を目指すのではなく、受講者の反応を見ながら改善を繰り返す設計が現実的です。

## まとめ

本記事では、対話型LLMツールの活用をテーマとした研修設計に関する研究を紹介しました。シナリオを使った実践練習と、AIによる即時フィードバックを組み合わせることで、文脈を踏まえた入力の工夫が身につきやすくなることが示されています。

自動評価システムは一定の精度で活用できるものの、評価基準の調整や人による補完が必要な場面もあります。また、スキルの評価には、多択式だけでなく、正誤式や記述式を取り入れることで、理解と応用の両面を把握しやすくなることも示唆されています。

こうした工夫は、教育現場に限らず、業務での研修やスキル育成にも柔軟に応用できそうです。

**参照文献情報**

-   タイトル：Learning to Use AI for Learning: How Can We Effectively Teach and Measure Prompting Literacy for K-12 Students?
-   URL：[https://doi.org/10.48550/arXiv.2508.13962](https://doi.org/10.48550/arXiv.2508.13962)
-   著者：Ruiwei Xiao, Xinying Hou, Ying-Jui Tseng, Hsuan Nieu, Guanze Liao, John Stamper, Kenneth R. Koedinger
-   所属：Carnegie Mellon University, University of Michigan, Taiwan National Tsing Hua University
