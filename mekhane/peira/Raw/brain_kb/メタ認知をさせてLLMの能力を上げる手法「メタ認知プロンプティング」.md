---
created: 2026-01-01T09:30:38 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/54435
author: AIDB Research
---

# メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」 - AIDB

> ## Excerpt
> この記事では、大規模言語モデル（LLM）の理解を向上させるための新しい手法、メタ認知プロンプティング（Metacognitive Prompting）について紹介します。この研究がどのようにしてLLMの理解を深めるのかについて詳しくみていきます。 参照論文情報 関連研究 大規模言語モデルの現状 大規模言語モデル（LLM）は、特定のクエリや文に対して正確な出力を生成するために設計されています。また、…

---
この記事では、大規模言語モデル（LLM）の理解を向上させるための新しい手法、メタ認知プロンプティング（Metacognitive Prompting）について紹介します。この研究がどのようにしてLLMの理解を深めるのかについて詳しくみていきます。

**参照論文情報**

-   タイトル：Metacognitive Prompting Improves Understanding in Large Language Models
-   著者：Yuqing Wang, Yun Zhao
-   所属：カリフォルニア大学サンタバーバラ校、Meta Platforms, Inc.
-   URL：[https://doi.org/10.48550/arXiv.2308.05342](https://doi.org/10.48550/arXiv.2308.05342)
-   GitHub：[https://github.com/EternityYW/Metacognitive-Prompting](https://github.com/EternityYW/Metacognitive-Prompting)

![[メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」 - AIDB/AIDB_54435_1-1024x576.jpg]]

**関連研究**

-   [Metaの研究者ら「GPT-4をきびしくサポートする」AIのShepherd（シェパード）開発](https://ai-data-base.com/archives/54440)
-   [大規模言語モデルへのプロンプト、重要な情報はどこに書く？](https://ai-data-base.com/archives/53522)
-   [ChatGPTの”ふるまいの変化”を定量的に分析した結果](https://ai-data-base.com/archives/53638)

## 大規模言語モデルの現状

大規模言語モデル（LLM）は、特定のクエリや文に対して正確な出力を生成するために設計されています。また、現在の研究は主にLLMの推理能力の向上に焦点を当てており、多段階の推理や自己整合性の技術などが開発されています。

しかし、ユーザー側のプロンプティングの工夫によりパフォーマンスを高めることも可能です。そこで一役買うと期待されているのがメタ認知です。

メタ認知は、複雑な問題解決や意思決定における鍵となる要素であり、抽象的な概念を分解し、シナリオを批判的に評価し、推理を微調整する能力の基盤となっています。この高次認知プロセスは、人間が「思考についての思考」を行う能力を反映しています。

今回紹介する研究の主要な目標は、言語モデルに人間の「思考についての思考」を模倣するメタ認知プロセスを導入することです。このプロセスは、人間の認知の段階を反映した連続した認知のステージから構成されます。

![[メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」 - AIDB/AIDB_54435_3.png]]

人間のメタ認知に倣ってLLMのメタ認知プロンプティングは構成されている

## そもそもメタ認知とは何か

メタ認知は、自分の思考プロセスとそれらの背後にあるパターンへの認識を指します。この用語は、ギリシャ語の「meta」（超える、または上に）から来ており、問題解決の特定の戦略をいつ、どのように使用するかを知り、反映する形態を取る能力を意味します。

### メタ認知の種類

-   **メタ認知的知識**: 自分自身と他人としての認知プロセッサーについての知識。
-   **メタ認知的調整**: 認知と学習経験を制御する一連の活動を通じて、自分の学習をコントロールする。
-   **メタ認知的経験**: 現在進行中の認知的努力と何か関係がある経験。

### メタ認知の重要性

メタ認知は、思考、学習、倫理的/道徳的規則の適切な評価の最大化に役立つ能力を規制するために使用される高次認知です。また、応答時間の短縮や問題やタスクの完了時間の削減にもつながる可能性があります。

メタ認知の研究は、自己に関連するものだけでなく、他人の精神的プロセスについての信念、文化的影響、自己に対する信念など、より広い視野をもって行われています。

## メタ認知プロンプティングの導入

今回Metaなどの研究者らが開発したメタ認知プロンプティング（MP）は、LLMのタスク処理を強化し、応答における文脈認識と内省を向上させるための構造化されたアプローチです。MPは、人間の認知プロセスを模倣する段階を通じて、モデルをより深い内省に促します。

MPは5つの異なる段階からなり、入力テキストの理解から始まり、人間の認知プロセスを模倣します。またMPは、標準的なプロンプティングとCoTプロンプティングとは異なるガイドラインと目的を持ちます。

### メタ認知プロンプティングの5つの段階

ここから限定コンテンツ

1.  **入力テキストの理解**
    -   **目的**: 与えられたテキストの内容を正確に把握する。
    -   **機能**: モデルはテキストの意味を解釈し、その背後にあるコンテキストやニュアンスを理解します。この段階は、後続の分析の基盤となります。
    -   **プロンプト例**：「〇〇を理解してください」
2.  **暫定的な判断の形成**
    -   **目的**: 初期の判断や分析を形成する。
    -   **機能**: モデルはテキストに基づいて最初の考えや感情を特定し、それを評価します。この段階は、問題解決の方向性を提供します。
    -   プロンプト例：「〇〇の理解に基づき、△△を行ってください」
3.  **暫定分析の批判的評価**
    -   **目的**: 初期の分析を批判的に評価し、必要に応じて再評価する。
    -   **機能**: モデルは初期の分析を検討し、その正確さや妥当性を評価します。必要に応じて、分析を修正または改善するためのステップを検討します。
    -   **プロンプト例**：「その△△を批判的に評価し、再評価する必要があると感じますか？」
4.  **最終決定と推理の説明**
    -   **目的**: 最終的な決定を下し、その推理を明確にする。
    -   **機能**: モデルは最終的な判断を確認し、その背後にあるロジックや推理を説明します。この段階は、分析の透明性と理解を促進します。
    -   **プロンプト例**：「△△をそのように実行or作成した理由は何ですか？」
5.  **全体のプロセスに対する信頼度の評価**
    -   **目的**: 分析プロセス全体に対する信頼度を評価する。
    -   **機能**: モデルは全体の分析プロセスに対する信頼度を評価し、その信頼度レベルに対する説明を提供します。この段階は、分析の信頼性と自信のレベルを明確にし、その結果の解釈を助けます。
    -   **プロンプト例**：「その△△に対する信頼度を評価し、その理由を説明してください。どれくらい自信を持っていますか？」

![[メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」 - AIDB/AIDB_54435_4.png]]

メタ認知プロンプティングの各段階のついての説明図（論文より引用）

## メタ認知プロンプティングのシミュレーション

### 例１：感情の推定

以下の例では、宮沢賢治の「春と修羅」を引用し、感情を推定させています。

ユーザー：**まず、以下のテキストを理解してください。** 「わたくしといふ現象は 仮定された有機交流電燈の ひとつの青い照明です （あらゆる透明な幽霊の複合体） 風景やみんなといつしよに せはしくせはしく明滅しながら いかにもたしかにともりつづける 因果交流電燈の ひとつの青い照明です （ひかりはたもち　その電燈は失はれ） これらは二十二箇月の 過去とかんずる方角から 紙と鉱質インクをつらね （すべてわたくしと明滅し 　みんなが同時に感ずるもの） ここまでたもちつゞけられた かげとひかりのひとくさりづつ そのとほりの心象スケッチです」

LLM：このテキストは詩的で象徴的な表現が豊富に使われているように見受けられます。自己を「有機交流電燈のひとつの青い照明」と表現し、明滅する光としての存在を描写しています。また、過去の記憶や心象スケッチといった抽象的な概念も織り交ぜられています。

ユーザー：**このテキストの暫定的な感情を特定してください。**

LLM：このテキストの暫定的な感情は、中立からやや抽象的、哲学的なものであると感じます。感情的な強烈さや明確な喜び、悲しみなどの感情は特定できず、むしろ自己の存在や認識に対する内省的な観察が中心となっているようです。青い照明の明滅、心象スケッチ、過去の方角などのイメージは、感情よりもむしろ存在の本質や認識のプロセスに対する探求を象徴している可能性があります。

ユーザー：**その分析を批判的に評価し、再評価する必要があると感じますか？**

LLM：この初期の分析に対して批判的に評価し、再評価する必要があるかどうかを考えると、テキストの抽象的な性質と詩的な表現が中心であるため、感情の特定は一義的ではない可能性があります。しかし、この段階での分析は、テキストの主要なテーマ性と象徴を捉えていると感じます。再評価の必要性は特に高くないと考えますが、テキストの背景や作者の意図に基づくさらなる解釈も考えられるでしょう。

ユーザー：**文の感情をそのように判断した理由は何ですか？**

LLM：文の感情を中立からやや抽象的、哲学的なものと判断した理由は以下の通りです。〜〜

ユーザー：**その分析に対する信頼度を評価し、その理由を説明してください。どれくらい自信を持っていますか？**

LLM：この分析に対する信頼度を評価すると、私はこの分析に約80%の自信を持っています。以下、その理由を説明します。〜〜

このような要因を考慮して、分析の信頼度を80%と評価しています。

### 例2：記事の要約

以下の例では、AIDBの記事「[大規模言語モデルに16,000以上のAPIを理解し適切に操作する能力を与える「ToolLLM」](https://ai-data-base.com/archives/54120)」を読んで、記事の要約を行わせています。

ユーザー：**まず、以下の記事を理解してください。**https://ai-data-base.com/archives/54120

LLM：記事の内容を理解しました。この記事は、大規模言語モデルが実世界のAPIを理解し、適切に操作する能力を向上させるためのフレームワーク「ToolLLM」について詳しく説明しています。ToolLLMは、16,000以上のAPIを理解し、それらを適切に操作することができるとされています。具体的には、APIのドキュメンテーションを自然言語処理によって理解し、それを基にAPIを操作することが可能です。このフレームワークは、ToolBench、ToolLLaMA、およびToolLLMという三つの主要なコンポーネントから構成され、それぞれ異なる役割を果たしています。検証の結果、ToolLLMは高い精度でAPIを操作することができ、大規模言語モデルがAPIを理解し、操作する能力を大幅に向上させることができることが示されています。

ユーザー：**この記事の暫定的な要約を作成してください。**

LLM：この記事は、大規模言語モデルのAPI操作能力を向上させるための新しいフレームワーク「ToolLLM」について紹介しています。ToolLLMは、16,000以上のAPIを理解し、操作することができるとされており、APIのドキュメンテーションを自然言語処理で解釈することが可能です。このフレームワークは、ToolBench、ToolLLaMA、ToolLLMの三つのコンポーネントから成り立っており、それぞれ異なる機能を果たしています。検証結果により、ToolLLMはAPIの操作において高い精度を示し、大規模言語モデルのAPI理解と操作能力を大幅に向上させることができると報告されています。

ユーザー：**作成した要約を批判的に評価し、再評価する必要があると感じますか？**

LLM：はい、批判的に評価し、再評価する必要があると感じます。要約には、ToolLLMの具体的な機能や、それがどのようにAPI操作能力を向上させるのか、その具体的な応用例など、記事の主要なポイントがいくつか欠けている可能性があります。この段階では、要約が記事の全体的な内容を適切に反映しているかどうかを検討するために、より詳細な分析が必要であると考えられます。

ユーザー：**記事の要約をそのように作成した理由はなんですか？**

LLM：記事の要約をそのように作成した理由は、記事の主要なテーマ性と新しいフレームワーク「ToolLLM」の概要を簡潔に伝えようとしたためです。記事の中心的な内容であるToolLLMの概要、構成要素、およびその効果に焦点を当て、読者に対して最も重要な情報を提供しようとしました。

しかし、このアプローチにより、ToolLLMの具体的な機能や応用例、技術的な詳細など、記事の他の重要な側面が欠落してしまった可能性があります。このため、要約が完全にバランスが取れているとは言えないかもしれません。

ユーザー：**作成したその要約に対する信頼度を評価し、その理由を説明してください。どれくらい自信を持っていますか？**

その要約に対する信頼度を評価すると、私は約70%の自信を持っています。

理由は以下の通りです：

-   **正確性**: 要約は記事の主要なテーマ性とToolLLMの概要を正確に捉えています。この部分に関しては高い自信を持っています。
-   **完全性**: しかし、要約はToolLLMの具体的な機能や応用例、技術的な詳細など、記事の他の重要な側面を欠落している可能性があります。この部分に関しては自信が低いです。

この結果、要約は記事の主要な内容を反映していると言えますが、より詳細な分析と調整が必要であると感じています。全体的な信頼度は高くはないため、最終的な要約として使用する前に、さらなる検討と改善が必要であると考えます。

### さまざまな分野で応用可能なテクニック

メタ認知プロンプティングは、LLMが単にタスクを実行するだけでなく、そのプロセスと結果に対する深い理解と評価を促進するための手法です。様々なコンテキストと課題に対して適用可能な柔軟性を持っています。

情報の理解、分析、評価、改善のプロセスを強化するフレームワークであるため、感情分析だけでなく、多岐にわたる分野での応用が可能な強力なテクニックです。

## 発展的な話

![[メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」 - AIDB/AIDB_54435_5.png]]

5つのモデルにおける、ゼロショット、5ショット、メタ認知プロンプティングの性能比較

### 自信の度合いが100%ではない場合、その理由をもとに、再度タスクを行う

メタ認知プロンプティングのプロセスは、理解、分析、評価の段階から成り立っています。しかし、このプロセスは必ずしも一回限りのものではありません。特に、分析の結果に対する自信が100%に達しない場合、その理由を深く探求し、再度タスクを行うことで完成度を高めることもできます。

なお、この段階に関しては論文には明示されていません。編集部が独自に工夫を説明するセクションとなります。

### なぜこのプロセスが有用なのか？

この反復プロセスは、結果の精度を高め、理解を深化するために不可欠です。自信が100%に達しない理由を明確にすることで、分析の欠点や誤解を特定し、それを改善するための具体的な方向性を提供します。

### どのように実施するのか？

1\. 分析の結果に対する自信を評価する: まず、現在の分析結果に対する自信の度合いを評価します。

2\. 自信が不足している理由を特定する: 自信が100%に達していない場合、その理由を明確に特定します。

3\. 分析を再評価し改善する: 自信の不足している理由をもとに、分析を再評価し、必要に応じて改善します。

4\. 再度自信を評価する: 改善された分析に対して再度自信を評価し、必要に応じてこのプロセスを繰り返します。

このプロセスは、メタ認知プロンプティングの効果を最大化し、より正確で信頼性の高い結果を得るための鍵となるでしょう。

## まとめ

メタ認知プロンプティングは、大規模言語モデルの理解を深めるための新しい戦略であり、人間のメタ認知プロセスに基づいています。この研究は、LLMの理解能力を向上させ、信頼性を高めるための重要な一歩であると言えるでしょう。

![[メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」 - AIDB/AIDB_54435_6.png]]

おまけ：メタ認知プロンプティングにおける2種類のよくあるエラー
