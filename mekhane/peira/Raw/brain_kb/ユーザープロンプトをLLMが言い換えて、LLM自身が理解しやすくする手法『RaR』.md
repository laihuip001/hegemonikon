---
created: 2026-01-01T09:29:12 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/51160
author: AIDB Research
---

# ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB

> ## Excerpt
> 本記事では、大規模言語モデル（LLM）に対するユーザーの質問・指示に対する応答の質を向上させる新しい手法「RaR（Rephrase and Respond）」について、論文をもとに紹介します。本研究はカリフォルニア大学ロサンゼルス校（UCLA）の研究者によって発表されています。 「RaR」は、LLMがユーザーの質問を自身が理解しやすい形に自ら言い換える手法で、GPTシリーズ（GPT-4、GPT-3…

---
本記事では、大規模言語モデル（LLM）に対するユーザーの質問・指示に対する応答の質を向上させる新しい手法「RaR（Rephrase and Respond）」について、論文をもとに紹介します。本研究はカリフォルニア大学ロサンゼルス校（UCLA）の研究者によって発表されています。

「RaR」は、LLMがユーザーの質問を自身が理解しやすい形に自ら言い換える手法で、GPTシリーズ（GPT-4、GPT-3.5）など複数のLLMで効果が確認されています。  
RaRの実行プロンプトは比較的シンプルであり、LLMに質問の言い換えと回答を一度に行わせることが可能です。

以下ではRaRの研究背景、理論、実行プロンプト例、実験の内容と結果、デモンストレーションなどを掲載します。

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160-1024x576.jpg]]

**参照論文情報**

・タイトル：Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves  
・著者：Yihe Deng, Weitong Zhang, Zixiang Chen, Quanquan Gu  
・所属：University of California, Los Angeles  
・URL：[https://doi.org/10.48550/arXiv.2311.04205](https://doi.org/10.48550/arXiv.2311.04205)  
・GitHub：[https://github.com/uclaml/Rephrase-and-Respond](https://github.com/uclaml/Rephrase-and-Respond)

## 背景

### 人間とLLMの「思考フレームの違い」

人間と大規模言語モデル（LLM）には、思考のフレーム（枠組み）に顕著な違いが存在します。思考の違いは、人間指示に基づくLLMのパフォーマンスに大きな影響を与えることがあります。例えば人間が明確だと感じる質問でも、LLMは異なる解釈をして、誤った応答をすることがあります。

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_1-1024x404.png]]

LLMにとって質問に含まれる曖昧さを示す例

人間の言葉や表現は、しばしば主観的な経験や文脈に依存しており、人間同士であっても異なる解釈がされることがあります。LLMも人間と同様に、特定の思考フレームに基づいて入力された情報を解釈します。ただしLLMの「思考フレーム」の構造や特徴は人間とは異なるため、誤解や誤った応答につながると考えられています。

### 誤解の解消

この誤解を解消するためには、LLMが人間からの質問を自分自身のフレームに合わせて言い換え、追加の詳細を組み込むことが効果的です。LLM自身による言い換えプロセスを通じて、質問はLLMにとってより明確な形に変換され、元の質問に内在する曖昧さが解消されます。LLM自身が言い換えを行うことでパフォーマンスが上がることは、これまでの研究でも示唆されてきました。

**本記事の関連研究：**[「自分を信じて限界を超えてください」など感情をグッと込めた指示プロンプトが添えられると、ChatGPTなどのLLMのパフォーマンスは向上する](https://ai-data-base.com/archives/58158)

### RaRメソッドの概要

今回カリフォルニア大学の研究者たちは、LLMに対して、人間の質問を自分で言い換えて応答させるためのプロンプト指示「RaR（Rephrase and Respond）」という新しい方法を提案しています。RaRは、パフォーマンスを改善するためのシンプルで効果的なプロンプト方法です。LLMが人間からの指示を言い換えて拡張を行い、単一のプロンプトで応答を提供します。

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_2-1024x310.png]]

元の質問とGPT-4を使用して自己言い換えされた質問の比較

### RaRの主なポイント

**「質問の意図」の明確化**

質問の意図をより明確にすることにより、より正確な応答を促します。質問の意味の明瞭さが向上すると、LLMによる解釈の精度が高まります。

**One-stepとTwo-stepのオプション**

RaRには、「One-step RaR」と「Two-step RaR」という2つのバリエーションがあります。One-step RaRは、単一のプロンプトを使用して言い換えた質問と回答を同時に生成します。一方、Two-step RaRは最初に質問を言い換え、その後で元の質問と言い換えた質問を組み合わせて応答します。のちほど詳細を紹介します。

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_3-1024x263.png]]

One-step RaRの例

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_4-1024x268.png]]

Two-step RaRの例

**教師なしでトレーニング不要**

RaRは教師なしでトレーニングが不要な手法であり、すべての質問に適用可能です。経済的であり、幅広い用途に利用できます。

**本記事の関連研究：**[GPT-4などLLMのコード生成能力にデバッグ機能を追加する『SELF-DEBUGGING（セルフデバッギング）』と実行プロンプト](https://ai-data-base.com/archives/57709)

## 実行プロンプト

### RaRのプロンプト形式

RaR（Rephrase and Respond）メソッドは、LLMが与えられた質問を再構築し、単一のプロンプトで応答するよう促します。例えば、特定の質問や指示に対して次のようなプロンプトを追加します。

ここから限定コンテンツ

```
「上記の質問を、より良く答えるために言い換えて拡張してください。元の質問の情報を全て維持してください。」
```

```
「言い換えた質問に対するあなたの答えを使って、元の質問に答えてください。」
```

上記の例はTwo-step RaRのプロンプトを日本語で具体化したものです。

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_10-1024x184.png]]

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_11-1024x164.png]]

**本記事の関連研究：**[LLMに非線形的な思考を与えてCoTを上回る性能を引き出す手法『IEP』と実行プロンプト　CoTと組合せでさらに強力になる場合も](https://ai-data-base.com/archives/57628)

## 実験の内容と結果

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_5-1024x361.png]]

実験で検討された全てのタスクの詳細

### 実験手法

RaR（Rephrase and Respond）メソッドの評価実験では、知識分類タスクや常識理解タスクなど、さまざまなベンチマークが使用されました。RaRの二つのバリエーション、One-step RaRとTwo-step RaRの両方が検証されました。

### GPT-4におけるパフォーマンス向上

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_6-1024x403.png]]

GPT-4を使用した異なるプロンプトの精度比較

GPT-4を使用した実験では、Two-step RaRがGPT-4のパフォーマンスを有意に向上させることが確認されました。特に、GPT-4が元々困難と見なしていたタスク（例えば、単語の最後の文字を結合するタスク）などにおいて、Two-step RaRはほぼ100％の精度まで改善を示しました。RaRが質問の質を自動的に向上させるユニバーサルな手法であることが示唆されました。

### 他のLLMモデルでの性能向上

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_7-1024x325.png]]

Two-step RaRを使用したオリジナルと自己言い換えされた質問でのGPT-4-0613、GPT-3.5-turbo-0613、Vicuna-13bの精度

実験結果は、GPT-4だけでなく、GPT-3.5やVicunaなど他のLLMモデルにおいても、両方のRaRアプローチの有効性を示しています。

また、Two-step RaRはより能力の高いLLMから生成された言い換えた質問を、能力の低いモデルに移すことで、曖昧さを明確にするのに役立ちます。つまり、GPT-4にRaRを使用して得られた「言い換え済みプロンプト文」をGPT-3.5で使用するといったテクニックは有効とのことです。

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_9-1024x130.png]]

異なるLLMモデルによって生成された自己言い換えされた質問の例

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_8-1024x628.png]]

GPT-4によって言い換えられた質問とVicunaによって言い換えされた質問を比較

また、RaRはCoT（Chain-of-Thought）メソッドと補完的であり、組み合わせて強化することができます。RaRがLLMの質問応答性能を向上させるための汎用的な方法のようです。

**本記事の関連研究：**[LLMにまず前提から尋ることで出力精度を向上させる『ステップバック・プロンプティング』と実行プロンプト](https://ai-data-base.com/archives/56671)

## デモ

例として、「Was Barack Obama born in an even day?」（バラク・オバマは偶数日に生まれましたか？）という質問に対して、RaRメソッドを使用します。One step版である「Rephrase and expand the question and respond.」（質問を言い換えて拡張し、応答してください。）という指示を与えて実施すると以下のようになります。

```
言い換えた質問（x′）: 「What is the birth year of Barack Obama and is it an even number?」（バラク・オバマの生年は何年で、それは偶数ですか？）
回答（y）: 「No」（いいえ）
```

上記はRaRが質問の言い換えを行い、それに基づいて回答する方法の一例を示しています。

RaRは、CoTにおける多数の中間ステップを生成するのとは対照的に、効率的に改善された質問を生み出す手法です。トークンの使用量を節約できるためコストパフォーマンスを上げる効果もあります。

![[ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』 - AIDB/AIDB_51160_13-1024x337.png]]

RaRとCoTメソッドの数学的な定式化

**本記事の関連研究：**[ChatGPTの効果的なプロンプト手法における「基本のキ」を理論とテンプレート両方で紹介](https://ai-data-base.com/archives/58361)[](https://t.co/QceaTHYg3C)

## まとめ

この記事では、新しいRaR（Rephrase and Respond）メソッドについて紹介しました。この方法は、大規模言語モデル（LLM）が人間の質問を自身が理解しやすい形に言い換える手法です。質問の意図を明確にし、意味の明瞭さを向上させることに重点を置いています。

実験では、GPTシリーズを含む様々なモデルでのパフォーマンスを有意に向上させることが示されています。RaRには、One-step RaRとTwo-step RaRの2つのバリエーションがあり、どちらも教師なしでトレーニング不要であり、すべての質問に適用可能です。

知識分類タスクや常識理解タスクなど、様々なベンチマークを使用し、GPT-4、GPT-3.5、Vicunaなどの複数のLLMモデルでのパフォーマンス向上が確認されました。
