---
created: 2026-01-01T09:37:58 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/61555
author: AIDB Research
---

# 人間のカリキュラム教育のような学習でLLMの性能は向上するとの報告 - AIDB

> ## Excerpt
> ペンシルベニア大学やNAVERの研究者らは、人間の教材にインスパイアされたカリキュラム学習によるチューニング手法によってLLMを賢くする手法を検証しています。 問題や難易度や認知負荷レベルを徐々に高めるような学習の仕方を用いると、従来のチューニング手法よりもLLMの性能が上がるとのことです。 本記事では背景、手法のポイント、実験と結果、そして展望と注意点について紹介します。 参照論文情報 なお上記…

---
ペンシルベニア大学やNAVERの研究者らは、人間の教材にインスパイアされたカリキュラム学習によるチューニング手法によってLLMを賢くする手法を検証しています。

問題や難易度や認知負荷レベルを徐々に高めるような学習の仕方を用いると、従来のチューニング手法よりもLLMの性能が上がるとのことです。

本記事では背景、手法のポイント、実験と結果、そして展望と注意点について紹介します。

![[人間のカリキュラム教育のような学習でLLMの性能は向上するとの報告 - AIDB/AIDB_61555-1024x576.jpg]]

**参照論文情報**

-   タイトル：Instruction Tuning with Human Curriculum
-   著者：Bruce W. Lee, Hyunsoo Cho, Kang Min Yoo
-   所属：ペンシルベニア大学, ソウル国立大学, NAVER Cloud
-   URL：[https://doi.org/10.48550/arXiv.2310.09518](https://doi.org/10.48550/arXiv.2310.09518)

なお上記論文公開のあとに、関連研究が別のグループから発表されました（下記）。下記はファインチューニングフェーズではなくコンテキスト内学習の工夫（プロンプトエンジニアリング）　において人間のカリキュラム学習を模倣することの有効性を明らかにしています。

Jacob Russin et al., “Human Curriculum Effects Emerge with In-Context Learning in Neural Networks”, 2024/2/13, [https://arxiv.org/abs/2402.08674](https://arxiv.org/abs/2402.08674)

**本記事の関連研究**：

-   [わずか2行のプロンプトでも実効性のある新しいアライメント手法『URIAL』](https://ai-data-base.com/archives/60678)
-   [ハーバード研究者などがLLMを創造的にすべく考案した、大喜利データセットでユーモアラスにチューニングする手法『LCoT』](https://ai-data-base.com/archives/60765)
-   [LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』](https://ai-data-base.com/archives/57018)

## 研究に至る背景

GPT-4のような優れたモデルは、用途の広さでも大きな注目を集めています。人間の指示に基づいて正確に動く能力も高く、開発時のチューニング手法（人間のフィードバックによる強化学習）が功を奏しているとも言われています。

しかし世の中のニーズとしては、モデルがさまざまなタスクをもっと上手くこなせるようになることが望まれています。そこで研究が進む中、指示の質や形式が全体の性能に影響することがわかってきました。また、段階的な説明を加えることでモデルの理解力が向上することもわかっています。しかし、データの管理やトレーニング方法については、まだ改善の余地があると考えられています。

一部では、人間の学び方に似せた方法でモデルを訓練することで、もっと効果的な学習ができるかもしれないという考えが提案されています。特定のタスクにおいては効果があることは検証が進んでおり、今後はもっと広い範囲での実験も期待されています。

そして今回研究者たちは、人間のカリキュラム学習に似せた方法でLLMを訓練するための「CORGI」というデータセットを作成しました。学校や大学で教えられる内容を基にして作られており、学習の段階に応じた構造になっています。

## 手法のポイント

研究者らは、人間の教育プロセスからヒントを得たデータセットの作り方と、効果的なトレーニング方法を開発しました。

### カリキュラム学習用データセットの構築

まず、

ここから限定コンテンツ

今回のデータセットの作成方針は、カリキュラムを通じて習得すべき知識を網羅すること、そしてそれぞれのデータに順序を持たせることです。

広範な知識データセットを一から作るのは大変な作業なので、ChatGPTのような言語モデルを利用して、合成データを自動的に生成する方法も採用しています。  
さらに、実際の教育カリキュラム（例えば、大学のカタログやケンブリッジIGCSEカリキュラムなど）も、合成データセットの基礎として使います。

データセットの作成プロセスは、大まかに3つのステップで進みます。

1.  各コースのシラバスに基づき、重要な学術的概念を抽出します。
2.  収集した概念を基に、Bloomの分類（※）に基づいて指示データを生成します。
3.  Contrieverというツールを使って、合成データから低品質のデータを除外します。

※Bloomの分類とは、教育学者ベンジャミン・ブルームが提唱した、学習者の認知プロセスを階層化したフレームワークです。6つの階層からなり、簡単な思考スキル（記憶、理解、適用）からより複雑な認知プロセス（分析、評価、創造）へと進む構造になっています。

下記は、中学から大学院レベルまでのカリキュラムに基づいたデータセット構造を示しています。Bloomの分類に従い、異なる認知レベルの質問を順番に行うことで、言語モデルが段階的に学習するようになっています。

![[人間のカリキュラム教育のような学習でLLMの性能は向上するとの報告 - AIDB/AIDB_61555_1-1024x589.jpg]]

### カリキュラムに基づくトレーニング

さらに研究者らは、データセットから知識を効率的に取り入れるためのトレーニング方法を考案しています。

前提として彼らは、人間の教育方法には、基本的に「ブロッキング」と「インターリービング」という二つのアプローチがあると述べています。ブロッキングは、各科目の階層を順番に積み上げていく方法ですが、インターリービングは異なるトピックを混ぜ合わせる戦略で、新しい知識を既存の知識に統合する際に有用だと言われています。

下記はトレーニングの進行方法であるブロッキングとインターリービングを比較している図です。

![[人間のカリキュラム教育のような学習でLLMの性能は向上するとの報告 - AIDB/AIDB_61555_2-1024x433.png]]

インターリービングは、前に学んだ概念が長期間放置されることによって減退されるのを防ぐ特徴もあり、LLMにおける忘却の現象にも役立つ可能性があると考えられました。なお、機械学習全般において、忘却の現象はよく見られるものとのことです。

実験ではLLMに対してブロッキングとインターリービングに基づくトレーニング手法がどちらも検証されています。

## 実験と結果

### 実験設計

まず研究者らは、前述の構造で作成されたデータセットCORGIを用意しました。人間の教育カリキュラムを模倣し、様々な認知レベルに基づいた教材をカバーするものです。

また、実験に使用する基本的なモデルとしては、LLaMA-2-13Bが選ばれました。他に競合するモデルとして、Vicuna v1.5とWizardLM v1.2が選ばれました（ただしこれらもLLaMA-2をベースにしており、ただしデータ収集の方法が異なるモデルです）。

### 学習

モデルは、CORGIデータセットに含まれる多様な指示＆応答ペアで訓練されました。教育段階や認知レベルを徐々に上げていくような学習アプローチが採用されており、前章で触れられた「ブロッキング」と「インターリービング」に加えて「クラスタリング」と「スパイラル」も検証されています。クラスタリングは関連するトピックを集中的に学習する方法で、スパイラルは異なるトピックを周期的に復習しながら進む方法です。（下図）

![[人間のカリキュラム教育のような学習でLLMの性能は向上するとの報告 - AIDB/AIDB_61555_4-1024x439.png]]

**本記事の関連研究**：[基盤モデル（GPT-4）はプロンプトの工夫で専門特化モデルに匹敵するほど性能が向上することが「医学分野」で示唆される](https://ai-data-base.com/archives/59798)

### 実験結果

本手法は、MMLU（Massive Multitask Language Understanding）ベンチマークなどの性能向上をもたらしました。MMLUとは、科学を含む多岐にわたる分野の知識を評価するテストであり、本ベンチマークでの性能は、専門的な理解力と応用力を示しています。

なお、MMLUベンチマーク以外でも本手法（CORGIデータセットを使用したモデル）が他のモデルと比較して高い性能を示しています。かなり大きな変化ではないかもしれませんが、軒並み向上しているのは特徴的です。

![[人間のカリキュラム教育のような学習でLLMの性能は向上するとの報告 - AIDB/AIDB_61555_3-1024x347.png]]

### 結論

本結果により、人間の教育カリキュラムに触発された体系的な学習アプローチが、言語モデルのパフォーマンスを向上させる有効な手法であることが示唆されました。段階的かつ体系的な学習プロセスは、モデルの理解力と応用力を高めることに繋がるだろうという結論です。

下の図は、タスク別（世界知識と常識推論、言語理解の分野）におけるLLaMA-2-13Bモデルのトレーニング手法ごとの平均パフォーマンス改善を示しており、インターリービング手法が最も効果的であることが顕著な値で確認できます。

![[人間のカリキュラム教育のような学習でLLMの性能は向上するとの報告 - AIDB/AIDB_61555_5-1024x381.png]]

下のグラフも、多様な学問分野においてインターリービングによるトレーニングがランダムな学習順序よりもLLaMA-2-13Bモデルの学習における安定した改善をもたらすことを示しています。

![[人間のカリキュラム教育のような学習でLLMの性能は向上するとの報告 - AIDB/AIDB_61555_6.png]]

なお、フィルタリングされた高品質なデータセットが、LLaMA 1 13Bモデルのパフォーマンス改善を実現することも示されました。

![[人間のカリキュラム教育のような学習でLLMの性能は向上するとの報告 - AIDB/AIDB_61555_7.png]]

## 展望や注意点

研究者らは、本実験結果から、LLMのトレーニングにおいて人間の教育ノウハウが役立つ可能性を示唆しています。今後さまざまなモデルや学習データで本アプローチを試し、適用範囲を広げることが重要だとしています。

なお、本研究アプローチの効果を他の言語モデルやデータセットに適用する際には、それぞれの特性に合わせた適切な調整が必要であることが注意されています。

## まとめ

本記事では、教育カリキュラムに基づくデータセットとトレーニング方法の研究を紹介しました。

データセット作成においては教材にインスパイアされた構造を取り入れること、また合成データで質を高める工夫が紹介されています。

研究ではカリキュラム学習に適するトレーニング手法が探求され、インターリービングが様々なベンチマークで優れた性能を示すことが明らかになりました。

今回の実験結果では、さまざまなベンチマークで軒並み性能向上が確認できました。他のモデルやデータセットでも試されていくことが期待されるアプローチですね。
