---
created: 2026-01-01T09:36:17 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/65359
author: AIDB Research
---

# 検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上 - AIDB

> ## Excerpt
> メタ認知をRAGに応用し、回答の品質がいまいちだとLLMが認識した際に検索を繰り返すアプローチの有効性が検証されました。 実験の結果、通常のRAGよりも大幅に精度が高い回答が一貫して得られると述べられています。今回の条件下では5回反復した時に最高精度になったとのことです。 参照論文情報 本記事の関連研究： 背景 LLMは時として事実と異なる内容を生成してしまうことがあります（ハルシネーションや幻覚…

---
メタ認知をRAGに応用し、回答の品質がいまいちだとLLMが認識した際に検索を繰り返すアプローチの有効性が検証されました。

実験の結果、通常のRAGよりも大幅に精度が高い回答が一貫して得られると述べられています。  
今回の条件下では5回反復した時に最高精度になったとのことです。

![[検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上 - AIDB/AIDB_65359_thum-1024x576.jpg]]

**参照論文情報**

-   タイトル：Metacognitive Retrieval-Augmented Large Language Models
-   URL：[https://doi.org/10.48550/arXiv.2402.11626](https://doi.org/10.48550/arXiv.2402.11626)
-   機関：Renmin University, Beijing Academy of Artificial Intelligence, University de Montreal
-   著者：Yujia Zhou, Zheng Liu, Jiajie Jin, Jian-Yun Nie, Zhicheng Dou

**本記事の関連研究**：

-   [RAGにおいて取得された情報と事前知識が矛盾しても、情報に説得力があるときLLMは受け入れる](https://ai-data-base.com/archives/64979)
-   [GPT-4にRAG（検索拡張生成）を適用するケーススタディ　臨床問題で人間の医師よりも高い精度を達成](https://ai-data-base.com/archives/63952)
-   [LLMの検索結果をさらに正確にする手法『CRAG（修正型検索拡張生成：Corrective Retrieval Augmented Generation）』](https://ai-data-base.com/archives/63672)
-   [LLMに対するプロンプトで「無関係な」文書を混ぜたほうが出力精度が上がる可能性がRAGシステムの検証で示唆された](https://ai-data-base.com/archives/63536)
-   [LLMに外部知識を取り入れる2つの手法、ファインチューニングとRAGを比較した実験結果](https://ai-data-base.com/archives/63401)
-   [メタ認知をさせてLLMの能力を上げる手法「メタ認知プロンプティング」](https://ai-data-base.com/archives/54435)

## 背景

LLMは時として事実と異なる内容を生成してしまうことがあります（ハルシネーションや幻覚と言われています）。この問題を解決するために考案されたのが、LLMと検索システムを組み合わせる方法（RAG）です。

RAGは、1回の検索で知識を取り出す方式が一般的です。しかし1回きりの検索は単純な情報ニーズには効果的でも、複雑なタスクには不向きという弱点があると考えられています。  
そこで、必要に応じて複数回の検索を行う方法が注目され始めています。ただし、これまで試されてきた方法は回答の誤りを診断する能力に欠けています。

人間の場合は、複雑な問題に直面した時には自分の思考パターンを内省します。これはメタ認知と呼ばれています。今回研究者らは、メタ認知の概念をLLMに取り入れ、検索拡張生成（RAG）の性能向上を目指すことにしました。メタ認知的検索拡張生成フレームワーク（MetaRAG）です。

![[検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上 - AIDB/AIDB_65359_1-1024x742.png]]

実験の結果、本手法がRAGの精度を大幅に向上させることが示唆されました。以下で詳しく紹介していきます。

ここから限定コンテンツ

### 全体的なフレームワーク

まずMetaRAGは、認知空間とメタ認知空間の2つの空間で構成されています。

前者（認知空間）はQAシステム、後者（メタ認知空間）は評価者および批評者として機能し、推論プロセスを内省します。

![[検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上 - AIDB/AIDB_65359_3-1024x420.jpg]]

メタ認知空間は、主に3つの段階で構成されています。

1.  モニタリング
2.  評価
3.  プランニング

以下で3つのステップの詳細を説明します。

**モニタリング（回答の満足度評価をする）ステップ**

モニタリングの主な機能は、認知プロセスを追跡することです。

人間の脳では、すべての認知活動に対して必ずしもメタ認知が引き起こされるわけではありません。問題が複雑になり、認知プロセスの正確性が保証されなくなった場合にのみ、「答える前に3回考える」などの必要が出てくるのです。

マルチホップQAタスク（複数の推論ステップに基づく質問応答タスク）では、タスクが複雑だったりモデルが知識不足だったりした際に、検索拡張LLMが正しい答えを推論できないことがあります。モニタリングの役割は、メタ認知的評価段階を活性化するかどうかを決定する回答の満足度を評価することです。

QAタスクに関する専門家モデルを選択し、生成された回答の満足度を評価します。  
専門家モデルの認知とLLMの認知が一致している場合、回答が高い確率で正しいと仮定します。  
逆に、ある程度の逸脱があれば、メタ認知の介入が必要になります。

質問と検索結果の文書が与えられたとき、まず専門家モデルにプロンプトを与えて回答を生成させます。そして、LLMの出力と専門家モデルの出力の類似度を計算することで、モデルの次のアクションを決定します。

**評価（回答の限界を特定する）ステップ**

上記のステップで回答が質問に十分に対応していないと判断された場合、次に評価というメタ認知プロセスが開始されます。応答の欠点を特定し、モデルが推論で失敗した理由を見極めるプロセスです。

評価ステップでは2種類のメタ認知的知識「手続き的知識」と「宣言的知識」を用います。

（１）手続き的知識

LLMを活用して、内部知識の妥当性を評価します。また、自然言語推論（NLI）モデルを用いて、外部知識の十分性を測定します。

-   内部知識の評価：質問が事前知識だけで適切に答えられるかどうかを判断します。
-   外部知識の評価：高度なNLIモデルTRUEを導入し、検索された文書が質問に答えるのに十分な情報を提供しているかどうかを調べます。

（２）宣言的知識

本研究では、推論における落とし穴は、典型的な3つのタイプに分類可能とされています。

1.  不完全な推論
2.  回答の冗長性
3.  あいまいな理解

LLMによって、提案された回答が上記のエラーのいずれかに陥っているかどうかを批判して判断します。

**プランニング（回答改善）ステップ**

上記の評価で得られた結果に基づいてプロセスを調整するステップです。

今回研究者らは事前実験をもとに、モデルが正しく答えられない3つの主なケースを指摘しています。

1.  知識不足
2.  知識の矛盾
3.  推論エラー

以下でそれぞれの課題に対処するためのプランニング戦略を紹介します。

（１）知識不足への対処

質問に答えるための内部知識と外部知識の両方が不足している場合、コーパスからさらに情報を検索するために新しいクエリを生成するようプロンプトされます。生成される新しいクエリは以下の2つの特徴を備えるものになります。

1.  不足している情報を的確に把握するために、元の質問とは異なる内容であること。
2.  元の質問をより具体的なサブ質問に分解すること。

（２）知識の矛盾への対処

内部知識と外部知識の間に不一致がある場合、モデルは混乱する可能性があります。以下の2つのケースに分類できます。

-   外部情報が妨げになる場合は、質問応答プロンプトを変更し、モデルが内部知識のみに依存するように誘導します。
-   逆に、クエリに対応できるのが外部知識のみの場合は、LLMに提供された参照情報のみに基づいて回答するように求めます。

なお、モデルが内部知識と外部知識の両方を使って質問に一貫して答えられる場合でも、多段階の推論中にエラーが発生する可能性があります。その場合、推論プロセスの二重チェックやChain of Thoughtプロンプティングなどによって改善を提案します。

## ケーススタディ

MetaRAGの実際の動作を理解するために、2WikiMultihopQAデータセットからのケーススタディを見てみましょう。MetaRAGがどのようにして反復的にメタ認知プロセスを適用し、最終的に正しい回答に到達するかを示しています。

**質問:** _Say It With FlowersとBoot Hill Banditsのどちらの映画の監督が後に亡くなったのでしょうか？_

ラウンド1では、最初の検索結果だけでは、どちらの映画の監督が後に亡くなったのかを判断できませんでした。モニタリングスコアが0.06と低いため、メタ認知的評価が開始されます。内部知識と外部知識はともに不十分であると判断され、新しいクエリ「S. Roy LubyとJune Kovachの死亡情報」が生成されました。

ラウンド2では、新しい参照情報が追加されたことで、Boot Hill Banditsの監督が後に亡くなったと答えることができるようになりました。しかし、モニタリングスコアは0.47とまだ低く、宣言的判断では回答の冗長性が指摘されています。そこで、「参考資料に頼るように」という提案がなされました。

ラウンド3では、提案に従って参考資料に基づいて簡潔に「Boot Hill Bandits」と答えられました。モニタリングスコアは0.88となり、十分な値に達したため、最終的にこの回答が出力されます。

上記のようにMetaRAGのプロセスは知識の不足を特定し、追加の検索を行い、推論プロセスを改善することで、モデルに人間のような内省的な推論を実行させています。

## 実験設定

研究者らは上記提案手法のマルチホップ推論能力をテストするために、2つのマルチホップ質問応答データセットを用いて実験を行いました。

使用したデータセットは以下の2つです。

1.  HotpotQA
2.  2WikiMultiHopQA

いずれもWikipediaの文書に基づいて構築されています。

評価指標としては、回答レベルではExact Match（予測が参照回答と一致するかどうか）をテストしました。トークンレベルでは、F1、精度（Prec.）、再現率（Rec.）を使用しました。

また、合計8個のベースラインが設定されました。

1.  Standard Prompting（LLMにクエリへの応答を指示する）
2.  Chain-of-Thought（推論プロセスを含む例をLLMに提供し、深い推論を促す）
3.  Standard RAG（クエリを使用して複数の文書を検索し、LLMに入力して回答する）
4.  ReAct（推論と行動の連携を行う）
5.  Flare（回答生成プロセス中にアクティブな検索を採用する）
6.  IR-CoT（CoT推論と検索を交互に行う）
7.  Self-Ask（複雑な問題を熟考するために中間ステップを使用する）
8.  Reflexion（フィードバックを通じてエージェントを強化する評価器を組み込む）

認知プロセス（QAシステム）では、gpt-3.5-turbo-16kを使用し、温度設定を0としてAPIに繰り返しクエリを行いました。

メタ認知プロセス（評価・批評システム）では、ファインチューニングされたT5-largeモデルが専門家モニタリングモデルとして使用されました。反復回数の最大値は5に設定されています。

## 実験結果と分析

主な結果が下記にまとめられています。

![[検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上 - AIDB/AIDB_65359_4-1024x364.png]]

MetaRAGはすべてのベースライン手法を一貫して上回っています。自己評価メカニズムを推論プロセスに組み込んでいるReflexionと比較しても大幅な改善を示しています。

2つのデータセットを比較すると、MetaRAGはHotpotQAよりも2WikiMultihopQAで大きな改善を示しています。ベースラインモデルのReflexionと比較して、それぞれ34.6%と26.0%の性能向上が見られました。  
データセットを詳しく調べてみると、2WikiMultihopQAセットには矛盾する知識の割合が高いことがわかります。つまり、検索エンジンがLLMに含まれる知識と矛盾する情報を検索する可能性が高いということです。

### モニタリングの評価

研究者らは、モニタリングがフレームワーク全体に与える影響を理解するために、モニタリングモデルの違いとの類似性のしきい値kを比較する2つの実験を行いました。

まず様々な専門家モデルを使用した場合の影響についての実験です。モニタリングには主に2種類のモデルに着目しました。LLMと、ファインチューニングされたQAモデルです。LLaMA2-chatやChatGLM2などのLLMは、優れたゼロショット能力を提供し、回答の質を評価することができます。ファインチューニングされたQAモデルであるSpanBERT-largeとT5-largeは、規模は小さいですが、特定のデータセットで訓練されています。

下記の表に示すように、モニタリング段階でファインチューニングされたQAモデルを専門家モデルとして使用すると、LLMと比較して優れた性能が得られています。

![[検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上 - AIDB/AIDB_65359_5-1024x419.png]]

なおT5-largeはSpanBERT-largeをわずかに上回っていますが、生成モデルがより大きなパラメータ容量を持つことで、このタスクにより適していることに起因している可能性があります。

### メタ知識に関する分析

メタ認知的評価は、推論における誤りを特定し、内部知識と外部知識を評価するものです。研究者らはメタ認知的知識の必要性を探るために、一般的なエラータイプの評価を除外する分析実験を行いました。

実験結果より、メタ認知的知識のいずれかの側面を取り除くと、すべての評価指標でパフォーマンスに悪影響を及ぼすことが示されています（下記の表）。

![[検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上 - AIDB/AIDB_65359_6-1024x617.png]]

多くの質問が「外部知識の不足」から生じていることを示唆しています。MetaRAGのアーキテクチャはこの問題を緩和し、モデルは知識獲得のために新しいクエリを生成するようになります。

また、一般的な各エラーがモデルの全体的な有効性に多大な影響を与えています。中でも不完全な推論に起因するエラーが最も大きいとのことです。そしてメタ認知的知識、つまり検索の反復を実行することで、モデルの推論精度を向上させることができます。

### プランニングにおける分析

プランニングフェーズでは、知識不足、知識の矛盾、推論エラーの3つのシナリオに対して改善戦略を行います。研究者らは、改善の有効性を測定する実験を行いました。知識の状態に基づいてすべての質問を3つのシナリオに分類し、各シナリオにおけるプランニングアプローチの影響を調べました。

下の図は、3つのシナリオにおける各モデルのパフォーマンスを示しています。

![[検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上 - AIDB/AIDB_65359_8-1024x460.png]]

概して、知識の豊富さが増すにつれて、各モデルの精度が向上しています。

ReActとReflexionのモデルは、複数回の検索と評価メカニズムを採用することで、知識不足の状況下でのパフォーマンスを向上させています。しかし、知識の矛盾がある場合や知識が完全な場合の改善は比較的わずかです。  
これら2つの手法とは対照的に、MetaRAGは、知識の矛盾がある場合や知識が完全な場合における推論の精度を大幅に向上させています。

### 反復回数について

MetaRAGにおける結果は最大反復回数に大きく影響されます。理想的な回数を特定するために、最大反復回数を1から6まで体系的に増やしながら、精度がどのように変化するかが観察されました。

![[検索結果をLLMでチェックして自動的に再検索する『MetaRAG』出力精度を大幅に向上 - AIDB/AIDB_65359_7-1024x460.png]]

MetaRAGの精度は最大反復回数が増えるにつれて徐々に向上しています。しかし、反復回数が5に達すると、パフォーマンスはピークに達します。また、反復回数が2のときに小さな精度のピークがあります。今回実験に使用したデータセットでは、質問の大半が2つのソースからの参照を必要としています。そのため質問に必要な知識を収集するには、2回のメタ認知的反省で十分だった可能性があります。

## まとめ

本記事では、LLMの推論プロセスにメタ認知の概念を取り入れることで、マルチホップ質問応答タスクにおける性能向上を目指した研究を紹介しました。  
一般的なRAGシステムは、固定された推論ステップに縛られており、回答の誤りを診断する能力に欠けるという課題があります。そこで著者らが考えたのがMetaRAGです。モニタリング、評価、プランニングの3段階からなるメタ認知プロセスを通じて、モデル自身の推論を内省し、知識の不足や推論エラーを特定・修正するものです。

実験では、2つのマルチホップQAデータセットを用いて、MetaRAGが全ての評価指標において優れた性能を示し、特に知識の矛盾が多いデータセットで顕著な改善が見られました。

今後は、感情の理解や直感といった他の認知的側面も取り入れることで、さらなる性能向上を行いたいとのことです。

LLMと人間の認知的な類似性に着目することで精度を向上させる取り組み、本当に面白いですね。
