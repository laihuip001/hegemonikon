---
created: 2026-01-01T09:36:25 (UTC +09:00)
tags: []
source: https://ai-data-base.com/archives/65583
author: AIDB Research
---

# 表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法 - AIDB

> ## Excerpt
> テキストと表の両方を含むハイブリッドな文書からLLMで情報を抽出する能力についてはまだ十分に研究されていません。そこで研究者らは、分割・再結合ベースの方法論を提案しています。実験により、抽出の精度が格段に上昇することを明らかにしました。 参照論文情報 本記事の関連研究： 背景 LLMは、テキストデータの理解と処理、およびと表形式データの理解と処理において優れた性能を示しています。しかし、それらを組…

---
テキストと表の両方を含むハイブリッドな文書からLLMで情報を抽出する能力についてはまだ十分に研究されていません。そこで研究者らは、分割・再結合ベースの方法論を提案しています。実験により、抽出の精度が格段に上昇することを明らかにしました。

![[表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法 - AIDB/AIDB_65583-1024x576.jpg]]

**参照論文情報**

-   タイトル：Enabling and Analyzing How to Efficiently Extract Information from Hybrid Long Documents with LLMs
-   機関：Peking University, Microsoft, Institute of Software Chinese Academy of Sciences, University of Technology Sydney
-   著者：Chongjian Yue, Xinrun Xu, Xiaojun Ma, Lun Du, Hengyu Liu, Zhiming Ding, Yanbing Jiang, Shi Han, Dongmei Zhang

**本記事の関連研究**：

-   [LLMにおける情報抽出（文章から必要な事柄を読み取る）タスクについての調査](https://ai-data-base.com/archives/61703)
-   [GoogleがLLMで「非構造化文書」高精度テキスト抽出するOCR『LMDX』発表](https://ai-data-base.com/archives/55759)
-   [LLMの検索結果をさらに正確にする手法『CRAG（修正型検索拡張生成：Corrective Retrieval Augmented Generation）』](https://ai-data-base.com/archives/63672)
-   [LLMのRAG（外部知識検索による強化）をまとめた調査報告  
    ](https://ai-data-base.com/archives/61367)

## 背景

LLMは、テキストデータの理解と処理、およびと表形式データの理解と処理において優れた性能を示しています。しかし、それらを組み合わせたハイブリッドドキュメントの処理については、まだ不十分です。

一方で、世の中の資料は表とテキストを同時に含む資料が非常に多くあります。

またハイブリッドドキュメントは多くの場合とても長い文書であり、LLMのトークン制限を大幅に超えています。

そこで今回研究者らは、LLMがハイブリッドかつ長文の文書を処理できるようにするために、分割・再結合ベースのフレームワーク『SiReF』を開発し、ハイブリッド長文文書からの情報抽出に関する実験を行いました。

1.  ドキュメントの有用な部分を選択・要約する効果的な方法
2.  LLMがテーブルを理解するための簡単なテーブルシリアル化方法
3.  本ケースにおいて有用なプロンプトエンジニアリング

さらに実験のために金融レポートデータセットも構築しました。

以下では、手法の詳細に触れていきます。

ここから限定コンテンツ

## フレームワークの方法論

LLMがハイブリッドドキュメントを処理できるようにするために研究者らが提案した手法は、Automated Information Extraction (AIE) フレームワークと言います。AIEは、Segmentation、Retrieval、Summarization、Extractionの4つのモジュールで構成されています。

1.  Segmentation: ドキュメントをLLMが処理可能なセグメントに分割
2.  Retrieval: キーワードに基づいて、最も関連性の高いセグメントを選択
3.  Summarization: 関連情報を要約するためにLLMを活用
4.  Extraction: 生成された要約からキーワードに対応する値を抽出

以下、各モジュールの最適な実装方法です。

**Segmentation**

テーブルをテキストに変換し、長すぎる要素を分割した後、隣接要素をセグメントとしてマージ

**Retrieval**

Sentence-Transformerモデルを使用して、セグメントとキーワードの類似度を計算し、上位のセグメントを取得

**Summarization**

Refine戦略を適用し、各セグメントの情報を組み込んで要約を更新

**Extraction**

要約からキーワードに対応する値を抽出するためにLLMを活用

なお、Few-Shot学習ほか全3種類のプロンプトエンジニアリングも試されました。

## データセット

3つの代表的なドメイン（財務報告書、Wikipedia、科学論文）でLLMのハイブリッドドキュメント理解力を評価するための実験が行われました。

それに伴い、各ドメインに対して以下のデータセットが構築されました。

![[表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法 - AIDB/AIDB_65583_3.png]]

**財務報告書ドメイン（Financial Reports Numerical Extraction (FINE) データセット）**

-   SEC’s EDGARから手動で抽出したKPIを含む
-   財務報告書をコンテンツとし、財務KPIと関連値を（キー、値）ペアとして使用

**Wikipediaドメイン（Wikireading-Recycled (WIKIR) データセット）**

-   Wikipediaページをコンテンツとし、対応するキーと値をWikidataから抽出

**科学論文ドメイン（MPP (Massive Paper Processing) データセット）**

-   科学論文をコンテンツとし、化学物質をキー、対応する冷却速度を値として使用

なおFINEではRelative Error Tolerance Accuracy (RETA) 指標が、他の2つのデータセットではAccuracy (Acc) 指標が使用されました。RETAは、予測値の相対誤差が指定された許容範囲内にある場合に正解とみなす指標です。

## 主な実験結果

本手法（AIEフレームワーク）の各モジュールの性能を示すために、3つのデータセットすべてにおいて、AIEと単純な手法（特に工夫を施さないシンプルな読み取り）の比較が行われました。AIEは、知見に基づいて各モジュールに最適な実装が適用されています。

FINEでの実験結果（下記）は、1％から10％までのさまざまなRETA水準での精度と、すべてのRETA設定での平均精度を示しています。WIKIRとMPPでの実験結果は、すべてのサンプルの平均精度を示しています。

![[表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法 - AIDB/AIDB_65583_4.png]]

![[表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法 - AIDB/AIDB_65583_5.png]]

実験結果から、AIE手法は3つのデータセットすべてにおいて単純な手法を上回っていることがわかります。FINEでは、RETAがより厳しくなるにつれて、ナイーブ手法とAIEの性能差が大きくなっています。

## GPT-4ではどうか

AIEの異なる能力のLLMに対する適応性を調べるために、GPT-4でも実験を行いました。GPT-4は現在、総合的な能力において最も優れたLLMです。GPT-4は最大32,768トークンのシーケンスを処理できますが、WIKIRとMPPデータセットの各サンプルの平均長は32,768トークンを超えていません。そのためGPT-4を使用する場合には、WIKIRとMPPは長文書ではないので、FINEで実験が行われました。

![[表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法 - AIDB/AIDB_65583_6.png]]

実験結果は、異なるRETA水準でも単純な戦略よりも優れた性能を示しています。

## あいまいさに対処する能力

ハイブリッドドキュメントでは、同じ概念が複数の表現を持つ場合があり、そのためLLMにはあいまいさを処理する能力が求められます。AIEがそのような能力を高められるかどうかを評価するために、研究者らは2組のキーワード（Revenue vs. Total Net Sales、Total Equity vs. Total Stockholders’ Equity）で比較を行いました。

実験の結果、AIEはさまざまなRETA水準で優れていることがわかりました。Revenue vs. Total Net Salesの比較では、AIEは単純な手法よりも平均RPDが22.52％低く、Total Equity vs. Total Stockholders’ Equityでは、AIEは単純な手法よりも平均RPDが37.94％低くなっています。

## テーブルシリアル化フォーマットの分析

LLMがテーブルデータを処理できるようにするためには、テーブルをテキストとして表現する特定のシリアル化方法を使用する必要があります。そこで研究者らは、PLAIN、CSV、XML、HTMLの4つの一般的なシリアル化方法を比較しました。

![[表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法 - AIDB/AIDB_65583_7.png]]

XMLとHTMLのフォーマットは階層情報を保持しているためリッチですが、タグの組み込みによってトークン数が増加し、LLMの最大シーケンス長を超える可能性があり、より頻繁なテーブル分割が必要になります。

PLAINとCSVのフォーマットは、簡潔なテーブル表現によってテーブルの断片化を減らし、テーブルの完全な意味情報を捉えているため、XMLとHTMLのフォーマットよりも精度が高くなっています。

なおPLAIN形式は、テーブルの各セルを空白文字（通常はスペース）で区切り、各行を改行文字（`\n`）で区切るものです。シンプルな形式のため、テーブルの階層構造やセル間の複雑な関係性は捉えませんが、テキストとしての直感的な理解と処理が可能になります。

またCSV（Comma-Separated Values）形式は、各セルはコンマ（`,`）で区切られ、各行は改行文字で区切られます。セル内のデータにコンマが含まれる場合、そのセルは通常、二重引用符（`"`）で囲まれます。データの交換と保存に広く用いられている形式です。

## 取得したセグメント数の分析

取得したセグメントの数が、フレームワークの性能にどのような影響を与えるかも調べられました。

![[表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法 - AIDB/AIDB_65583_8.png]]

実験結果から、すべてのRETA水準で最も高い精度が得られるのは、検索で取得するセグメント数が3（R@3）に設定されている場合であることがわかりました。

セグメント数が1から3に増加すると精度が上がるものの、3を超えると精度が低下します。あまりに多くのセグメントを含めると、ノイズや無関係な情報が導入され、パフォーマンスに悪影響を与える可能性があることを示唆しています。

## ショット数の分析

AIEのパフォーマンスに対するショット数（コンテキスト内学習における例の数）の影響を調査するために、研究者らは0から3までのさまざまなショット数で実験を行いました。

![[表とテキストを両方含むドキュメントからLLMで上手に情報抽出を行う手法 - AIDB/AIDB_65583_14.png]]

実験結果から、1ショット設定がすべての RETA レベルで最も高い精度を達成していることがわかりました。1 つの適切に設計された例が LLM を効果的に導き、より正確な応答を生成できることを示しています。

## 結論

本記事では、表とテキストからなるハイブリッドドキュメントから情報を効率的に抽出するために開発された自動情報抽出（AIE）フレームワークの研究を紹介しました。

本フレームワークは、セグメンテーション、検索、要約、抽出の4つのモジュールから構成されています。研究チームは、フレームワークの有効性を検証するために、Financial Reports Numerical Extraction (FINE) データセットを作成し、AIEがLLMのハイブリッドドキュメント処理能力を大幅に向上させることを実証しました。

今回の研究結果は、複雑な文書からの情報抽出タスクにおける実用的な知見といえます。ぜひ活用してみてはいかがでしょうか。

-   参照論文URL：[https://doi.org/10.48550/arXiv.2305.16344](https://doi.org/10.48550/arXiv.2305.16344)
