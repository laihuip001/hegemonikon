#!/usr/bin/env python3
# PROOF: [L2/„Ç§„É≥„Éï„É©] <- mekhane/peira/ A0‚Üínote.comË®ò‰∫ãÂèéÈõÜ„ÅåÂøÖË¶Å‚Üínote-collector„ÅåÊãÖ„ÅÜ
"""
note.com Ë®ò‰∫ãÂèéÈõÜ„Çπ„ÇØ„É™„Éó„Éà v2
„Ç∑„É≥„Éó„É´Áâà - Âç≥ÊôÇÂÆüË°å
"""

import asyncio
import aiohttp
import json
import os
import time
from pathlib import Path
from datetime import datetime

# Ë®≠ÂÆö
USER_URLNAME = "tasty_dunlin998"
OUTPUT_DIR = Path("/home/makaron8426/oikos/mneme/.hegemonikon/raw/note")
API_BASE = "https://note.com/api/v2"

async def fetch_page(session, url, params, headers):
    try:
        async with session.get(url, params=params, headers=headers, timeout=30) as resp:
            resp.raise_for_status()
            data = await resp.json()
            return data, params["page"]
    except Exception as e:
        print(f"‚ùå Error on page {params['page']}: {e}")
        return None, params["page"]

# PURPOSE: CLI „Ç®„É≥„Éà„É™„Éù„Ç§„É≥„Éà ‚Äî „Éá„Éº„Çø„Éë„Ç§„Éó„É©„Ç§„É≥„ÅÆÁõ¥Êé•ÂÆüË°å
async def async_main():
    print(f"üîç Collecting articles from note.com/{USER_URLNAME}")
    
    # Âá∫Âäõ„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    all_articles_by_page = {}
    page = 1
    
    async with aiohttp.ClientSession() as session:
        pending = []
        
        # ÂÖ®„Éö„Éº„Ç∏„ÇíÂèñÂæó (‰∏¶Ë°åÂá¶ÁêÜ„Å†„Åå„Éá„Ç£„É¨„Ç§„ÇíÂÖ•„Çå„Çã)
        while page <= 20:  # ÊúÄÂ§ß20„Éö„Éº„Ç∏
            url = f"{API_BASE}/creators/{USER_URLNAME}/contents"
            params = {"kind": "note", "page": page, "per_page": 20}
            headers = {"User-Agent": "Mozilla/5.0", "Accept": "application/json"}
            
            print(f"üìÑ Fetching page {page}...", flush=True)
            task = asyncio.create_task(fetch_page(session, url, params, headers))
            pending.append(task)
            
            # API„ÅÆ„É¨„Éº„Éà„É™„Éü„ÉÉ„Éà„ÇíËÄÉÊÖÆ„Åó„ÅüÂæÖÊ©ü
            await asyncio.sleep(0.5)
            
            # ÂÆå‰∫Ü„Åó„Å¶„ÅÑ„Çã„Çø„Çπ„ÇØ„ÇíË¶ã„Å¶„ÄÅÊúÄÂæå„ÅÆ„Éö„Éº„Ç∏„Å´Âà∞ÈÅî„Åó„Åü„Åã„ÉÅ„Çß„ÉÉ„ÇØ
            last_page_reached = False
            for t in pending:
                if t.done() and not t.cancelled():
                    res = t.result()
                    if res:
                        data, p = res
                        if data:
                            contents = data.get("data", {}).get("contents", [])
                            is_last = data.get("data", {}).get("isLastPage", True)
                            if not contents or is_last:
                                last_page_reached = True
            
            if last_page_reached:
                print(f"üì≠ No more articles")
                break
            
            page += 1
            
        # ÊÆã„Çä„ÅÆ„Çø„Çπ„ÇØ„ÇíÂæÖÊ©ü
        if pending:
            await asyncio.gather(*pending, return_exceptions=True)

        # ÁµêÊûú„ÇíÂèéÈõÜ
        for t in pending:
            if t.done() and not t.cancelled():
                res = t.result()
                if res and not isinstance(res, Exception):
                    data, p = res
                    if data:
                        contents = data.get("data", {}).get("contents", [])
                        all_articles_by_page[p] = contents
                        print(f"   Found {len(contents)} articles on page {p}", flush=True)

    all_articles = []
    # „Éö„Éº„Ç∏È†Ü„Å´Ë®ò‰∫ã„ÇíÁµêÂêà
    for p in sorted(all_articles_by_page.keys()):
        all_articles.extend(all_articles_by_page[p])

    print(f"\nüìä Total: {len(all_articles)} articles")
    
    # ÂêÑË®ò‰∫ã„Çí‰øùÂ≠ò
    for i, article in enumerate(all_articles, 1):
        key = article.get("key", "unknown")
        title = article.get("name", "untitled")
        body = article.get("body", "")
        publish_at = article.get("publishAt", "")
        
        # „Éï„Ç°„Ç§„É´ÂêçÁîüÊàê
        safe_title = "".join(c if c.isalnum() or c in "-_" else "_" for c in title[:40])
        filename = f"{key}_{safe_title}.md"
        
        # Markdown ÁîüÊàê
        md = f"""# {title}

> **Source**: https://note.com/{USER_URLNAME}/n/{key}
> **Published**: {publish_at}
> **Collected**: {datetime.now().isoformat()}

---

{body}
"""
        
        filepath = OUTPUT_DIR / filename
        filepath.write_text(md, encoding="utf-8")
        print(f"[{i}/{len(all_articles)}] ‚úÖ {filename[:50]}", flush=True)
    
    # „Éû„Éã„Éï„Çß„Çπ„Éà‰øùÂ≠ò
    manifest = {
        "user": USER_URLNAME,
        "collected_at": datetime.now().isoformat(),
        "total_articles": len(all_articles),
        "articles": [
            {"key": a.get("key"), "name": a.get("name"), "publishAt": a.get("publishAt")}
            for a in all_articles
        ]
    }
    
    manifest_path = OUTPUT_DIR / "manifest.json"
    manifest_path.write_text(json.dumps(manifest, ensure_ascii=False, indent=2), encoding="utf-8")
    
    print(f"\n‚úÖ Done! {len(all_articles)} articles saved to {OUTPUT_DIR}")

def main():
    asyncio.run(async_main())

if __name__ == "__main__":
    main()
