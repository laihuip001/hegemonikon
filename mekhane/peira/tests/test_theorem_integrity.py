#!/usr/bin/env python3
# PROOF: [L2/æ¤œè¨¼] <- DX-008: THEOREM_WORKFLOWS ãƒã‚°å†ç™ºé˜²æ­¢
"""
Theorem Integrity Tests â€” å®šç†ãƒ†ãƒ¼ãƒ–ãƒ«æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯

doctrine.md (æ­£æœ¬) ã¨ theorem_activity.py ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç…§åˆã—ã€
LLM ç”Ÿæˆã«ã‚ˆã‚‹å®šç†åæ±šæŸ“ã‚’è‡ªå‹•æ¤œå‡ºã™ã‚‹ã€‚

BC-16 (å‚ç…§å…ˆè¡Œç¾©å‹™) ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ çš„å¼·åˆ¶ã€‚
"""

import re
from pathlib import Path

import pytest

# --- Constants ---

PROJECT_ROOT = Path(__file__).resolve().parents[3]  # hegemonikon/
DOCTRINE_PATH = PROJECT_ROOT / "kernel" / "doctrine.md"
WORKFLOWS_DIR = PROJECT_ROOT / ".agent" / "workflows"
SKILLS_DIR = PROJECT_ROOT / ".agent" / "skills"

# Import the tables under test
import sys
sys.path.insert(0, str(PROJECT_ROOT))
from mekhane.peira.theorem_activity import (
    THEOREM_WORKFLOWS,
    HUB_EXPANSION,
    MACRO_EXPANSION,
    PERAS_WORKFLOWS,
)


# --- Doctrine Parser ---

def parse_adjunction_table(doctrine_path: Path) -> dict[str, str]:
    """
    doctrine.md ã®çµ±ä¸€éšä¼´è¡¨ã‹ã‚‰æ­£æœ¬ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æŠ½å‡ºã€‚

    Returns:
        dict[wf_id, "SeriesNum Name"] e.g. {"noe": "O1 NoÄ“sis", "bou": "O2 BoulÄ“sis", ...}
    """
    content = doctrine_path.read_text(encoding="utf-8")

    # çµ±ä¸€éšä¼´è¡¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³:
    # | 1 | **noe âŠ£ zet** (O1âŠ£O3) | ...
    # Each row has TWO theorems (F and G sides of adjunction)
    pattern = re.compile(
        r'\|\s*\d+\w?\s*\|'                     # | 1 | or | 0a |
        r'\s*\*\*(\w+)\s*âŠ£\s*(\w+)\*\*'         # **noe âŠ£ zet**
        r'\s*\((\w\d)âŠ£(\w\d)\)',                 # (O1âŠ£O3)
        re.UNICODE
    )

    canonical: dict[str, str] = {}

    for match in pattern.finditer(content):
        wf_f, wf_g = match.group(1), match.group(2)
        series_f, series_g = match.group(3), match.group(4)

        # We need the full name. Extract from THEOREM_WORKFLOWS as cross-check,
        # but the series+number is the canonical identifier from doctrine.md
        canonical[wf_f] = series_f  # e.g. "noe" -> "O1"
        canonical[wf_g] = series_g  # e.g. "zet" -> "O3"

    return canonical


def parse_series_definitions(doctrine_path: Path) -> dict[str, str]:
    """
    doctrine.md ã®å®šç†ç¾¤ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ Series åã‚’æŠ½å‡ºã€‚

    Returns:
        dict[series_letter, series_name]  e.g. {"O": "Ousia", "S": "Schema", ...}
    """
    content = doctrine_path.read_text(encoding="utf-8")

    # | O | Ousia | æœ¬è³ª |
    pattern = re.compile(
        r'\|\s*([OSHPKA])\s*\|\s*(\w+)\s*\|',
        re.UNICODE
    )

    series: dict[str, str] = {}
    for match in pattern.finditer(content):
        series[match.group(1)] = match.group(2)

    return series


# --- Fixtures ---

@pytest.fixture(scope="module")
def canonical_mapping():
    """doctrine.md ã‹ã‚‰æ­£æœ¬ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å–å¾—"""
    assert DOCTRINE_PATH.exists(), f"doctrine.md not found: {DOCTRINE_PATH}"
    return parse_adjunction_table(DOCTRINE_PATH)


@pytest.fixture(scope="module")
def series_names():
    """doctrine.md ã‹ã‚‰ Series åã‚’å–å¾—"""
    return parse_series_definitions(DOCTRINE_PATH)


# --- Tests ---

class TestTheoremWorkflowsIntegrity:
    """THEOREM_WORKFLOWS ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ•´åˆæ€§æ¤œè¨¼"""

    def test_all_24_theorems_present(self):
        """24å®šç†ãŒå…¨ã¦å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã“ã¨"""
        assert len(THEOREM_WORKFLOWS) == 24, (
            f"Expected 24 theorems, got {len(THEOREM_WORKFLOWS)}: "
            f"{sorted(THEOREM_WORKFLOWS.keys())}"
        )

    def test_wf_ids_match_doctrine(self, canonical_mapping):
        """WF ID ãŒ doctrine.md ã®çµ±ä¸€éšä¼´è¡¨ã¨ä¸€è‡´ã™ã‚‹ã“ã¨"""
        doctrine_ids = set(canonical_mapping.keys())
        table_ids = set(THEOREM_WORKFLOWS.keys())

        # doctrine.md ã«ã‚ã‚‹ãŒ THEOREM_WORKFLOWS ã«ãªã„
        missing_from_table = doctrine_ids - table_ids
        assert not missing_from_table, (
            f"doctrine.md ã«å­˜åœ¨ã™ã‚‹ãŒ THEOREM_WORKFLOWS ã«ãªã„ WF ID: {missing_from_table}"
        )

        # THEOREM_WORKFLOWS ã«ã‚ã‚‹ãŒ doctrine.md ã«ãªã„ (= LLM æé€ ã®ç–‘ã„)
        extra_in_table = table_ids - doctrine_ids
        assert not extra_in_table, (
            f"âš ï¸ THEOREM_WORKFLOWS ã«å­˜åœ¨ã™ã‚‹ãŒ doctrine.md ã«ãªã„ WF ID (BC-16 é•åå€™è£œ): "
            f"{extra_in_table}"
        )

    def test_series_numbers_match_doctrine(self, canonical_mapping):
        """å®šç†ã® Series ç•ªå· (O1, S2, ...) ãŒ doctrine.md ã¨ä¸€è‡´ã™ã‚‹ã“ã¨"""
        mismatches = []
        for wf_id, label in THEOREM_WORKFLOWS.items():
            if wf_id not in canonical_mapping:
                continue  # test_wf_ids_match_doctrine ã§æ¤œå‡ºæ¸ˆã¿

            # label format: "O1 NoÄ“sis" -> series_num = "O1"
            series_num = label.split()[0]
            expected = canonical_mapping[wf_id]

            if series_num != expected:
                mismatches.append(
                    f"  /{wf_id}: table says '{series_num}', "
                    f"doctrine.md says '{expected}'"
                )

        assert not mismatches, (
            f"Series ç•ªå·ã®ä¸ä¸€è‡´ (å®šç†åæ±šæŸ“ã®å¯èƒ½æ€§):\n" +
            "\n".join(mismatches)
        )

    def test_series_coverage(self):
        """å„ Series (O/S/H/P/K/A) ã«4ã¤ã®å®šç†ãŒå­˜åœ¨ã™ã‚‹ã“ã¨"""
        series_count: dict[str, int] = {}
        for label in THEOREM_WORKFLOWS.values():
            series_letter = label[0]
            series_count[series_letter] = series_count.get(series_letter, 0) + 1

        expected_series = {"O", "S", "H", "P", "K", "A"}
        assert set(series_count.keys()) == expected_series, (
            f"Series ãŒä¸è¶³: expected {expected_series}, got {set(series_count.keys())}"
        )

        for series, count in series_count.items():
            assert count == 4, (
                f"Series {series} has {count} theorems, expected 4"
            )

    def test_theorem_numbers_sequential(self):
        """å„ Series å†…ã§å®šç†ç•ªå·ãŒ 1-4 ã§ã‚ã‚‹ã“ã¨"""
        series_nums: dict[str, list[int]] = {}
        for label in THEOREM_WORKFLOWS.values():
            series_letter = label[0]
            num = int(label[1])
            series_nums.setdefault(series_letter, []).append(num)

        for series, nums in series_nums.items():
            assert sorted(nums) == [1, 2, 3, 4], (
                f"Series {series} has numbers {sorted(nums)}, expected [1, 2, 3, 4]"
            )


class TestWorkflowFilesExist:
    """WF ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨æ¤œè¨¼"""

    def test_all_theorem_wf_files_exist(self):
        """å…¨24å®šç†ã® WF ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨"""
        missing = []
        for wf_id in THEOREM_WORKFLOWS:
            wf_path = WORKFLOWS_DIR / f"{wf_id}.md"
            if not wf_path.exists():
                missing.append(f"/{wf_id} -> {wf_path}")

        assert not missing, (
            f"WF ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å®šç†:\n" +
            "\n".join(missing)
        )

    def test_all_peras_wf_files_exist(self):
        """å…¨ Peras WF ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨"""
        missing = []
        for wf_id in PERAS_WORKFLOWS:
            wf_path = WORKFLOWS_DIR / f"{wf_id}.md"
            if not wf_path.exists():
                missing.append(f"/{wf_id} -> {wf_path}")

        assert not missing, (
            f"Peras WF ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„:\n" +
            "\n".join(missing)
        )


class TestHubExpansionIntegrity:
    """HUB_EXPANSION ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ•´åˆæ€§æ¤œè¨¼"""

    def test_hub_wf_ids_are_valid_theorems(self):
        """HUB_EXPANSION ã®å±•é–‹å…ˆãŒå…¨ã¦ THEOREM_WORKFLOWS ã«å­˜åœ¨ã™ã‚‹ã“ã¨"""
        invalid = []
        for hub_id, sub_wfs in HUB_EXPANSION.items():
            for sub_wf in sub_wfs:
                if sub_wf not in THEOREM_WORKFLOWS:
                    invalid.append(
                        f"  HUB '{hub_id}' -> '{sub_wf}' "
                        f"(THEOREM_WORKFLOWS ã«å­˜åœ¨ã—ãªã„)"
                    )

        assert not invalid, (
            f"HUB_EXPANSION ã«ç„¡åŠ¹ãª WF ID:\n" +
            "\n".join(invalid)
        )

    def test_hub_covers_all_series(self):
        """å„ Series Peras ãŒå¯¾å¿œã™ã‚‹4å®šç†ã‚’å±•é–‹ã™ã‚‹ã“ã¨"""
        series_map = {"o": "O", "s": "S", "h": "H", "p": "P", "k": "K", "a": "A"}

        for hub_id, expected_series in series_map.items():
            assert hub_id in HUB_EXPANSION, f"HUB_EXPANSION ã« '{hub_id}' ãŒãªã„"
            expanded = HUB_EXPANSION[hub_id]

            # Check all expanded WFs belong to the expected series
            for wf_id in expanded:
                label = THEOREM_WORKFLOWS.get(wf_id, "")
                assert label.startswith(expected_series), (
                    f"HUB '{hub_id}' expanded to '{wf_id}' ({label}), "
                    f"but expected Series {expected_series}"
                )

            assert len(expanded) == 4, (
                f"HUB '{hub_id}' expands to {len(expanded)} theorems, expected 4"
            )

    def test_ax_covers_all_24(self):
        """/ax ãŒå…¨24å®šç†ã‚’å±•é–‹ã™ã‚‹ã“ã¨"""
        assert "ax" in HUB_EXPANSION
        ax_expanded = set(HUB_EXPANSION["ax"])
        all_theorems = set(THEOREM_WORKFLOWS.keys())

        missing = all_theorems - ax_expanded
        assert not missing, f"/ax ãŒå±•é–‹ã—ãªã„å®šç†: {missing}"


class TestMacroExpansionIntegrity:
    """MACRO_EXPANSION ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ•´åˆæ€§æ¤œè¨¼"""

    def test_macro_wf_ids_are_valid_theorems(self):
        """MACRO_EXPANSION ã®å±•é–‹å…ˆãŒå…¨ã¦ THEOREM_WORKFLOWS ã«å­˜åœ¨ã™ã‚‹ã“ã¨"""
        invalid = []
        for macro, sub_wfs in MACRO_EXPANSION.items():
            for sub_wf in sub_wfs:
                if sub_wf not in THEOREM_WORKFLOWS:
                    invalid.append(
                        f"  MACRO '@{macro}' -> '{sub_wf}' "
                        f"(THEOREM_WORKFLOWS ã«å­˜åœ¨ã—ãªã„)"
                    )

        assert not invalid, (
            f"MACRO_EXPANSION ã«ç„¡åŠ¹ãª WF ID (BC-16 é•åå€™è£œ):\n" +
            "\n".join(invalid)
        )

    def test_macro_definitions_not_empty(self):
        """å…¨ãƒã‚¯ãƒ­ãŒå°‘ãªãã¨ã‚‚1ã¤ã®å®šç†ã‚’å±•é–‹ã™ã‚‹ã“ã¨"""
        empty = [m for m, wfs in MACRO_EXPANSION.items() if not wfs]
        assert not empty, f"ç©ºã®ãƒã‚¯ãƒ­å®šç¾©: {empty}"


class TestSkillDirectoriesExist:
    """SKILL ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨æ¤œè¨¼"""

    SERIES_SKILL_DIRS = {
        "O": "ousia",
        "S": "schema",
        "H": "horme",
        "P": "perigraphe",
        "K": "kairos",
        "A": "akribeia",
    }

    def test_all_series_skill_dirs_exist(self):
        """å…¨ Series ã® SKILL ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã™ã‚‹ã“ã¨"""
        missing = []
        for series, dirname in self.SERIES_SKILL_DIRS.items():
            skill_path = SKILLS_DIR / dirname
            if not skill_path.exists():
                missing.append(f"Series {series} -> {skill_path}")

        assert not missing, (
            f"SKILL ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„:\n" +
            "\n".join(missing)
        )


# --- Standalone runner ---

if __name__ == "__main__":
    print("=" * 60)
    print("å®šç†ãƒ†ãƒ¼ãƒ–ãƒ«æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯")
    print("=" * 60)

    errors = []

    # 1. Parse doctrine.md
    if not DOCTRINE_PATH.exists():
        print(f"âŒ doctrine.md not found: {DOCTRINE_PATH}")
        sys.exit(1)

    canonical = parse_adjunction_table(DOCTRINE_PATH)
    print(f"\nğŸ“– doctrine.md ã‹ã‚‰ {len(canonical)} WF ID ã‚’æŠ½å‡º")

    # 2. Check THEOREM_WORKFLOWS
    print(f"\n--- THEOREM_WORKFLOWS ({len(THEOREM_WORKFLOWS)} entries) ---")

    table_ids = set(THEOREM_WORKFLOWS.keys())
    doctrine_ids = set(canonical.keys())

    missing = doctrine_ids - table_ids
    extra = table_ids - doctrine_ids

    if missing:
        msg = f"âŒ doctrine.md ã«ã‚ã‚‹ãŒ THEOREM_WORKFLOWS ã«ãªã„: {missing}"
        print(msg)
        errors.append(msg)
    if extra:
        msg = f"âš ï¸ THEOREM_WORKFLOWS ã«ã‚ã‚‹ãŒ doctrine.md ã«ãªã„ (LLM æé€ ç–‘ã„): {extra}"
        print(msg)
        errors.append(msg)

    # Series number check
    for wf_id, label in THEOREM_WORKFLOWS.items():
        if wf_id in canonical:
            series_num = label.split()[0]
            expected = canonical[wf_id]
            if series_num != expected:
                msg = f"âŒ /{wf_id}: '{series_num}' â‰  doctrine '{expected}'"
                print(msg)
                errors.append(msg)

    if not missing and not extra:
        print("âœ… WF ID ãŒ doctrine.md ã¨å®Œå…¨ä¸€è‡´")

    # 3. Check WF files
    print(f"\n--- WF ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª ---")
    wf_missing = []
    for wf_id in THEOREM_WORKFLOWS:
        if not (WORKFLOWS_DIR / f"{wf_id}.md").exists():
            wf_missing.append(wf_id)

    if wf_missing:
        msg = f"âŒ WF ãƒ•ã‚¡ã‚¤ãƒ«ãªã—: {wf_missing}"
        print(msg)
        errors.append(msg)
    else:
        print("âœ… å…¨24å®šç†ã® WF ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨")

    # 4. Check HUB_EXPANSION
    print(f"\n--- HUB_EXPANSION ---")
    hub_invalid = []
    for hub_id, sub_wfs in HUB_EXPANSION.items():
        for sub_wf in sub_wfs:
            if sub_wf not in THEOREM_WORKFLOWS:
                hub_invalid.append(f"{hub_id} -> {sub_wf}")
    if hub_invalid:
        msg = f"âŒ ç„¡åŠ¹ãª HUB å±•é–‹å…ˆ: {hub_invalid}"
        print(msg)
        errors.append(msg)
    else:
        print("âœ… HUB_EXPANSION ã®å…¨å±•é–‹å…ˆãŒ THEOREM_WORKFLOWS ã«å­˜åœ¨")

    # 5. Check MACRO_EXPANSION
    print(f"\n--- MACRO_EXPANSION ---")
    macro_invalid = []
    for macro, sub_wfs in MACRO_EXPANSION.items():
        for sub_wf in sub_wfs:
            if sub_wf not in THEOREM_WORKFLOWS:
                macro_invalid.append(f"@{macro} -> {sub_wf}")
    if macro_invalid:
        msg = f"âŒ ç„¡åŠ¹ãªãƒã‚¯ãƒ­å±•é–‹å…ˆ: {macro_invalid}"
        print(msg)
        errors.append(msg)
    else:
        print("âœ… MACRO_EXPANSION ã®å…¨å±•é–‹å…ˆãŒ THEOREM_WORKFLOWS ã«å­˜åœ¨")

    # Summary
    print(f"\n{'=' * 60}")
    if errors:
        print(f"âŒ {len(errors)} ä»¶ã®ã‚¨ãƒ©ãƒ¼")
        for e in errors:
            print(f"  {e}")
        sys.exit(1)
    else:
        print("âœ… å…¨ãƒã‚§ãƒƒã‚¯é€šé â€” ãƒ†ãƒ¼ãƒ–ãƒ«æ•´åˆæ€§ã«å•é¡Œãªã—")
        sys.exit(0)
