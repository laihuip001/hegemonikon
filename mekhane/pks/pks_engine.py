# noqa: AI-ALL
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] <- mekhane/pks/
"""
PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å­˜åœ¨ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„

A0 (FEP) â†’ äºˆæ¸¬èª¤å·®æœ€å°åŒ–ã«ã¯èƒ½å‹•çš„çŸ¥è­˜è¡¨é¢åŒ–ãŒå¿…è¦
â†’ Pullå‹æ¤œç´¢ã®é€†è»¢ â†’ Pushå‹ã§çŸ¥è­˜ãŒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«èªã‚Šã‹ã‘ã‚‹
â†’ pks_engine.py ãŒæ‹…ã†

# PURPOSE: Proactive Knowledge Surface ã‚¨ãƒ³ã‚¸ãƒ³
# å¾“æ¥ã®ã€Œæ¤œç´¢ã—ã¦ã‹ã‚‰çµæœã‚’å¾—ã‚‹ã€ã‚’ã€Œãƒ‡ãƒ¼ã‚¿ãŒè‡ªã‚‰èªã‚Šã‹ã‘ã¦ãã‚‹ã€ã«é€†è»¢ã™ã‚‹ã€‚
"""

from __future__ import annotations

import json
import math
import os
import re
import sys
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Optional

# Path resolution
_PKS_DIR = Path(__file__).resolve().parent
_MEKHANE_DIR = _PKS_DIR.parent
_HEGEMONIKON_ROOT = _MEKHANE_DIR.parent

if str(_HEGEMONIKON_ROOT) not in sys.path:
    sys.path.insert(0, str(_HEGEMONIKON_ROOT))

# --- Data Models ---


@dataclass
# PURPOSE: çŸ¥è­˜ã®æœ€å°å˜ä½ â€” PKS ãŒãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹æƒ…å ±ã®ç²’
class KnowledgeNugget:
    """çŸ¥è­˜ã®æœ€å°å˜ä½ â€” PKS ãŒãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹æƒ…å ±ã®ç²’"""

    title: str
    abstract: str
    source: str
    relevance_score: float
    url: Optional[str] = None
    authors: Optional[str] = None
    push_reason: str = ""  # ãªãœã“ã®çŸ¥è­˜ã‚’ä»Šãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã®ã‹
    suggested_questions: list[str] = field(default_factory=list)  # v2: èãã¹ãè³ªå•
    serendipity_score: float = 0.0  # v2: æ„å¤–æ€§ã‚¹ã‚³ã‚¢

    # PURPOSE: Markdown å½¢å¼ã§å‡ºåŠ›
    def to_markdown(self) -> str:
        """Markdown å½¢å¼ã§å‡ºåŠ›"""
        lines = [
            f"### ğŸ“¡ {self.title}",
            f"",
            f"**é–¢é€£åº¦**: {self.relevance_score:.2f} | **ã‚½ãƒ¼ã‚¹**: {self.source}",
        ]
        if self.push_reason:
            lines.append(f"**ãƒ—ãƒƒã‚·ãƒ¥ç†ç”±**: {self.push_reason}")
        lines.append(f"")
        if self.abstract:
            lines.append(f"> {self.abstract[:300]}...")
        if self.authors:
            lines.append(f"")
            lines.append(f"*Authors: {self.authors[:100]}*")
        if self.url:
            lines.append(f"")
            lines.append(f"[è«–æ–‡ãƒªãƒ³ã‚¯]({self.url})")
        return "\n".join(lines)


# PURPOSE: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä½œæ¥­ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
@dataclass
class SessionContext:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä½œæ¥­ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""

    topics: list[str] = field(default_factory=list)
    recent_queries: list[str] = field(default_factory=list)
    active_workflows: list[str] = field(default_factory=list)
    handoff_keywords: list[str] = field(default_factory=list)
    timestamp: str = ""

    # PURPOSE: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸ‹ã‚è¾¼ã¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
    def to_embedding_text(self) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸ‹ã‚è¾¼ã¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
        parts = []
        if self.topics:
            parts.append(f"Topics: {', '.join(self.topics)}")
        if self.recent_queries:
            parts.append(f"Recent queries: {', '.join(self.recent_queries[-5:])}")
        if self.active_workflows:
            parts.append(f"Active workflows: {', '.join(self.active_workflows)}")
        if self.handoff_keywords:
            parts.append(f"Handoff context: {', '.join(self.handoff_keywords)}")
        return " | ".join(parts) if parts else "general knowledge"


# --- Core Engine ---
# PURPOSE: ä½œæ¥­ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¿æŒ


class ContextTracker:
    """ä½œæ¥­ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¿æŒ"""

    # PURPOSE: å†…éƒ¨å‡¦ç†: init__
    def __init__(self):
        self._context = SessionContext()

    @property
    # PURPOSE: é–¢æ•°: context
    def context(self) -> SessionContext:
        return self._context

    # PURPOSE: ãƒˆãƒ”ãƒƒã‚¯æ›´æ–°
    def update_topics(self, topics: list[str]) -> None:
        """ãƒˆãƒ”ãƒƒã‚¯æ›´æ–°"""
        self._context.topics = topics
        self._context.timestamp = datetime.now().isoformat()

    # PURPOSE: æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å±¥æ­´ã«è¿½åŠ 
    def add_query(self, query: str) -> None:
        """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å±¥æ­´ã«è¿½åŠ ï¼ˆé‡è¤‡æ™‚ã¯æœ«å°¾ã«ç§»å‹•ï¼‰"""
        # é‡è¤‡æ’é™¤: æ—¢å­˜ãªã‚‰é™¤å»ã—ã¦æœ«å°¾ã«å†è¿½åŠ 
        if query in self._context.recent_queries:
            self._context.recent_queries.remove(query)
        self._context.recent_queries.append(query)
        # ç›´è¿‘ 20 ä»¶ã®ã¿ä¿æŒ
        if len(self._context.recent_queries) > 20:
            self._context.recent_queries = self._context.recent_queries[-20:]

    # PURPOSE: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è¨­å®š
    def set_workflows(self, workflows: list[str]) -> None:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è¨­å®š"""
        self._context.active_workflows = workflows

    # PURPOSE: æœ€æ–° Handoff ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    def load_from_handoff(self, handoff_path: Path) -> None:
        """æœ€æ–° Handoff ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        if not handoff_path.exists():
            return

        text = handoff_path.read_text(encoding="utf-8", errors="replace")

        # YAML frontmatter ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        keywords = []
        for line in text.split("\n"):
# PURPOSE: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ Ã— æœªæ¶ˆåŒ–ãƒ‡ãƒ¼ã‚¿ã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
            line = line.strip()
            if line.startswith("primary_task:"):
                keywords.append(line.split(":", 1)[1].strip().strip('"'))
            elif line.startswith("- \"") and line.endswith("âœ“\""):
                keywords.append(line.strip("- \"âœ“"))
        self._context.handoff_keywords = keywords[:10]


class RelevanceDetector:
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ Ã— æœªæ¶ˆåŒ–ãƒ‡ãƒ¼ã‚¿ã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

    GnosisIndex ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚’åˆ©ç”¨ã—ã€
    ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã™ã‚‹å„çŸ¥è­˜ã®é–¢é€£åº¦ã‚’ç®—å‡ºã™ã‚‹ã€‚
    """

    # PURPOSE: å†…éƒ¨å‡¦ç†: init__
    def __init__(self, threshold: float = 0.65):
        self.threshold = threshold

    # PURPOSE: æ¤œç´¢çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã®é–¢é€£åº¦ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    def score(
        self,
        context: SessionContext,
        search_results: list[dict],
    ) -> list[KnowledgeNugget]:
        """æ¤œç´¢çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã®é–¢é€£åº¦ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

        LanceDB ã®è·é›¢ã‚¹ã‚³ã‚¢ã‚’æ­£è¦åŒ–ã—ã€é–¾å€¤ä»¥ä¸Šã®ã‚‚ã®ã‚’ KnowledgeNugget ã«å¤‰æ›ã€‚
        """
        nuggets = []

        for result in search_results:
            # LanceDB ã® _distance ã¯ä½ã„ã»ã©é¡ä¼¼åº¦ãŒé«˜ã„
            distance = result.get("_distance", float("inf"))

            # è·é›¢ã‚’ 0-1 ã®ã‚¹ã‚³ã‚¢ã«æ­£è¦åŒ– (ä½è·é›¢ = é«˜ã‚¹ã‚³ã‚¢)
            # BGE-small ã® cosine distance ã¯é€šå¸¸ 0ã€œ2 ã®ç¯„å›²
            score = max(0.0, 1.0 - (distance / 2.0))

            if score >= self.threshold:
                nugget = KnowledgeNugget(
                    title=result.get("title", "Untitled"),
                    abstract=result.get("abstract", ""),
                    source=result.get("source", "unknown"),
                    relevance_score=score,
                    url=result.get("url"),
                    authors=result.get("authors", ""),
                    push_reason=self._generate_push_reason(context, result, score),
                )
                nuggets.append(nugget)

        # ã‚¹ã‚³ã‚¢é™é †ã§ã‚½ãƒ¼ãƒˆ
        nuggets.sort(key=lambda n: n.relevance_score, reverse=True)
        return nuggets

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥ç†ç”±ã‚’ç”Ÿæˆ
    def _generate_push_reason(
        self, context: SessionContext, result: dict, score: float
    ) -> str:
        """ãƒ—ãƒƒã‚·ãƒ¥ç†ç”±ã‚’ç”Ÿæˆ"""
        reasons = []
        title = result.get("title", "").lower()
        abstract = result.get("abstract", "").lower()
# PURPOSE: é–¾å€¤è¶…éæ™‚ã«çŸ¥è­˜ã‚’èƒ½å‹•çš„ã«ãƒ—ãƒƒã‚·ãƒ¥

        for topic in context.topics:
            if topic.lower() in title or topic.lower() in abstract:
                reasons.append(f"ç¾åœ¨ã®ãƒˆãƒ”ãƒƒã‚¯ '{topic}' ã«ç›´æ¥é–¢é€£")

        if not reasons:
            reasons.append(f"ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯é¡ä¼¼åº¦ {score:.2f} ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«é©åˆ")

        return " / ".join(reasons)


# --- v2: AutophÅnos ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ ---


# PURPOSE: Handoff ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’è‡ªå‹•æŠ½å‡ºã™ã‚‹
class AutoTopicExtractor:
    """Handoff ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’è‡ªå‹•æŠ½å‡ºã™ã‚‹ (Mem é¢¨)

    Handoff ã®æ§‹é€ ï¼ˆYAML frontmatter + Markdownï¼‰ã‚’è§£æã—ã€
    é‡è¦ãªãƒˆãƒ”ãƒƒã‚¯ã‚’æ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ã§æŠ½å‡ºã™ã‚‹ã€‚
    LLM ä¸è¦ã®è»½é‡å®Ÿè£…ã€‚
    """

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã®æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³
    _YAML_KEYS = re.compile(
        r"(?:primary_task|decision|pattern|topic|recommendation):\s*[\"']?(.+?)[\"']?\s*$",
        re.MULTILINE,
    )
    _COMPLETED_TASKS = re.compile(r"-\s*\[x\]\s*(.+?)(?:\s*âœ“|$)", re.MULTILINE)
    _NEXT_TASKS = re.compile(r"-\s*\[\s\]\s*(.+?)$", re.MULTILINE)
    _HEADERS = re.compile(r"^#{1,3}\s+(.+)$", re.MULTILINE)
    # SBAR å½¢å¼: å¤ªå­—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (**keyword**)
    _BOLD_KEYWORDS = re.compile(r"\*\*([^*]{3,60})\*\*", re.MULTILINE)
    # Situation ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å†’é ­æ–‡ (SBAR format)
    _SITUATION_LINE = re.compile(
        r"^##\s*Situation\s*\n+(.+?)$", re.MULTILINE
    )

    # PURPOSE: Handoff ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’è‡ªå‹•æŠ½å‡º
    def extract(self, text: str, max_topics: int = 8) -> list[str]:
        """Handoff ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’è‡ªå‹•æŠ½å‡º

        æŠ½å‡ºæˆ¦ç•¥ (å„ªå…ˆåº¦é †):
        1. YAML frontmatter ã®ã‚­ãƒ¼å€¤ (primary_task, decision ç­‰)
        2. å®Œäº†ã‚¿ã‚¹ã‚¯ã®åå‰ ([x])
        3. æœªå®Œäº†ã‚¿ã‚¹ã‚¯ã®åå‰ ([ ])
        4. SBAR: Situation ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å†’é ­æ–‡
        5. SBAR: å¤ªå­—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (**keyword**)

        Returns:
            é‡è¤‡æ’é™¤ã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯ãƒªã‚¹ãƒˆ (æœ€å¤§ max_topics ä»¶)
        """
        topics: list[str] = []

        # 1. YAML ã‚­ãƒ¼å€¤
        for m in self._YAML_KEYS.finditer(text):
            val = m.group(1).strip()
            if len(val) > 3:  # ãƒã‚¤ã‚ºé™¤å»
                topics.append(val)

        # 2. å®Œäº†ã‚¿ã‚¹ã‚¯å
        for m in self._COMPLETED_TASKS.finditer(text):
            task_name = m.group(1).strip()
            if len(task_name) > 5:
                topics.append(task_name)

        # 3. æœªå®Œäº†ã‚¿ã‚¹ã‚¯å (æ¬¡å›ã®æ–‡è„ˆã¨ã—ã¦é‡è¦)
        for m in self._NEXT_TASKS.finditer(text):
            task_name = m.group(1).strip()
            if len(task_name) > 5:
                topics.append(task_name)

        # 4. SBAR: Situation ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å†’é ­æ–‡
        for m in self._SITUATION_LINE.finditer(text):
            situation = m.group(1).strip()
            if len(situation) > 10:
                # é•·æ–‡ã¯æœ€åˆã®å¥ç‚¹ã§åˆ‡ã‚‹
                first_sentence = situation.split("ã€‚")[0]
                if len(first_sentence) > 5:
                    topics.append(first_sentence)

        # 5. SBAR: å¤ªå­—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (ä¸Šé™ 5 ä»¶)
        bold_count = 0
        noise_words = {
            "å‰ã‚»ãƒƒã‚·ãƒ§ãƒ³", "æœ¬ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹åœ°ç‚¹", "çµ‚äº†åœ°ç‚¹",
            "ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“", "Handoff", "æ³¨æ„",
        }
        for m in self._BOLD_KEYWORDS.finditer(text):
            kw = m.group(1).strip()
            if kw in noise_words or kw.startswith("V["):
                continue
            if len(kw) > 3 and bold_count < 5:
                topics.append(kw)
                bold_count += 1

        # é‡è¤‡æ’é™¤ (é †åºä¿æŒ)
        seen: set[str] = set()
        unique: list[str] = []
        for t in topics:
            key = t.lower()
            if key not in seen:
                seen.add(key)
                unique.append(t)

        return unique[:max_topics]


# PURPOSE: ã€Œé–¢é€£ã™ã‚‹ãŒæ„å¤–ã€ãªæƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
class SerendipityScorer:
    """Serendipity Score â€” æ„å¤–ã ãŒæœ‰ç”¨ãªæƒ…å ±ã‚’ç™ºè¦‹ã™ã‚‹ (Glean/Obsidian é¢¨)

    é€šå¸¸ã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢ã¯ã€Œå®Œå…¨ä¸€è‡´ã€ã‚’æœ€é«˜ã¨ã—ã¦ãƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹ãŒã€
    ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã‚¹ã‚³ã‚¢ã¯ã€Œé–¢é€£ã™ã‚‹ãŒäºˆæƒ³å¤–ã€ãªæƒ…å ±ã‚’å„ªå…ˆã™ã‚‹ã€‚

    æƒ…å ±ç†è«–: Serendipity â‰ˆ Relevance Ã— Surprise
    - Relevance: æ—¢å­˜ã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢
    - Surprise: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®ã€Œè·é›¢ã€(è¿‘ã™ããšé ã™ããšã®æƒ…å ±é‡)
    """

    # PURPOSE: ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º
    def score(
        self,
        relevance: float,
        distance: float,
        sweet_spot: float = 0.45,
        spread: float = 0.15,
    ) -> float:
        """ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º

        Relevance Ã— Gaussian(distance, sweet_spot, spread)

        sweet_spot: ã€Œã¡ã‚‡ã†ã©ã„ã„æ„å¤–æ€§ã€ã®è·é›¢
        spread: sweet_spot å‘¨ã‚Šã®è¨±å®¹å¹…

        Returns:
            0.0ã€œ1.0 ã®ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã‚¹ã‚³ã‚¢
        """
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³: sweet_spot ä»˜è¿‘ã§æœ€å¤§ã€é›¢ã‚Œã‚‹ã»ã©æ¸›è¡°
        surprise = math.exp(
            -((distance - sweet_spot) ** 2) / (2 * spread**2)
        )
        return relevance * surprise

    # PURPOSE: KnowledgeNugget ãƒªã‚¹ãƒˆã«ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸
    def enrich(
        self, nuggets: list[KnowledgeNugget], raw_distances: list[float]
    ) -> list[KnowledgeNugget]:
        """KnowledgeNugget ãƒªã‚¹ãƒˆã«ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸

        Args:
            nuggets: ã‚¹ã‚³ã‚¢ä»˜ããƒŠã‚²ãƒƒãƒˆ
            raw_distances: å„ãƒŠã‚²ãƒƒãƒˆã®å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«è·é›¢
        """
        for nugget, dist in zip(nuggets, raw_distances):
            nugget.serendipity_score = self.score(nugget.relevance_score, dist)
        return nuggets


# PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçŸ¥è­˜ã‹ã‚‰ã€Œèãã¹ãè³ªå•ã€ã‚’ LLM ç”Ÿæˆã™ã‚‹
class SuggestedQuestionGenerator:
    """Suggested Questions â€” NotebookLM ã®ã€Œèãã¹ãè³ªå•ã€æ©Ÿèƒ½ã®å†ç¾

    ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸ KnowledgeNugget ã‚’åˆ†æã—ã€
    Creator ãŒæ·±æ˜ã‚Šã™ã¹ãè³ªå•ã‚’ 3 ã¤è‡ªå‹•ç”Ÿæˆã™ã‚‹ã€‚

    Gemini API (google.genai SDK) ã‚’ä½¿ç”¨ã€‚
    API ä¸å¯æ™‚ã¯ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
    """

    _PROMPT_TEMPLATE = (
        "ä»¥ä¸‹ã®çŸ¥è­˜ã«ã¤ã„ã¦ã€ã“ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦æ´å¯Ÿã‚’å¾—ã‚‹ãŸã‚ã«"
        "æœ€ã‚‚é‡è¦ãªè³ªå•ã‚’3ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n\n"
        "è³ªå•ã¯å…·ä½“çš„ã§ã€å˜ãªã‚‹è¦ç´„ã®ç¹°ã‚Šè¿”ã—ã§ã¯ãªãã€\n"
        "- å¿œç”¨å¯èƒ½æ€§\n"
        "- æ—¢å­˜çŸ¥è­˜ã¨ã®æ¥ç¶šç‚¹\n"
        "- éš ã‚ŒãŸå‰æã‚„é™ç•Œ\n"
        "ã‚’å•ã†ã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚\n\n"
        "ã‚¿ã‚¤ãƒˆãƒ«: {title}\n"
        "è¦ç´„: {abstract}\n"
        "ã‚½ãƒ¼ã‚¹: {source}\n\n"
        "å‡ºåŠ›å½¢å¼: å„è³ªå•ã‚’1è¡Œãšã¤ã€ç•ªå·ãªã—ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    )

    # PURPOSE: Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
    def __init__(self, model: str = "gemini-2.0-flash"):
        self.model_name = model
        self._client = None
        self._init_client()

    def _init_client(self) -> None:
        """Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é…å»¶åˆæœŸåŒ–"""
        try:
            from google import genai

            api_key = (
                os.environ.get("GOOGLE_API_KEY")
                or os.environ.get("GEMINI_API_KEY")
                or os.environ.get("GOOGLE_GENAI_API_KEY")
            )
            if api_key:
                self._client = genai.Client(api_key=api_key)
            else:
                self._client = genai.Client()
        except (ImportError, Exception):
            self._client = None

    @property
    def is_available(self) -> bool:
        return self._client is not None

    # PURPOSE: KnowledgeNugget ã‹ã‚‰ã€Œèãã¹ãè³ªå•ã€ã‚’ç”Ÿæˆ
    def generate(
        self, nugget: KnowledgeNugget, num_questions: int = 3
    ) -> list[str]:
        """KnowledgeNugget ã‹ã‚‰ã€Œèãã¹ãè³ªå•ã€ã‚’ç”Ÿæˆ

        LLM å¯ç”¨æ™‚ã¯ Gemini ã§ç”Ÿæˆã€‚ä¸å¯æ™‚ã¯ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚

        Returns:
            è³ªå•æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆ (æœ€å¤§ num_questions ä»¶)
        """
        if self.is_available:
            return self._generate_llm(nugget, num_questions)
        return self._generate_fallback(nugget, num_questions)

    def _generate_llm(
        self, nugget: KnowledgeNugget, num_questions: int
    ) -> list[str]:
        """Gemini API ã§è³ªå•ã‚’ç”Ÿæˆ"""
        prompt = self._PROMPT_TEMPLATE.format(
            title=nugget.title,
            abstract=nugget.abstract[:500] if nugget.abstract else "(ãªã—)",
            source=nugget.source,
        )

        try:
            response = self._client.models.generate_content(
                model=self.model_name, contents=prompt
            )
            text = response.text if response else ""
            if text:
                lines = [
                    line.strip()
                    for line in text.strip().split("\n")
                    if line.strip() and not line.strip().startswith("#")
                ]
                # ç•ªå·ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»
                cleaned = []
                for line in lines:
                    cleaned_line = re.sub(r"^\d+[.\)]\s*", "", line)
                    if cleaned_line:
                        cleaned.append(cleaned_line)
                return cleaned[:num_questions]
        except Exception as e:
            print(f"[PKS] SuggestedQuestion LLM error: {e}")

        return self._generate_fallback(nugget, num_questions)

    def _generate_fallback(
        self, nugget: KnowledgeNugget, num_questions: int
    ) -> list[str]:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆ"""
        title = nugget.title
        questions = [
            f"ã€{title}ã€ã®çŸ¥è¦‹ã¯ã€ç¾åœ¨ã®ä½œæ¥­ã«ã©ã†å¿œç”¨ã§ãã‚‹ã‹ï¼Ÿ",
            f"ã€{title}ã€ãŒå‰æã¨ã—ã¦ã„ã‚‹ä»®å®šã¯ä½•ã‹ï¼Ÿãã®ä»®å®šã¯å¦¥å½“ã‹ï¼Ÿ",
            f"ã€{title}ã€ã¨çŸ›ç›¾ã™ã‚‹æ—¢çŸ¥ã®çŸ¥è­˜ã¯ã‚ã‚‹ã‹ï¼Ÿ",
        ]
        return questions[:num_questions]

    # PURPOSE: è¤‡æ•°ãƒŠã‚²ãƒƒãƒˆã«ä¸€æ‹¬ã§è³ªå•ã‚’ä»˜ä¸
    def enrich_batch(self, nuggets: list[KnowledgeNugget]) -> list[KnowledgeNugget]:
        """è¤‡æ•°ãƒŠã‚²ãƒƒãƒˆã«ä¸€æ‹¬ã§è³ªå•ã‚’ä»˜ä¸"""
        for nugget in nuggets:
            nugget.suggested_questions = self.generate(nugget)
        return nuggets


class PushController:
    """é–¾å€¤è¶…éæ™‚ã«çŸ¥è­˜ã‚’èƒ½å‹•çš„ã«ãƒ—ãƒƒã‚·ãƒ¥

    RelevanceDetector ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°çµæœã‚’å—ã‘å–ã‚Šã€
    ãƒ—ãƒƒã‚·ãƒ¥å¯¾è±¡ã®åˆ¶å¾¡ï¼ˆæœ€å¤§ä»¶æ•°ã€é‡è¤‡æ’é™¤ç­‰ï¼‰ã‚’è¡Œã†ã€‚
    """

    # PURPOSE: å†…éƒ¨å‡¦ç†: init__
    def __init__(self, max_push: int = 5, cooldown_hours: float = 24.0):
        self.max_push = max_push
        self.cooldown_hours = cooldown_hours
        self._push_history: dict[str, str] = {}  # title -> last_pushed_at ISO

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥å¯¾è±¡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    def filter_pushable(self, nuggets: list[KnowledgeNugget]) -> list[KnowledgeNugget]:
        """ãƒ—ãƒƒã‚·ãƒ¥å¯¾è±¡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        now = datetime.now()
        pushable = []

        for nugget in nuggets:
            # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯
            last_pushed = self._push_history.get(nugget.title)
            if last_pushed:
                elapsed = (now - datetime.fromisoformat(last_pushed)).total_seconds()
                if elapsed < self.cooldown_hours * 3600:
                    continue

            pushable.append(nugget)

            if len(pushable) >= self.max_push:
                break

        return pushable

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’è¨˜éŒ²
    def record_push(self, nuggets: list[KnowledgeNugget]) -> None:
        """ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’è¨˜éŒ²"""
        now_iso = datetime.now().isoformat()
        for nugget in nuggets:
            self._push_history[nugget.title] = now_iso

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    def save_history(self, path: Path) -> None:
# PURPOSE: Proactive Knowledge Surface â€” ãƒ¡ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿
        """ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(self._push_history, f, ensure_ascii=False, indent=2)

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
    def load_history(self, path: Path) -> None:
        """ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿"""
        if path.exists():
            with open(path, "r", encoding="utf-8") as f:
                self._push_history = json.load(f)


# --- Orchestrator ---


class PKSEngine:
    """Proactive Knowledge Surface â€” ãƒ¡ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿

    ä½¿ã„æ–¹:
        engine = PKSEngine()
        engine.set_context(topics=["FEP", "CCL"])
        nuggets = engine.proactive_push()
        for n in nuggets:
            print(n.to_markdown())
    """

    # Push å±¥æ­´ã®ä¿å­˜å…ˆ
    HISTORY_FILE = "pks_push_history.json"

    # PURPOSE: å†…éƒ¨å‡¦ç†: init__
    def __init__(
        self,
        threshold: float = 0.65,
        max_push: int = 5,
        lance_dir: Optional[Path] = None,
        enable_questions: bool = True,
        enable_serendipity: bool = True,
    ):
        self.tracker = ContextTracker()
        self.detector = RelevanceDetector(threshold=threshold)
        self.controller = PushController(max_push=max_push)
        self.topic_extractor = AutoTopicExtractor()
        self.serendipity_scorer = SerendipityScorer() if enable_serendipity else None
        self.question_gen = SuggestedQuestionGenerator() if enable_questions else None

        # é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (GnosisIndex ã¯é‡ã„)
        self._index = None
        self._lance_dir = lance_dir

        # å±¥æ­´èª­ã¿è¾¼ã¿
        history_path = _PKS_DIR / self.HISTORY_FILE
        self.controller.load_history(history_path)

    # PURPOSE: GnosisIndex ã‚’é…å»¶åˆæœŸåŒ–
    def _get_index(self):
        """GnosisIndex ã‚’é…å»¶åˆæœŸåŒ–"""
        if self._index is None:
            from mekhane.anamnesis.index import GnosisIndex

            self._index = GnosisIndex(lance_dir=self._lance_dir)
        return self._index

    # PURPOSE: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
    def set_context(
        self,
        topics: Optional[list[str]] = None,
        workflows: Optional[list[str]] = None,
        handoff_path: Optional[Path] = None,
    ) -> None:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š"""
        if topics:
            self.tracker.update_topics(topics)
        if workflows:
            self.tracker.set_workflows(workflows)
        if handoff_path:
            self.tracker.load_from_handoff(handoff_path)

    # PURPOSE: v2: Handoff ã‹ã‚‰è‡ªå‹•çš„ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
    def auto_context_from_handoff(self, handoff_path: Optional[Path] = None) -> list[str]:
        """Handoff ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒˆãƒ”ãƒƒã‚¯ã‚’è‡ªå‹•æŠ½å‡ºã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¨­å®š

        Args:
            handoff_path: Handoff ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€‚None ã®å ´åˆã¯æœ€æ–°ã‚’è‡ªå‹•æ¤œå‡ºã€‚

        Returns:
            æŠ½å‡ºã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯ã®ãƒªã‚¹ãƒˆ
        """
        if handoff_path is None:
            # æœ€æ–°ã® Handoff ã‚’è‡ªå‹•æ¤œå‡º
            handoff_dir = Path.home() / "oikos" / "mneme" / ".hegemonikon" / "sessions"
            if handoff_dir.exists():
                # handoff_YYYY-MM-DD_HHMM.md ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿å¯¾è±¡ (handoff_final ç­‰ã‚’é™¤å¤–)
                handoffs = list(handoff_dir.glob("handoff_20??-??-??_????.md"))
                if handoffs:
                    # mtime ã§ã‚½ãƒ¼ãƒˆ (æœ€æ–°å„ªå…ˆ)
                    handoffs.sort(key=lambda p: p.stat().st_mtime, reverse=True)
                    handoff_path = handoffs[0]

        if handoff_path is None or not handoff_path.exists():
            print("[PKS] Handoff ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []

        text = handoff_path.read_text(encoding="utf-8", errors="replace")
        topics = self.topic_extractor.extract(text)

        if topics:
            self.tracker.update_topics(topics)
            self.tracker.load_from_handoff(handoff_path)
            print(f"[PKS] è‡ªå‹•ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡º: {topics}")

        return topics

    # PURPOSE: èƒ½å‹•çš„ãƒ—ãƒƒã‚·ãƒ¥: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦çŸ¥è­˜ã‚’è¡¨é¢åŒ–
    def proactive_push(self, k: int = 20) -> list[KnowledgeNugget]:
        """èƒ½å‹•çš„ãƒ—ãƒƒã‚·ãƒ¥: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦çŸ¥è­˜ã‚’è¡¨é¢åŒ–

        1. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ã‚¨ãƒªã«å¤‰æ›
        2. GnosisIndex ã§ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
        3. RelevanceDetector ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        4. PushController ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        5. ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’è¨˜éŒ²

        Returns:
            ãƒ—ãƒƒã‚·ãƒ¥å¯¾è±¡ã® KnowledgeNugget ãƒªã‚¹ãƒˆ
        """
        context = self.tracker.context
        query_text = context.to_embedding_text()

        if query_text == "general knowledge":
            print("[PKS] ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæœªè¨­å®šã€‚topics ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            return []

        # GnÅsis æ¤œç´¢
        self.tracker.add_query(query_text)
        index = self._get_index()
        results = index.search(query_text, k=k)

        if not results:
            print("[PKS] æ¤œç´¢çµæœãªã—")
            return []

        # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° + ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        nuggets = self.detector.score(context, results)
        pushable = self.controller.filter_pushable(nuggets)

        # å±¥æ­´è¨˜éŒ²
        if pushable:
            self.controller.record_push(pushable)
            self.controller.save_history(_PKS_DIR / self.HISTORY_FILE)

        return pushable

    # PURPOSE: æ˜ç¤ºçš„ã‚¯ã‚¨ãƒªã§ãƒ—ãƒƒã‚·ãƒ¥: é€šå¸¸æ¤œç´¢ + PKS ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    def search_and_push(self, query: str, k: int = 10) -> list[KnowledgeNugget]:
        """æ˜ç¤ºçš„ã‚¯ã‚¨ãƒªã§ãƒ—ãƒƒã‚·ãƒ¥: é€šå¸¸æ¤œç´¢ + PKS ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

        cli.py ã® `proactive` ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã€‚
        """
        self.tracker.add_query(query)
        index = self._get_index()
        results = index.search(query, k=k)

        if not results:
            return []

        nuggets = self.detector.score(self.tracker.context, results)
        return nuggets  # æ˜ç¤ºçš„æ¤œç´¢ã§ã¯ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãªã—

    # PURPOSE: v2: ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçŸ¥è­˜ã«å¯¾ã™ã‚‹ã€Œèãã¹ãè³ªå•ã€ã‚’ç”Ÿæˆ
    def suggest_questions(
        self, nuggets: list[KnowledgeNugget]
    ) -> list[KnowledgeNugget]:
        """ãƒ—ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒŠã‚²ãƒƒãƒˆã«ã€Œèãã¹ãè³ªå•ã€ã‚’ä»˜ä¸

        Returns:
            suggested_questions ãŒä»˜ä¸ã•ã‚ŒãŸ KnowledgeNugget ãƒªã‚¹ãƒˆ
        """
        if self.question_gen:
            return self.question_gen.enrich_batch(nuggets)
        return nuggets

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥çµæœã‚’ Markdown ãƒ¬ãƒãƒ¼ãƒˆã«æ•´å½¢
    def format_push_report(self, nuggets: list[KnowledgeNugget]) -> str:
        """ãƒ—ãƒƒã‚·ãƒ¥çµæœã‚’ Markdown ãƒ¬ãƒãƒ¼ãƒˆã«æ•´å½¢"""
        if not nuggets:
            return "ğŸ“­ ãƒ—ãƒƒã‚·ãƒ¥å¯¾è±¡ã®çŸ¥è­˜ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

        lines = [
            "## ğŸ“¡ PKS â€” çŸ¥è­˜ãŒèªã‚Šã‹ã‘ã¦ã„ã¾ã™",
            "",
            f"_ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {', '.join(self.tracker.context.topics) if self.tracker.context.topics else '(æœªè¨­å®š)'}_",
            f"_æ¤œå‡ºæ•°: {len(nuggets)} ä»¶_",
            "",
            "---",
        ]

        for nugget in nuggets:
            lines.append("")
            lines.append(nugget.to_markdown())

            # v2: èãã¹ãè³ªå•ã‚’è¡¨ç¤º
            if nugget.suggested_questions:
                lines.append("")
                lines.append("**ğŸ’¡ èãã¹ãè³ªå•:**")
                for q in nugget.suggested_questions:
                    lines.append(f"- {q}")

            # v2: ã‚»ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ”ãƒ†ã‚£ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
            if nugget.serendipity_score > 0:
                lines.append(f"")
                lines.append(f"_ğŸ² æ„å¤–æ€§: {nugget.serendipity_score:.2f}_")

            lines.append("")
            lines.append("---")

        return "\n".join(lines)
