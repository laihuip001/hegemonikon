# noqa: AI-ALL
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] <- mekhane/pks/
"""
PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å­˜åœ¨ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„

A0 (FEP) â†’ äºˆæ¸¬èª¤å·®æœ€å°åŒ–ã«ã¯èƒ½å‹•çš„çŸ¥è­˜è¡¨é¢åŒ–ãŒå¿…è¦
â†’ Pullå‹æ¤œç´¢ã®é€†è»¢ â†’ Pushå‹ã§çŸ¥è­˜ãŒã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«èªã‚Šã‹ã‘ã‚‹
â†’ pks_engine.py ãŒæ‹…ã†

# PURPOSE: Proactive Knowledge Surface ã‚¨ãƒ³ã‚¸ãƒ³
# å¾“æ¥ã®ã€Œæ¤œç´¢ã—ã¦ã‹ã‚‰çµæœã‚’å¾—ã‚‹ã€ã‚’ã€Œãƒ‡ãƒ¼ã‚¿ãŒè‡ªã‚‰èªã‚Šã‹ã‘ã¦ãã‚‹ã€ã«é€†è»¢ã™ã‚‹ã€‚
"""

from __future__ import annotations

import json
import sys
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Optional

# Path resolution
_PKS_DIR = Path(__file__).resolve().parent
_MEKHANE_DIR = _PKS_DIR.parent
_HEGEMONIKON_ROOT = _MEKHANE_DIR.parent

if str(_HEGEMONIKON_ROOT) not in sys.path:
    sys.path.insert(0, str(_HEGEMONIKON_ROOT))

# --- Data Models ---


@dataclass
# PURPOSE: çŸ¥è­˜ã®æœ€å°å˜ä½ â€” PKS ãŒãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹æƒ…å ±ã®ç²’
class KnowledgeNugget:
    """çŸ¥è­˜ã®æœ€å°å˜ä½ â€” PKS ãŒãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹æƒ…å ±ã®ç²’"""

    title: str
    abstract: str
    source: str
    relevance_score: float
    url: Optional[str] = None
    authors: Optional[str] = None
    push_reason: str = ""  # ãªãœã“ã®çŸ¥è­˜ã‚’ä»Šãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã®ã‹

    # PURPOSE: Markdown å½¢å¼ã§å‡ºåŠ›
    def to_markdown(self) -> str:
        """Markdown å½¢å¼ã§å‡ºåŠ›"""
        lines = [
            f"### ğŸ“¡ {self.title}",
            f"",
            f"**é–¢é€£åº¦**: {self.relevance_score:.2f} | **ã‚½ãƒ¼ã‚¹**: {self.source}",
        ]
        if self.push_reason:
            lines.append(f"**ãƒ—ãƒƒã‚·ãƒ¥ç†ç”±**: {self.push_reason}")
        lines.append(f"")
        if self.abstract:
            lines.append(f"> {self.abstract[:300]}...")
        if self.authors:
            lines.append(f"")
            lines.append(f"*Authors: {self.authors[:100]}*")
        if self.url:
            lines.append(f"")
            lines.append(f"[è«–æ–‡ãƒªãƒ³ã‚¯]({self.url})")
        return "\n".join(lines)


# PURPOSE: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä½œæ¥­ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
@dataclass
class SessionContext:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ä½œæ¥­ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""

    topics: list[str] = field(default_factory=list)
    recent_queries: list[str] = field(default_factory=list)
    active_workflows: list[str] = field(default_factory=list)
    handoff_keywords: list[str] = field(default_factory=list)
    timestamp: str = ""

    # PURPOSE: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸ‹ã‚è¾¼ã¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
    def to_embedding_text(self) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸ‹ã‚è¾¼ã¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›"""
        parts = []
        if self.topics:
            parts.append(f"Topics: {', '.join(self.topics)}")
        if self.recent_queries:
            parts.append(f"Recent queries: {', '.join(self.recent_queries[-5:])}")
        if self.active_workflows:
            parts.append(f"Active workflows: {', '.join(self.active_workflows)}")
        if self.handoff_keywords:
            parts.append(f"Handoff context: {', '.join(self.handoff_keywords)}")
        return " | ".join(parts) if parts else "general knowledge"


# --- Core Engine ---
# PURPOSE: ä½œæ¥­ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¿æŒ


class ContextTracker:
    """ä½œæ¥­ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¿æŒ"""

    # PURPOSE: å†…éƒ¨å‡¦ç†: init__
    def __init__(self):
        self._context = SessionContext()

    @property
    # PURPOSE: é–¢æ•°: context
    def context(self) -> SessionContext:
        return self._context

    # PURPOSE: ãƒˆãƒ”ãƒƒã‚¯æ›´æ–°
    def update_topics(self, topics: list[str]) -> None:
        """ãƒˆãƒ”ãƒƒã‚¯æ›´æ–°"""
        self._context.topics = topics
        self._context.timestamp = datetime.now().isoformat()

    # PURPOSE: æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å±¥æ­´ã«è¿½åŠ 
    def add_query(self, query: str) -> None:
        """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å±¥æ­´ã«è¿½åŠ """
        self._context.recent_queries.append(query)
        # ç›´è¿‘ 20 ä»¶ã®ã¿ä¿æŒ
        if len(self._context.recent_queries) > 20:
            self._context.recent_queries = self._context.recent_queries[-20:]

    # PURPOSE: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è¨­å®š
    def set_workflows(self, workflows: list[str]) -> None:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è¨­å®š"""
        self._context.active_workflows = workflows

    # PURPOSE: æœ€æ–° Handoff ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    def load_from_handoff(self, handoff_path: Path) -> None:
        """æœ€æ–° Handoff ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        if not handoff_path.exists():
            return

        text = handoff_path.read_text(encoding="utf-8", errors="replace")

        # YAML frontmatter ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        keywords = []
        for line in text.split("\n"):
# PURPOSE: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ Ã— æœªæ¶ˆåŒ–ãƒ‡ãƒ¼ã‚¿ã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
            line = line.strip()
            if line.startswith("primary_task:"):
                keywords.append(line.split(":", 1)[1].strip().strip('"'))
            elif line.startswith("- \"") and line.endswith("âœ“\""):
                keywords.append(line.strip("- \"âœ“"))
        self._context.handoff_keywords = keywords[:10]


class RelevanceDetector:
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ Ã— æœªæ¶ˆåŒ–ãƒ‡ãƒ¼ã‚¿ã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

    GnosisIndex ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚’åˆ©ç”¨ã—ã€
    ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã™ã‚‹å„çŸ¥è­˜ã®é–¢é€£åº¦ã‚’ç®—å‡ºã™ã‚‹ã€‚
    """

    # PURPOSE: å†…éƒ¨å‡¦ç†: init__
    def __init__(self, threshold: float = 0.65):
        self.threshold = threshold

    # PURPOSE: æ¤œç´¢çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã®é–¢é€£åº¦ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    def score(
        self,
        context: SessionContext,
        search_results: list[dict],
    ) -> list[KnowledgeNugget]:
        """æ¤œç´¢çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã®é–¢é€£åº¦ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

        LanceDB ã®è·é›¢ã‚¹ã‚³ã‚¢ã‚’æ­£è¦åŒ–ã—ã€é–¾å€¤ä»¥ä¸Šã®ã‚‚ã®ã‚’ KnowledgeNugget ã«å¤‰æ›ã€‚
        """
        nuggets = []

        for result in search_results:
            # LanceDB ã® _distance ã¯ä½ã„ã»ã©é¡ä¼¼åº¦ãŒé«˜ã„
            distance = result.get("_distance", float("inf"))

            # è·é›¢ã‚’ 0-1 ã®ã‚¹ã‚³ã‚¢ã«æ­£è¦åŒ– (ä½è·é›¢ = é«˜ã‚¹ã‚³ã‚¢)
            # BGE-small ã® cosine distance ã¯é€šå¸¸ 0ã€œ2 ã®ç¯„å›²
            score = max(0.0, 1.0 - (distance / 2.0))

            if score >= self.threshold:
                nugget = KnowledgeNugget(
                    title=result.get("title", "Untitled"),
                    abstract=result.get("abstract", ""),
                    source=result.get("source", "unknown"),
                    relevance_score=score,
                    url=result.get("url"),
                    authors=result.get("authors", ""),
                    push_reason=self._generate_push_reason(context, result, score),
                )
                nuggets.append(nugget)

        # ã‚¹ã‚³ã‚¢é™é †ã§ã‚½ãƒ¼ãƒˆ
        nuggets.sort(key=lambda n: n.relevance_score, reverse=True)
        return nuggets

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥ç†ç”±ã‚’ç”Ÿæˆ
    def _generate_push_reason(
        self, context: SessionContext, result: dict, score: float
    ) -> str:
        """ãƒ—ãƒƒã‚·ãƒ¥ç†ç”±ã‚’ç”Ÿæˆ"""
        reasons = []
        title = result.get("title", "").lower()
        abstract = result.get("abstract", "").lower()
# PURPOSE: é–¾å€¤è¶…éæ™‚ã«çŸ¥è­˜ã‚’èƒ½å‹•çš„ã«ãƒ—ãƒƒã‚·ãƒ¥

        for topic in context.topics:
            if topic.lower() in title or topic.lower() in abstract:
                reasons.append(f"ç¾åœ¨ã®ãƒˆãƒ”ãƒƒã‚¯ '{topic}' ã«ç›´æ¥é–¢é€£")

        if not reasons:
            reasons.append(f"ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯é¡ä¼¼åº¦ {score:.2f} ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«é©åˆ")

        return " / ".join(reasons)


class PushController:
    """é–¾å€¤è¶…éæ™‚ã«çŸ¥è­˜ã‚’èƒ½å‹•çš„ã«ãƒ—ãƒƒã‚·ãƒ¥

    RelevanceDetector ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°çµæœã‚’å—ã‘å–ã‚Šã€
    ãƒ—ãƒƒã‚·ãƒ¥å¯¾è±¡ã®åˆ¶å¾¡ï¼ˆæœ€å¤§ä»¶æ•°ã€é‡è¤‡æ’é™¤ç­‰ï¼‰ã‚’è¡Œã†ã€‚
    """

    # PURPOSE: å†…éƒ¨å‡¦ç†: init__
    def __init__(self, max_push: int = 5, cooldown_hours: float = 24.0):
        self.max_push = max_push
        self.cooldown_hours = cooldown_hours
        self._push_history: dict[str, str] = {}  # title -> last_pushed_at ISO

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥å¯¾è±¡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    def filter_pushable(self, nuggets: list[KnowledgeNugget]) -> list[KnowledgeNugget]:
        """ãƒ—ãƒƒã‚·ãƒ¥å¯¾è±¡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        now = datetime.now()
        pushable = []

        for nugget in nuggets:
            # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯
            last_pushed = self._push_history.get(nugget.title)
            if last_pushed:
                elapsed = (now - datetime.fromisoformat(last_pushed)).total_seconds()
                if elapsed < self.cooldown_hours * 3600:
                    continue

            pushable.append(nugget)

            if len(pushable) >= self.max_push:
                break

        return pushable

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’è¨˜éŒ²
    def record_push(self, nuggets: list[KnowledgeNugget]) -> None:
        """ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’è¨˜éŒ²"""
        now_iso = datetime.now().isoformat()
        for nugget in nuggets:
            self._push_history[nugget.title] = now_iso

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    def save_history(self, path: Path) -> None:
# PURPOSE: Proactive Knowledge Surface â€” ãƒ¡ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿
        """ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(self._push_history, f, ensure_ascii=False, indent=2)

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
    def load_history(self, path: Path) -> None:
        """ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿"""
        if path.exists():
            with open(path, "r", encoding="utf-8") as f:
                self._push_history = json.load(f)


# --- Orchestrator ---


class PKSEngine:
    """Proactive Knowledge Surface â€” ãƒ¡ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿

    ä½¿ã„æ–¹:
        engine = PKSEngine()
        engine.set_context(topics=["FEP", "CCL"])
        nuggets = engine.proactive_push()
        for n in nuggets:
            print(n.to_markdown())
    """

    # Push å±¥æ­´ã®ä¿å­˜å…ˆ
    HISTORY_FILE = "pks_push_history.json"

    # PURPOSE: å†…éƒ¨å‡¦ç†: init__
    def __init__(
        self,
        threshold: float = 0.65,
        max_push: int = 5,
        lance_dir: Optional[Path] = None,
    ):
        self.tracker = ContextTracker()
        self.detector = RelevanceDetector(threshold=threshold)
        self.controller = PushController(max_push=max_push)

        # é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (GnosisIndex ã¯é‡ã„)
        self._index = None
        self._lance_dir = lance_dir

        # å±¥æ­´èª­ã¿è¾¼ã¿
        history_path = _PKS_DIR / self.HISTORY_FILE
        self.controller.load_history(history_path)

    # PURPOSE: GnosisIndex ã‚’é…å»¶åˆæœŸåŒ–
    def _get_index(self):
        """GnosisIndex ã‚’é…å»¶åˆæœŸåŒ–"""
        if self._index is None:
            from mekhane.anamnesis.index import GnosisIndex

            self._index = GnosisIndex(lance_dir=self._lance_dir)
        return self._index

    # PURPOSE: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š
    def set_context(
        self,
        topics: Optional[list[str]] = None,
        workflows: Optional[list[str]] = None,
        handoff_path: Optional[Path] = None,
    ) -> None:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¨­å®š"""
        if topics:
            self.tracker.update_topics(topics)
        if workflows:
            self.tracker.set_workflows(workflows)
        if handoff_path:
            self.tracker.load_from_handoff(handoff_path)

    # PURPOSE: èƒ½å‹•çš„ãƒ—ãƒƒã‚·ãƒ¥: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦çŸ¥è­˜ã‚’è¡¨é¢åŒ–
    def proactive_push(self, k: int = 20) -> list[KnowledgeNugget]:
        """èƒ½å‹•çš„ãƒ—ãƒƒã‚·ãƒ¥: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦çŸ¥è­˜ã‚’è¡¨é¢åŒ–

        1. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ã‚¨ãƒªã«å¤‰æ›
        2. GnosisIndex ã§ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
        3. RelevanceDetector ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        4. PushController ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        5. ãƒ—ãƒƒã‚·ãƒ¥å±¥æ­´ã‚’è¨˜éŒ²

        Returns:
            ãƒ—ãƒƒã‚·ãƒ¥å¯¾è±¡ã® KnowledgeNugget ãƒªã‚¹ãƒˆ
        """
        context = self.tracker.context
        query_text = context.to_embedding_text()

        if query_text == "general knowledge":
            print("[PKS] ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæœªè¨­å®šã€‚topics ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
            return []

        # GnÅsis æ¤œç´¢
        self.tracker.add_query(query_text)
        index = self._get_index()
        results = index.search(query_text, k=k)

        if not results:
            print("[PKS] æ¤œç´¢çµæœãªã—")
            return []

        # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° + ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        nuggets = self.detector.score(context, results)
        pushable = self.controller.filter_pushable(nuggets)

        # å±¥æ­´è¨˜éŒ²
        if pushable:
            self.controller.record_push(pushable)
            self.controller.save_history(_PKS_DIR / self.HISTORY_FILE)

        return pushable

    # PURPOSE: æ˜ç¤ºçš„ã‚¯ã‚¨ãƒªã§ãƒ—ãƒƒã‚·ãƒ¥: é€šå¸¸æ¤œç´¢ + PKS ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    def search_and_push(self, query: str, k: int = 10) -> list[KnowledgeNugget]:
        """æ˜ç¤ºçš„ã‚¯ã‚¨ãƒªã§ãƒ—ãƒƒã‚·ãƒ¥: é€šå¸¸æ¤œç´¢ + PKS ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

        cli.py ã® `proactive` ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã€‚
        """
        self.tracker.add_query(query)
        index = self._get_index()
        results = index.search(query, k=k)

        if not results:
            return []

        nuggets = self.detector.score(self.tracker.context, results)
        return nuggets  # æ˜ç¤ºçš„æ¤œç´¢ã§ã¯ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãªã—

    # PURPOSE: ãƒ—ãƒƒã‚·ãƒ¥çµæœã‚’ Markdown ãƒ¬ãƒãƒ¼ãƒˆã«æ•´å½¢
    def format_push_report(self, nuggets: list[KnowledgeNugget]) -> str:
        """ãƒ—ãƒƒã‚·ãƒ¥çµæœã‚’ Markdown ãƒ¬ãƒãƒ¼ãƒˆã«æ•´å½¢"""
        if not nuggets:
            return "ğŸ“­ ãƒ—ãƒƒã‚·ãƒ¥å¯¾è±¡ã®çŸ¥è­˜ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

        lines = [
            "## ğŸ“¡ PKS â€” çŸ¥è­˜ãŒèªã‚Šã‹ã‘ã¦ã„ã¾ã™",
            "",
            f"_ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {', '.join(self.tracker.context.topics) if self.tracker.context.topics else '(æœªè¨­å®š)'}_",
            f"_æ¤œå‡ºæ•°: {len(nuggets)} ä»¶_",
            "",
            "---",
        ]

        for nugget in nuggets:
            lines.append("")
            lines.append(nugget.to_markdown())
            lines.append("")
            lines.append("---")

        return "\n".join(lines)
