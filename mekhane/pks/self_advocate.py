#!/usr/bin/env python3
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] <- mekhane/pks/
"""
PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å­˜åœ¨ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„

A0 (FEP) â†’ äºˆæ¸¬èª¤å·®æœ€å°åŒ–ã«ã¯çŸ¥è­˜ã®ä¸»ä½“çš„è¡¨é¢åŒ–ãŒå¿…è¦
â†’ Pullå‹ã®é€†è»¢ â†’ ãƒ‡ãƒ¼ã‚¿ãŒè‡ªã‚‰ä¸€äººç§°ã§èªã‚Šã‹ã‘ã‚‹
â†’ self_advocate.py ãŒæ‹…ã†

# PURPOSE: è«–æ–‡ãŒä¸€äººç§°ã§ã€Œç§ã‚’ä½¿ã£ã¦ãã ã•ã„ã€ã¨èªã‚Šã‹ã‘ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆã™ã‚‹
# AutophÅnos (Î±á½Ï„ÏŒÏ†Ï‰Î½Î¿Ï‚ = è‡ªã‚‰å£°ã‚’ç™ºã™ã‚‹ã‚‚ã®) ã®æ ¸å¿ƒæ€æƒ³ã®å®Ÿè£…
"""

from __future__ import annotations

import re
from dataclasses import dataclass
from typing import Optional

from mekhane.pks.llm_client import PKSLLMClient
from mekhane.pks.pks_engine import KnowledgeNugget, SessionContext


# PURPOSE: è«–æ–‡ä¸€äººç§°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ â€” AutophÅnos ã®æ ¸å¿ƒå‡ºåŠ›
@dataclass
class Advocacy:
    """è«–æ–‡ä¸€äººç§°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""

    paper_title: str
    voice: str  # ä¸€äººç§°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æœ¬ä½“
    key_contribution: str  # å…·ä½“çš„ãªè²¢çŒ®
    how_to_use: str  # ä½¿ã„æ–¹ã®ææ¡ˆ
    relevance_score: float = 0.0

    # PURPOSE: Markdown å½¢å¼ã§å‡ºåŠ›
    def to_markdown(self) -> str:
        """Markdown å½¢å¼ã§å‡ºåŠ›"""
        lines = [
            f"### ğŸ“„ **{self.paper_title}** ãŒèªã‚Šã‹ã‘ã¦ã„ã¾ã™:",
            "",
            f"> {self.voice}",
            "",
            f"**ğŸ”‘ å…·ä½“çš„ãªè²¢çŒ®**: {self.key_contribution}",
            f"**ğŸ“‹ ä½¿ã„æ–¹**: {self.how_to_use}",
        ]
        if self.relevance_score > 0:
            lines.append(f"**ğŸ“Š é–¢é€£åº¦**: {self.relevance_score:.2f}")
        return "\n".join(lines)


# PURPOSE: è«–æ–‡ã«ä¸»ä½“æ€§ã‚’ä¸ãˆã€ä¸€äººç§°ã§èªã‚Šã‹ã‘ã•ã›ã‚‹
class SelfAdvocate:
    """SelfAdvocate â€” è«–æ–‡ãŒè‡ªã‚‰èªã‚Šã‹ã‘ã‚‹

    AutophÅnos ã®æ ¸å¿ƒã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã€‚
    KnowledgeNugget + SessionContext â†’ è«–æ–‡ä¸€äººç§°ã® Advocacy ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚

    LLM (Gemini) ã§é«˜å“è³ªãªä¸€äººç§°ç”Ÿæˆã€‚
    ä¸å¯æ™‚ã¯ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚

    Usage:
        advocate = SelfAdvocate()
        advocacy = advocate.generate(nugget, context)
        print(advocacy.to_markdown())
    """

    _LLM_PROMPT = (
        "ã‚ãªãŸã¯ä»¥ä¸‹ã®è«–æ–‡ã§ã™ã€‚ä¸€äººç§°ï¼ˆã€Œç§ã€ï¼‰ã§ã€"
        "ä»Šã¾ã•ã«å›°ã£ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯¾ã—ã¦è‡ªåˆ†ã®ä¾¡å€¤ã‚’èªã‚Šã‹ã‘ã¦ãã ã•ã„ã€‚\n\n"
        "## ã‚ãªãŸï¼ˆè«–æ–‡ï¼‰ã®æƒ…å ±\n"
        "- ã‚¿ã‚¤ãƒˆãƒ«: {title}\n"
        "- è¦ç´„: {abstract}\n"
        "- ã‚½ãƒ¼ã‚¹: {source}\n\n"
        "## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ\n"
        "- ãƒˆãƒ”ãƒƒã‚¯: {topics}\n"
        "- é–¢é€£åº¦: {score}\n\n"
        "## å‡ºåŠ›å½¢å¼ï¼ˆå³å¯†ã«å®ˆã‚‹ã“ã¨ï¼‰\n"
        "VOICE: ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®èªã‚Šã‹ã‘ã€‚ã€Œç§ã¯ã€œã€ã§å§‹ã‚ã€"
        "ã‚ãªãŸè‡ªèº«ã®çŸ¥è¦‹ãŒã©ã†å½¹ç«‹ã¤ã‹å…·ä½“çš„ã«è¿°ã¹ã‚‹ã€‚3-4æ–‡ã€‚ï¼‰\n"
        "CONTRIBUTION: ï¼ˆã‚ãªãŸã®æœ€ã‚‚é‡è¦ãªè²¢çŒ®ã‚’1æ–‡ã§ã€‚ï¼‰\n"
        "HOW_TO_USE: ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚ãªãŸã‚’æ´»ç”¨ã™ã‚‹æ–¹æ³•ã‚’1æ–‡ã§ã€‚ï¼‰\n\n"
        "è‡ªç„¶ãªæ—¥æœ¬èªã§ã€æŠ¼ã—ã¤ã‘ãŒã¾ã—ããªãã€ã§ã‚‚è‡ªä¿¡ã‚’æŒã£ã¦èªã£ã¦ãã ã•ã„ã€‚"
    )

    # PURPOSE: SelfAdvocate ã®åˆæœŸåŒ–
    def __init__(self, model: str = "gemini-2.0-flash"):
        self._llm = PKSLLMClient(model=model)

    # PURPOSE: LLM åˆ©ç”¨å¯èƒ½ã‹ã©ã†ã‹
    @property
    def llm_available(self) -> bool:
        return self._llm.available

    # PURPOSE: KnowledgeNugget ã‹ã‚‰ä¸€äººç§°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
    def generate(
        self,
        nugget: KnowledgeNugget,
        context: Optional[SessionContext] = None,
    ) -> Advocacy:
        """è«–æ–‡ä¸€äººç§°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
        if self.llm_available:
            result = self._generate_llm(nugget, context)
            if result:
                return result
        return self._generate_template(nugget, context)

    # PURPOSE: è¤‡æ•°ãƒŠã‚²ãƒƒãƒˆã‚’ä¸€æ‹¬ã§ä¸€äººç§°å¤‰æ›
    def generate_batch(
        self,
        nuggets: list[KnowledgeNugget],
        context: Optional[SessionContext] = None,
    ) -> list[Advocacy]:
        """è¤‡æ•°ãƒŠã‚²ãƒƒãƒˆã‚’ä¸€æ‹¬ã§ä¸€äººç§°å¤‰æ›"""
        return [self.generate(n, context) for n in nuggets]

    # PURPOSE: Advocacy ãƒªã‚¹ãƒˆã‚’ Markdown ãƒ¬ãƒãƒ¼ãƒˆã«æ•´å½¢
    def format_report(self, advocacies: list[Advocacy]) -> str:
        """Advocacy ãƒªã‚¹ãƒˆã‚’ Markdown ãƒ¬ãƒãƒ¼ãƒˆã«æ•´å½¢"""
        if not advocacies:
            return "ğŸ“­ èªã‚Šã‹ã‘ã‚‹è«–æ–‡ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

        lines = [
            "## ğŸ“„ AutophÅnos â€” è«–æ–‡ãŒèªã‚Šã‹ã‘ã¦ã„ã¾ã™",
            "",
            f"_èªã‚Šã‹ã‘æ•°: {len(advocacies)} ä»¶_",
            "",
            "---",
        ]
        for adv in advocacies:
            lines.append("")
            lines.append(adv.to_markdown())
            lines.append("")
            lines.append("---")

        return "\n".join(lines)

    # --- LLM ç”Ÿæˆ ---

    # PURPOSE: Gemini ã§ä¸€äººç§°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ
    def _generate_llm(
        self,
        nugget: KnowledgeNugget,
        context: Optional[SessionContext],
    ) -> Optional[Advocacy]:
        """Gemini ã§ä¸€äººç§°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
        topics = ", ".join(context.topics) if context and context.topics else "(æœªè¨­å®š)"
        prompt = self._LLM_PROMPT.format(
            title=nugget.title,
            abstract=(nugget.abstract or "")[:500],
            source=nugget.source,
            topics=topics,
            score=f"{nugget.relevance_score:.2f}",
        )

        try:
            text = self._llm.generate(prompt)
            if text:
                return self._parse_llm_response(text, nugget)
        except Exception as e:
            print(f"[SelfAdvocate] LLM error: {e}")

        return None

    # PURPOSE: LLM å¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹
    def _parse_llm_response(
        self, text: str, nugget: KnowledgeNugget
    ) -> Optional[Advocacy]:
        """LLM å¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹"""
        voice_match = re.search(r"VOICE:\s*(.+?)(?=CONTRIBUTION:|$)", text, re.DOTALL)
        contrib_match = re.search(
            r"CONTRIBUTION:\s*(.+?)(?=HOW_TO_USE:|$)", text, re.DOTALL
        )
        how_match = re.search(r"HOW_TO_USE:\s*(.+?)$", text, re.DOTALL)

        voice = voice_match.group(1).strip() if voice_match else None
        contribution = contrib_match.group(1).strip() if contrib_match else ""
        how_to_use = how_match.group(1).strip() if how_match else ""

        if voice:
            return Advocacy(
                paper_title=nugget.title,
                voice=voice,
                key_contribution=contribution,
                how_to_use=how_to_use,
                relevance_score=nugget.relevance_score,
            )

        return None

    # --- ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ---

    # PURPOSE: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ä¸€äººç§°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ
    def _generate_template(
        self,
        nugget: KnowledgeNugget,
        context: Optional[SessionContext],
    ) -> Advocacy:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ä¸€äººç§°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ"""
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã®æ¥ç‚¹ã‚’è¦‹ã¤ã‘ã‚‹
        connection = self._find_context_connection(nugget, context)
        abstract_short = (nugget.abstract or "")[:150]

        voice = (
            f"ç§ã¯ã€{nugget.title}ã€ã§ã™ã€‚{connection}"
            f"ç§ã®ç ”ç©¶ã§ã¯ã€{abstract_short}... "
            f"ã‚ãªãŸã®ä½œæ¥­ã«æ–°ã—ã„è¦–ç‚¹ã‚’æä¾›ã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚"
        )

        contribution = nugget.push_reason or f"é–¢é€£åº¦ {nugget.relevance_score:.2f} ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«é©åˆ"

        how_to_use = (
            f"ã¾ãšã¯ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆã‚’ç¢ºèªã—ã€"
            f"ã‚ãªãŸã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã®æ¥ç‚¹ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚"
        )

        return Advocacy(
            paper_title=nugget.title,
            voice=voice,
            key_contribution=contribution,
            how_to_use=how_to_use,
            relevance_score=nugget.relevance_score,
        )

    # PURPOSE: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã®æ¥ç‚¹ã‚’æ—¥æœ¬èªã§èª¬æ˜
    def _find_context_connection(
        self,
        nugget: KnowledgeNugget,
        context: Optional[SessionContext],
    ) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã®æ¥ç‚¹ã‚’æ—¥æœ¬èªã§èª¬æ˜"""
        if not context or not context.topics:
            return ""

        title_lower = nugget.title.lower()
        abstract_lower = (nugget.abstract or "").lower()

        for topic in context.topics:
            if topic.lower() in title_lower or topic.lower() in abstract_lower:
                return f"ã‚ãªãŸãŒä»Šå–ã‚Šçµ„ã‚“ã§ã„ã‚‹ã€Œ{topic}ã€ã«é–¢ã—ã¦ã€ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚"

        return "ã‚ãªãŸã®ä½œæ¥­ã«é–¢é€£ãŒã‚ã‚‹ã¨æ„Ÿã˜ã¦ã‚„ã£ã¦ãã¾ã—ãŸã€‚"
