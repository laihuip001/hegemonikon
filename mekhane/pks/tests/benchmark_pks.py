#!/usr/bin/env python3
# PURPOSE: PKS æ¤œç´¢å“è³ªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ â€” Precision@K, MRR, Coverage, Latency ã‚’è‡ªå‹•è¨ˆæ¸¬
"""
PKS Search Quality Benchmark

4 ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (GnÅsis, Kairos, Sophia, Chronos) ã®æ¨ªæ–­æ¤œç´¢å“è³ªã‚’
15 ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã§å®šé‡è©•ä¾¡ã™ã‚‹ã€‚

Usage:
    cd ~/oikos/hegemonikon && PYTHONPATH=. .venv/bin/python mekhane/pks/tests/benchmark_pks.py
"""

import json
import os
import sys
import time
from dataclasses import dataclass, field, asdict
from pathlib import Path
from typing import Optional

# Add project root
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

# Suppress proxy/offline warnings
for key in ["HTTP_PROXY", "HTTPS_PROXY", "http_proxy", "https_proxy"]:
    os.environ.pop(key, None)
os.environ.setdefault("HF_HUB_OFFLINE", "1")
os.environ.setdefault("TRANSFORMERS_OFFLINE", "1")

# â”€â”€ Constants â”€â”€
MNEME_ROOT = Path.home() / "oikos" / "mneme" / ".hegemonikon"
INDICES_DIR = MNEME_ROOT / "indices"
REPORT_PATH = Path(__file__).parent / "benchmark_report.md"
RESULTS_JSON = Path(__file__).parent / "benchmark_results.json"


# â”€â”€ Test Query Set (15 queries, 5 categories Ã— 3) â”€â”€
BENCHMARK_QUERIES = [
    # Category 1: Theoretical Core (FEP / Active Inference)
    {
        "id": "T1",
        "category": "theoretical_core",
        "query": "FEP variational free energy minimization",
        "expected_sources": ["gnosis"],
        "relevance_keywords": ["free energy", "FEP", "variational", "Friston", "inference"],
        "description": "FEP ã®åŸºç¤ç†è«–",
    },
    {
        "id": "T2",
        "category": "theoretical_core",
        "query": "active inference expected free energy planning",
        "expected_sources": ["gnosis"],
        "relevance_keywords": ["active inference", "expected free energy", "planning", "EFE"],
        "description": "èƒ½å‹•çš„æ¨è«–ã¨è¨ˆç”»",
    },
    {
        "id": "T3",
        "category": "theoretical_core",
        "query": "Markov blanket self organization biological systems",
        "expected_sources": ["gnosis"],
        "relevance_keywords": ["Markov blanket", "self-organization", "biological", "partition"],
        "description": "ãƒãƒ«ã‚³ãƒ•æ¯›å¸ƒã¨è‡ªå·±çµ„ç¹”åŒ–",
    },
    # Category 2: HGK Concepts
    {
        "id": "H1",
        "category": "hgk_concepts",
        "query": "CCL cognitive control language workflow",
        "expected_sources": ["kairos", "sophia", "chronos"],
        "relevance_keywords": ["CCL", "cognitive", "control", "workflow", "HegemonikÃ³n"],
        "description": "CCL ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨€èª",
    },
    {
        "id": "H2",
        "category": "hgk_concepts",
        "query": "NoÄ“sis BoulÄ“sis ZÄ“tÄ“sis ousia series theorem",
        "expected_sources": ["kairos", "sophia", "gnosis"],
        "relevance_keywords": ["NoÄ“sis", "BoulÄ“sis", "ZÄ“tÄ“sis", "ousia", "theorem", "O-series"],
        "description": "O-series å®šç†ç¾¤",
    },
    {
        "id": "H3",
        "category": "hgk_concepts",
        "query": "äºŒå±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ criterion cognitive novelty tensor product",
        "expected_sources": ["kairos", "sophia", "gnosis"],
        "relevance_keywords": ["äºŒå±¤", "criterion", "novelty", "tensor", "ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼"],
        "description": "äºŒå±¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç†è«–",
    },
    # Category 3: Implementation
    {
        "id": "I1",
        "category": "implementation",
        "query": "PKS proactive knowledge surface push embedding",
        "expected_sources": ["kairos", "chronos"],
        "relevance_keywords": ["PKS", "proactive", "knowledge", "push", "embedding"],
        "description": "PKS å®Ÿè£…",
    },
    {
        "id": "I2",
        "category": "implementation",
        "query": "Dendron PROOF existence proof verification",
        "expected_sources": ["kairos", "chronos", "sophia"],
        "relevance_keywords": ["Dendron", "PROOF", "existence", "proof", "verification"],
        "description": "Dendron å­˜åœ¨è¨¼æ˜",
    },
    {
        "id": "I3",
        "category": "implementation",
        "query": "HermÄ“neus parser CCL AST dispatch runtime",
        "expected_sources": ["kairos", "chronos"],
        "relevance_keywords": ["HermÄ“neus", "parser", "CCL", "AST", "dispatch", "runtime"],
        "description": "HermÄ“neus ãƒ‘ãƒ¼ã‚µãƒ¼",
    },
    # Category 4: Cross-Domain
    {
        "id": "X1",
        "category": "cross_domain",
        "query": "category theory adjunction cognitive framework",
        "expected_sources": ["gnosis", "sophia"],
        "relevance_keywords": ["category", "adjunction", "cognitive", "functor", "åœè«–"],
        "description": "åœè«–ã¨èªçŸ¥ã®æ¥ç¶š",
    },
    {
        "id": "X2",
        "category": "cross_domain",
        "query": "precision weighting attention interoception prediction error",
        "expected_sources": ["gnosis"],
        "relevance_keywords": ["precision", "attention", "interoception", "prediction", "error"],
        "description": "ç²¾åº¦åŠ é‡ã¨æ³¨æ„",
    },
    {
        "id": "X3",
        "category": "cross_domain",
        "query": "Cortex API direct access bypass language server",
        "expected_sources": ["kairos", "chronos"],
        "relevance_keywords": ["Cortex", "API", "direct", "bypass", "language server"],
        "description": "Cortex API ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹",
    },
    # Category 5: Edge Cases
    {
        "id": "E1",
        "category": "edge_case",
        "query": "xylophone quantum teleportation recipe cooking",
        "expected_sources": [],
        "relevance_keywords": [],
        "description": "å®Œå…¨ç„¡é–¢ä¿‚ã‚¯ã‚¨ãƒª (ãƒã‚¤ã‚ºæ¤œå‡º)",
    },
    {
        "id": "E2",
        "category": "edge_case",
        "query": "æ—¥æœ¬èªã ã‘ã®ã‚¯ã‚¨ãƒª è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼åŸç† äºˆæ¸¬èª¤å·®æœ€å°åŒ–",
        "expected_sources": ["gnosis", "kairos"],
        "relevance_keywords": ["è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼", "äºˆæ¸¬èª¤å·®", "FEP"],
        "description": "æ—¥æœ¬èªã‚¯ã‚¨ãƒªã®ç²¾åº¦",
    },
    {
        "id": "E3",
        "category": "edge_case",
        "query": "boot handoff session bye workflow",
        "expected_sources": ["kairos", "chronos", "sophia"],
        "relevance_keywords": ["boot", "handoff", "session", "bye", "workflow"],
        "description": "é‹ç”¨ç³»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
    },
]


@dataclass
class SearchResult:
    """A single search result."""
    source: str
    score: float
    title: str
    snippet: str


@dataclass
class QueryResult:
    """Results for a single benchmark query."""
    query_id: str
    query: str
    category: str
    description: str
    results: list[SearchResult] = field(default_factory=list)
    latency_seconds: float = 0.0
    precision_at_5: float = 0.0
    mrr: float = 0.0
    source_coverage: float = 0.0
    keyword_hits: int = 0
    total_keywords: int = 0


def run_search(query: str, k: int = 10) -> tuple[list[SearchResult], float]:
    """Execute PKS search and return results with latency."""
    t0 = time.time()
    all_results = []

    # 1. GnÅsis (LanceDB)
    try:
        from mekhane.anamnesis.index import GnosisIndex
        gi = GnosisIndex()
        results = gi.search(query, k=k)
        for r in results:
            title = r.get("title", r.get("primary_key", "?"))
            dist = float(r.get("_distance", 1.0))
            score = max(0.0, min(1.0, 1.0 - dist / 2.0))
            snippet = r.get("abstract", r.get("content", ""))[:200]
            all_results.append(SearchResult("gnosis", score, title, snippet))
    except Exception as e:
        print(f"  âš ï¸ GnÅsis error: {e}", file=sys.stderr)

    # 2-4. pkl indices
    try:
        from mekhane.symploke.adapters.embedding_adapter import EmbeddingAdapter
        adapter = EmbeddingAdapter()
        query_vec = adapter.encode(query)

        for name in ["kairos", "sophia", "chronos"]:
            pkl = INDICES_DIR / f"{name}.pkl"
            if not pkl.exists():
                continue
            try:
                idx = EmbeddingAdapter()
                idx.load(str(pkl))
                hits = idx.search(query_vec, k=k)
                for hit in hits:
                    meta = hit.metadata if hasattr(hit, "metadata") else {}
                    title = meta.get("title", meta.get("doc_id", str(hit.id)))
                    hit_score = hit.score if hasattr(hit, "score") else 0
                    all_results.append(SearchResult(name, hit_score, title, ""))
            except Exception as e:
                print(f"  âš ï¸ {name} error: {e}", file=sys.stderr)
    except Exception as e:
        print(f"  âš ï¸ Embedder error: {e}", file=sys.stderr)

    elapsed = time.time() - t0
    all_results.sort(key=lambda x: x.score, reverse=True)
    return all_results, elapsed


def evaluate_relevance(result: SearchResult, keywords: list[str]) -> bool:
    """Check if a result is relevant based on keyword matching."""
    if not keywords:
        return False
    text = (result.title + " " + result.snippet).lower()
    hits = sum(1 for kw in keywords if kw.lower() in text)
    return hits >= max(1, len(keywords) // 3)


def compute_metrics(
    results: list[SearchResult],
    expected_sources: list[str],
    keywords: list[str],
    k: int = 5,
) -> tuple[float, float, float, int, int]:
    """Compute Precision@K, MRR, and Source Coverage."""
    top_k = results[:k]

    # Precision@K: fraction of relevant results in top-k
    relevant_count = sum(1 for r in top_k if evaluate_relevance(r, keywords))
    precision = relevant_count / k if k > 0 else 0.0

    # MRR: reciprocal rank of first relevant result
    mrr = 0.0
    for i, r in enumerate(results):
        if evaluate_relevance(r, keywords):
            mrr = 1.0 / (i + 1)
            break

    # Source Coverage: fraction of expected sources present in results
    if expected_sources:
        found_sources = set(r.source for r in top_k)
        coverage = len(found_sources & set(expected_sources)) / len(expected_sources)
    else:
        # Edge case: if no sources expected, coverage = 1.0 if results have low scores
        avg_score = sum(r.score for r in top_k) / len(top_k) if top_k else 0
        coverage = 1.0 if avg_score < 0.3 else 0.0

    # Keyword hit count
    all_text = " ".join((r.title + " " + r.snippet).lower() for r in top_k)
    keyword_hits = sum(1 for kw in keywords if kw.lower() in all_text) if keywords else 0

    return precision, mrr, coverage, keyword_hits, len(keywords)


def run_benchmark() -> list[QueryResult]:
    """Run the full benchmark suite."""
    print("=" * 60)
    print("PKS Search Quality Benchmark")
    print("=" * 60)
    print()

    query_results = []

    for i, q in enumerate(BENCHMARK_QUERIES, 1):
        print(f"[{i:2d}/{len(BENCHMARK_QUERIES)}] {q['id']}: {q['description']}...")

        results, latency = run_search(q["query"])
        precision, mrr, coverage, kw_hits, kw_total = compute_metrics(
            results, q["expected_sources"], q["relevance_keywords"]
        )

        qr = QueryResult(
            query_id=q["id"],
            query=q["query"],
            category=q["category"],
            description=q["description"],
            results=results[:10],
            latency_seconds=latency,
            precision_at_5=precision,
            mrr=mrr,
            source_coverage=coverage,
            keyword_hits=kw_hits,
            total_keywords=kw_total,
        )
        query_results.append(qr)

        # Progress indicator
        status = "âœ…" if precision >= 0.4 else "âš ï¸" if precision > 0 else "âŒ"
        print(f"       {status} P@5={precision:.2f} MRR={mrr:.2f} Cov={coverage:.2f} {latency:.1f}s")

    return query_results


def generate_report(results: list[QueryResult]) -> str:
    """Generate markdown benchmark report."""
    lines = []
    lines.append("# PKS æ¤œç´¢å“è³ªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¬ãƒãƒ¼ãƒˆ")
    lines.append("")
    lines.append(f"å®Ÿè¡Œæ—¥æ™‚: {time.strftime('%Y-%m-%d %H:%M')}")
    lines.append("")

    # Overall metrics
    avg_p5 = sum(r.precision_at_5 for r in results) / len(results)
    avg_mrr = sum(r.mrr for r in results) / len(results)
    avg_cov = sum(r.source_coverage for r in results) / len(results)
    avg_lat = sum(r.latency_seconds for r in results) / len(results)
    total_lat = sum(r.latency_seconds for r in results)

    lines.append("## ã‚µãƒãƒªãƒ¼")
    lines.append("")
    lines.append("| æŒ‡æ¨™ | å€¤ | ç›®æ¨™ | åˆ¤å®š |")
    lines.append("|:-----|---:|:----:|:----:|")
    lines.append(f"| **Precision@5** (å¹³å‡) | {avg_p5:.3f} | â‰¥ 0.60 | {'âœ…' if avg_p5 >= 0.6 else 'âš ï¸' if avg_p5 >= 0.4 else 'âŒ'} |")
    lines.append(f"| **MRR** (å¹³å‡) | {avg_mrr:.3f} | â‰¥ 0.50 | {'âœ…' if avg_mrr >= 0.5 else 'âš ï¸' if avg_mrr >= 0.3 else 'âŒ'} |")
    lines.append(f"| **Source Coverage** (å¹³å‡) | {avg_cov:.3f} | â‰¥ 0.70 | {'âœ…' if avg_cov >= 0.7 else 'âš ï¸' if avg_cov >= 0.5 else 'âŒ'} |")
    lines.append(f"| **Latency** (å¹³å‡) | {avg_lat:.1f}s | â‰¤ 15s | {'âœ…' if avg_lat <= 15 else 'âŒ'} |")
    lines.append(f"| **Latency** (åˆè¨ˆ) | {total_lat:.1f}s | â€” | â€” |")
    lines.append("")

    # Per-query results
    lines.append("## ã‚¯ã‚¨ãƒªåˆ¥çµæœ")
    lines.append("")
    lines.append("| ID | ã‚«ãƒ†ã‚´ãƒª | èª¬æ˜ | P@5 | MRR | Cov | Latency | KW |")
    lines.append("|:---|:---------|:-----|----:|----:|----:|--------:|---:|")
    for r in results:
        cat_short = r.category[:12]
        p5_icon = "âœ…" if r.precision_at_5 >= 0.6 else "âš ï¸" if r.precision_at_5 > 0 else "âŒ"
        kw_str = f"{r.keyword_hits}/{r.total_keywords}" if r.total_keywords > 0 else "â€”"
        lines.append(
            f"| {r.query_id} | {cat_short} | {r.description} | "
            f"{r.precision_at_5:.2f} {p5_icon} | {r.mrr:.2f} | {r.source_coverage:.2f} | "
            f"{r.latency_seconds:.1f}s | {kw_str} |"
        )
    lines.append("")

    # Category analysis
    lines.append("## ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ")
    lines.append("")
    categories = {}
    for r in results:
        if r.category not in categories:
            categories[r.category] = []
        categories[r.category].append(r)

    cat_names = {
        "theoretical_core": "ç†è«–ã‚³ã‚¢",
        "hgk_concepts": "HGK æ¦‚å¿µ",
        "implementation": "å®Ÿè£…",
        "cross_domain": "ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³",
        "edge_case": "ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹",
    }

    for cat, cat_results in categories.items():
        cat_p5 = sum(r.precision_at_5 for r in cat_results) / len(cat_results)
        cat_mrr = sum(r.mrr for r in cat_results) / len(cat_results)
        cat_cov = sum(r.source_coverage for r in cat_results) / len(cat_results)
        icon = "âœ…" if cat_p5 >= 0.6 else "âš ï¸" if cat_p5 >= 0.3 else "âŒ"
        lines.append(f"### {icon} {cat_names.get(cat, cat)} (P@5={cat_p5:.2f}, MRR={cat_mrr:.2f}, Cov={cat_cov:.2f})")
        lines.append("")
        for r in cat_results:
            lines.append(f"- **{r.query_id}** {r.description}: P@5={r.precision_at_5:.2f}")
            if r.results:
                top3 = r.results[:3]
                for j, sr in enumerate(top3, 1):
                    title_short = sr.title[:50]
                    lines.append(f"  {j}. [{sr.source}] {sr.score:.3f} â€” {title_short}")
        lines.append("")

    # Source distribution
    lines.append("## ã‚½ãƒ¼ã‚¹åˆ†å¸ƒ")
    lines.append("")
    source_counts: dict[str, int] = {}
    source_scores: dict[str, list[float]] = {}
    for r in results:
        for sr in r.results[:5]:
            source_counts[sr.source] = source_counts.get(sr.source, 0) + 1
            if sr.source not in source_scores:
                source_scores[sr.source] = []
            source_scores[sr.source].append(sr.score)

    lines.append("| ã‚½ãƒ¼ã‚¹ | å‡ºç¾å›æ•° (Top-5) | å¹³å‡ã‚¹ã‚³ã‚¢ | æœ€é«˜ | æœ€ä½ |")
    lines.append("|:-------|-----------------:|-----------:|-----:|-----:|")
    for src in ["gnosis", "kairos", "sophia", "chronos"]:
        cnt = source_counts.get(src, 0)
        scores = source_scores.get(src, [])
        if scores:
            avg_s = sum(scores) / len(scores)
            max_s = max(scores)
            min_s = min(scores)
            lines.append(f"| {src} | {cnt} | {avg_s:.3f} | {max_s:.3f} | {min_s:.3f} |")
        else:
            lines.append(f"| {src} | 0 | â€” | â€” | â€” |")
    lines.append("")

    # Weaknesses and recommendations
    lines.append("## å¼±ç‚¹åˆ†æ & æ”¹å–„ææ¡ˆ")
    lines.append("")

    weak_queries = [r for r in results if r.precision_at_5 < 0.4]
    if weak_queries:
        lines.append("### å¼±ã„ã‚¯ã‚¨ãƒª")
        lines.append("")
        for r in weak_queries:
            lines.append(f"- **{r.query_id}** ({r.description}): P@5={r.precision_at_5:.2f}")
            if r.category == "edge_case" and r.query_id == "E1":
                lines.append("  â†’ æœŸå¾…é€šã‚Šï¼ˆç„¡é–¢ä¿‚ã‚¯ã‚¨ãƒªï¼‰")
            else:
                lines.append(f"  â†’ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ’ãƒƒãƒˆ: {r.keyword_hits}/{r.total_keywords}")
        lines.append("")

    # Coverage issues
    low_cov = [r for r in results if r.source_coverage < 0.5 and r.category != "edge_case"]
    if low_cov:
        lines.append("### ã‚½ãƒ¼ã‚¹ã‚«ãƒãƒ¬ãƒƒã‚¸ä¸è¶³")
        lines.append("")
        for r in low_cov:
            found = set(sr.source for sr in r.results[:5])
            expected = set(r.category)  # simplified
            lines.append(f"- **{r.query_id}**: çµæœã‚½ãƒ¼ã‚¹={found}")
        lines.append("")

    lines.append("### æ”¹å–„ææ¡ˆ")
    lines.append("")
    lines.append("1. **ã‚¹ã‚³ã‚¢æ­£è¦åŒ–**: GnÅsis (L2è·é›¢) ã¨ pkl (cosine) ã®ç•°ãªã‚‹ã‚¹ã‚³ã‚¢ä½“ç³»ã‚’çµ±ä¸€")
    lines.append("2. **æ—¥æœ¬èªå¯¾å¿œ**: multilingual embedding ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡")
    lines.append("3. **ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ + ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°")
    lines.append("4. **ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°**: Sophia (116ä»¶) ã®æ‹¡å……")
    lines.append("")

    return "\n".join(lines)


def main():
    results = run_benchmark()

    # Generate report
    report = generate_report(results)
    REPORT_PATH.write_text(report, encoding="utf-8")
    print(f"\nğŸ“ Report: {REPORT_PATH}")

    # Save raw results as JSON
    json_data = []
    for r in results:
        d = {
            "query_id": r.query_id,
            "query": r.query,
            "category": r.category,
            "description": r.description,
            "precision_at_5": r.precision_at_5,
            "mrr": r.mrr,
            "source_coverage": r.source_coverage,
            "latency_seconds": r.latency_seconds,
            "keyword_hits": r.keyword_hits,
            "total_keywords": r.total_keywords,
            "top_results": [
                {"source": sr.source, "score": sr.score, "title": sr.title}
                for sr in r.results[:5]
            ],
        }
        json_data.append(d)
    RESULTS_JSON.write_text(json.dumps(json_data, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"ğŸ“Š Raw Data: {RESULTS_JSON}")

    # Summary
    avg_p5 = sum(r.precision_at_5 for r in results) / len(results)
    avg_mrr = sum(r.mrr for r in results) / len(results)
    print(f"\n{'='*40}")
    print(f"  Precision@5 = {avg_p5:.3f}  {'âœ…' if avg_p5 >= 0.6 else 'âš ï¸'}")
    print(f"  MRR         = {avg_mrr:.3f}  {'âœ…' if avg_mrr >= 0.5 else 'âš ï¸'}")
    print(f"{'='*40}")


if __name__ == "__main__":
    main()
