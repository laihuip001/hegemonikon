# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] O4â†’å‰µé€ æ©Ÿèƒ½ãŒå¿…è¦
"""
Doxa Cache â€” H4 Doxa Instantiation

Philosophical Reference:
    H4 Doxa (ä¿¡å¿µ): ä¿¡å¿µã®æ°¸ç¶šåŒ–ã€çµŒé¨“ã®è“„ç©

Design Principle:
    å‡¦ç†çµæžœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã€å†åˆ©ç”¨å¯èƒ½ã«ã™ã‚‹
    = çµŒé¨“ï¼ˆä¿¡å¿µï¼‰ã®è“„ç©ã¨è¨˜æ†¶

Original: Flow AI v5.0 CacheManager
Recast: HegemonikÃ³n H4 Doxa vocabulary
"""

import logging
import hashlib
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Optional, Any, Callable, List

from .metron_resolver import MetronResolver, METRON_LIGHT, METRON_MEDIUM, METRON_RICH

logger = logging.getLogger("doxa_cache")


class DoxaCache:
    """
    H4 Doxa ã® instantiation: ä¿¡å¿µã®æ°¸ç¶šåŒ–

    Philosophical Reference:
        Doxa (Î´ÏŒÎ¾Î±) = ã€Œä¿¡å¿µã€ã€Œæ„è¦‹ã€
        éŽåŽ»ã®å‡¦ç†çµæžœã‚’ã€Œä¿¡å¿µã€ã¨ã—ã¦ä¿å­˜ã—ã€å†åˆ©ç”¨ã™ã‚‹

    Design Principle:
        - TTL: ä¿¡å¿µã®è³žå‘³æœŸé™ï¼ˆå¤ããªã£ãŸä¿¡å¿µã¯æ¨ã¦ã‚‹ï¼‰
        - LRU: æœ€ã‚‚ä½¿ã‚ã‚Œã¦ã„ãªã„ä¿¡å¿µã‚’å„ªå…ˆçš„ã«å‰Šé™¤
        - ä¿¡é ¼åº¦: ã‚¨ãƒ©ãƒ¼çµæžœã¯ã€Œä¿¡å¿µã€ã¨ã—ã¦ä¿å­˜ã—ãªã„
    """

    @staticmethod
    def get_text_hash(text: str) -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ

        Philosophical Reference:
            ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’æŠ½å‡º
        """
        return hashlib.sha256(text.encode()).hexdigest()[:32]

    @staticmethod
    def sanitize_log(text: str) -> str:
        """
        ãƒ­ã‚°ç”¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ï¼‰

        Philosophical Reference:
            A2 EpochÄ“ ã¨ã®é€£æºï¼ˆåˆ¤æ–­ä¿ç•™çŠ¶æ…‹ã§ã®ãƒ­ã‚°ï¼‰
        """
        if not text:
            return "[empty]"
        text_hash = DoxaCache.get_text_hash(text)[:8]
        return f"[text:{text_hash}...len={len(text)}]"

    def __init__(self, settings: Dict = None):
        """
        Initialize DoxaCache

        Args:
            settings: Configuration with CACHE_TTL_HOURS, CACHE_MAX_ENTRIES
        """
        self.settings = settings or {
            "CACHE_TTL_HOURS": 24,
            "CACHE_MAX_ENTRIES": 1000,
        }
        # In-memory cache for standalone mode
        self._memory_cache: Dict[str, Dict] = {}

    def _check_ttl(self, cache_entry: Dict) -> bool:
        """
        TTL (è³žå‘³æœŸé™) ãƒã‚§ãƒƒã‚¯

        Philosophical Reference:
            å¤ã„ä¿¡å¿µã¯çœŸå®Ÿã§ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹
            K2 Chronos ã¨ã®é€£æºï¼ˆæ™‚é–“åˆ¶ç´„ï¼‰

        Returns:
            True if expired (should be removed)
        """
        created_at = cache_entry.get("created_at")
        if not created_at:
            return False

        ttl_hours = self.settings.get("CACHE_TTL_HOURS", 24)
        deadline = created_at + timedelta(hours=ttl_hours)

        if datetime.utcnow() > deadline:
            logger.info(f"ðŸ—‘ï¸ Doxa Expired: {cache_entry.get('hash_id', 'unknown')[:8]}")
            return True
        return False

    def _enforce_limit(self):
        """
        LRU (å®¹é‡åˆ¶é™) ãƒã‚§ãƒƒã‚¯

        Philosophical Reference:
            H3 Orexis ã¨ã®é€£æºï¼ˆå¿…è¦ãªä¿¡å¿µã‚’å„ªå…ˆï¼‰
            ä½¿ã‚ã‚Œãªã„ä¿¡å¿µã‚ˆã‚Šã€æ´»ããŸä¿¡å¿µã‚’ä¿æŒ
        """
        max_entries = self.settings.get("CACHE_MAX_ENTRIES", 1000)

        if len(self._memory_cache) > max_entries:
            # Sort by last_accessed_at and remove oldest
            sorted_keys = sorted(
                self._memory_cache.keys(),
                key=lambda k: self._memory_cache[k].get("last_accessed_at", datetime.min),
            )
            over = len(self._memory_cache) - max_entries
            for key in sorted_keys[:over]:
                del self._memory_cache[key]
            logger.info(f"ðŸ§¹ Doxa Limit Enforced: removed {over} entries")

    def check_cache(self, text: str, metron_level: int, db_session: Any = None) -> Optional[Dict]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¤œç´¢: ä¿¡å¿µã®æƒ³èµ·

        Philosophical Reference:
            AnamnÄ“sis (æƒ³èµ·): éŽåŽ»ã®çµŒé¨“ã‚’æ€ã„å‡ºã™

        Args:
            text: å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            metron_level: å‡¦ç†ãƒ¬ãƒ™ãƒ«
            db_session: Optional database session

        Returns:
            Cached result or None
        """
        text_hash = self.get_text_hash(text)
        cache_key = f"metron_{metron_level}"

        # Memory cache check
        cache_entry = self._memory_cache.get(text_hash)

        if cache_entry:
            # TTL Check
            if self._check_ttl(cache_entry):
                del self._memory_cache[text_hash]
                return None

            results = cache_entry.get("results", {})
            if cache_key in results:
                cached_result = results[cache_key]

                # Don't trust error results
                if isinstance(cached_result, str) and cached_result.startswith("Error:"):
                    return None

                # Update access time (LRU)
                cache_entry["last_accessed_at"] = datetime.utcnow()

                logger.info(f"ðŸ“¦ Doxa Hit: {self.sanitize_log(cached_result)}")
                return {
                    "result": cached_result,
                    "metron_level": metron_level,
                    "from_cache": True,
                    "model_used": None,
                }

        return None

    def store_cache(
        self, text: str, metron_level: int, result: str, db_session: Any = None
    ) -> None:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: ä¿¡å¿µã®æ°¸ç¶šåŒ–

        Philosophical Reference:
            H4 Doxa: çµŒé¨“ã‚’ä¿¡å¿µã¨ã—ã¦ä¿å­˜
        """
        text_hash = self.get_text_hash(text)
        cache_key = f"metron_{metron_level}"

        if text_hash not in self._memory_cache:
            self._memory_cache[text_hash] = {
                "hash_id": text_hash,
                "original_text": text,
                "results": {},
                "created_at": datetime.utcnow(),
                "last_accessed_at": datetime.utcnow(),
            }

        self._memory_cache[text_hash]["results"][cache_key] = result
        self._memory_cache[text_hash]["last_accessed_at"] = datetime.utcnow()

        # Enforce limit after storing
        self._enforce_limit()

        logger.info(f"ðŸ’¾ Doxa Stored: {self.sanitize_log(result)}")

    async def warmup_from_list(
        self,
        templates: List[str],
        client: Any,
        privacy: Any,
        callback: Callable = None,
        force: bool = False,
        db_session: Any = None,
    ) -> Dict:
        """
        Warmup: äº‹å‰ã«ä¿¡å¿µã‚’è“„ç©

        Philosophical Reference:
            K2 Chronos ã¨ã®é€£æºï¼ˆå°†æ¥ã«å‚™ãˆã‚‹ï¼‰

        Args:
            templates: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
            client: API client
            privacy: EpocheShield instance
            callback: Progress callback
            force: Force regeneration

        Returns:
            Statistics dict
        """
        stats = {"total": len(templates), "processed": 0, "skipped": 0, "errors": 0}
        levels = [METRON_LIGHT, METRON_MEDIUM, METRON_RICH]

        for i, text in enumerate(templates):
            text = text.strip()
            if not text:
                continue

            if callback:
                callback(i + 1, len(templates), text)

            try:
                text_hash = self.get_text_hash(text)
                cache_entry = self._memory_cache.get(text_hash)

                if cache_entry and not force:
                    if len(cache_entry.get("results", {})) >= 3:
                        stats["skipped"] += 1
                        continue

                for level in levels:
                    cache_key = f"metron_{level}"
                    if cache_entry and cache_key in cache_entry.get("results", {}) and not force:
                        continue

                    # Generate via API
                    masked, mapping = privacy.mask(text)
                    system_prompt = MetronResolver.get_system_prompt(level)

                    config = {"system": system_prompt, "params": {"temperature": 0.3}}

                    res = await client.generate_content(masked, config, model=None)

                    if res.get("success"):
                        final_text = res["result"]
                        if mapping:
                            final_text = privacy.unmask(final_text, mapping)

                        self.store_cache(text, level, final_text)
                        stats["processed"] += 1

                        # Rate limit protection
                        await asyncio.sleep(1.5)
                    else:
                        stats["errors"] += 1

            except Exception as e:
                logger.error(f"Warmup failed for {self.sanitize_log(text)}: {e}")
                stats["errors"] += 1

        return stats


# Backward compatibility alias
CacheManager = DoxaCache
