#!/usr/bin/env python3
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] <- mekhane/symploke/ A0â†’çŸ¥è­˜ç®¡ç†ãŒå¿…è¦â†’handoff_search ãŒæ‹…ã†
"""
Handoff & Conversation Search - /boot æ™‚ã«é–¢é€£ Handoff ã¨ä¼šè©±ãƒ­ã‚°ã‚’æ¤œç´¢

Usage:
    python handoff_search.py "query"                # Similar handoffs + conversations
    python handoff_search.py --latest               # Show latest handoff
    python handoff_search.py --recent 3             # Show 3 most recent
"""

import sys
import argparse
import logging
from pathlib import Path
from typing import List, Tuple
from datetime import datetime, timedelta

# Configure module logger
logger = logging.getLogger(__name__)

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from mekhane.symploke.kairos_ingest import (
    get_handoff_files,
    parse_handoff,
    get_conversation_files,
    parse_conversation,
)
from mekhane.symploke.adapters.embedding_adapter import EmbeddingAdapter
from mekhane.symploke.indices import Document

# Handoff ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ°¸ç¶šåŒ–ãƒ‘ã‚¹
HANDOFF_INDEX_PATH = Path(
    "/home/laihuip001/oikos/mneme/.hegemonikon/indices/handoffs.pkl"
)
# ä¼šè©±ãƒ­ã‚°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ°¸ç¶šåŒ–ãƒ‘ã‚¹ (Kairos ã¨å…±æœ‰)
CONVERSATION_INDEX_PATH = Path(
    "/home/laihuip001/oikos/mneme/.hegemonikon/indices/kairos.pkl"
)


def load_handoffs() -> List[Document]:
    """Load all handoffs as documents."""
    files = get_handoff_files()
    return [parse_handoff(f) for f in files]


def build_handoff_index(docs: List[Document] = None) -> EmbeddingAdapter:
    """Build and save handoff index."""
    if docs is None:
        docs = load_handoffs()

    if not docs:
        return None

    adapter = EmbeddingAdapter(model_name="all-MiniLM-L6-v2")

    # Encode all docs
    texts = [d.content for d in docs]
    doc_vectors = adapter.encode(texts)

    # Create index
    adapter.create_index(dimension=doc_vectors.shape[1])
    metadata = [
        {"doc_id": d.id, "idx": i, "primary_task": d.metadata.get("primary_task", "")}
        for i, d in enumerate(docs)
    ]
    adapter.add_vectors(doc_vectors, metadata=metadata)

    # Save
    HANDOFF_INDEX_PATH.parent.mkdir(parents=True, exist_ok=True)
    adapter.save(str(HANDOFF_INDEX_PATH))
    print(f"ğŸ’¾ Handoff index saved: {len(docs)} docs")

    return adapter


def load_handoff_index() -> EmbeddingAdapter:
    """Load saved handoff index."""
    adapter = EmbeddingAdapter(model_name="all-MiniLM-L6-v2")
    adapter.load(str(HANDOFF_INDEX_PATH))
    return adapter


# ã‚¹ã‚³ã‚¢èª¿æ•´è¨­å®š
SCORE_BOOST = {
    "handoff": 0.08,  # æ§‹é€ åŒ–ã•ã‚ŒãŸç·æ‹¬ã¯ä¾¡å€¤ãŒé«˜ã„
    "conversation": 0.0,  # ç”Ÿã®ä¼šè©±ã¯åŸºæº–å€¤
    "conversation_chunk": 0.0,  # ãƒãƒ£ãƒ³ã‚¯ã‚‚åŸºæº–å€¤
}


def adjust_score(score: float, doc_type: str) -> float:
    """ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢ã‚’èª¿æ•´ã™ã‚‹ã€‚

    Handoff ã¯æ§‹é€ åŒ–ã•ã‚ŒãŸç·æ‹¬ãªã®ã§ã€ç”Ÿã®ä¼šè©±ã‚ˆã‚Šä¾¡å€¤ãŒé«˜ã„ã¨ã¿ãªã™ã€‚
    æ™‚é–“æ¸›è¡°ã¯å®Ÿè£…ã—ãªã„ï¼ˆåŸå‰‡ãƒ»æ´å¯Ÿã®ä¾¡å€¤ã¯æ™‚é–“ã«ä¾å­˜ã—ãªã„ï¼‰ã€‚
    """
    boost = SCORE_BOOST.get(doc_type, 0.0)
    return min(1.0, score + boost)


def extract_keywords(doc: Document, max_keywords: int = 5) -> List[str]:
    """Handoff ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆProactive Recall ç”¨ï¼‰"""
    content = doc.content
    keywords = []

    # primary_task ã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã—ã¦æŠ½å‡º
    primary_task = doc.metadata.get("primary_task", "")
    if primary_task:
        keywords.append(primary_task)

    # æ—¥æœ¬èªã®é‡è¦ãã†ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
    import re

    # ã‚«ã‚¿ã‚«ãƒŠèªã‚’æŠ½å‡º
    katakana = re.findall(r"[ã‚¡-ãƒ´ãƒ¼]{3,}", content)
    keywords.extend(katakana[:3])

    # è‹±èªã®é‡è¦ãã†ãªèªã‚’æŠ½å‡º
    english = re.findall(r"[A-Z][a-z]+(?:[A-Z][a-z]+)*", content)
    keywords.extend(english[:3])

    return list(set(keywords))[:max_keywords]


def search_handoffs(query: str, top_k: int = 5) -> List[Tuple[Document, float]]:
    """Search handoffs by semantic similarity using cached index."""
    docs = load_handoffs()
    if not docs:
        return []

    # æ°¸ç¶šåŒ–ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼ˆãªã‘ã‚Œã°ãƒ“ãƒ«ãƒ‰ï¼‰
    if HANDOFF_INDEX_PATH.exists():
        adapter = load_handoff_index()
    else:
        adapter = build_handoff_index(docs)
        if adapter is None:
            return []

    # Search
    query_vector = adapter.encode([query])[0]
    results = adapter.search(query_vector, k=top_k)

    # Match results to docs (using idx from metadata)
    matched = []
    for r in results:
        idx = r.metadata.get("idx", r.id)
        if idx < len(docs):
            matched.append((docs[idx], r.score))

    return matched


def get_boot_handoffs(mode: str = "standard", context: str = None) -> dict:
    """
    /boot çµ±åˆ API: ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸ Handoff ã¨ä¼šè©±ãƒ­ã‚°ã‚’è¿”ã™

    Args:
        mode: "fast" (/boot-), "standard" (/boot), "detailed" (/boot+)
        context: ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ¤œç´¢ã‚¯ã‚¨ãƒªã«ä½¿ç”¨ï¼‰

    Returns:
        dict: {
            "latest": Document,           # æœ€æ–°ã® Handoff
            "related": List[Document],    # é–¢é€£ã™ã‚‹ Handoff
            "conversations": List[Document],  # é–¢é€£ã™ã‚‹ä¼šè©±ãƒ­ã‚° â† NEW
            "count": int                  # é–¢é€£ä»¶æ•° (handoff + conversation)
        }
    """
    # ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã‚‹é–¢é€£ä»¶æ•°
    related_count = {
        "fast": 0,  # /boot- : æœ€æ–°ã®ã¿
        "standard": 3,  # /boot  : æœ€æ–° + é–¢é€£ 3
        "detailed": 10,  # /boot+ : æœ€æ–° + é–¢é€£ 10
    }.get(mode, 3)

    conv_count = {
        "fast": 0,  # /boot- : ãªã—
        "standard": 2,  # /boot  : é–¢é€£ä¼šè©± 2
        "detailed": 5,  # /boot+ : é–¢é€£ä¼šè©± 5
    }.get(mode, 2)

    docs = load_handoffs()
    if not docs:
        return {"latest": None, "related": [], "conversations": [], "count": 0}

    latest = docs[0]

    # æ¤œç´¢ã‚¯ã‚¨ãƒª
    query = context or latest.metadata.get("primary_task", latest.content[:200])

    # é–¢é€£ Handoff æ¤œç´¢
    related = []
    if related_count > 0:
        results = search_handoffs(query, top_k=related_count + 1)
        related = [doc for doc, score in results if doc.id != latest.id][:related_count]

    # é–¢é€£ä¼šè©±ãƒ­ã‚°æ¤œç´¢ (Kairos Index ã‚’ä½¿ç”¨)
    conversations = []
    if conv_count > 0 and CONVERSATION_INDEX_PATH.exists():
        try:
            adapter = EmbeddingAdapter(model_name="all-MiniLM-L6-v2")
            adapter.load(str(CONVERSATION_INDEX_PATH))
            query_vec = adapter.encode([query])[0]
            results = adapter.search(query_vec, k=conv_count)

            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å†æ§‹ç¯‰
            for r in results:
                file_path = r.metadata.get("file_path")
                if file_path and Path(file_path).exists():
                    doc = parse_conversation(Path(file_path))
                    # ã‚¹ã‚³ã‚¢èª¿æ•´ã‚’é©ç”¨
                    adjusted_score = adjust_score(r.score, "conversation")
                    doc.metadata["score"] = adjusted_score
                    doc.metadata["raw_score"] = r.score
                    conversations.append(doc)
        except Exception as e:
            print(f"âš ï¸ Conversation search error: {e}")

    # Proactive Recall: æœ€æ–° Handoff ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã€è¿½åŠ æ¤œç´¢
    proactive_memories = []
    if mode == "detailed" and latest:
        keywords = extract_keywords(latest)
        if keywords and CONVERSATION_INDEX_PATH.exists():
            try:
                proactive_query = " ".join(keywords[:3])
                adapter = EmbeddingAdapter(model_name="all-MiniLM-L6-v2")
                adapter.load(str(CONVERSATION_INDEX_PATH))
                query_vec = adapter.encode([proactive_query])[0]
                results = adapter.search(query_vec, k=3)

                for r in results:
                    file_path = r.metadata.get("file_path")
                    if file_path and Path(file_path).exists():
                        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                        if not any(
                            c.metadata.get("file_path") == file_path
                            for c in conversations
                        ):
                            doc = parse_conversation(Path(file_path))
                            doc.metadata["score"] = adjust_score(
                                r.score, "conversation"
                            )
                            doc.metadata["proactive"] = (
                                True  # Proactive Recall ã§ãƒ’ãƒƒãƒˆ
                            )
                            proactive_memories.append(doc)
            except Exception as e:
                logger.error(f"âš ï¸ Proactive recall error: {e}", exc_info=True)

    return {
        "latest": latest,
        "related": related,
        "conversations": conversations,
        "proactive": proactive_memories,  # NEW: Proactive Recall çµæœ
        "count": len(related) + len(conversations) + len(proactive_memories),
    }


def format_boot_output(result: dict, verbose: bool = False) -> str:
    """
    /boot ç”¨ã®å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    """
    lines = []

    if result["latest"]:
        doc = result["latest"]
        lines.append("ğŸ“‹ æœ€æ–° Handoff:")
        lines.append(f"  ID: {doc.id}")
        lines.append(f"  ä¸»é¡Œ: {doc.metadata.get('primary_task', 'Unknown')}")
        lines.append(f"  æ™‚åˆ»: {doc.metadata.get('timestamp', 'Unknown')}")
        if verbose:
            lines.append(f"  å†…å®¹: {doc.content[:300]}...")
        lines.append("")

    if result.get("related"):
        lines.append(f"ğŸ”— é–¢é€£ Handoff ({len(result['related'])}ä»¶):")
        for doc in result["related"]:
            lines.append(f"  â€¢ {doc.metadata.get('primary_task', doc.id)}")
            lines.append(f"    æ™‚åˆ»: {doc.metadata.get('timestamp', 'Unknown')}")
        lines.append("")

    # NEW: ä¼šè©±ãƒ­ã‚°è¡¨ç¤º
    if result.get("conversations"):
        lines.append(f"ğŸ’¬ é–¢é€£ã™ã‚‹éå»ã®ä¼šè©± ({len(result['conversations'])}ä»¶):")
        for doc in result["conversations"]:
            score = doc.metadata.get("score", 0)
            msg_count = doc.metadata.get("msg_count", 0)
            title = doc.metadata.get("title", doc.id)
            lines.append(f"  â€¢ {title} ({msg_count} msgs, score: {score:.2f})")
            lines.append(f"    ID: {doc.id}")
        lines.append("")

    # NEW: Proactive Recall è¡¨ç¤º
    if result.get("proactive"):
        lines.append(f"ğŸ§  è‡ªå‹•æµ®ä¸Šã—ãŸè¨˜æ†¶ ({len(result['proactive'])}ä»¶):")
        for doc in result["proactive"]:
            score = doc.metadata.get("score", 0)
            title = doc.metadata.get("title", doc.id)
            lines.append(f"  âœ¨ {title} (score: {score:.2f})")

    return "\n".join(lines)


def show_latest(n: int = 1):
    """Show N most recent handoffs."""
    docs = load_handoffs()[:n]
    for doc in docs:
        print(f"\n{'='*60}")
        print(f"ğŸ“„ {doc.id}")
        print(f"ä¸»é¡Œ: {doc.metadata.get('primary_task', 'Unknown')}")
        print(f"æ™‚åˆ»: {doc.metadata.get('timestamp', 'Unknown')}")
        print("-" * 60)
        print(doc.content[:500] + "..." if len(doc.content) > 500 else doc.content)


def main():
    parser = argparse.ArgumentParser(description="Search handoffs for /boot")
    parser.add_argument("query", nargs="?", help="Search query")
    parser.add_argument("--latest", action="store_true", help="Show latest handoff")
    parser.add_argument("--recent", type=int, help="Show N most recent handoffs")
    parser.add_argument("-k", type=int, default=3, help="Number of results")
    parser.add_argument(
        "--boot",
        choices=["fast", "standard", "detailed"],
        help="/boot mode: fast (-), standard, detailed (+)",
    )
    parser.add_argument("--context", type=str, help="Context for /boot search")
    parser.add_argument("-v", "--verbose", action="store_true", help="Verbose output")
    args = parser.parse_args()

    # /boot mode
    if args.boot:
        result = get_boot_handoffs(mode=args.boot, context=args.context)
        print(format_boot_output(result, verbose=args.verbose))
        return

    if args.latest:
        show_latest(1)
    elif args.recent:
        show_latest(args.recent)
    elif args.query:
        print(f'ğŸ” Searching: "{args.query}"\n')
        results = search_handoffs(args.query, top_k=args.k)

        if not results:
            print("No matching handoffs found.")
            return

        for doc, score in results:
            print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            print(f"ğŸ“Š Score: {score:.3f}")
            print(f"ğŸ“„ {doc.id}")
            print(f"ä¸»é¡Œ: {doc.metadata.get('primary_task', 'Unknown')}")
            print(f"æ™‚åˆ»: {doc.metadata.get('timestamp', 'Unknown')}")
            print()
    else:
        # Default: show latest
        show_latest(1)


if __name__ == "__main__":
    main()
