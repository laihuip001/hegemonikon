# ネスト深度警報者 レビュー

## 対象ファイル
`mekhane/ergasterion/digestor/pipeline.py`

## 判定
発言（要改善）

## 発見事項
- [High] `_load_existing_keys`: ネスト深度 8 (Gnosis JSON読み込み部分)
- [High] `_load_existing_keys`: ネスト深度 5 (Sophia pickle読み込み部分)
- [High] `_fetch_from_gnosis`: ネスト深度 5 (リトライロジック内の条件分岐)
- [High] `_deduplicate_by_similarity`: ネスト深度 4 (類似度計算ループ内の条件分岐)
- [Medium] `_save_report`: リスト内包表記のネスト深度 2

## 修正案

### 1. `_load_existing_keys` の改善 (Gnosis)
Gnosis インデックス読み込み部分を独立したメソッド `_load_gnosis_keys` に抽出し、ガード節を活用してネストを浅くする。

```python
    def _load_gnosis_keys(self) -> set[str]:
        keys = set()
        gnosis_path = Path.home() / ".hegemonikon" / "gnosis"
        if not gnosis_path.exists():
            return keys

        for json_file in gnosis_path.glob("*.json"):
            try:
                with open(json_file, "r") as f:
                    data = json.load(f)

                if isinstance(data, list):
                    for item in data:
                        if isinstance(item, dict):
                            pk = item.get("primary_key") or item.get("id", "")
                            if pk: keys.add(pk)
                elif isinstance(data, dict):
                    pk = data.get("primary_key") or data.get("id", "")
                    if pk: keys.add(pk)
            except Exception:
                continue
        return keys
```

### 2. `_load_existing_keys` の改善 (Sophia)
Sophia インデックス読み込み部分も `_load_sophia_keys` に抽出する。

```python
    def _load_sophia_keys(self) -> set[str]:
        keys = set()
        sophia_path = Path.home() / ".hegemonikon" / "sophia" / "sophia.pkl"
        if not sophia_path.exists():
            return keys

        try:
            import pickle
            with open(sophia_path, "rb") as f:
                data = pickle.load(f)

            metadata = data.get("metadata", {})
            for _id, meta in metadata.items():
                if isinstance(meta, dict):
                    title = meta.get("title", "")
                    if title:
                        keys.add(f"title:{title}")
        except Exception as e:
            print(f"[Digestor]   → Sophia keys load failed: {e}")

        return keys
```

### 3. `_fetch_from_gnosis` の改善
リトライロジックを `_search_with_retry` として切り出す。

```python
    def _search_with_retry(self, collector, query: str, max_papers: int) -> list:
        papers = []
        max_retries = 3
        for attempt in range(max_retries):
            try:
                return collector.search(query, max_results=max_papers)
            except Exception as e:
                if attempt == max_retries - 1:
                    print(f"[Digestor] Query '{query[:30]}...' failed after {max_retries} attempts: {e}")
                    return []

                wait = 3 * (2 ** attempt)
                print(f"[Digestor] Query '{query[:30]}...' failed (attempt {attempt + 1}/{max_retries}): {e}")
                print(f"[Digestor]   → Retrying in {wait}s...")
                _time.sleep(wait)
        return []
```

### 4. `_deduplicate_by_similarity` の改善
類似度計算ループ内の条件分岐を整理し、計算ロジックを簡素化するかメソッド抽出する。

### 5. `_save_report` の改善
辞書生成部分をループ展開するか、ヘルパー関数を使用する。

```python
    candidates_data = []
    for c in result.candidates:
        suggested = [
            {"id": tid, "score": round(s, 3)}
            for tid, s in (c.suggested_templates or [])
        ]
        candidates_data.append({
            "title": c.paper.title,
            # ...
            "suggested_templates": suggested,
        })
```

## 重大度
High
