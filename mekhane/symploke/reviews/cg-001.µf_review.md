# ネスト深度警報者 レビュー

## 対象ファイル
`mekhane/ergasterion/digestor/pipeline.py`

## 判定
発言（要改善）

## 発見事項
- **_load_existing_keys**: ネスト深度 7 (High)
  - `try` (L1) -> `if` (L2) -> `for` (L3) -> `try` (L4) -> `if` (L5) -> `for` (L6) -> `if` (L7)
  - Gnosis インデックス読み込み処理が深くネストしている。
- **_fetch_from_gnosis**: ネスト深度 5 (High)
  - `try` (L1) -> `for` (L2) -> `for` (L3) -> `try` (L4) -> `if` (L5)
  - APIリトライロジックが深くネストしている。
- **_deduplicate_by_similarity**: ネスト深度 4 (High)
  - `try` (L1) -> `for` (L2) -> `for` (L3) -> `if` (L4)
  - ベクトル類似度計算ループが深くネストしている。

## 提案
ガード節（Guard Clause）や関数抽出（Extract Method）を使用してネストを浅くすることを推奨します。

### _load_existing_keys の改善案
```python
def _load_existing_keys(self) -> set[str]:
    keys = set()
    keys.update(self._load_gnosis_keys())
    keys.update(self._load_sophia_keys())
    if keys:
        print(f"[Digestor]   → Loaded {len(keys)} existing keys for dedup")
    return keys

def _load_gnosis_keys(self) -> set[str]:
    keys = set()
    path = Path.home() / ".hegemonikon" / "gnosis"
    if not path.exists():
        return keys

    for json_file in path.glob("*.json"):
        try:
            with open(json_file, "r") as f:
                data = json.load(f)
            keys.update(self._extract_keys_from_json(data))
        except Exception:
            continue
    return keys

def _extract_keys_from_json(self, data) -> set[str]:
    keys = set()
    items = data if isinstance(data, list) else [data]
    for item in items:
        if isinstance(item, dict):
             pk = item.get("primary_key") or item.get("id")
             if pk:
                 keys.add(pk)
    return keys
```

### _fetch_from_gnosis の改善案
リトライロジックを別メソッド `_fetch_with_retry` に抽出することでネストを削減可能です。

### _deduplicate_by_similarity の改善案
ベクトル計算部分を `_calculate_max_similarity` メソッドなどに抽出することでループのネストを削減可能です。

## 重大度
High
