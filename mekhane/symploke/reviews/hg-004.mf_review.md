# CCL式美学者 レビュー

## 対象ファイル
`mekhane/ochema/antigravity_client.py`

## 判定
発言（要改善）

## 発見事項
- (High) `session_episodes` メソッドのネストが深すぎます (レベル7)。`if os.path.isdir`, `if count > 0`, `if os.path.isfile`, `with open`, `for line`, `if line.startswith` と連なっており、可読性が著しく低下しています。ヘルパーメソッドへの分割を強く推奨します。
- (Medium) `_detect_ls` メソッド内のループと条件分岐のネストがレベル4に達しています。リスト内包表記やガード節（early return）を使用して平坦化可能です。
- (Medium) `session_read` メソッドの `for` ループ内の `if/elif` ブロックにおいて、`items` のループや `text` の抽出処理によりネストがレベル4に達しています。
- (Medium) `_poll_response` メソッドの `while` ループ内で `try-except` ブロックと `if` 文が重なり、ネストがレベル4に達しています。

## 重大度
High

## 修正案

### `session_episodes` のリファクタリング

```python
    def session_episodes(self, brain_id: Optional[str] = None) -> dict:
        """過去セッションのエピソード記憶 (.system_generated/steps/) にアクセスする。"""
        if not os.path.isdir(BRAIN_DIR):
            return {"error": f"Brain directory not found: {BRAIN_DIR}"}

        if brain_id:
            return self._get_single_brain_episodes(brain_id)

        return self._list_all_brains()

    def _get_single_brain_episodes(self, brain_id: str) -> dict:
        brain_path = os.path.join(BRAIN_DIR, brain_id, ".system_generated", "steps")
        if not os.path.isdir(brain_path):
            return {"error": f"No episodes for brain {brain_id}"}

        episodes = []
        for step_dir in sorted(os.listdir(brain_path)):
            output_file = os.path.join(brain_path, step_dir, "output.txt")
            if not os.path.isfile(output_file):
                continue

            size = os.path.getsize(output_file)
            try:
                with open(output_file, "r", errors="replace") as f:
                    preview = f.read(200)
            except Exception:
                preview = ""

            episodes.append({
                "step": int(step_dir) if step_dir.isdigit() else step_dir,
                "size_bytes": size,
                "preview": preview,
            })

        return {
            "brain_id": brain_id,
            "total_episodes": len(episodes),
            "episodes": episodes,
        }

    def _list_all_brains(self) -> dict:
        brains = []
        for entry in os.listdir(BRAIN_DIR):
            brain_path = os.path.join(BRAIN_DIR, entry)
            if not os.path.isdir(brain_path):
                continue

            sys_gen = os.path.join(brain_path, ".system_generated", "steps")
            if not os.path.isdir(sys_gen):
                continue

            episode_count = self._count_episodes(sys_gen)
            if episode_count > 0:
                brains.append({
                    "brain_id": entry,
                    "episode_count": episode_count,
                    "title": self._get_brain_title(brain_path),
                })

        brains.sort(key=lambda x: x["episode_count"], reverse=True)
        return {
            "total_brains": len(brains),
            "brains": brains,
        }

    def _count_episodes(self, steps_dir: str) -> int:
        return len([
            d for d in os.listdir(steps_dir)
            if os.path.isfile(os.path.join(steps_dir, d, "output.txt"))
        ])

    def _get_brain_title(self, brain_dir: str) -> str:
        task_file = os.path.join(brain_dir, "task.md")
        if not os.path.isfile(task_file):
            return ""

        try:
            with open(task_file, "r", errors="replace") as f:
                for line in f:
                    if line.startswith("# "):
                        return line[2:].strip()
        except Exception:
            pass
        return ""
```

### `_detect_ls` の改善方針

ループ内で `ws_normalized` のチェックと `grep` の除外を行う部分を、リスト内包表記またはフィルタ関数に抽出することでネストを削減できます。

```python
    def _find_ls_process_line(self) -> Optional[str]:
        # ... (ps aux 取得) ...

        ws_normalized = self.workspace.replace("-", "_")
        candidates = [
            line for line in ps_out.splitlines()
            if "language_server_linux" in line
            and "grep" not in line
            and ws_normalized in line.replace("-", "_")
        ]
        return candidates[0] if candidates else None
```
