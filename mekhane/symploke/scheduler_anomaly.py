#!/usr/bin/env python3
# PROOF: [L2/Infra] <- mekhane/symploke/scheduler_anomaly.py H3â†’Infraâ†’Symploke
"""F22: Scheduler Anomaly Detector â€” æˆåŠŸç‡ä½ä¸‹ã‚„é€£ç¶šå¤±æ•—ã‚’æ¤œçŸ¥ã— Sympatheia ã«é€šçŸ¥ã™ã‚‹ã€‚

ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©å®Ÿè¡Œçµæœã‚’åˆ†æã—ã€
ç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæˆåŠŸç‡æ€¥è½ã€é€£ç¶šå¤±æ•—ã€ã‚¼ãƒ­ã‚¿ã‚¹ã‚¯é€±ï¼‰ã‚’æ¤œå‡ºã™ã‚‹ã€‚

Usage:
    python scheduler_anomaly.py [--days 7] [--notify]
"""
from __future__ import annotations

import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional

logger = logging.getLogger(__name__)

_PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
LOG_DIR = _PROJECT_ROOT / "logs" / "scheduler"

# ç•°å¸¸åˆ¤å®šé–¾å€¤
THRESHOLD_SUCCESS_RATE = 0.6    # æˆåŠŸç‡ãŒã“ã‚Œä»¥ä¸‹ã§è­¦å‘Š
THRESHOLD_CONSECUTIVE_FAIL = 3  # é€£ç¶šå¤±æ•—å›æ•°
THRESHOLD_MIN_TASKS_PER_WEEK = 3  # é€±ã‚ãŸã‚Šæœ€å°ã‚¿ã‚¹ã‚¯æ•°


class AnomalyReport:
    """ç•°å¸¸æ¤œçŸ¥ãƒ¬ãƒãƒ¼ãƒˆã€‚"""
    def __init__(self) -> None:
        self.anomalies: list[dict] = []
        self.stats: dict = {}

    def add(self, kind: str, severity: str, message: str, data: Optional[dict] = None) -> None:
        self.anomalies.append({
            "kind": kind,
            "severity": severity,
            "message": message,
            "data": data or {},
            "detected_at": datetime.now().isoformat(),
        })

    @property
    def has_critical(self) -> bool:
        return any(a["severity"] == "CRITICAL" for a in self.anomalies)

    @property
    def has_warnings(self) -> bool:
        return len(self.anomalies) > 0

    def to_dict(self) -> dict:
        return {
            "total_anomalies": len(self.anomalies),
            "has_critical": self.has_critical,
            "anomalies": self.anomalies,
            "stats": self.stats,
            "generated_at": datetime.now().isoformat(),
        }


def _load_recent_logs(days: int = 7) -> list[dict]:
    """ç›´è¿‘ N æ—¥åˆ†ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã‚€ã€‚"""
    if not LOG_DIR.exists():
        return []

    cutoff = datetime.now() - timedelta(days=days)
    logs = []

    for f in sorted(LOG_DIR.glob("scheduler_*.json"), reverse=True):
        try:
            data = json.loads(f.read_text())
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ¨å®š: scheduler_YYYYMMDD_HHMM.json
            name_parts = f.stem.replace("scheduler_", "").split("_")
            if len(name_parts) >= 1:
                date_str = name_parts[0]
                file_date = datetime.strptime(date_str, "%Y%m%d")
                if file_date >= cutoff:
                    data["_file"] = str(f.name)
                    data["_date"] = file_date.isoformat()
                    logs.append(data)
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"Failed to parse {f}: {e}")

    return logs


def detect_anomalies(days: int = 7) -> AnomalyReport:
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ­ã‚°ã‚’åˆ†æã—ç•°å¸¸ã‚’æ¤œçŸ¥ã™ã‚‹ã€‚"""
    report = AnomalyReport()
    logs = _load_recent_logs(days)

    if not logs:
        report.stats = {"total_runs": 0, "period_days": days}
        report.add(
            kind="no_data",
            severity="WARNING",
            message=f"ç›´è¿‘ {days} æ—¥é–“ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ­ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
        )
        return report

    # åŸºæœ¬çµ±è¨ˆ
    total_tasks = sum(log.get("total_tasks", 0) for log in logs)
    total_started = sum(log.get("total_started", 0) for log in logs)
    total_failed = sum(log.get("total_failed", 0) for log in logs)
    success_rate = (total_started - total_failed) / total_started if total_started > 0 else 0.0

    report.stats = {
        "total_runs": len(logs),
        "total_tasks": total_tasks,
        "total_started": total_started,
        "total_failed": total_failed,
        "success_rate": round(success_rate, 3),
        "period_days": days,
    }

    # ç•°å¸¸1: å…¨ä½“æˆåŠŸç‡ä½ä¸‹
    if success_rate < THRESHOLD_SUCCESS_RATE and total_started > 0:
        report.add(
            kind="low_success_rate",
            severity="CRITICAL" if success_rate < 0.3 else "WARNING",
            message=f"æˆåŠŸç‡ãŒ {success_rate:.0%} ã«ä½ä¸‹ (é–¾å€¤: {THRESHOLD_SUCCESS_RATE:.0%})",
            data={"success_rate": success_rate, "threshold": THRESHOLD_SUCCESS_RATE},
        )

    # ç•°å¸¸2: é€£ç¶šå¤±æ•—
    consecutive_fails = 0
    max_consecutive = 0
    for log in logs:  # newest first
        failed = log.get("total_failed", 0)
        started = log.get("total_started", 0)
        if started > 0 and failed / started > 0.5:
            consecutive_fails += 1
            max_consecutive = max(max_consecutive, consecutive_fails)
        else:
            consecutive_fails = 0

    if max_consecutive >= THRESHOLD_CONSECUTIVE_FAIL:
        report.add(
            kind="consecutive_failures",
            severity="CRITICAL",
            message=f"{max_consecutive} å›é€£ç¶šã§éåŠæ•°ãŒå¤±æ•—",
            data={"consecutive": max_consecutive, "threshold": THRESHOLD_CONSECUTIVE_FAIL},
        )

    # ç•°å¸¸3: ã‚¿ã‚¹ã‚¯æ•°ä¸è¶³ (æ´»å‹•ä½ä¸‹)
    if len(logs) < THRESHOLD_MIN_TASKS_PER_WEEK and days >= 7:
        report.add(
            kind="low_activity",
            severity="WARNING",
            message=f"ç›´è¿‘ {days} æ—¥é–“ã®å®Ÿè¡Œå›æ•°ãŒ {len(logs)} å› (æœ€å°: {THRESHOLD_MIN_TASKS_PER_WEEK})",
            data={"runs": len(logs), "threshold": THRESHOLD_MIN_TASKS_PER_WEEK},
        )

    return report


def notify_sympatheia(report: AnomalyReport) -> dict:
    """Sympatheia API ã«ç•°å¸¸é€šçŸ¥ã‚’é€ä¿¡ã™ã‚‹ã€‚"""
    import urllib.request

    payload = {
        "source": "scheduler_anomaly",
        "level": "CRITICAL" if report.has_critical else "WARNING",
        "title": f"Scheduler Anomaly: {len(report.anomalies)} issues detected",
        "body": "\n".join(a["message"] for a in report.anomalies),
        "data": report.to_dict(),
    }

    try:
        req = urllib.request.Request(
            "http://localhost:8392/api/sympatheia/notification",
            data=json.dumps(payload).encode(),
            headers={"Content-Type": "application/json"},
            method="POST",
        )
        with urllib.request.urlopen(req, timeout=10) as resp:
            result = json.loads(resp.read().decode())
            logger.info(f"Sympatheia notification sent: {result.get('id', 'unknown')}")
            return {"sent": True, "response": result}
    except Exception as e:
        logger.warning(f"Failed to notify Sympatheia: {e}")
        return {"sent": False, "error": str(e)}


# CLI ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="F22: Scheduler Anomaly Detector")
    parser.add_argument("--days", type=int, default=7, help="Analysis period in days")
    parser.add_argument("--notify", action="store_true", help="Send to Sympatheia")
    parser.add_argument("--json", action="store_true", help="JSON output")
    args = parser.parse_args()

    report = detect_anomalies(days=args.days)

    if args.json:
        print(json.dumps(report.to_dict(), indent=2, ensure_ascii=False))
    else:
        print(f"\n{'='*50}")
        print(f"Scheduler Anomaly Report ({args.days} days)")
        print(f"{'='*50}")
        print(f"  Runs: {report.stats.get('total_runs', 0)}")
        print(f"  Rate: {report.stats.get('success_rate', 0):.0%}")
        if report.anomalies:
            print(f"\nâš ï¸  {len(report.anomalies)} anomalies detected:")
            for a in report.anomalies:
                icon = "ğŸ”´" if a["severity"] == "CRITICAL" else "ğŸŸ¡"
                print(f"  {icon} [{a['kind']}] {a['message']}")
        else:
            print("\nâœ… No anomalies detected")

    if args.notify and report.has_warnings:
        result = notify_sympatheia(report)
        sent = "âœ…" if result["sent"] else "âŒ"
        print(f"\n  Sympatheia: {sent}")
