#!/usr/bin/env python3
# PROOF: [L2/ã‚¤ãƒ³ãƒ•ãƒ©] A0â†’çŸ¥è­˜ç®¡ç†ãŒå¿…è¦â†’sophia_backlinker ãŒæ‹…ã†
"""
Sophia Backlinker - çŸ¥è­˜ã‚¢ã‚¤ãƒ†ãƒ é–“ã®ãƒªãƒ³ã‚¯ã‚°ãƒ©ãƒ•æ§‹ç¯‰

[[wikilink]] æ§‹æ–‡ã‚’æ¤œå‡ºã—ã€ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’æä¾›ã™ã‚‹ã€‚

Usage:
    python sophia_backlinker.py              # ã‚°ãƒ©ãƒ•æ§‹ç¯‰ + çµ±è¨ˆè¡¨ç¤º
    python sophia_backlinker.py --backlinks "ki_name"  # ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯å–å¾—
"""

import sys
import re
import json
from pathlib import Path
from typing import Set, Dict, List, Optional

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    import networkx as nx
except ImportError:
    print("âŒ networkx not installed. Run: pip install networkx")
    sys.exit(1)


KNOWLEDGE_DIR = Path("/home/laihuip001/oikos/.gemini/antigravity/knowledge")


class SophiaBacklinker:
    """NetworkX ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.graph = nx.DiGraph()  # æ–¹å‘æ€§ã‚°ãƒ©ãƒ•
        self.cache: Dict[str, Dict] = {}  # ãƒŽãƒ¼ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥

    def extract_links(self, content: str) -> Set[str]:
        """[[wikilink]] ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º

        å¯¾å¿œå½¢å¼:
        - [[å˜ç´”ãƒªãƒ³ã‚¯]]
        - [[ãƒ‘ã‚¹/ä»˜ããƒªãƒ³ã‚¯]]
        - [[ãƒªãƒ³ã‚¯|åˆ¥å]] (åˆ¥åã¯ç„¡è¦–)
        """
        # [[...]] å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º (| ä»¥é™ã¯é™¤å¤–)
        pattern = r"\[\[([^\]|]+?)(?:\|[^\]]+)?\]\]"
        matches = re.findall(pattern, content)
        return set(matches)

    def parse_ki_links(self, ki_path: Path) -> Set[str]:
        """KI ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒªãƒ³ã‚¯ã‚’æŠ½å‡º"""
        links = set()

        # artifacts/*.md ã‚’èµ°æŸ»
        artifacts_dir = ki_path / "artifacts"
        if artifacts_dir.exists():
            for md_file in artifacts_dir.rglob("*.md"):
                content = md_file.read_text(encoding="utf-8")
                file_links = self.extract_links(content)
                links.update(file_links)

        return links

    def build_graph(self, ki_dir: Path = None) -> int:
        """å…¨ KI ã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰

        Returns:
            è¿½åŠ ã•ã‚ŒãŸã‚¨ãƒƒã‚¸æ•°
        """
        ki_dir = ki_dir or KNOWLEDGE_DIR
        edge_count = 0

        for ki_path in ki_dir.iterdir():
            if not ki_path.is_dir():
                continue

            ki_name = ki_path.name
            links = self.parse_ki_links(ki_path)

            # ãƒŽãƒ¼ãƒ‰è¿½åŠ 
            if not self.graph.has_node(ki_name):
                self.graph.add_node(ki_name, type="ki")

            # ã‚¨ãƒƒã‚¸è¿½åŠ  (outlinks)
            for link in links:
                self.graph.add_edge(ki_name, link)
                edge_count += 1

                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ›´æ–°
                if ki_name not in self.cache:
                    self.cache[ki_name] = {"outlinks": set(), "backlinks": set()}
                self.cache[ki_name]["outlinks"].add(link)

        # ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ§‹ç¯‰
        self._build_backlink_cache()

        return edge_count

    def _build_backlink_cache(self):
        """é€†æ–¹å‘ãƒªãƒ³ã‚¯ (ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯) ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ§‹ç¯‰"""
        for node in self.graph.nodes():
            backlinks = set(self.graph.predecessors(node))
            if node not in self.cache:
                self.cache[node] = {"outlinks": set(), "backlinks": set()}
            self.cache[node]["backlinks"] = backlinks

    def get_backlinks(self, note_name: str) -> Set[str]:
        """O(1) ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯æ¤œç´¢"""
        if note_name in self.cache:
            return self.cache[note_name].get("backlinks", set())
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã‘ã‚Œã°ã‚°ãƒ©ãƒ•ã‹ã‚‰å–å¾—
        if self.graph.has_node(note_name):
            return set(self.graph.predecessors(note_name))
        return set()

    def get_outlinks(self, note_name: str) -> Set[str]:
        """O(1) ã‚¢ã‚¦ãƒˆãƒªãƒ³ã‚¯æ¤œç´¢"""
        if note_name in self.cache:
            return self.cache[note_name].get("outlinks", set())
        if self.graph.has_node(note_name):
            return set(self.graph.successors(note_name))
        return set()

    def get_stats(self) -> Dict:
        """ã‚°ãƒ©ãƒ•çµ±è¨ˆã‚’è¿”ã™"""
        return {
            "nodes": self.graph.number_of_nodes(),
            "edges": self.graph.number_of_edges(),
            "isolated": len(list(nx.isolates(self.graph))),
            "most_linked": self._get_most_linked(5),
        }

    def _get_most_linked(self, n: int) -> List[tuple]:
        """æœ€ã‚‚å¤šãã®ãƒãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’æŒã¤ãƒŽãƒ¼ãƒ‰"""
        in_degrees = [(node, self.graph.in_degree(node)) for node in self.graph.nodes()]
        return sorted(in_degrees, key=lambda x: x[1], reverse=True)[:n]

    def to_dict(self) -> Dict:
        """ã‚°ãƒ©ãƒ•ã‚’è¾žæ›¸å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        return {
            "nodes": list(self.graph.nodes()),
            "edges": list(self.graph.edges()),
            "cache": {
                k: {"outlinks": list(v["outlinks"]), "backlinks": list(v["backlinks"])}
                for k, v in self.cache.items()
            },
        }

    def to_mermaid(self, direction: str = "LR", max_nodes: int = 50) -> str:
        """Mermaid.js å½¢å¼ã§ã‚°ãƒ©ãƒ•ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ

        Args:
            direction: ã‚°ãƒ©ãƒ•ã®æ–¹å‘ (LR, TB, RL, BT)
            max_nodes: è­¦å‘Šã‚’è¡¨ç¤ºã™ã‚‹ãƒŽãƒ¼ãƒ‰æ•°é–¾å€¤

        Returns:
            Mermaid è¨˜æ³•ã®æ–‡å­—åˆ—
        """
        node_count = self.graph.number_of_nodes()
        lines = [f"graph {direction}"]

        # å¤§è¦æ¨¡ã‚°ãƒ©ãƒ•è­¦å‘Š
        if node_count > max_nodes:
            lines.insert(
                0,
                f"%% âš ï¸ è­¦å‘Š: {node_count} ãƒŽãƒ¼ãƒ‰ (> {max_nodes}) â€” å¯è¦–åŒ–ãŒå´©å£Šã™ã‚‹å¯èƒ½æ€§",
            )

        def sanitize(name: str) -> str:
            """ãƒŽãƒ¼ãƒ‰åã‚’Mermaidå®‰å…¨ãªå½¢å¼ã«å¤‰æ›"""
            # ç‰¹æ®Šæ–‡å­—ã‚’ç½®æ›ã€å¼•ç”¨ç¬¦ã§å›²ã‚€
            safe = name.replace('"', "'").replace("-", "_").replace(" ", "_")
            return f'"{safe}"'

        for src, dst in self.graph.edges():
            lines.append(f"    {sanitize(src)} --> {sanitize(dst)}")

        return "\n".join(lines)

    def to_json_for_d3(self) -> Dict:
        """D3.js force-directed ç”¨ JSON

        Returns:
            D3.js äº’æ›ã® nodes/links æ§‹é€ 
        """
        return {
            "nodes": [
                {"id": n, "type": self.graph.nodes[n].get("type", "unknown")}
                for n in self.graph.nodes()
            ],
            "links": [{"source": s, "target": t} for s, t in self.graph.edges()],
        }


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Sophia Backlinker")
    parser.add_argument("--backlinks", type=str, help="Get backlinks for a note")
    parser.add_argument("--outlinks", type=str, help="Get outlinks for a note")
    parser.add_argument("--stats", action="store_true", help="Show graph stats")
    parser.add_argument("--mermaid", action="store_true", help="Output Mermaid diagram")
    parser.add_argument("--json", action="store_true", help="Output D3.js JSON")
    args = parser.parse_args()

    backlinker = SophiaBacklinker()

    print("ðŸ“Š Building knowledge graph...")
    edges = backlinker.build_graph()
    stats = backlinker.get_stats()

    print(f"âœ… Graph built: {stats['nodes']} nodes, {stats['edges']} edges")

    if args.mermaid:
        print(f"\nðŸ“ˆ Mermaid diagram:")
        print(backlinker.to_mermaid())
        return

    if args.json:
        print(f"\nðŸ“ˆ D3.js JSON:")
        print(json.dumps(backlinker.to_json_for_d3(), indent=2, ensure_ascii=False))
        return

    if args.backlinks:
        backlinks = backlinker.get_backlinks(args.backlinks)
        print(f"\nðŸ”™ Backlinks for '{args.backlinks}':")
        if backlinks:
            for link in sorted(backlinks):
                print(f"  â† {link}")
        else:
            print("  (no backlinks)")

    if args.outlinks:
        outlinks = backlinker.get_outlinks(args.outlinks)
        print(f"\nðŸ”— Outlinks from '{args.outlinks}':")
        if outlinks:
            for link in sorted(outlinks):
                print(f"  â†’ {link}")
        else:
            print("  (no outlinks)")

    if args.stats or (not args.backlinks and not args.outlinks):
        print(f"\nðŸ“ˆ Stats:")
        print(f"  Nodes: {stats['nodes']}")
        print(f"  Edges: {stats['edges']}")
        print(f"  Isolated: {stats['isolated']}")
        if stats["most_linked"]:
            print(f"  Most linked:")
            for name, count in stats["most_linked"]:
                if count > 0:
                    print(f"    {name}: {count} backlinks")


if __name__ == "__main__":
    main()
