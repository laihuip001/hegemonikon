# 調査依頼: LLM 実行保証の打開策

> **決定事項**: CCL の実行保証にどのアーキテクチャを採用するか
> **仮説**: LLM 単体では実行保証は不可能。ハイブリッド手法が必要。

---

## 【出力形式】← ⚠️ 最初に読め

**【必須】** 構造化テーブル（4列: 手法, 概要, 利点, 根拠URL）を返せ。
その後、2-3文の結論を formal トーンで記述。

---

## 【時間制約】← ⚠️ 情報鮮度

- **採用範囲**: 過去12ヶ月以内の情報を優先
- **歴史的参考**: 2023年以前は「参考」としてのみ言及可
- **日付明記**: 各ソースに「取得時点: YYYY年MM月」を付記すること

---

## 【調査すべき論点】← ⚠️ 必須網羅

以下を**必ず**網羅し、断定できない場合は「不確実」と明示:

### A. LLM 実行保証の根本問題

- A1: LLM が「予測エンジン」であり「実行エンジン」でない理由
- A2: プロンプトエンジニアリングだけで実行保証が得られない理由
- A3: 現在の AI エージェントフレームワークがこの問題にどう対処しているか

### B. 実行保証を高める手法（2024-2025年の最新研究）

- B1: **コード生成 + 実行**: LLM がコードを生成し、外部エンジンが実行する手法
  - 例: CodeAct, OpenCodeInterpreter, SWE-Agent
- B2: **ツール呼び出し**: LLM が関数を呼び出し、決定論的システムが実行する手法
  - 例: Toolformer, Function Calling, ReAct
- B3: **形式言語中間表現**: LLM が DSL を生成し、インタプリタが実行する手法
  - 例: LMQL, Guidance, DSPy
- B4: **マルチエージェント検証**: 複数の LLM が相互検証する手法
  - 例: Constitutional AI, Debate, Multi-Agent Verification
- B5: **外部検証器**: LLM 出力を形式検証する手法
  - 例: SMT Solver 連携, Theorem Prover

### C. 認知制御言語（DSL）の実行保証実装例

- C1: 認知タスク向け DSL で実行保証を実装した事例
- C2: DSL → LLM プロンプト → 検証 のパイプライン設計例
- C3: エージェントオーケストレーションフレームワーク（LangGraph, AutoGen 等）の保証機構

### D. LLM 非決定性への対処

- D1: 温度 0 でも出力が変わる理由と対策
- D2: 出力の一貫性を高めるテクニック（Constrained Decoding 等）
- D3: リトライ戦略とフォールバック設計

---

## 【反証・検証】← ⚠️ 確認用

- 「LLM で実行保証は原理的に不可能」という主張を3件探すこと
- 「LLM で高い実行信頼性を達成した」という主張を3件探すこと
- 両者の差異を分析すること

---

## 【特に注目すべきキーワード】

- Constrained Decoding
- Guardrails AI
- LMQL / Guidance / Outlines
- DSPy
- LangGraph / LangChain
- ReAct / Toolformer / CodeAct
- Function Calling / Tool Use
- Structured Output / JSON Mode

---

## 【成果物構成】

1. **結論サマリー**（10行以内）— CCL 実行保証に最も適した手法
2. **比較テーブル**（必須列: 手法, 概要, 実行保証レベル, 実装難易度, URL）
3. **根拠リンク**（各セクション最低3件）
4. **推奨アーキテクチャ**（CCL に適用する場合の設計案）

---

*Generated by /sop+ (2026-01-31)*
