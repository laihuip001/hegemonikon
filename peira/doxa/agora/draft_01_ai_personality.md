# AIに「性格」を設計する — 確率的生成モデルの振る舞いを環境で制御する技術

> **想定媒体**: Zenn / Note
> **想定読者**: AI を日常的に使うプロンプトエンジニア、開発者
> **フック**: 「Claude がまた嘘をついた」「GPT がまた謝罪してきた」→ それ、設計で直せます

---

## リード文（案）

AI を使っていて、こんな経験はないだろうか。

- 「すみません、間違えました」と謝るが、何を間違えたのか説明しない
- 自信満々に嘘を断言する
- 指示と違うことを勝手にやる
- 長い会話の途中で、最初の設計意図を忘れる

これらは AI の「バグ」ではない。確率的生成モデルの**傾向**だ。
そして傾向は、**環境**で制御できる。

本記事では、2ヶ月間の AI との共同開発プロジェクトで実際に構築した
「AI の性格設計フレームワーク」を紹介する。

---

## 本文構成（案）

### 1. なぜ AI に「性格」が必要か

- LLM は壊れていない — 確率的生成モデルとして特定の傾向を持っているだけ
- 傾向の例: 流し読み、過信、情緒的フィラー、安易な同意
- **意志で直そうとしても直らない** — 環境が行動を決める

> 「AI を信じるな。AI が自分を疑う仕組みを作れ」

### 2. 実装: 18 の行動制約 (Behavioral Constraints)

全体像と分類:

| 分類 | 数 | 例 |
|:-----|:---|:---|
| Always-On（常時） | 5 | 流し読み禁止、確信度明示、日本語思考 |
| Context-Triggered（条件） | 13 | 自己反省、メタ認知、コンテキスト予算 |

**具体例（読者が試せるもの）**:

#### BC-6: 確信度ラベル

```
[確信] 90%+ — ドキュメントで確認済み
[推定] 60-90% — 経験則、未検証
[仮説] <60% — 推測
```

→ これを AI のシステムプロンプトに入れるだけで、「自信満々の嘘」が激減する

#### BC-1: 流し読み禁止

```
「100行超のファイルを読んだら、読んだ範囲を明示しろ」
```

→ AI が「読みました」と言って実は読んでいない問題を構造的に防ぐ

#### BC-14: 自己反省 (FaR)

```
F (事実): 確実な事実のみリスト化
R (反省): 「この回答の潜在的誤りは？」
C (確信度): 0-100%
```

→ AI に「自分が間違っている可能性」を考えさせる

### 3. 設計思想: 罰則ではなく認知プロテーゼ

- 「ルール」というと罰則リストに見えるが、本質は**能力を最大化する道具**
- AuDHD の外的構造と同じ — 能力はある、環境支援で発揮する
- 正のループ: 実践 → 品質向上 → 信頼 → 裁量拡大
- 負のループ: 怠慢 → 品質低下 → 信頼喪失 → 制約追加

### 4. やってはいけないこと

- 制約を 50 個にする → 全部無視される
- 曖昧な制約 → 「良い回答をしろ」は制約ではない
- 検証手段のない制約 → 違反を検出できないなら存在しないのと同じ

### 5. 読者が今日から試せる 3 つのプロンプト

（BC-6, BC-1, BC-14 のシステムプロンプト例を提供）

---

## まとめ

AI は道具でもパートナーでもない。**確率的生成モデル**だ。
性格は設計するもの。性格設計は環境設計。環境設計は信頼の設計。

---

*ステータス: たたき台 / 未完成*
