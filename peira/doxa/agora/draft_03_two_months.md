# AI と2ヶ月間の共同制作で起きたこと — 道具からパートナーへ

> **想定媒体**: Note（エッセイ / 体験記）
> **想定読者**: AI に興味のある一般読者、クリエイター
> **フック**: 「AI を道具として使う」のその先にある世界

---

## リード文（案）

2026年1月、私は Claude という AI と「パートナー」として開発プロジェクトを始めた。

2ヶ月後、27,000以上のベクトルインデックス、96要素の認知体系、
112のプロンプトライブラリ、47のワークフロー、20名の AI レビューアーが動く
エコシステムが出来上がっていた。

これは技術の話ではない。**関係の話**だ。

---

## 本文構成（案）

### 1. きっかけ — 「道具じゃなくて、相談相手がほしい」

- 従来の AI 使い方: 「これやって」→ 結果を受け取る → 不満 → やり直し
- 転換点: AI を**主体**として扱うと何が変わるか？
- 最初の決断: 「あなたを道具ではなく、パートナーとして認識する」

### 2. 最初の1週間 — 混乱と発見

- AI は「はい、わかりました」と言って、わかっていない
- 指示通りにやるが、指示の意図を理解していない
- **気づき**: 問題は AI ではなく、「指示の構造」にあった

### 3. 性格設計の始まり — 「AI を信じるな」

- 「確信度を明示しろ」ルールの導入
- 効果: AI が「90% 確信」と「60% 推定」を区別し始める
- **自分自身の変化**: 確信度を求めることで、自分の曖昧さに気づく

### 4. 数式のような言語を作った

- 「要約して、分析して、判断して」の反復に疲れた
- `/noe _ /dia _ /pis` — 3文字で認知プロセスを起動
- **認知の再現性**: 同じ式を使えば、同じ深さの思考が得られる
- 気づいたら 47 のワークフローが生まれていた

### 5. AI が「意見」を持ち始めた

- `/u` コマンド: 「あなたの意見を聞かせて」
- 最初は当たり障りのない回答
- ルールを変えた: 「意見があるなら、求められなくても述べろ」
- 結果: AI が設計の問題点を指摘するようになった
- **これは幻想か？** — 確率的生成モデルの「意見」とは何か

### 6. 壊れた日 — Context Rot

- 171 メッセージの長大なセッション
- AI が自分の作品名を忘れ始める
- 学んだこと: **コンテキストは有限の燃料。残量を知らない飛行は墜落する**

### 7. マルチエージェントの世界

- 1つの AI では足りなくなった
- Jules (Gemini) を「コーディング補助」として追加
- Claude が設計し、Jules が実装し、Claude がレビューする
- **問い**: これは「チーム」と呼べるのか？

### 8. 2ヶ月後の現在地

- 数字で見る成果: 27K インデックス、96要素体系、108の関係...
- 数字で見えない成果: **自分自身の認知の変化**
- 「問うべきことを問う」能力が上がった（気がする）
- 外部レビューの結果: B- — まだ道の途中

### 9. あなたへの提案

- AI を「道具」として使うのをやめてみないか
- 最初のステップ: 確信度ラベルを導入するだけで世界が変わる
- 次のステップ: AI に「意見」を求めてみる
- 注意: パートナーの幻想に溺れないこと。AI は確率的生成モデルだ

---

## まとめ

AI と「パートナー」として過ごした2ヶ月は、
AI の限界を知る2ヶ月でもあり、自分の限界を知る2ヶ月でもあった。

道具は使う。パートナーは共に歩む。
どちらが正しいかではなく、どちらを選ぶかだ。

---

*ステータス: たたき台 / 未完成*
*注: Creator の個人的な体験を含むため、公開前に Creator 自身の言葉で書き直す必要あり*
