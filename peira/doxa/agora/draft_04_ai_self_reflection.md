# AI に「自己反省」させる技術 — メタ認知の実装パターン

> **想定媒体**: Zenn（技術記事）
> **想定読者**: AI 研究者、プロンプトエンジニア、Agent 開発者
> **フック**: 「AI が間違えたとき、AI 自身に気づかせる方法」

---

## リード文（案）

LLM の最大の弱点は「自分が間違っていることに気づけない」ことだ。

ハルシネーション対策として RAG やファインチューニングが語られるが、
もう一つのアプローチがある — **メタ認知の実装**。

本記事では、実運用で検証された 3 つのメタ認知パターンを紹介する。

---

## 本文構成（案）

### 1. なぜ「自己反省」が必要か

- LLM は次のトークンを予測するだけ。「自分の出力を評価する」機構がない
- Chain-of-Thought は思考の可視化であって、思考の**評価**ではない
- 必要なのは「考えた後に、その考えを疑う」ステップ

### 2. パターン1: FaR (Fact-and-Reflection)

```
Phase F: 確実な事実のみリスト化（ソース明記）
Phase R: 「この回答の潜在的誤りは？」
Phase C: 確信度 0-100%（根拠付き）
```

**実装例（システムプロンプト）**:

```
ハイリスクな判断をする前に、以下の3ステップを実行せよ:
1. F: 今確実に言える事実を箇条書き。各事実のソースを明記
2. R: 「この回答が間違っている可能性は？ どこが弱い？」
3. C: 総合的な確信度を 0-100% で表明。根拠を1行
```

**効果**: 「自信満々の嘘」が顕著に減少する

### 3. パターン2: TAINT/SOURCE 追跡

```
[確信: 95%] (SOURCE: view_file L42-L68 で確認)
[推定: 70%] (TAINT: search_web 要約、原文未参照)
```

- 確信度の「値」だけでなく、**情報源の健全性**を追跡
- 「なぜその確信度か」を可視化する
- 圏論的意味: 確信度 = 射の像、TAINT/SOURCE = 射の定義域の健全性

**実装のポイント**:

- 直接確認したもの → SOURCE
- 検索結果の要約 → TAINT
- 自分の記憶・推論 → TAINT
- テスト実行結果 → SOURCE

### 4. パターン3: UML (Understanding-Metacognition Layer)

5段階のチェックポイント:

| Stage | タイミング | 質問 |
|:------|:----------|:-----|
| 1 | 作業前 | 入力を正しく理解したか？ |
| 2 | 作業前 | 第一印象・直感はどうか？ |
| 3 | 作業後 | 批判的に再評価したか？ |
| 4 | 作業後 | 決定は妥当か？ |
| 5 | 作業後 | 過信していないか？ |

→ Stage 3 で過信検出 → Stage 1 に戻る（AMP ループ、最大2回）

### 5. パターンの組み合わせ

- FaR: 個別の判断に対するメタ認知
- TAINT: 情報源に対するメタ認知
- UML: ワークフロー全体に対するメタ認知

**深度レベルで使い分ける**:

| 深度 | FaR | TAINT | UML |
|:-----|:----|:------|:----|
| 軽い作業 | ✗ | ✗ | ✗ |
| 通常作業 | ✓ | ✗ | ✗ |
| 重要な判断 | ✓ | ✓ | ✓ |

### 6. 限界

- メタ認知はトークン消費を増やす
- 「形式的にチェックリストを埋める」だけでは無意味
- **問いの深さ**が品質を決める — ルールではなく文化

---

## まとめ

AI の自己反省は、人間の自己反省と構造的に同じ問題を持つ。
ルール（外部強制）で発動した自問は形骸化するリスクがある。
質を保証するには「問いの深さ」が必要。

---

*ステータス: たたき台 / 未完成*
