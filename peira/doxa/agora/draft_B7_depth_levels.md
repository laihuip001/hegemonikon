# AI との対話に「深度」を設定する

> **ID**: B7
> **想定媒体**: Note → Zenn
> **想定読者**: AI ヘビーユーザー、プロンプトエンジニア
> **フック**: 「毎回全力で考えさせる」と AI は壊れる

---

## リード文（案）

AI に「深く考えて」と言えば良い答えが返ってくる？
**半分正解、半分間違い。**

「今日の天気は？」と「人生の意味は？」に同じ深度で答えさせたら、
前者は無駄に遅く、後者は不十分。

**思考にも「ギア」が必要**。

---

## 本文構成（案）

### 1. 4段階の深度レベル

| Level | 名称 | 適用場面 | ルール数 | 思考の深さ |
|:------|:-----|:---------|:---------|:----------|
| L0 | Bypass | 「ls」「はい」 | 5個のみ | 最小限 |
| L1 | Quick | コード実装 | +3個 | 短い計画→即実行 |
| L2 | Standard | 設計・分析 | +3個 | 構造化された思考 |
| L3 | Deep | 本質問題 | 全部 | 全展開+多角的検証 |

### 2. なぜギアが必要か

| 問題 | 原因 | 解決 |
|:-----|:-----|:-----|
| 「深く考えて」が効かない | 全タスクに L3 → 疲弊 | ギアを設定 |
| 単純作業が遅い | L2 で処理 → オーバーヘッド | L0/L1 で高速化 |
| 重要判断が浅い | L1 で処理 → メタ認知なし | L2/L3 に引き上げ |

### 3. CCL での表現

```
/noe-   → L1 (Quick)
/noe    → L2 (Standard)
/noe+   → L3 (Deep)
```

1文字の接尾辞で深度を制御。

### 4. 深度の自動判定ルール

1. CCL 派生が明示されていれば従う
2. タスクの階層で自動判定: Ω層=L3, Δ層=L2, τ層=L1
3. Creator が明示指定すれば従う
4. 不明なら L2 (Standard) がデフォルト

### 5. 過剰な深度の害

- L3 で単純タスク → トークン浪費、Context Rot 加速
- L0 で設計判断 → メタ認知なし、見落とし
- **深度 × 思考量 の最適化**が重要

### 6. 読者が試せること

```
# システムプロンプトに追加
以下のルールで思考の深さを調整してください:
- 単純な質問/確認 → 即答 (深く考えない)
- コード実装 → 短い計画→実行
- 設計判断 → 構造化された分析
- 本質的な問い → 多角的に深く考える

各回答の冒頭に [L0/L1/L2/L3] を表示してください。
```

---

*ステータス: たたき台*
*関連: B3 (環境設計), B6 (ルール進化)*
