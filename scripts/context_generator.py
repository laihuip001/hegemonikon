#!/usr/bin/env python3
# PROOF: [L3/Utility] <- scripts/ A0â†’Implementationâ†’context_generator
# PROOF: [L2/è‡ªå‹•åŒ–] <- scripts/ F6 è¨­è¨ˆ (designs/f6_context_auto_update.md) ã®å®Ÿè£… Phase 1
"""
Context Generator â€” context/ ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•æ›´æ–°ã‚¹ã‚±ãƒ«ãƒˆãƒ³

KI ã‚„ Sophia ã®æ›´æ–°ã‚’æ¤œçŸ¥ã—ã€context/ ã®å„ãƒ†ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å·®åˆ†æ›´æ–°ã™ã‚‹ã€‚
F6 è¨­è¨ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ãå®Ÿè£…ã€‚

Usage:
    python context_generator.py --check       # å¤‰æ›´æ¤œçŸ¥ã®ã¿
    python context_generator.py --generate    # å†ç”Ÿæˆå®Ÿè¡Œ
    python context_generator.py --status      # ç¾åœ¨ã®çŠ¶æ…‹è¡¨ç¤º
"""

from __future__ import annotations

import argparse
import hashlib
import json
import sys
from datetime import datetime
from pathlib import Path

# === è¨­å®š ===
PROJECT_ROOT = Path(__file__).parent.parent
CONTEXT_DIR = PROJECT_ROOT / "mekhane" / "symploke" / "context"
KI_DIR = Path.home() / ".gemini" / "antigravity" / "knowledge"
SOPHIA_DIR = Path.home() / "oikos" / "mneme" / ".hegemonikon" / "sophia"
STATE_FILE = PROJECT_ROOT / ".context_generator_state.json"

# ãƒ†ãƒ¼ãƒåˆ†é¡ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯
THEME_KEYWORDS: dict[str, list[str]] = {
    "fep_foundation": ["fep", "free energy", "active inference", "precision",
                       "variational", "markov blanket", "prediction error"],
    "hgk_knowledge": ["hegemonikon", "theorem", "å®šç†", "series", "ousia",
                      "schema", "horme", "kairos", "akribeia"],
    "hgk_vocabulary": ["definition", "greek", "åå‰", "ç”¨èª", "æ„å‘³"],
    "category_patterns": ["adjunction", "functor", "category", "morphism",
                          "åœè«–", "éšä¼´", "é–¢æ‰‹", "è‡ªç„¶å¤‰æ›"],
    "ccl_language": ["ccl", "operator", "syntax", "æ¼”ç®—å­", "æ§‹æ–‡"],
    "quality_assurance": ["test", "review", "quality", "check", "å“è³ª",
                          "æ¤œè¨¼", "dendron", "proof"],
    "design_patterns": ["design", "pattern", "architecture", "è¨­è¨ˆ",
                        "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£", "module"],
    "morphism_guide": ["morphism", "bridge", "anchor", "å°„", "ææ¡ˆ"],
}


def load_state() -> dict:
    """å‰å›ã®çŠ¶æ…‹ã‚’èª­ã¿è¾¼ã‚€ã€‚"""
    if STATE_FILE.exists():
        return json.loads(STATE_FILE.read_text(encoding="utf-8"))
    return {"last_check": None, "file_hashes": {}}


def save_state(state: dict) -> None:
    """çŠ¶æ…‹ã‚’ä¿å­˜ã™ã‚‹ã€‚"""
    STATE_FILE.write_text(json.dumps(state, indent=2, default=str),
                          encoding="utf-8")


def hash_file(path: Path) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã® MD5 ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—ã™ã‚‹ã€‚"""
    return hashlib.md5(path.read_bytes()).hexdigest()


def detect_changes(state: dict) -> dict[str, list[Path]]:
    """KI, Sophia ã®å¤‰æ›´ã‚’æ¤œçŸ¥ã™ã‚‹ã€‚"""
    changes: dict[str, list[Path]] = {"new": [], "modified": [], "deleted": []}
    old_hashes = state.get("file_hashes", {})
    current_hashes: dict[str, str] = {}

    for source_dir in [KI_DIR, SOPHIA_DIR]:
        if not source_dir.exists():
            continue
        for md_file in source_dir.rglob("*.md"):
            key = str(md_file)
            h = hash_file(md_file)
            current_hashes[key] = h
            if key not in old_hashes:
                changes["new"].append(md_file)
            elif old_hashes[key] != h:
                changes["modified"].append(md_file)

    for key in old_hashes:
        if key not in current_hashes:
            changes["deleted"].append(Path(key))

    state["file_hashes"] = current_hashes
    state["last_check"] = datetime.now().isoformat()
    return changes


def classify_theme(content: str) -> str:
    """å†…å®¹ã‹ã‚‰ãƒ†ãƒ¼ãƒã‚’åˆ†é¡ã™ã‚‹ã€‚"""
    content_lower = content.lower()
    scores: dict[str, int] = {}
    for theme, keywords in THEME_KEYWORDS.items():
        score = sum(1 for kw in keywords if kw in content_lower)
        if score > 0:
            scores[theme] = score

    if not scores:
        return "hgk_knowledge"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    return max(scores, key=scores.get)  # type: ignore[arg-type]


def show_status() -> None:
    """ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""
    state = load_state()
    print("=== Context Generator Status ===")
    print(f"  Last check: {state.get('last_check', 'never')}")
    print(f"  Tracked files: {len(state.get('file_hashes', {}))}")
    print()
    print("=== context/ Files ===")
    if CONTEXT_DIR.exists():
        for md_file in sorted(CONTEXT_DIR.glob("*.md")):
            lines = len(md_file.read_text(encoding="utf-8").splitlines())
            print(f"  {md_file.name:<35} {lines:>4} lines")
    print()
    print("=== Source Directories ===")
    for name, d in [("KI", KI_DIR), ("Sophia", SOPHIA_DIR)]:
        if d.exists():
            count = len(list(d.rglob("*.md")))
            print(f"  {name}: {d} ({count} files)")
        else:
            print(f"  {name}: {d} (not found)")


def check_changes() -> None:
    """å¤‰æ›´ã‚’æ¤œçŸ¥ã—ã¦è¡¨ç¤ºã™ã‚‹ã€‚"""
    state = load_state()
    changes = detect_changes(state)

    total = sum(len(v) for v in changes.values())
    if total == 0:
        print("âœ… No changes detected since last check.")
    else:
        print(f"ğŸ”„ {total} changes detected:")
        for kind, files in changes.items():
            for f in files:
                print(f"  [{kind}] {f}")

        # ãƒ†ãƒ¼ãƒåˆ†é¡ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        print("\n--- Theme Classification Preview ---")
        for f in changes["new"] + changes["modified"]:
            if f.exists():
                content = f.read_text(encoding="utf-8")
                theme = classify_theme(content)
                print(f"  {f.name} â†’ {theme}")

    save_state(state)


def generate() -> None:
    """context/ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿæˆã™ã‚‹ (Phase 1: å½±éŸ¿ç¯„å›²ã®è¡¨ç¤ºã®ã¿)ã€‚"""
    state = load_state()
    changes = detect_changes(state)
    total = sum(len(v) for v in changes.values())

    if total == 0:
        print("âœ… No changes â€” nothing to generate.")
        save_state(state)
        return

    print(f"ğŸ”§ Generation plan ({total} source changes):")
    affected_themes: set[str] = set()
    for f in changes["new"] + changes["modified"]:
        if f.exists():
            content = f.read_text(encoding="utf-8")
            theme = classify_theme(content)
            affected_themes.add(theme)
            print(f"  {f.name} â†’ {theme}")

    print(f"\nğŸ“ Affected context files: {', '.join(sorted(affected_themes))}")
    print("\nâš ï¸ Phase 1: Dry-run only. Actual generation not yet implemented.")
    print("   TODO: Implement incremental update logic for each theme file.")

    save_state(state)


def main() -> None:
    parser = argparse.ArgumentParser(description="Context Generator (Phase 1)")
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--check", action="store_true", help="å¤‰æ›´æ¤œçŸ¥ã®ã¿")
    group.add_argument("--generate", action="store_true", help="å†ç”Ÿæˆ (dry-run)")
    group.add_argument("--status", action="store_true", help="ç¾åœ¨ã®çŠ¶æ…‹è¡¨ç¤º")
    args = parser.parse_args()

    if args.status:
        show_status()
    elif args.check:
        check_changes()
    elif args.generate:
        generate()


if __name__ == "__main__":
    main()
