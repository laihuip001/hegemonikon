#!/usr/bin/env bash
# PURPOSE: Cortex API (cloudcode-pa v1internal) ç›´å©ãã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# å‚ç…§: kernel/doxa/DX-010_ide_hack_cortex_direct_access.md
# 
# ä½¿ã„æ–¹:
#   cortex.sh "Hello"                          # åŸºæœ¬ (gemini-2.0-flash)
#   cortex.sh -m gemini-2.5-pro "Hello"        # ãƒ¢ãƒ‡ãƒ«æŒ‡å®š
#   cortex.sh -s "You are a poet" "Write haiku" # system instruction
#   cortex.sh --stream "Hello"                 # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
#   cortex.sh --think 1024 "Hard problem"      # thinking budget
#   cortex.sh --raw '{"contents":[...]}'       # raw JSON (requestãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰)
#   cortex.sh --info                           # loadCodeAssist æƒ…å ±è¡¨ç¤º
#   cortex.sh --quota                          # ã‚¯ã‚©ãƒ¼ã‚¿ç¢ºèª
#
# ç’°å¢ƒå¤‰æ•°:
#   CORTEX_MODEL        ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ« (default: gemini-2.0-flash)
#   CORTEX_PROJECT      ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID (default: è‡ªå‹•å–å¾—)
#   CORTEX_MAX_TOKENS   æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ (default: 8192)
#   CORTEX_TEMPERATURE  æ¸©åº¦ (default: 0.7)

set -euo pipefail

# Google API ã¸ã¯ç›´æ¥æ¥ç¶š (mitmproxy æ®‹éª¸å›é¿)
unset HTTPS_PROXY HTTP_PROXY https_proxy http_proxy 2>/dev/null || true

# â”€â”€â”€ Constants â”€â”€â”€
readonly CLIENT_ID="REDACTED_CLIENT_ID"
readonly CLIENT_SECRET="REDACTED_CLIENT_SECRET"
readonly CREDS_FILE="$HOME/.gemini/oauth_creds.json"
readonly BASE_URL="https://cloudcode-pa.googleapis.com/v1internal"
readonly TOKEN_CACHE="/tmp/.cortex_token_cache"

# â”€â”€â”€ Defaults â”€â”€â”€
MODEL="${CORTEX_MODEL:-gemini-2.0-flash}"
PROJECT="${CORTEX_PROJECT:-}"
MAX_TOKENS="${CORTEX_MAX_TOKENS:-8192}"
TEMPERATURE="${CORTEX_TEMPERATURE:-0.7}"
SYSTEM_INSTRUCTION=""
STREAM=false
THINK_BUDGET=""
RAW_REQUEST=""
SHOW_INFO=false
SHOW_QUOTA=false
SHOW_USAGE=false
VERBOSE=false

# â”€â”€â”€ Functions â”€â”€â”€

die() { echo "âŒ $*" >&2; exit 1; }

usage() {
    sed -n '3,16p' "$0" | sed 's/^# *//'
    exit 0
}

# Token refresh (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ã â€” æœ‰åŠ¹æœŸé™å†…ãªã‚‰å†åˆ©ç”¨)
get_token() {
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒ55åˆ†ä»¥å†…ãªã‚‰å†åˆ©ç”¨
    if [[ -f "$TOKEN_CACHE" ]]; then
        local age=$(( $(date +%s) - $(stat -c %Y "$TOKEN_CACHE" 2>/dev/null || echo 0) ))
        if (( age < 3300 )); then
            cat "$TOKEN_CACHE"
            return
        fi
    fi

    [[ -f "$CREDS_FILE" ]] || die "OAuth èªè¨¼ãŒå¿…è¦ã§ã™ã€‚å…ˆã«: npx @google/gemini-cli --prompt 'hello'"

    local refresh_token
    refresh_token=$(python3 -c "import json; print(json.load(open('$CREDS_FILE'))['refresh_token'])" 2>/dev/null) \
        || die "refresh_token ã®èª­ã¿å–ã‚Šã«å¤±æ•—"

    local response
    response=$(curl -s -X POST "https://oauth2.googleapis.com/token" \
        -d "client_id=$CLIENT_ID" \
        -d "client_secret=$CLIENT_SECRET" \
        -d "refresh_token=$refresh_token" \
        -d "grant_type=refresh_token") || die "Token refresh å¤±æ•—"

    local token
    token=$(echo "$response" | python3 -c "import sys,json; print(json.load(sys.stdin)['access_token'])" 2>/dev/null) \
        || die "access_token ã®è§£æã«å¤±æ•—: $response"

    echo "$token" > "$TOKEN_CACHE"
    chmod 600 "$TOKEN_CACHE"
    echo "$token"
}

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ ID å–å¾— (loadCodeAssist)
get_project() {
    local token="$1"

    if [[ -n "$PROJECT" ]]; then
        echo "$PROJECT"
        return
    fi

    local response
    response=$(curl -s -X POST \
        -H "Authorization: Bearer $token" \
        -H "Content-Type: application/json" \
        "$BASE_URL:loadCodeAssist" \
        -d '{"metadata":{"ideType":"IDE_UNSPECIFIED","platform":"PLATFORM_UNSPECIFIED","pluginType":"GEMINI"}}') \
        || die "loadCodeAssist å¤±æ•—"

    local project
    project=$(echo "$response" | python3 -c "import sys,json; print(json.load(sys.stdin)['cloudaicompanionProject'])" 2>/dev/null) \
        || die "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ ID ã®è§£æã«å¤±æ•—: $response"

    echo "$project"
}

# generateContent å®Ÿè¡Œ
generate() {
    local token="$1" project="$2" prompt="$3"
    local endpoint="$BASE_URL:generateContent"
    local curl_opts=(-s)

    if $STREAM; then
        endpoint="$BASE_URL:streamGenerateContent?alt=sse"
        curl_opts=(-sN)  # -N: no buffer for streaming
    fi

    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹ç¯‰ (ç’°å¢ƒå¤‰æ•°ã§Pythonã«å®‰å…¨ã«æ¸¡ã™)
    local request_json
    request_json=$(CORTEX_PROMPT="$prompt" \
        CORTEX_SI="$SYSTEM_INSTRUCTION" \
        CORTEX_TB="$THINK_BUDGET" \
        CORTEX_RAW="$RAW_REQUEST" \
        CORTEX_M="$MODEL" \
        CORTEX_P="$project" \
        CORTEX_T="$TEMPERATURE" \
        CORTEX_N="$MAX_TOKENS" \
        python3 << 'PYEOF'
import json, os

prompt = os.environ.get("CORTEX_PROMPT", "")
si = os.environ.get("CORTEX_SI", "")
tb = os.environ.get("CORTEX_TB", "")
raw = os.environ.get("CORTEX_RAW", "")
model = os.environ.get("CORTEX_M", "gemini-2.0-flash")
project = os.environ.get("CORTEX_P", "")
temp = float(os.environ.get("CORTEX_T", "0.7"))
max_tok = int(os.environ.get("CORTEX_N", "8192"))

if raw:
    req = json.loads(raw)
else:
    req = {
        "contents": [{"role": "user", "parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": temp,
            "maxOutputTokens": max_tok
        }
    }
    if si:
        req["systemInstruction"] = {
            "role": "user",
            "parts": [{"text": si}]
        }
    if tb:
        req["generationConfig"]["thinkingConfig"] = {
            "thinkingBudget": int(tb)
        }

payload = {"model": model, "project": project, "request": req}
print(json.dumps(payload, ensure_ascii=False))
PYEOF
    ) || die "ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹ç¯‰å¤±æ•—"

    $VERBOSE && echo "ğŸ“¡ $endpoint" >&2
    $VERBOSE && echo "ğŸ“¦ $(echo "$request_json" | python3 -m json.tool 2>/dev/null || echo "$request_json")" >&2

    local response
    response=$(curl "${curl_opts[@]}" -X POST \
        -H "Authorization: Bearer $token" \
        -H "Content-Type: application/json" \
        "$endpoint" \
        -d "$request_json") || die "API å‘¼ã³å‡ºã—å¤±æ•—"

    # å‡ºåŠ›
    if $STREAM; then
        # SSE: data: è¡Œã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        echo "$response" | python3 -c "
import sys, json
for line in sys.stdin:
    line = line.strip()
    if line.startswith('data: '):
        try:
            d = json.loads(line[6:])
            parts = d.get('response',{}).get('candidates',[{}])[0].get('content',{}).get('parts',[])
            for p in parts:
                if 'text' in p:
                    print(p['text'], end='')
        except: pass
print()
" 2>/dev/null
    else
        echo "$response" | CORTEX_SHOW_USAGE="$SHOW_USAGE" python3 -c "
import sys, json, os
show_usage = os.environ.get('CORTEX_SHOW_USAGE', 'false') == 'true'
try:
    d = json.load(sys.stdin)
except json.JSONDecodeError:
    print(sys.stdin.read(), file=sys.stderr)
    sys.exit(1)
r = d.get('response', d)
# error check
if 'error' in d:
    print(f\"âŒ API Error: {json.dumps(d['error'], indent=2)}\", file=sys.stderr)
    sys.exit(1)
# text output
for c in r.get('candidates', []):
    for p in c.get('content', {}).get('parts', []):
        if 'text' in p:
            print(p['text'])
# usage
if show_usage:
    u = r.get('usageMetadata', {})
    if u:
        print(f'---')
        print(f\"ğŸ“Š tokens: {u.get('promptTokenCount','?')} in â†’ {u.get('candidatesTokenCount','?')} out = {u.get('totalTokenCount','?')} total\")
        print(f\"ğŸ“ model: {r.get('modelVersion','?')}\")
" 2>/dev/null || echo "$response"
    fi
}

# â”€â”€â”€ Parse Arguments â”€â”€â”€
while [[ $# -gt 0 ]]; do
    case "$1" in
        -m|--model)     MODEL="$2"; shift 2 ;;
        -s|--system)    SYSTEM_INSTRUCTION="$2"; shift 2 ;;
        -t|--temp)      TEMPERATURE="$2"; shift 2 ;;
        -n|--max-tokens) MAX_TOKENS="$2"; shift 2 ;;
        --stream)       STREAM=true; shift ;;
        --think)        THINK_BUDGET="$2"; shift 2 ;;
        --raw)          RAW_REQUEST="$2"; shift 2 ;;
        --info)         SHOW_INFO=true; shift ;;
        --quota)        SHOW_QUOTA=true; shift ;;
        --usage)        SHOW_USAGE=true; shift ;;
        --verbose|-v)   VERBOSE=true; shift ;;
        -h|--help)      usage ;;
        --)             shift; break ;;
        -*)             die "Unknown option: $1" ;;
        *)              break ;;
    esac
done

PROMPT="${*:-}"

# â”€â”€â”€ Main â”€â”€â”€

# Token å–å¾—
TOKEN=$(get_token)

# --info ãƒ¢ãƒ¼ãƒ‰
if $SHOW_INFO; then
    echo "ğŸ“¡ loadCodeAssist..."
    curl -s -X POST \
        -H "Authorization: Bearer $TOKEN" \
        -H "Content-Type: application/json" \
        "$BASE_URL:loadCodeAssist" \
        -d '{"metadata":{"ideType":"IDE_UNSPECIFIED","platform":"PLATFORM_UNSPECIFIED","pluginType":"GEMINI"}}' \
        | python3 -m json.tool
    exit 0
fi

# --quota ãƒ¢ãƒ¼ãƒ‰
if $SHOW_QUOTA; then
    PROJ=$(get_project "$TOKEN")
    echo "ğŸ“¡ retrieveUserQuota (project: $PROJ)..."
    curl -s -X POST \
        -H "Authorization: Bearer $TOKEN" \
        -H "Content-Type: application/json" \
        "$BASE_URL:retrieveUserQuota" \
        -d "{\"project\":\"$PROJ\"}" \
        | python3 -m json.tool
    exit 0
fi

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¿…é ˆãƒã‚§ãƒƒã‚¯
[[ -z "$PROMPT" && -z "$RAW_REQUEST" ]] && die "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚ä¾‹: cortex.sh \"Hello\""

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå–å¾—
PROJ=$(get_project "$TOKEN")
$VERBOSE && echo "ğŸ—ï¸  project: $PROJ" >&2
$VERBOSE && echo "ğŸ¤– model: $MODEL" >&2

# ç”Ÿæˆ
generate "$TOKEN" "$PROJ" "$PROMPT"
