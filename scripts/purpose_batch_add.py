#!/usr/bin/env python3
# PROOF: [L2/ãƒ„ãƒ¼ãƒ«] <- scripts/
# PURPOSE: docstringã¨é–¢æ•°åã‹ã‚‰ PURPOSE ã‚³ãƒ¡ãƒ³ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã€ä¸è¶³ã—ã¦ã„ã‚‹é–¢æ•°ã«ä¸€æ‹¬è¿½åŠ ã™ã‚‹
"""
PURPOSE Batch Adder â€” Docstring/åå‰ã‹ã‚‰ PURPOSE ã‚’æ¨è«–ã—ã¦è‡ªå‹•è¿½åŠ 

Strategy:
1. docstring ã®ç¬¬1æ–‡ â†’ PURPOSE å€™è£œã‚’ç”Ÿæˆ
2. docstring ãŒãªã‘ã‚Œã°é–¢æ•°åã‹ã‚‰æ¨è«–
3. æ—¢ã« PURPOSE ãŒã‚ã‚‹è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—

Usage:
    python scripts/purpose_batch_add.py mekhane/           # dry-run
    python scripts/purpose_batch_add.py mekhane/ --write   # å®Ÿéš›ã«æ›¸ãè¾¼ã¿
    python scripts/purpose_batch_add.py mekhane/ --write --dir anamnesis  # 1ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿
"""

import argparse
import ast
import re
import sys
from pathlib import Path

# Skip patterns
SKIP_DIRS = {"__pycache__", ".pytest_cache", ".venv", "node_modules", "models"}
SKIP_FILES = {"__init__.py"}

# PURPOSE pattern
PURPOSE_RE = re.compile(r"#\s*PURPOSE\s*:", re.IGNORECASE)


def _infer_purpose_from_docstring(docstring: str) -> str | None:
    """docstring ã®ç¬¬1æ–‡ã‹ã‚‰ PURPOSE ã‚’ç”Ÿæˆã™ã‚‹."""
    if not docstring:
        return None

    # æœ€åˆã®æ„å‘³ã®ã‚ã‚‹è¡Œã‚’å–å¾—
    lines = [l.strip() for l in docstring.strip().splitlines() if l.strip()]
    if not lines:
        return None

    first_line = lines[0]

    # çŸ­ã™ãã‚‹ or é•·ã™ãã‚‹
    if len(first_line) < 5 or len(first_line) > 120:
        if len(first_line) > 120:
            first_line = first_line[:117] + "..."
        elif len(first_line) < 5:
            return None

    # æœ«å°¾ã®ãƒ”ãƒªã‚ªãƒ‰ã‚’é™¤å»
    first_line = first_line.rstrip(".")

    return first_line


def _infer_purpose_from_name(name: str, is_class: bool = False) -> str:
    """é–¢æ•°å/ã‚¯ãƒ©ã‚¹åã‹ã‚‰ PURPOSE ã‚’æ¨è«–ã™ã‚‹."""
    # CamelCase â†’ words
    if is_class:
        words = re.findall(r"[A-Z][a-z]*|[a-z]+", name)
        return " ".join(words).capitalize() + " ã®å®Ÿè£…"

    # snake_case â†’ words
    words = name.split("_")
    words = [w for w in words if w]

    # Common verb patterns
    verb_map = {
        "get": "ã‚’å–å¾—ã™ã‚‹",
        "set": "ã‚’è¨­å®šã™ã‚‹",
        "add": "ã‚’è¿½åŠ ã™ã‚‹",
        "create": "ã‚’ç”Ÿæˆã™ã‚‹",
        "build": "ã‚’æ§‹ç¯‰ã™ã‚‹",
        "make": "ã‚’ä½œæˆã™ã‚‹",
        "check": "ã‚’æ¤œè¨¼ã™ã‚‹",
        "validate": "ã‚’æ¤œè¨¼ã™ã‚‹",
        "parse": "ã‚’è§£æã™ã‚‹",
        "load": "ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹",
        "save": "ã‚’ä¿å­˜ã™ã‚‹",
        "run": "ã‚’å®Ÿè¡Œã™ã‚‹",
        "process": "ã‚’å‡¦ç†ã™ã‚‹",
        "update": "ã‚’æ›´æ–°ã™ã‚‹",
        "delete": "ã‚’å‰Šé™¤ã™ã‚‹",
        "remove": "ã‚’é™¤å»ã™ã‚‹",
        "find": "ã‚’æ¤œç´¢ã™ã‚‹",
        "search": "ã‚’æ¤œç´¢ã™ã‚‹",
        "format": "ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹",
        "convert": "ã‚’å¤‰æ›ã™ã‚‹",
        "extract": "ã‚’æŠ½å‡ºã™ã‚‹",
        "collect": "ã‚’åé›†ã™ã‚‹",
        "init": "ã‚’åˆæœŸåŒ–ã™ã‚‹",
        "setup": "ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹",
        "cleanup": "ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹",
        "close": "ã‚’é–‰ã˜ã‚‹",
        "open": "ã‚’é–‹ã",
        "read": "ã‚’èª­ã¿å–ã‚‹",
        "write": "ã‚’æ›¸ãè¾¼ã‚€",
        "send": "ã‚’é€ä¿¡ã™ã‚‹",
        "receive": "ã‚’å—ä¿¡ã™ã‚‹",
        "start": "ã‚’é–‹å§‹ã™ã‚‹",
        "stop": "ã‚’åœæ­¢ã™ã‚‹",
        "reset": "ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹",
        "clear": "ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹",
        "flush": "ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã™ã‚‹",
        "emit": "ã‚’ç™ºè¡Œã™ã‚‹",
        "dispatch": "ã‚’ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã™ã‚‹",
        "register": "ã‚’ç™»éŒ²ã™ã‚‹",
        "handle": "ã‚’å‡¦ç†ã™ã‚‹",
        "render": "ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã™ã‚‹",
        "compute": "ã‚’è¨ˆç®—ã™ã‚‹",
        "calculate": "ã‚’è¨ˆç®—ã™ã‚‹",
        "estimate": "ã‚’æ¨å®šã™ã‚‹",
        "diagnose": "ã‚’è¨ºæ–­ã™ã‚‹",
        "recommend": "ã‚’æ¨è–¦ã™ã‚‹",
        "suggest": "ã‚’ææ¡ˆã™ã‚‹",
        "classify": "ã‚’åˆ†é¡ã™ã‚‹",
        "embed": "ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹",
        "index": "ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã™ã‚‹",
        "ingest": "ã‚’å–ã‚Šè¾¼ã‚€",
        "export": "ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹",
        "import": "ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹",
        "merge": "ã‚’ãƒãƒ¼ã‚¸ã™ã‚‹",
        "split": "ã‚’åˆ†å‰²ã™ã‚‹",
        "sort": "ã‚’ã‚½ãƒ¼ãƒˆã™ã‚‹",
        "filter": "ã‚’ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹",
        "map": "ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹",
        "reduce": "ã‚’é›†ç´„ã™ã‚‹",
        "transform": "ã‚’å¤‰æ›ã™ã‚‹",
        "normalize": "ã‚’æ­£è¦åŒ–ã™ã‚‹",
        "test": "ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹",
        "verify": "ã‚’æ¤œè¨¼ã™ã‚‹",
        "assert": "ã‚’è¡¨æ˜ã™ã‚‹",
        "log": "ã‚’è¨˜éŒ²ã™ã‚‹",
        "print": "ã‚’å‡ºåŠ›ã™ã‚‹",
        "display": "ã‚’è¡¨ç¤ºã™ã‚‹",
        "show": "ã‚’è¡¨ç¤ºã™ã‚‹",
    }

    if words and words[0].lower() in verb_map:
        verb = words[0].lower()
        obj = "_".join(words[1:]) if len(words) > 1 else name
        return f"{obj} {verb_map[verb]}"

    return f"{name} ã®å‡¦ç†"


def process_file(filepath: Path, write: bool = False) -> tuple[int, int]:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ PURPOSE ã‚’è¿½åŠ ã™ã‚‹.

    Returns:
        (added_count, skipped_count)
    """
    try:
        source = filepath.read_text(encoding="utf-8")
    except Exception:
        return 0, 0

    try:
        tree = ast.parse(source)
    except SyntaxError:
        return 0, 0

    lines = source.splitlines(keepends=True)
    insertions: list[tuple[int, str]] = []  # (line_number_0based, purpose_text)

    for node in ast.walk(tree):
        if not isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
            continue

        name = node.name

        # Skip private/dunder
        if name.startswith("_"):
            continue

        # Check if PURPOSE already exists in the lines above the function
        has_purpose = False
        start_line = node.lineno - 1  # 0-based

        # Search upward from the function definition (up to 5 lines)
        search_start = max(0, start_line - 5)
        for check_line in range(search_start, start_line + 1):
            if check_line < len(lines) and PURPOSE_RE.search(lines[check_line]):
                has_purpose = True
                break

        if has_purpose:
            continue

        # Get docstring
        docstring = ast.get_docstring(node) or ""

        # Infer PURPOSE
        is_class = isinstance(node, ast.ClassDef)
        purpose = _infer_purpose_from_docstring(docstring)
        if not purpose:
            purpose = _infer_purpose_from_name(name, is_class=is_class)

        # Find insertion point (just before the def/class line)
        # Account for decorators
        if node.decorator_list:
            insert_line = node.decorator_list[0].lineno - 1  # before first decorator
        else:
            insert_line = start_line

        insertions.append((insert_line, purpose))

    if not insertions:
        return 0, 0

    if not write:
        for line_num, purpose_text in insertions:
            rel = filepath.relative_to(filepath.parent.parent) if filepath.parent.parent.exists() else filepath.name
            print(f"  ğŸ“‹ {rel}:{line_num + 1} â†’ # PURPOSE: {purpose_text}")
        return len(insertions), 0

    # Apply insertions (reverse order to maintain line numbers)
    insertions.sort(key=lambda x: x[0], reverse=True)
    for line_num, purpose_text in insertions:
        # Get indentation from the target line
        target_line = lines[line_num] if line_num < len(lines) else ""
        indent = len(target_line) - len(target_line.lstrip())
        indent_str = " " * indent

        purpose_line = f"{indent_str}# PURPOSE: {purpose_text}\n"
        lines.insert(line_num, purpose_line)

    filepath.write_text("".join(lines), encoding="utf-8")
    return len(insertions), 0


def main():
    parser = argparse.ArgumentParser(description="PURPOSE Batch Adder")
    parser.add_argument("root", help="Root directory to scan")
    parser.add_argument("--write", action="store_true", help="Actually write files")
    parser.add_argument("--dir", type=str, help="Only process this subdirectory")
    args = parser.parse_args()

    root = Path(args.root).resolve()
    if not root.is_dir():
        print(f"âŒ Not a directory: {root}")
        sys.exit(1)

    total_added = 0
    total_files = 0

    for filepath in sorted(root.rglob("*.py")):
        # Skip patterns
        if any(part in SKIP_DIRS for part in filepath.parts):
            continue
        if filepath.name in SKIP_FILES:
            continue
        if args.dir and args.dir not in str(filepath):
            continue

        added, _ = process_file(filepath, write=args.write)
        if added > 0:
            total_files += 1
            total_added += added

    action = "Added" if args.write else "Would add"
    print(f"\n{action}: {total_added} PURPOSE annotations across {total_files} files")


if __name__ == "__main__":
    main()
