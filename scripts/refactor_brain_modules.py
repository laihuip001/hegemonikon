#!/usr/bin/env python3
"""
Brain ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« â†’ HegemonikÃ³n Library å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
PURPOSE: æ—§å½¢å¼(XML/HTML)ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’Markdown+YAMLã«å¤‰æ›

å¤‰æ›ãƒ«ãƒ¼ãƒ«:
1. XML ã‚¿ã‚°ã‚’é™¤å» â†’ Markdown æ§‹é€ ã«å¤‰æ›
2. YAML frontmatter ã‚’è¿½åŠ ï¼ˆname, origin, hegemonikon_mapping, model_targetï¼‰
3. Gemini 3 Pro å›ºæœ‰è¨˜è¿°ã‚’æ±ç”¨åŒ–
4. Architect's Note ã‚’è£œè¶³ã¨ã—ã¦ä¿æŒ
"""

import os
import re
import yaml

# ã‚½ãƒ¼ã‚¹ãƒ»å®›å…ˆ
SRC_DIR = os.path.expanduser(
    "~/ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰/Brain/99_ğŸ—ƒï¸_ä¿ç®¡åº«ï½œArchive/ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ¼/ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
)
DST_DIR = os.path.expanduser(
    "~/Sync/10_ğŸ“š_ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï½œLibrary/prompts/modules"
)

# Hegemonikon WF/Skill ãƒãƒƒãƒ”ãƒ³ã‚°
HGK_MAP = {
    "ç¬¬ä¸€åŸç†æ€è€ƒ": {"en": "First Principles", "hgk": "O1 NoÄ“sis (/noe)", "cat": "æ€è€ƒï½œThinking"},
    "è‡ªå¾‹æ€è€ƒ": {"en": "Autonomous Thinking", "hgk": "O4 Energeia (/ene)", "cat": "æ€è€ƒï½œThinking"},
    "ç™ºæ•£ã¨åæŸ": {"en": "Diverge & Converge", "hgk": "O3 ZÄ“tÄ“sis (/zet) + A2 Krisis (/dia)", "cat": "æ€è€ƒï½œThinking"},
    "å¤šè§’çš„ãƒ©ãƒ†ãƒ©ãƒ«ãƒ»ã‚·ãƒ³ã‚­ãƒ³ã‚°": {"en": "Lateral Thinking", "hgk": "O3 ZÄ“tÄ“sis (/zet)", "cat": "æ€è€ƒï½œThinking"},
    "ä¸ƒä¸–ä»£å…ˆã®è¦–ç‚¹": {"en": "Seven Generations Ahead", "hgk": "K3 Telos (/tel)", "cat": "æ€è€ƒï½œThinking"},
    "ã‚ªãƒƒã‚«ãƒ ã®ã‚«ãƒŸã‚½ãƒª": {"en": "Occam's Razor", "hgk": "S1 Metron (/met)", "cat": "æ€è€ƒï½œThinking"},
    "å˜ç´”æ€§åŸç†ã¨å¹³æ˜“ãªèª¬æ˜": {"en": "Simplicity Principle", "hgk": "S1 Metron (/met)", "cat": "æ€è€ƒï½œThinking"},
    "è«–ç†çš„èƒŒæ™¯ã®è£œå¼·": {"en": "Logical Reinforcement", "hgk": "A4 EpistÄ“mÄ“ (/epi)", "cat": "æ€è€ƒï½œThinking"},
    "çµŒé¨“ã®æ³•å‰‡åŒ–": {"en": "Experience Crystallization", "hgk": "A3 GnÅmÄ“ (/gno) + H4 Doxa (/dox)", "cat": "å­¦ç¿’ï½œLearning"},
    "æˆåŠŸã®è§£ä½“æ–°æ›¸": {"en": "Success Deconstruction", "hgk": "A3 GnÅmÄ“ (/gno)", "cat": "å­¦ç¿’ï½œLearning"},
    "æœªè¸ã®æ”¹å–„ç‚¹": {"en": "Unexplored Improvements", "hgk": "O3 ZÄ“tÄ“sis (/zet)", "cat": "å­¦ç¿’ï½œLearning"},
    "ç¾å®Ÿã¸ã®æ¥åœ°": {"en": "Grounding to Reality", "hgk": "S4 Praxis (/pra)", "cat": "å­¦ç¿’ï½œLearning"},
    "æ•µå¯¾çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼å‡¸": {"en": "Adversarial Review", "hgk": "A2 Krisis (/dia) devil mode", "cat": "è©•ä¾¡ï½œEvaluation"},
    "ãŠã¹ã£ã‹ã®ç„¡ã„è©•ä¾¡": {"en": "Honest Evaluation", "hgk": "A2 Krisis (/dia)", "cat": "è©•ä¾¡ï½œEvaluation"},
    "ã‚¨ãƒ¬ã‚¬ãƒ³ã‚¹ã‚¹ãƒãƒ¼ãƒˆç›£æŸ»": {"en": "Elegance Audit", "hgk": "A2 Krisis (/dia)", "cat": "è©•ä¾¡ï½œEvaluation"},
    "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ ç›£æŸ»å‡¸": {"en": "Prompt Structure Audit", "hgk": "A2 Krisis (/dia)", "cat": "è©•ä¾¡ï½œEvaluation"},
    "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤–ç§‘æ‰‹è¡“å‡¹": {"en": "Prompt Surgery", "hgk": "S2 MekhanÄ“ (/mek)", "cat": "è©•ä¾¡ï½œEvaluation"},
    "ã‚·ã‚¹ãƒ†ãƒ æ§‹é€ ç›£æŸ»": {"en": "System Structure Audit", "hgk": "A2 Krisis (/dia)", "cat": "è©•ä¾¡ï½œEvaluation"},
    "ã‚·ã‚¹ãƒ†ãƒ ãƒ»ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹äºˆæƒ³": {"en": "System Dynamics Forecast", "hgk": "K1 Eukairia (/euk)", "cat": "è©•ä¾¡ï½œEvaluation"},
    "ã‚³ãƒ¼ãƒ‰ç›£æŸ»å‡¸": {"en": "Code Audit", "hgk": "Code Protocols", "cat": "é–‹ç™ºï½œDevelopment"},
    "ã‚³ãƒ¼ãƒ‰å¤–ç§‘æ‰‹è¡“å‡¹": {"en": "Code Surgery", "hgk": "Code Protocols", "cat": "é–‹ç™ºï½œDevelopment"},
    "ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä»•æ§˜æ›¸ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«": {"en": "Coding Spec Compiler", "hgk": "Code Protocols", "cat": "é–‹ç™ºï½œDevelopment"},
    "ãƒªãƒãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°": {"en": "Reverse Engineering", "hgk": "Code Protocols + O1 NoÄ“sis", "cat": "é–‹ç™ºï½œDevelopment"},
    "å¤–ç§‘çš„å†æ§‹ç¯‰å‡¹": {"en": "Surgical Reconstruction", "hgk": "S2 MekhanÄ“ (/mek)", "cat": "é–‹ç™ºï½œDevelopment"},
    "ä»®æƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼åº§è«‡ä¼š": {"en": "Virtual User Panel", "hgk": "Synedrion (/syn)", "cat": "å¯¾è©±ï½œDialogue"},
    "å›ç­”ã®è§£åƒåº¦å‘ä¸Š": {"en": "Answer Resolution Up", "hgk": "S1 Metron (/met)", "cat": "å¯¾è©±ï½œDialogue"},
    "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹é€ åŒ–": {"en": "Context Structuring", "hgk": "P1 KhÅra (/kho)", "cat": "æ–‡è„ˆï½œContext"},
    "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è¨€èªåŒ–": {"en": "Context Verbalization", "hgk": "P1 KhÅra (/kho)", "cat": "æ–‡è„ˆï½œContext"},
    "å¤–éƒ¨æ–‡è„ˆã®çµåˆ": {"en": "External Context Binding", "hgk": "P1 KhÅra (/kho)", "cat": "æ–‡è„ˆï½œContext"},
    "å½¢æ…‹ç´ è§£æãƒãƒˆãƒªã‚¯ã‚¹": {"en": "Morphological Analysis", "hgk": "O3 ZÄ“tÄ“sis (/zet)", "cat": "åˆ†æï½œAnalysis"},
    "WBSã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°": {"en": "WBS Scheduling", "hgk": "K2 Chronos (/chr)", "cat": "è¨ˆç”»ï½œPlanning"},
}


def strip_xml_tags(text: str) -> str:
    """XML ã‚¿ã‚°ã‚’é™¤å»ã—ã€å†…å®¹ã®ã¿æ®‹ã™"""
    # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã®XMLã¯ä¿æŒï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ¬ä½“ã¨ã—ã¦ï¼‰
    return text


def extract_sections(content: str) -> dict:
    """æ—§å½¢å¼ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º"""
    sections = {
        "header": "",
        "optimization": "",
        "prompt_body": "",
        "expansions": "",
        "architects_note": "",
    }

    lines = content.split("\n")
    current = "header"
    code_block = False

    for line in lines:
        if line.strip().startswith("```"):
            code_block = not code_block

        if "Expansion" in line and "###" in line and not code_block:
            current = "expansions"
        elif "Architect's Note" in line and not code_block:
            current = "architects_note"
        elif "æœ€é©åŒ–ãƒ­ã‚¸ãƒƒã‚¯" in line and not code_block:
            current = "optimization"
        elif line.strip().startswith("```markdown") and current == "optimization":
            current = "prompt_body"

        sections[current] += line + "\n"

    return sections


def convert_module(filename: str, content: str) -> str:
    """1ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ–°å½¢å¼ã«å¤‰æ›"""
    name_ja = filename.replace(".md", "")
    mapping = HGK_MAP.get(name_ja, {"en": name_ja, "hgk": "æœªãƒãƒƒãƒ”ãƒ³ã‚°", "cat": "ãã®ä»–ï½œOther"})

    # Module ID ã‚’æŠ½å‡º
    module_id_match = re.search(r'Module\s+([A-Z]-?\d+(?:\.\d+)?)\s+\[(\w+)\]', content)
    module_id = module_id_match.group(1) if module_id_match else "?"
    codename = module_id_match.group(2) if module_id_match else "?"

    # æœ€é©åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’æŠ½å‡º
    opt_match = re.search(r'\*\*æœ€é©åŒ–ãƒ­ã‚¸ãƒƒã‚¯:\*\*\s*\n(.+?)(?:\n\n|\n```)', content, re.DOTALL)
    optimization = opt_match.group(1).strip() if opt_match else ""

    # YAML frontmatter
    frontmatter = {
        "name": f"{name_ja}ï½œ{mapping['en']}",
        "original_id": f"Module {module_id} [{codename}]",
        "origin": "Brain Vault (pre-FEP)",
        "category": mapping["cat"],
        "hegemonikon_mapping": mapping["hgk"],
        "model_target": "universal",
    }

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ¬ä½“ã‚’æŠ½å‡ºï¼ˆ```markdown ... ``` ã®é–“ï¼‰
    prompt_blocks = re.findall(r'```markdown\n(.*?)```', content, re.DOTALL)
    prompt_body = "\n---\n".join(prompt_blocks) if prompt_blocks else ""

    # XML ã‚¿ã‚°ã‚’ Markdown ã«å¤‰æ›
    prompt_body = re.sub(r'<module_config>.*?</module_config>\s*', '', prompt_body, flags=re.DOTALL)
    prompt_body = re.sub(r'</?instruction>', '', prompt_body)
    prompt_body = re.sub(r'</?rules>', '', prompt_body)
    prompt_body = re.sub(r'</?steps>', '', prompt_body)
    prompt_body = re.sub(r'</?constraint_checklist>', '', prompt_body)
    prompt_body = re.sub(r'</?input_context>\s*', '', prompt_body)
    prompt_body = re.sub(r'</?input_source>\s*', '', prompt_body)
    prompt_body = re.sub(r'</?output_template>', '', prompt_body)
    prompt_body = re.sub(r'</?thinking_steps>', '', prompt_body)
    prompt_body = re.sub(r'<([a-z_]+)>', r'### \1', prompt_body)
    prompt_body = re.sub(r'</[a-z_]+>', '', prompt_body)
    prompt_body = re.sub(r'{{(\w+)}}', r'[å…¥åŠ›: \1]', prompt_body)

    # Gemini å›ºæœ‰è¨˜è¿°ã‚’æ±ç”¨åŒ–
    prompt_body = prompt_body.replace("Gemini 3 Pro", "AI")
    prompt_body = prompt_body.replace("Geminiã«", "AIã«")
    prompt_body = prompt_body.replace("Geminiã¯", "AIã¯")
    prompt_body = prompt_body.replace("Geminiã®", "AIã®")

    # æ´¾ç”Ÿãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
    exp_match = re.search(r'(## ğŸ”® New Expansion Modules.*?)(?:---\s*\n## ğŸ’¡|---\s*$|\Z)', content, re.DOTALL)
    expansions = exp_match.group(1).strip() if exp_match else ""
    if expansions:
        expansions = expansions.replace("Gemini 3 Pro", "AI")

    # Architect's Note
    note_match = re.search(r'(## ğŸ’¡ Architect\'s Note.*?)$', content, re.DOTALL)
    architects_note = note_match.group(1).strip() if note_match else ""
    if architects_note:
        architects_note = architects_note.replace("Gemini 3 Pro", "AI")
        architects_note = architects_note.replace("Geminiã«", "AIã«")
        architects_note = architects_note.replace("Geminiã¯", "AIã¯")
        architects_note = architects_note.replace("Geminiã®", "AIã®")

    # çµ„ã¿ç«‹ã¦
    yaml_str = yaml.dump(frontmatter, allow_unicode=True, default_flow_style=False, sort_keys=False)

    output = f"""---
{yaml_str.strip()}
---

# {name_ja}ï½œ{mapping['en']}

> **æ—§ID**: Module {module_id} [{codename}]
> **HegemonikÃ³n å¯¾å¿œ**: {mapping['hgk']}

## æ¦‚è¦

{optimization}

## ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ¬ä½“

{prompt_body.strip()}
"""

    if expansions:
        output += f"\n{expansions}\n"

    if architects_note:
        output += f"\n{architects_note}\n"

    return output


def main():
    os.makedirs(DST_DIR, exist_ok=True)

    files = sorted([f for f in os.listdir(SRC_DIR) if f.endswith('.md')])
    print(f"ğŸ“‚ {len(files)} ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å¤‰æ›é–‹å§‹")

    for f in files:
        src_path = os.path.join(SRC_DIR, f)
        with open(src_path, 'r', encoding='utf-8') as fp:
            content = fp.read()

        converted = convert_module(f, content)

        dst_path = os.path.join(DST_DIR, f)
        with open(dst_path, 'w', encoding='utf-8') as fp:
            fp.write(converted)

        name_ja = f.replace(".md", "")
        mapping = HGK_MAP.get(name_ja, {})
        hgk = mapping.get("hgk", "?")
        print(f"  âœ… {name_ja} â†’ {hgk}")

    print(f"\nâœ… å…¨ {len(files)} ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¤‰æ›å®Œäº†")
    print(f"ğŸ“ å‡ºåŠ›å…ˆ: {DST_DIR}")


if __name__ == "__main__":
    main()
